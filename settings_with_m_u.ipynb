{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _m_ and _u_ probabilities\n",
    "### TO DO:\n",
    "1. Load settings from saved params\n",
    "2. Function to add m and u probs to existing settings from saved params (e.g. `settings_with_m_u(settings, params)` with `params` from saved params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import StructType\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "conf=SparkConf()\n",
    "\n",
    "# Load in a jar that provides extended string comparison functions such as Jaro Winkler.\n",
    "# Splink \n",
    "conf.set('spark.driver.extraClassPath', 'jars/scala-udf-similarity-0.0.6.jar')\n",
    "conf.set('spark.jars', 'jars/scala-udf-similarity-0.0.6.jar')   \n",
    "\n",
    "\n",
    "# WARNING:\n",
    "# These config options are appropriate only if you're running Spark locally!!!\n",
    "conf.set('spark.driver.memory', '4g')\n",
    "conf.set(\"spark.sql.shuffle.partitions\", \"8\") \n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession(sc)\n",
    "\n",
    " # Register UDFs\n",
    "from pyspark.sql import types\n",
    "spark.udf.registerJavaFunction('jaro_winkler_sim', 'uk.gov.moj.dash.linkage.JaroWinklerSimilarity', types.DoubleType())\n",
    "spark.udf.registerJavaFunction('Dmetaphone', 'uk.gov.moj.dash.linkage.DoubleMetaphone', types.StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredients:\n",
    "- input settings\n",
    "- complete settings (with missing fields populated by defaults - incl. m and u probs)\n",
    "- saved params (including param history, and complete input settings dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules\": [\n",
    "        \"l.first_name = r.first_name\",\n",
    "        \"l.surname = r.surname\",\n",
    "        \"l.dob = r.dob\"\n",
    "    ],\n",
    "    \"comparison_columns\": [\n",
    "        {\n",
    "            \"col_name\": \"first_name\",\n",
    "            \"num_levels\": 3,\n",
    "            \"term_frequency_adjustments\": True\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"surname\",\n",
    "            \"num_levels\": 3,\n",
    "            \"term_frequency_adjustments\": True\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"dob\"\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"city\"\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"email\"\n",
    "        }\n",
    "    ],\n",
    "    \"additional_columns_to_retain\": [\"group\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative `input_settings` (for testing)\n",
    "Includes:\n",
    "- NEW comparison column NOT in the saved params (`full_name`)\n",
    "- MISSING column that IS in the saved params (`city`)\n",
    "- \"custom column\" example (`full_name`)\n",
    "- different number of levels from saved params (`email`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_settings2 = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules\": [\n",
    "        \"l.first_name = r.first_name\",\n",
    "        \"l.surname = r.surname\",\n",
    "        \"l.dob = r.dob\"\n",
    "    ],\n",
    "    \"comparison_columns\": [\n",
    "        {\n",
    "            \"col_name\": \"first_name\",\n",
    "            \"num_levels\": 3,\n",
    "            \"term_frequency_adjustments\": True\n",
    "        },\n",
    "        {\n",
    "            \"custom_name\": \"full_name\",\n",
    "            \"custom_columns_used\": [\"first_name\", \"surname\"],\n",
    "            \"num_levels\": 2,\n",
    "            \"case_expression\": \"\"\"\n",
    "                case when concat(first_name_l, surname_l) = concat(first_name_r, surname_r) then 1\n",
    "                else 0 end\n",
    "            \"\"\",\n",
    "            \"term_frequency_adjustments\": True\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"dob\"\n",
    "        },\n",
    "        {\n",
    "            \"col_name\": \"email\",\n",
    "            \"num_levels\": 3\n",
    "        }\n",
    "    ],\n",
    "    \"additional_columns_to_retain\": [\"group\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.settings import complete_settings_dict\n",
    "from splink import Params, load_params_from_json\n",
    "\n",
    "complete_settings = complete_settings_dict(input_settings, spark)\n",
    "generated_params = Params(input_settings, spark)\n",
    "saved_params = load_params_from_json(\"saved_params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \"_I'm setting up a new job and I want to use the results of another job as default where applicable_\"\n",
    "### Update input settings with saved `m` and `u` probabilities\n",
    "\n",
    "Potential gotchas:\n",
    "- Column names don't match\n",
    "- Number of levels missing/don't match\n",
    "- Custom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.validate import _get_default_value\n",
    "\n",
    "def add_saved_m_and_u(settings, spark, json_path):\n",
    "    \n",
    "    #settings = complete_settings_dict(settings, spark)\n",
    "    saved_params = load_params_from_json(json_path)\n",
    "    \n",
    "    for comp in settings[\"comparison_columns\"]:\n",
    "        if \"col_name\" in comp.keys():\n",
    "            label = \"gamma_\"+comp[\"col_name\"]\n",
    "        else:\n",
    "            label = \"gamma_\"+comp[\"custom_name\"]\n",
    "            \n",
    "        if \"num_levels\" in comp.keys():\n",
    "            num_levels = comp[\"num_levels\"]\n",
    "        else:\n",
    "            num_levels = _get_default_value(\"num_levels\", is_column_setting=True)\n",
    "        \n",
    "        \n",
    "        if label in saved_params.params[\"π\"].keys():\n",
    "            saved = saved_params.params[\"π\"][label]\n",
    "    \n",
    "            if num_levels == saved[\"num_levels\"]:\n",
    "                m_probs = [val['probability'] for key, val in saved[\"prob_dist_match\"].items()]\n",
    "                u_probs = [val['probability'] for key, val in saved[\"prob_dist_non_match\"].items()]\n",
    "    \n",
    "                comp[\"m_probabilities\"] = m_probs\n",
    "                comp[\"u_probabilities\"] = u_probs\n",
    "            else:\n",
    "                print(f\"{label}: Saved m and u probabilities do not match the specified number of levels ({num_levels}) - default probabilities will be used\")\n",
    "    \n",
    "    return(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_settings = add_saved_m_and_u(input_settings2, spark, \"saved_params.json\")\n",
    "new_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_settings_dict(new_settings, spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) \"_I'm restarting/re-running a job and want to pick up where the parameters finished_\"\n",
    "### As above but `settings` also comes from \"saved_params.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete input settings (default m and u probs)\n",
    "saved_settings = saved_params.settings\n",
    "\n",
    "add_saved_m_and_u(saved_settings, spark, \"saved_params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
