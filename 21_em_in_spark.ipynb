{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to implement the basic EM approach used by the R fastLink package in Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import StructType\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l = spark.read.csv(\"em_in_spark/input_data/left_table.csv\", header=True)\n",
    "\n",
    "labels = spark.read.csv(\"em_in_spark/input_data/real_matches.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l.registerTempTable(\"df_l\")\n",
    "df_r.registerTempTable(\"df_r\")\n",
    "labels.registerTempTable(\"labels\")\n",
    "\n",
    "sql = \"\"\"\n",
    "select \n",
    "    df_l.row_id_l, \n",
    "    df_l.mob_l, \n",
    "    df_l.surname_l, \n",
    "    df_r.row_id_r, \n",
    "    df_r.mob_r, \n",
    "    df_r.surname_r,\n",
    "    coalesce(labels.label, 0)  as label\n",
    "from df_l\n",
    "cross join df_r\n",
    "left join labels\n",
    "on labels.row_id_l = df_l.row_id_l and \n",
    "labels.row_id_r = df_r.row_id_r\n",
    "\n",
    "\"\"\"\n",
    "df = spark.sql(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"df\")\n",
    "sql = \"\"\"\n",
    "select *, \n",
    "\n",
    "case when\n",
    "mob_l = mob_r then 1 \n",
    "else 0\n",
    "end\n",
    "as gamma_0,\n",
    "\n",
    "case when\n",
    "surname_l = surname_r then 1 \n",
    "when levenshtein(surname_l, surname_r)<4 then 0.5\n",
    "else 0\n",
    "end\n",
    "as gamma_1\n",
    "\n",
    "\n",
    "from df \n",
    "\n",
    "\"\"\"\n",
    "df_with_gamma = spark.sql(sql)\n",
    "df_with_gamma.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"λ\": 0.12,\n",
    "    \"π\": {\n",
    "        \"gamma_0\": {\n",
    "            \"desc\": \"Month of birth match\",\n",
    "            \"type\": \"exact_match_only\",\n",
    "            \"prob_dist_match\": {\n",
    "                \"level_0\": {\n",
    "                    \"value\": 0,\n",
    "                    \"probability\": 0.4\n",
    "                },\n",
    "                \"level_1\": {\n",
    "                    \"value\": 1,\n",
    "                    \"probability\": 0.6\n",
    "                }\n",
    "            },\n",
    "            \"prob_dist_non_match\": {\n",
    "                \"level_0\": {\n",
    "                    \"value\": 0,\n",
    "                    \"probability\": 0.6\n",
    "                },\n",
    "                \"level_1\": {\n",
    "                    \"value\": 1,\n",
    "                    \"probability\": 0.4\n",
    "                }\n",
    "            },\n",
    "\n",
    "        },\n",
    "        \"gamma_1\": {\n",
    "            \"desc\": \"Surname match\",\n",
    "            \"type\": \"include_approximate_match\",\n",
    "            \"prob_dist_match\": {\n",
    "                \"level_0\": {\n",
    "                    \"value\": 0,\n",
    "                    \"probability\": 0.3\n",
    "                },\n",
    "                \"level_1\": {\n",
    "                    \"value\": 0.5,\n",
    "                    \"probability\": 0.4\n",
    "                },\n",
    "                \"level_2\": {\n",
    "                    \"value\": 1,\n",
    "                    \"probability\": 0.4\n",
    "                }\n",
    "            },\n",
    "            \"prob_dist_non_match\": {\n",
    "                \"level_0\": {\n",
    "                    \"value\": 0,\n",
    "                    \"probability\": 0.4\n",
    "                },\n",
    "                \"level_1\": {\n",
    "                    \"value\": 0.5,\n",
    "                    \"probability\": 0.3\n",
    "                },\n",
    "                \"level_2\": {\n",
    "                    \"value\": 1,\n",
    "                    \"probability\": 0.3\n",
    "                }\n",
    "            },\n",
    "\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from em_in_spark.fns import *\n",
    "df_e = run_expectation_step(df_with_gamma, spark, params)\n",
    "new_params = update_params(df_e, spark, params)\n",
    "\n",
    "df_e = run_expectation_step(df_with_gamma, spark, new_params)\n",
    "new_params = update_params(df_e, spark, new_params)\n",
    "\n",
    "df_e = run_expectation_step(df_with_gamma, spark, new_params)\n",
    "new_params = update_params(df_e, spark, new_params)\n",
    "\n",
    "df_e = run_expectation_step(df_with_gamma, spark, new_params)\n",
    "new_params = update_params(df_e, spark, new_params)\n",
    "\n",
    "df_e = run_expectation_step(df_with_gamma, spark, new_params)\n",
    "new_params = update_params(df_e, spark, new_params)\n",
    "\n",
    "df_e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
