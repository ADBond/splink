{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b58c35",
   "metadata": {},
   "source": [
    "## Evaluation of prediction results\n",
    "\n",
    " <a target=\"_blank\" href=\"https://colab.research.google.com/github/moj-analytical-services/splink/blob/splink4_dev/docs/demos/tutorials/07_Quality_assurance.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "In the previous tutorial, we looked at various ways to visualise the results of our model.\n",
    "These are useful for evaluating a linkage pipeline because they allow us to understand how our model works and verify that it is doing something sensible. They can also be useful to identify examples where the model is not performing as expected.\n",
    "\n",
    "In addition to these spot checks, Splink also has functions to perform more formal accuracy analysis. These functions allow you to understand the likely prevalence of false positives and false negatives in your linkage models.\n",
    "\n",
    "They rely on the existence of a sample of labelled (ground truth) matches, which may have been produced (for example) by human beings. For the accuracy analysis to be unbiased, the sample should be representative of the overall dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08e61e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T15:09:26.148311Z",
     "iopub.status.busy": "2024-03-27T15:09:26.147921Z",
     "iopub.status.idle": "2024-03-27T15:09:26.153691Z",
     "shell.execute_reply": "2024-03-27T15:09:26.152925Z"
    }
   },
   "source": [
    "# Uncomment and run this cell if you're running in Google Colab.\n",
    "# !pip install git+https://github.com/moj-analytical-services/splink.git@splink4_dev"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb29d421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T15:09:26.157566Z",
     "iopub.status.busy": "2024-03-27T15:09:26.157276Z",
     "iopub.status.idle": "2024-03-27T15:09:27.756910Z",
     "shell.execute_reply": "2024-03-27T15:09:27.755955Z"
    }
   },
   "source": [
    "# Rerun our predictions to we're ready to view the charts\n",
    "from splink import Linker, DuckDBAPI, splink_datasets\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "db_api = DuckDBAPI()\n",
    "df = splink_datasets.fake_1000"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88cc1c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T15:09:27.761005Z",
     "iopub.status.busy": "2024-03-27T15:09:27.760695Z",
     "iopub.status.idle": "2024-03-27T15:09:28.338768Z",
     "shell.execute_reply": "2024-03-27T15:09:28.338174Z"
    }
   },
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/moj-analytical-services/splink_demos/master/demo_settings/saved_model_from_demo.json\"\n",
    "\n",
    "with urllib.request.urlopen(url) as u:\n",
    "    settings = json.loads(u.read().decode())\n",
    "\n",
    "\n",
    "linker = Linker(df, settings, database_api=DuckDBAPI())\n",
    "df_predictions = linker.predict(threshold_match_probability=0.2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7b0dedd9",
   "metadata": {},
   "source": [
    "## Load in labels\n",
    "\n",
    "The labels file contains a list of pairwise comparisons which represent matches and non-matches.\n",
    "\n",
    "The required format of the labels file is described [here](https://moj-analytical-services.github.io/splink/linkerqa.html#splink.linker.Linker.roc_chart_from_labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfdc70c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T15:09:28.342154Z",
     "iopub.status.busy": "2024-03-27T15:09:28.341906Z",
     "iopub.status.idle": "2024-03-27T15:09:28.360869Z",
     "shell.execute_reply": "2024-03-27T15:09:28.360286Z"
    }
   },
   "source": [
    "from splink.datasets import splink_dataset_labels\n",
    "\n",
    "df_labels = splink_dataset_labels.fake_1000_labels\n",
    "df_labels.head(5)\n",
    "labels_table = linker.register_labels_table(df_labels)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "030c4cde",
   "metadata": {},
   "source": [
    "### Threshold Selection chart\n",
    "\n",
    "Splink includes an interactive dashboard that shows key accuracy statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d9645",
   "metadata": {},
   "source": [
    "linker.accuracy_analysis_from_labels_table(\n",
    "    labels_table, output_type=\"threshold_selection\", add_metrics=[\"f1\"]\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "81e4396d",
   "metadata": {},
   "source": [
    "## Receiver operating characteristic curve\n",
    "\n",
    "A [ROC chart](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) shows how the number of false positives and false negatives varies depending on the match threshold chosen. The match threshold is the match weight chosen as a cutoff for which pairwise comparisons to accept as matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01dd7eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T15:09:28.364336Z",
     "iopub.status.busy": "2024-03-27T15:09:28.364081Z",
     "iopub.status.idle": "2024-03-27T15:09:30.739598Z",
     "shell.execute_reply": "2024-03-27T15:09:30.738784Z"
    }
   },
   "source": [
    "linker.accuracy_analysis_from_labels_table(\n",
    "    labels_table, output_type=\"roc\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9f749c3c",
   "metadata": {},
   "source": [
    "### Precision-recall chart\n",
    "\n",
    "An alternative representation of truth space is called a [precision recall curve](https://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves).\n",
    "\n",
    "This can be plotted as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d25327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T15:09:30.748669Z",
     "iopub.status.busy": "2024-03-27T15:09:30.748369Z",
     "iopub.status.idle": "2024-03-27T15:09:32.783998Z",
     "shell.execute_reply": "2024-03-27T15:09:32.783324Z"
    }
   },
   "source": [
    "linker.accuracy_analysis_from_labels_table(\n",
    "    labels_table, output_type=\"precision_recall\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "12e6ba74",
   "metadata": {},
   "source": [
    "## Truth table\n",
    "\n",
    "Finally, Splink can also report the underlying table used to construct the ROC and precision recall curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c283ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T15:09:32.792153Z",
     "iopub.status.busy": "2024-03-27T15:09:32.791875Z",
     "iopub.status.idle": "2024-03-27T15:09:33.010920Z",
     "shell.execute_reply": "2024-03-27T15:09:33.010123Z"
    }
   },
   "source": [
    "roc_table = linker.accuracy_analysis_from_labels_table(labels_table, output_type=\"table\")\n",
    "roc_table.as_pandas_dataframe(limit=5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ff86458e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2d6d5f4",
   "metadata": {},
   "source": [
    "!!! note \"Further Reading\"\n",
    ":material-tools: For more on the quality assurance tools in Splink, please refer to the [Evaluation API documentation](../../linkereval.md).\n",
    "\n",
    "    :bar_chart: For more on the charts used in this tutorial, please refer to the [Charts Gallery](../../charts/index.md#model-evaluation).\n",
    "\n",
    "    :material-thumbs-up-down: For more on the Evaluation Metrics used in this tutorial, please refer to the [Edge Metrics guide.](../../topic_guides/evaluation/edge_metrics.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee8f2d",
   "metadata": {},
   "source": [
    "## :material-flag-checkered: That's it!\n",
    "\n",
    "That wraps up the Splink tutorial! Don't worry, there are still plenty of resources to help on the next steps of your Splink journey:\n",
    "\n",
    ":octicons-link-16: For some end-to-end notebooks of Splink pipelines, check out our [Examples](../examples/examples_index.md)\n",
    "\n",
    ":simple-readme: For more deepdives into the different aspects of Splink, and record linkage more generally, check out our [Topic Guides](../../topic_guides/topic_guides_index.md)\n",
    "\n",
    ":material-tools: For a reference on all the functionality avalable in Splink, see our [Documentation](../../documentation_index.md)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
