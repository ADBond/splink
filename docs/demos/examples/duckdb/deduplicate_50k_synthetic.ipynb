{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking a dataset of real historical persons\n",
    "\n",
    "In this example, we deduplicate a more realistic dataset. The data is based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors introduced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/moj-analytical-services/splink/blob/splink4_dev/docs/demos/examples/duckdb/deduplicate_50k_synthetic.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:03.040913Z",
     "iopub.status.busy": "2024-05-15T16:07:03.040529Z",
     "iopub.status.idle": "2024-05-15T16:07:03.045834Z",
     "shell.execute_reply": "2024-05-15T16:07:03.045063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're running in Google Colab.\n",
    "# !pip install git+https://github.com/moj-analytical-services/splink.git@splink4_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:03.049635Z",
     "iopub.status.busy": "2024-05-15T16:07:03.049337Z",
     "iopub.status.idle": "2024-05-15T16:07:04.275040Z",
     "shell.execute_reply": "2024-05-15T16:07:04.274317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>full_name</th>\n",
       "      <th>first_and_surname</th>\n",
       "      <th>first_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>birth_place</th>\n",
       "      <th>postcode_fake</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2296770-1</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas clifford, 1st baron clifford of chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>male</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2296770-2</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas of chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>male</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2296770-3</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>tom 1st baron clifford of chudleigh</td>\n",
       "      <td>tom chudleigh</td>\n",
       "      <td>tom</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>male</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2296770-4</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas 1st chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8hu</td>\n",
       "      <td>None</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2296770-5</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas clifford, 1st baron chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>None</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id   cluster                                         full_name  \\\n",
       "0  Q2296770-1  Q2296770  thomas clifford, 1st baron clifford of chudleigh   \n",
       "1  Q2296770-2  Q2296770                               thomas of chudleigh   \n",
       "2  Q2296770-3  Q2296770               tom 1st baron clifford of chudleigh   \n",
       "3  Q2296770-4  Q2296770                              thomas 1st chudleigh   \n",
       "4  Q2296770-5  Q2296770              thomas clifford, 1st baron chudleigh   \n",
       "\n",
       "  first_and_surname first_name    surname         dob birth_place  \\\n",
       "0  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "1  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "2     tom chudleigh        tom  chudleigh  1630-08-01       devon   \n",
       "3  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "4  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "\n",
       "  postcode_fake gender  occupation  \n",
       "0      tq13 8df   male  politician  \n",
       "1      tq13 8df   male  politician  \n",
       "2      tq13 8df   male  politician  \n",
       "3      tq13 8hu   None  politician  \n",
       "4      tq13 8df   None  politician  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import splink_datasets\n",
    "\n",
    "df = splink_datasets.historical_50k\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:04.316719Z",
     "iopub.status.busy": "2024-05-15T16:07:04.315783Z",
     "iopub.status.idle": "2024-05-15T16:07:05.112833Z",
     "shell.execute_reply": "2024-05-15T16:07:05.112087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-f5640dad6c1542f2bb897a0cf9710349.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-f5640dad6c1542f2bb897a0cf9710349.vega-embed details,\n",
       "  #altair-viz-f5640dad6c1542f2bb897a0cf9710349.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-f5640dad6c1542f2bb897a0cf9710349\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f5640dad6c1542f2bb897a0cf9710349\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f5640dad6c1542f2bb897a0cf9710349\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.362713098526001, \"percentile_inc_nulls\": 0.36355727910995483, \"value_count\": 69, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3586743474006653, \"percentile_inc_nulls\": 0.3595238924026489, \"value_count\": 68, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 204.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.35734790563583374, \"percentile_inc_nulls\": 0.35819923877716064, \"value_count\": 67, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 67.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.35606104135513306, \"percentile_inc_nulls\": 0.35691410303115845, \"value_count\": 65, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3547940254211426, \"percentile_inc_nulls\": 0.3556486964225769, \"value_count\": 64, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3522995114326477, \"percentile_inc_nulls\": 0.35315752029418945, \"value_count\": 63, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3510720729827881, \"percentile_inc_nulls\": 0.35193169116973877, \"value_count\": 62, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.34744906425476074, \"percentile_inc_nulls\": 0.34831351041793823, \"value_count\": 61, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 183.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3427768349647522, \"percentile_inc_nulls\": 0.34364742040634155, \"value_count\": 59, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 236.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.33933204412460327, \"percentile_inc_nulls\": 0.34020721912384033, \"value_count\": 58, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 174.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3382035493850708, \"percentile_inc_nulls\": 0.33908021450042725, \"value_count\": 57, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.33709490299224854, \"percentile_inc_nulls\": 0.33797305822372437, \"value_count\": 56, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 56.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.33602583408355713, \"percentile_inc_nulls\": 0.3369053602218628, \"value_count\": 54, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3328779935836792, \"percentile_inc_nulls\": 0.33376169204711914, \"value_count\": 53, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 159.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3287600874900818, \"percentile_inc_nulls\": 0.32964926958084106, \"value_count\": 52, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 208.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.32674068212509155, \"percentile_inc_nulls\": 0.3276325464248657, \"value_count\": 51, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 102.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.32575082778930664, \"percentile_inc_nulls\": 0.32664400339126587, \"value_count\": 50, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3238106369972229, \"percentile_inc_nulls\": 0.32470637559890747, \"value_count\": 49, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 98.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.32095980644226074, \"percentile_inc_nulls\": 0.32185930013656616, \"value_count\": 48, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3200293183326721, \"percentile_inc_nulls\": 0.3209300637245178, \"value_count\": 47, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.31729722023010254, \"percentile_inc_nulls\": 0.31820160150527954, \"value_count\": 46, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 138.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.31373363733291626, \"percentile_inc_nulls\": 0.3146427273750305, \"value_count\": 45, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 180.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.30937814712524414, \"percentile_inc_nulls\": 0.3102930188179016, \"value_count\": 44, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 220.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3076755404472351, \"percentile_inc_nulls\": 0.30859267711639404, \"value_count\": 43, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.30434954166412354, \"percentile_inc_nulls\": 0.30527108907699585, \"value_count\": 42, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 168.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.30353784561157227, \"percentile_inc_nulls\": 0.30446046590805054, \"value_count\": 41, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 41.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2987864017486572, \"percentile_inc_nulls\": 0.2997152805328369, \"value_count\": 40, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 240.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.29569798707962036, \"percentile_inc_nulls\": 0.2966309189796448, \"value_count\": 39, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2934410572052002, \"percentile_inc_nulls\": 0.29437702894210815, \"value_count\": 38, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 114.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2912434935569763, \"percentile_inc_nulls\": 0.29218238592147827, \"value_count\": 37, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2891647219657898, \"percentile_inc_nulls\": 0.2901063561439514, \"value_count\": 35, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 105.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.28579914569854736, \"percentile_inc_nulls\": 0.28674525022506714, \"value_count\": 34, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 170.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.281879186630249, \"percentile_inc_nulls\": 0.28283047676086426, \"value_count\": 33, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 198.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2799786329269409, \"percentile_inc_nulls\": 0.2809324264526367, \"value_count\": 32, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2775236964225769, \"percentile_inc_nulls\": 0.27848076820373535, \"value_count\": 31, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 124.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.27336621284484863, \"percentile_inc_nulls\": 0.2743287682533264, \"value_count\": 30, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 210.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.27049553394317627, \"percentile_inc_nulls\": 0.2714619040489197, \"value_count\": 29, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 145.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.26772385835647583, \"percentile_inc_nulls\": 0.2686939239501953, \"value_count\": 28, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 140.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2639821171760559, \"percentile_inc_nulls\": 0.264957070350647, \"value_count\": 27, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 189.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.26037895679473877, \"percentile_inc_nulls\": 0.26135867834091187, \"value_count\": 26, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 182.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2579042315483093, \"percentile_inc_nulls\": 0.25888729095458984, \"value_count\": 25, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 125.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.25410306453704834, \"percentile_inc_nulls\": 0.25509113073349, \"value_count\": 24, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 192.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.25091564655303955, \"percentile_inc_nulls\": 0.25190794467926025, \"value_count\": 23, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.24612462520599365, \"percentile_inc_nulls\": 0.24712324142456055, \"value_count\": 22, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 242.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2411355972290039, \"percentile_inc_nulls\": 0.24214082956314087, \"value_count\": 21, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 252.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.23638415336608887, \"percentile_inc_nulls\": 0.23739570379257202, \"value_count\": 20, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 240.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.22998952865600586, \"percentile_inc_nulls\": 0.23100954294204712, \"value_count\": 19, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 323.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2228623628616333, \"percentile_inc_nulls\": 0.22389179468154907, \"value_count\": 18, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 360.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2188236117362976, \"percentile_inc_nulls\": 0.21985840797424316, \"value_count\": 17, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 204.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.20995426177978516, \"percentile_inc_nulls\": 0.21100085973739624, \"value_count\": 16, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 448.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.20193618535995483, \"percentile_inc_nulls\": 0.20299339294433594, \"value_count\": 15, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 405.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.194452702999115, \"percentile_inc_nulls\": 0.1955198049545288, \"value_count\": 14, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 378.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.18158423900604248, \"percentile_inc_nulls\": 0.18266832828521729, \"value_count\": 13, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 650.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.17279404401779175, \"percentile_inc_nulls\": 0.17388981580734253, \"value_count\": 12, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 444.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.16538971662521362, \"percentile_inc_nulls\": 0.16649532318115234, \"value_count\": 11, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 374.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.15588682889938354, \"percentile_inc_nulls\": 0.15700501203536987, \"value_count\": 10, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 480.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.14394885301589966, \"percentile_inc_nulls\": 0.14508283138275146, \"value_count\": 9, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 603.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.13143670558929443, \"percentile_inc_nulls\": 0.13258731365203857, \"value_count\": 8, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 632.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.12145870923995972, \"percentile_inc_nulls\": 0.12262248992919922, \"value_count\": 7, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 504.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.11076796054840088, \"percentile_inc_nulls\": 0.11194592714309692, \"value_count\": 6, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 540.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.10017621517181396, \"percentile_inc_nulls\": 0.10136818885803223, \"value_count\": 5, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 535.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.08655542135238647, \"percentile_inc_nulls\": 0.08776545524597168, \"value_count\": 4, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 688.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.0702817440032959, \"percentile_inc_nulls\": 0.07151329517364502, \"value_count\": 3, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 822.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.047276854515075684, \"percentile_inc_nulls\": 0.04853886365890503, \"value_count\": 2, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1162.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0013247132301330566, \"value_count\": 1, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 2388.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.9449625015258789, \"percentile_inc_nulls\": 0.9450353980064392, \"value_count\": 2780, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 2780.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8907960653305054, \"percentile_inc_nulls\": 0.8909407258033752, \"value_count\": 2736, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 2736.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8621290326118469, \"percentile_inc_nulls\": 0.8623116612434387, \"value_count\": 1448, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1448.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8341153264045715, \"percentile_inc_nulls\": 0.8343350887298584, \"value_count\": 1415, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1415.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8082596063613892, \"percentile_inc_nulls\": 0.8085135817527771, \"value_count\": 1306, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1306.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7832155227661133, \"percentile_inc_nulls\": 0.7835026979446411, \"value_count\": 1265, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1265.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7582308650016785, \"percentile_inc_nulls\": 0.7585511207580566, \"value_count\": 1262, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1262.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7341569066047668, \"percentile_inc_nulls\": 0.7345091104507446, \"value_count\": 1216, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1216.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7161211967468262, \"percentile_inc_nulls\": 0.7164973020553589, \"value_count\": 911, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 911.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.698620080947876, \"percentile_inc_nulls\": 0.6990193128585815, \"value_count\": 884, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 884.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6826632022857666, \"percentile_inc_nulls\": 0.6830835342407227, \"value_count\": 806, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 806.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6697155237197876, \"percentile_inc_nulls\": 0.670153021812439, \"value_count\": 654, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 654.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6573221683502197, \"percentile_inc_nulls\": 0.6577761173248291, \"value_count\": 626, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 626.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6471858024597168, \"percentile_inc_nulls\": 0.6476531028747559, \"value_count\": 512, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 512.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6370691657066345, \"percentile_inc_nulls\": 0.6375499367713928, \"value_count\": 511, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 511.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6269921064376831, \"percentile_inc_nulls\": 0.6274862289428711, \"value_count\": 509, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 509.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6171329021453857, \"percentile_inc_nulls\": 0.6176400780677795, \"value_count\": 498, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 498.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6079269647598267, \"percentile_inc_nulls\": 0.6084463596343994, \"value_count\": 465, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 465.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5987408757209778, \"percentile_inc_nulls\": 0.5992723703384399, \"value_count\": 464, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 464.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5904456377029419, \"percentile_inc_nulls\": 0.5909881591796875, \"value_count\": 419, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 419.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5831403136253357, \"percentile_inc_nulls\": 0.5836925506591797, \"value_count\": 369, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 369.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5762308835983276, \"percentile_inc_nulls\": 0.5767922401428223, \"value_count\": 349, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 349.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5698164701461792, \"percentile_inc_nulls\": 0.5703862905502319, \"value_count\": 324, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 324.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5634812116622925, \"percentile_inc_nulls\": 0.5640594959259033, \"value_count\": 320, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 320.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5573043823242188, \"percentile_inc_nulls\": 0.557890772819519, \"value_count\": 312, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 312.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5513848066329956, \"percentile_inc_nulls\": 0.551979124546051, \"value_count\": 299, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 299.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5457029342651367, \"percentile_inc_nulls\": 0.5463047027587891, \"value_count\": 287, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 287.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5401991605758667, \"percentile_inc_nulls\": 0.5408082604408264, \"value_count\": 278, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 278.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5348538160324097, \"percentile_inc_nulls\": 0.5354700088500977, \"value_count\": 270, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 270.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5298252105712891, \"percentile_inc_nulls\": 0.5304480195045471, \"value_count\": 254, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 254.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5250935554504395, \"percentile_inc_nulls\": 0.5257226228713989, \"value_count\": 239, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 239.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5204806923866272, \"percentile_inc_nulls\": 0.5211158990859985, \"value_count\": 233, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 233.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5164815187454224, \"percentile_inc_nulls\": 0.5171220302581787, \"value_count\": 202, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 202.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.51287841796875, \"percentile_inc_nulls\": 0.5135236978530884, \"value_count\": 182, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 182.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5092949867248535, \"percentile_inc_nulls\": 0.5099450349807739, \"value_count\": 181, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 181.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5058304071426392, \"percentile_inc_nulls\": 0.5064850449562073, \"value_count\": 175, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 175.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.49898040294647217, \"percentile_inc_nulls\": 0.49964410066604614, \"value_count\": 173, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 346.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.49563461542129517, \"percentile_inc_nulls\": 0.4963027238845825, \"value_count\": 169, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 169.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4923086166381836, \"percentile_inc_nulls\": 0.4929811358451843, \"value_count\": 168, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 168.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4890221953392029, \"percentile_inc_nulls\": 0.4896990656852722, \"value_count\": 166, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 166.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.48587435483932495, \"percentile_inc_nulls\": 0.48655539751052856, \"value_count\": 159, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 159.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4827859401702881, \"percentile_inc_nulls\": 0.4834710955619812, \"value_count\": 156, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.47664862871170044, \"percentile_inc_nulls\": 0.4773419499397278, \"value_count\": 155, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 310.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4705509543418884, \"percentile_inc_nulls\": 0.47125232219696045, \"value_count\": 154, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 308.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4675813317298889, \"percentile_inc_nulls\": 0.4682866334915161, \"value_count\": 150, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 150.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.46471065282821655, \"percentile_inc_nulls\": 0.4654197692871094, \"value_count\": 145, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 145.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.46195876598358154, \"percentile_inc_nulls\": 0.46267151832580566, \"value_count\": 139, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 139.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.459286093711853, \"percentile_inc_nulls\": 0.4600023627281189, \"value_count\": 135, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 135.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.45405954122543335, \"percentile_inc_nulls\": 0.45478272438049316, \"value_count\": 132, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 264.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.451485812664032, \"percentile_inc_nulls\": 0.45221245288848877, \"value_count\": 130, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 130.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4464572072029114, \"percentile_inc_nulls\": 0.44719046354293823, \"value_count\": 127, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 254.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.44402211904525757, \"percentile_inc_nulls\": 0.4447585940361023, \"value_count\": 123, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.44164639711380005, \"percentile_inc_nulls\": 0.44238603115081787, \"value_count\": 120, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4393102526664734, \"percentile_inc_nulls\": 0.44005298614501953, \"value_count\": 118, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 118.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4370335340499878, \"percentile_inc_nulls\": 0.4377792477607727, \"value_count\": 115, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 115.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4347766041755676, \"percentile_inc_nulls\": 0.4355252981185913, \"value_count\": 114, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 114.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4325592517852783, \"percentile_inc_nulls\": 0.43331092596054077, \"value_count\": 112, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 112.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4304013252258301, \"percentile_inc_nulls\": 0.43115586042404175, \"value_count\": 109, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 109.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4283621311187744, \"percentile_inc_nulls\": 0.42911940813064575, \"value_count\": 103, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 103.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.42634278535842896, \"percentile_inc_nulls\": 0.4271026849746704, \"value_count\": 102, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 102.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4223436713218689, \"percentile_inc_nulls\": 0.42310887575149536, \"value_count\": 101, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 202.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4203639030456543, \"percentile_inc_nulls\": 0.4211317300796509, \"value_count\": 100, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 100.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.418443500995636, \"percentile_inc_nulls\": 0.4192138910293579, \"value_count\": 97, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 97.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4165429472923279, \"percentile_inc_nulls\": 0.41731584072113037, \"value_count\": 96, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4146621823310852, \"percentile_inc_nulls\": 0.4154375195503235, \"value_count\": 95, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 95.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4128011465072632, \"percentile_inc_nulls\": 0.4135790467262268, \"value_count\": 94, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 94.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4055156111717224, \"percentile_inc_nulls\": 0.4063031077384949, \"value_count\": 92, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 368.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4001108407974243, \"percentile_inc_nulls\": 0.4009055495262146, \"value_count\": 91, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 273.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.39832907915115356, \"percentile_inc_nulls\": 0.3991261124610901, \"value_count\": 90, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3948447108268738, \"percentile_inc_nulls\": 0.395646333694458, \"value_count\": 88, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 176.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.39139991998672485, \"percentile_inc_nulls\": 0.392206072807312, \"value_count\": 87, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 174.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.38971710205078125, \"percentile_inc_nulls\": 0.3905255198478699, \"value_count\": 85, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3864702582359314, \"percentile_inc_nulls\": 0.3872830271720886, \"value_count\": 82, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 164.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3848666548728943, \"percentile_inc_nulls\": 0.38568150997161865, \"value_count\": 81, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3816990256309509, \"percentile_inc_nulls\": 0.38251811265945435, \"value_count\": 80, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 160.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3801349997520447, \"percentile_inc_nulls\": 0.38095617294311523, \"value_count\": 79, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 79.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.37859082221984863, \"percentile_inc_nulls\": 0.3794139623641968, \"value_count\": 78, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 78.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.37706637382507324, \"percentile_inc_nulls\": 0.3778916001319885, \"value_count\": 77, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 77.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.37556177377700806, \"percentile_inc_nulls\": 0.3763889670372009, \"value_count\": 76, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 76.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3740769624710083, \"percentile_inc_nulls\": 0.374906063079834, \"value_count\": 75, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 75.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3726118803024292, \"percentile_inc_nulls\": 0.37344300746917725, \"value_count\": 74, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 74.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3697214722633362, \"percentile_inc_nulls\": 0.3705563545227051, \"value_count\": 73, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 146.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.36687058210372925, \"percentile_inc_nulls\": 0.36770927906036377, \"value_count\": 72, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3654649257659912, \"percentile_inc_nulls\": 0.36630553007125854, \"value_count\": 71, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 71.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3640791177749634, \"percentile_inc_nulls\": 0.364921510219574, \"value_count\": 70, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 70.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 69, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 4413}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column first_name\", \"subtitle\": \"In this col, 67 values (0.1%) are null and there are 4413 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 2780, \"group_name\": \"first_name\", \"value\": \"william\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 2736, \"group_name\": \"first_name\", \"value\": \"john\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1448, \"group_name\": \"first_name\", \"value\": \"thomas\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1415, \"group_name\": \"first_name\", \"value\": \"george\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1306, \"group_name\": \"first_name\", \"value\": \"henry\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1265, \"group_name\": \"first_name\", \"value\": \"james\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1262, \"group_name\": \"first_name\", \"value\": \"sir\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1216, \"group_name\": \"first_name\", \"value\": \"charles\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 911, \"group_name\": \"first_name\", \"value\": \"edward\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 884, \"group_name\": \"first_name\", \"value\": \"robert\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"clifford,\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"colomi\\u00e8s\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"pollard\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"vauvhan\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"agnrs\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"marguerite\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"henderima\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"haeold\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"h.m.\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"mcilquham\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 2780]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9620519876480103, \"percentile_inc_nulls\": 0.96543949842453, \"value_count\": 1748, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1748.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.9272083640098572, \"percentile_inc_nulls\": 0.9337063431739807, \"value_count\": 1605, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1605.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8945791721343994, \"percentile_inc_nulls\": 0.903989851474762, \"value_count\": 1503, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1503.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8677246570587158, \"percentile_inc_nulls\": 0.8795325756072998, \"value_count\": 1237, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1237.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8411957621574402, \"percentile_inc_nulls\": 0.85537189245224, \"value_count\": 1222, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1222.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8200073838233948, \"percentile_inc_nulls\": 0.836074948310852, \"value_count\": 976, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 976.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7988624572753906, \"percentile_inc_nulls\": 0.816817581653595, \"value_count\": 974, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 974.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7782385349273682, \"percentile_inc_nulls\": 0.7980347275733948, \"value_count\": 950, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 950.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7581573128700256, \"percentile_inc_nulls\": 0.7797461152076721, \"value_count\": 925, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 925.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7402036190032959, \"percentile_inc_nulls\": 0.7633951306343079, \"value_count\": 827, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 827.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7224019169807434, \"percentile_inc_nulls\": 0.7471826076507568, \"value_count\": 820, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 820.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7047739028930664, \"percentile_inc_nulls\": 0.7311281561851501, \"value_count\": 812, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 812.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6874281167984009, \"percentile_inc_nulls\": 0.7153307795524597, \"value_count\": 799, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 799.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6718190312385559, \"percentile_inc_nulls\": 0.7011151313781738, \"value_count\": 719, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 719.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6564704775810242, \"percentile_inc_nulls\": 0.687136709690094, \"value_count\": 707, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 707.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6416212320327759, \"percentile_inc_nulls\": 0.6736130714416504, \"value_count\": 684, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 684.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6276403665542603, \"percentile_inc_nulls\": 0.6608802080154419, \"value_count\": 644, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 644.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6140068769454956, \"percentile_inc_nulls\": 0.6484637260437012, \"value_count\": 628, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 628.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6006121635437012, \"percentile_inc_nulls\": 0.6362648010253906, \"value_count\": 617, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 617.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5745174884796143, \"percentile_inc_nulls\": 0.612499475479126, \"value_count\": 601, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1202.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5632286071777344, \"percentile_inc_nulls\": 0.6022183895111084, \"value_count\": 520, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 520.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5519614219665527, \"percentile_inc_nulls\": 0.5919569730758667, \"value_count\": 519, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 519.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5411719083786011, \"percentile_inc_nulls\": 0.5821305513381958, \"value_count\": 497, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 497.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5307079553604126, \"percentile_inc_nulls\": 0.5726007223129272, \"value_count\": 482, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 482.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5206781625747681, \"percentile_inc_nulls\": 0.5634663105010986, \"value_count\": 462, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 462.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5006621479988098, \"percentile_inc_nulls\": 0.5452370643615723, \"value_count\": 461, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 922.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4908711910247803, \"percentile_inc_nulls\": 0.536320149898529, \"value_count\": 451, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 451.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4815361499786377, \"percentile_inc_nulls\": 0.5278184413909912, \"value_count\": 430, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 430.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.47239649295806885, \"percentile_inc_nulls\": 0.5194946527481079, \"value_count\": 421, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 421.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.463473916053772, \"percentile_inc_nulls\": 0.5113685727119446, \"value_count\": 411, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 411.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.45459479093551636, \"percentile_inc_nulls\": 0.5032820701599121, \"value_count\": 409, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 409.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4458025097846985, \"percentile_inc_nulls\": 0.4952746033668518, \"value_count\": 405, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 405.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4373575448989868, \"percentile_inc_nulls\": 0.4875835180282593, \"value_count\": 389, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 389.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4289342761039734, \"percentile_inc_nulls\": 0.4799122214317322, \"value_count\": 388, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 388.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4205544590950012, \"percentile_inc_nulls\": 0.47228044271469116, \"value_count\": 386, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 386.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.41258710622787476, \"percentile_inc_nulls\": 0.46502429246902466, \"value_count\": 367, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 367.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.40464144945144653, \"percentile_inc_nulls\": 0.45778799057006836, \"value_count\": 366, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 366.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.39678269624710083, \"percentile_inc_nulls\": 0.45063072443008423, \"value_count\": 362, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 362.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3893146514892578, \"percentile_inc_nulls\": 0.44382935762405396, \"value_count\": 344, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 344.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3819117546081543, \"percentile_inc_nulls\": 0.4370872974395752, \"value_count\": 341, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 341.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3745739459991455, \"percentile_inc_nulls\": 0.43040454387664795, \"value_count\": 338, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 338.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.36732304096221924, \"percentile_inc_nulls\": 0.42380088567733765, \"value_count\": 334, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 334.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.36039769649505615, \"percentile_inc_nulls\": 0.4174937605857849, \"value_count\": 319, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 319.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3535592555999756, \"percentile_inc_nulls\": 0.4112657904624939, \"value_count\": 315, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 315.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.34678590297698975, \"percentile_inc_nulls\": 0.4050970673561096, \"value_count\": 312, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 312.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3400343060493469, \"percentile_inc_nulls\": 0.39894813299179077, \"value_count\": 311, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 311.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3333261013031006, \"percentile_inc_nulls\": 0.3928387761116028, \"value_count\": 309, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 309.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.32679158449172974, \"percentile_inc_nulls\": 0.3868875503540039, \"value_count\": 301, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 301.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.32030045986175537, \"percentile_inc_nulls\": 0.3809759020805359, \"value_count\": 299, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 299.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3138744831085205, \"percentile_inc_nulls\": 0.3751235604286194, \"value_count\": 296, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 296.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.30751359462738037, \"percentile_inc_nulls\": 0.3693305253982544, \"value_count\": 293, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 293.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.30128300189971924, \"percentile_inc_nulls\": 0.3636561632156372, \"value_count\": 287, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 287.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.2950741648674011, \"percentile_inc_nulls\": 0.3580015301704407, \"value_count\": 286, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 286.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.28903889656066895, \"percentile_inc_nulls\": 0.35250502824783325, \"value_count\": 278, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 278.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.28302544355392456, \"percentile_inc_nulls\": 0.34702837467193604, \"value_count\": 277, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 277.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.27117210626602173, \"percentile_inc_nulls\": 0.33623313903808594, \"value_count\": 273, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 546.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.25940561294555664, \"percentile_inc_nulls\": 0.3255169987678528, \"value_count\": 271, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 542.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.25356578826904297, \"percentile_inc_nulls\": 0.3201984763145447, \"value_count\": 269, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 269.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.24776935577392578, \"percentile_inc_nulls\": 0.31491953134536743, \"value_count\": 267, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 267.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.24208152294158936, \"percentile_inc_nulls\": 0.3097394108772278, \"value_count\": 262, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 262.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.23645877838134766, \"percentile_inc_nulls\": 0.30461859703063965, \"value_count\": 259, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 259.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.23096626996994019, \"percentile_inc_nulls\": 0.2996164560317993, \"value_count\": 253, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 253.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.22551721334457397, \"percentile_inc_nulls\": 0.2946537733078003, \"value_count\": 251, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 251.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.22019845247268677, \"percentile_inc_nulls\": 0.28980982303619385, \"value_count\": 245, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 245.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.21496647596359253, \"percentile_inc_nulls\": 0.28504490852355957, \"value_count\": 241, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 241.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.20977789163589478, \"percentile_inc_nulls\": 0.2803195118904114, \"value_count\": 239, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 239.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.20474135875701904, \"percentile_inc_nulls\": 0.27573251724243164, \"value_count\": 232, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 232.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.19974815845489502, \"percentile_inc_nulls\": 0.27118510007858276, \"value_count\": 230, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 230.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.194776713848114, \"percentile_inc_nulls\": 0.26665741205215454, \"value_count\": 229, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 229.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.18989211320877075, \"percentile_inc_nulls\": 0.26220887899398804, \"value_count\": 225, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 225.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.18505090475082397, \"percentile_inc_nulls\": 0.25779980421066284, \"value_count\": 223, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 223.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.18053537607192993, \"percentile_inc_nulls\": 0.25368738174438477, \"value_count\": 208, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 208.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.17604148387908936, \"percentile_inc_nulls\": 0.24959468841552734, \"value_count\": 207, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 207.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.17161279916763306, \"percentile_inc_nulls\": 0.24556130170822144, \"value_count\": 204, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 204.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.167205810546875, \"percentile_inc_nulls\": 0.24154770374298096, \"value_count\": 203, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 203.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.16308099031448364, \"percentile_inc_nulls\": 0.23779112100601196, \"value_count\": 190, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 190.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1589779257774353, \"percentile_inc_nulls\": 0.2340543270111084, \"value_count\": 189, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 189.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1550702452659607, \"percentile_inc_nulls\": 0.23049545288085938, \"value_count\": 180, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 180.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.14747196435928345, \"percentile_inc_nulls\": 0.22357547283172607, \"value_count\": 175, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 350.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1437596082687378, \"percentile_inc_nulls\": 0.22019457817077637, \"value_count\": 171, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 171.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.14013415575027466, \"percentile_inc_nulls\": 0.21689271926879883, \"value_count\": 167, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 167.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.13327401876449585, \"percentile_inc_nulls\": 0.21064496040344238, \"value_count\": 158, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 316.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.12997418642044067, \"percentile_inc_nulls\": 0.2076396942138672, \"value_count\": 152, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 152.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.12695658206939697, \"percentile_inc_nulls\": 0.20489144325256348, \"value_count\": 139, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 139.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1240692138671875, \"percentile_inc_nulls\": 0.20226186513900757, \"value_count\": 133, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 133.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.12129038572311401, \"percentile_inc_nulls\": 0.19973111152648926, \"value_count\": 128, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 128.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11853331327438354, \"percentile_inc_nulls\": 0.19722014665603638, \"value_count\": 127, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 127.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11579793691635132, \"percentile_inc_nulls\": 0.19472891092300415, \"value_count\": 126, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11312764883041382, \"percentile_inc_nulls\": 0.1922970414161682, \"value_count\": 123, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11047911643981934, \"percentile_inc_nulls\": 0.18988490104675293, \"value_count\": 122, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 122.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1078522801399231, \"percentile_inc_nulls\": 0.18749260902404785, \"value_count\": 121, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 121.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1052471399307251, \"percentile_inc_nulls\": 0.18511998653411865, \"value_count\": 120, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.10268545150756836, \"percentile_inc_nulls\": 0.1827870011329651, \"value_count\": 118, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 118.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.10018885135650635, \"percentile_inc_nulls\": 0.18051326274871826, \"value_count\": 115, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 115.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0977357029914856, \"percentile_inc_nulls\": 0.1782791018486023, \"value_count\": 113, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 113.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.09532594680786133, \"percentile_inc_nulls\": 0.1760844588279724, \"value_count\": 111, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.09298133850097656, \"percentile_inc_nulls\": 0.17394912242889404, \"value_count\": 108, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 108.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0907018780708313, \"percentile_inc_nulls\": 0.17187315225601196, \"value_count\": 105, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 105.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08844411373138428, \"percentile_inc_nulls\": 0.16981691122055054, \"value_count\": 104, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 104.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08627313375473022, \"percentile_inc_nulls\": 0.16783976554870605, \"value_count\": 100, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 100.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08414560556411743, \"percentile_inc_nulls\": 0.16590219736099243, \"value_count\": 98, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 98.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0820615291595459, \"percentile_inc_nulls\": 0.16400408744812012, \"value_count\": 96, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08002084493637085, \"percentile_inc_nulls\": 0.16214561462402344, \"value_count\": 94, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 94.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.07802355289459229, \"percentile_inc_nulls\": 0.16032660007476807, \"value_count\": 92, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 92.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.076091468334198, \"percentile_inc_nulls\": 0.15856695175170898, \"value_count\": 89, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 89.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.07418102025985718, \"percentile_inc_nulls\": 0.15682709217071533, \"value_count\": 88, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 88.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0722922682762146, \"percentile_inc_nulls\": 0.15510696172714233, \"value_count\": 87, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 87.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.07042527198791504, \"percentile_inc_nulls\": 0.15340662002563477, \"value_count\": 86, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06690835952758789, \"percentile_inc_nulls\": 0.1502036452293396, \"value_count\": 81, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 162.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06521505117416382, \"percentile_inc_nulls\": 0.14866149425506592, \"value_count\": 78, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 78.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06356513500213623, \"percentile_inc_nulls\": 0.14715886116027832, \"value_count\": 76, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 76.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06202375888824463, \"percentile_inc_nulls\": 0.14575505256652832, \"value_count\": 71, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 71.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06052577495574951, \"percentile_inc_nulls\": 0.14439082145690918, \"value_count\": 69, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.05761677026748657, \"percentile_inc_nulls\": 0.14174145460128784, \"value_count\": 67, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 134.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0562056303024292, \"percentile_inc_nulls\": 0.14045631885528564, \"value_count\": 65, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.054816246032714844, \"percentile_inc_nulls\": 0.13919097185134888, \"value_count\": 64, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.05344855785369873, \"percentile_inc_nulls\": 0.13794535398483276, \"value_count\": 63, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 63.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.05210256576538086, \"percentile_inc_nulls\": 0.13671952486038208, \"value_count\": 62, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04949742555618286, \"percentile_inc_nulls\": 0.13434696197509766, \"value_count\": 60, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04821658134460449, \"percentile_inc_nulls\": 0.1331804394721985, \"value_count\": 59, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 59.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04702258110046387, \"percentile_inc_nulls\": 0.13209301233291626, \"value_count\": 55, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 55.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04595881700515747, \"percentile_inc_nulls\": 0.13112419843673706, \"value_count\": 49, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 49.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04493844509124756, \"percentile_inc_nulls\": 0.13019496202468872, \"value_count\": 47, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.043939828872680664, \"percentile_inc_nulls\": 0.12928545475006104, \"value_count\": 46, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.042984604835510254, \"percentile_inc_nulls\": 0.1284155249595642, \"value_count\": 44, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 44.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.042051076889038086, \"percentile_inc_nulls\": 0.12756532430648804, \"value_count\": 43, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 43.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.040227532386779785, \"percentile_inc_nulls\": 0.12590456008911133, \"value_count\": 42, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 84.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03933745622634888, \"percentile_inc_nulls\": 0.12509393692016602, \"value_count\": 41, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 41.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03846907615661621, \"percentile_inc_nulls\": 0.12430304288864136, \"value_count\": 40, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03764408826828003, \"percentile_inc_nulls\": 0.12355172634124756, \"value_count\": 38, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0329548716545105, \"percentile_inc_nulls\": 0.1192811131477356, \"value_count\": 36, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 216.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03221672773361206, \"percentile_inc_nulls\": 0.11860889196395874, \"value_count\": 34, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03150033950805664, \"percentile_inc_nulls\": 0.11795639991760254, \"value_count\": 33, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 33.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03015434741973877, \"percentile_inc_nulls\": 0.11673057079315186, \"value_count\": 31, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.028851807117462158, \"percentile_inc_nulls\": 0.11554431915283203, \"value_count\": 30, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02759265899658203, \"percentile_inc_nulls\": 0.11439758539199829, \"value_count\": 29, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 58.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.026984810829162598, \"percentile_inc_nulls\": 0.11384397745132446, \"value_count\": 28, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02581244707107544, \"percentile_inc_nulls\": 0.11277627944946289, \"value_count\": 27, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.024683594703674316, \"percentile_inc_nulls\": 0.11174821853637695, \"value_count\": 26, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02414083480834961, \"percentile_inc_nulls\": 0.11125391721725464, \"value_count\": 25, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 25.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02361983060836792, \"percentile_inc_nulls\": 0.11077940464019775, \"value_count\": 24, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 24.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.023120522499084473, \"percentile_inc_nulls\": 0.11032462120056152, \"value_count\": 23, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 23.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02266460657119751, \"percentile_inc_nulls\": 0.10990947484970093, \"value_count\": 21, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 21.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.022230446338653564, \"percentile_inc_nulls\": 0.10951399803161621, \"value_count\": 20, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 20.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.020580530166625977, \"percentile_inc_nulls\": 0.10801136493682861, \"value_count\": 19, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 76.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.019408226013183594, \"percentile_inc_nulls\": 0.10694372653961182, \"value_count\": 18, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.019039154052734375, \"percentile_inc_nulls\": 0.10660761594772339, \"value_count\": 17, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 17.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.01799708604812622, \"percentile_inc_nulls\": 0.10565859079360962, \"value_count\": 16, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 48.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.01702016592025757, \"percentile_inc_nulls\": 0.10476887226104736, \"value_count\": 15, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.016412317752838135, \"percentile_inc_nulls\": 0.10421526432037354, \"value_count\": 14, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.015565633773803711, \"percentile_inc_nulls\": 0.1034441590309143, \"value_count\": 13, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 39.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.014784097671508789, \"percentile_inc_nulls\": 0.10273241996765137, \"value_count\": 12, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.014545321464538574, \"percentile_inc_nulls\": 0.10251492261886597, \"value_count\": 11, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 11.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.014111101627349854, \"percentile_inc_nulls\": 0.10211950540542603, \"value_count\": 10, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 20.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.013524949550628662, \"percentile_inc_nulls\": 0.10158568620681763, \"value_count\": 9, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 27.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.011961877346038818, \"percentile_inc_nulls\": 0.10016214847564697, \"value_count\": 8, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 72.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.010594189167022705, \"percentile_inc_nulls\": 0.09891653060913086, \"value_count\": 7, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 63.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.010333657264709473, \"percentile_inc_nulls\": 0.09867924451828003, \"value_count\": 6, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 12.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.008488357067108154, \"percentile_inc_nulls\": 0.09699869155883789, \"value_count\": 5, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.006751596927642822, \"percentile_inc_nulls\": 0.09541696310043335, \"value_count\": 4, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 80.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.004797756671905518, \"percentile_inc_nulls\": 0.09363752603530884, \"value_count\": 3, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0024966001510620117, \"percentile_inc_nulls\": 0.09154176712036133, \"value_count\": 2, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 106.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.08926808834075928, \"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 115.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 1748, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1748.0, \"distinct_value_count\": 447}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column substr(surname,1,2)\", \"subtitle\": \"In this col, 4,515 values (8.9%) are null and there are 447 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1748, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ba\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1605, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ma\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1503, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ha\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1237, \"group_name\": \"substr_surname_1_2_\", \"value\": \"st\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1222, \"group_name\": \"substr_surname_1_2_\", \"value\": \"br\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 976, \"group_name\": \"substr_surname_1_2_\", \"value\": \"co\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 974, \"group_name\": \"substr_surname_1_2_\", \"value\": \"be\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 950, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ro\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 925, \"group_name\": \"substr_surname_1_2_\", \"value\": \"wa\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 827, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ca\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"xo\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"pq\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"6o\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"u4\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"v8\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"3d\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"0e\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"v4\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"c0\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"tn\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 1748]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import DuckDBAPI\n",
    "from splink.exploratory import profile_columns\n",
    "\n",
    "db_api = DuckDBAPI()\n",
    "profile_columns(df, db_api, column_expressions=[\"first_name\", \"substr(surname,1,2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:05.117580Z",
     "iopub.status.busy": "2024-05-15T16:07:05.117224Z",
     "iopub.status.idle": "2024-05-15T16:07:05.620193Z",
     "shell.execute_reply": "2024-05-15T16:07:05.619557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-04b0c3cd9e0b44cb8f4f105e72f86332.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-04b0c3cd9e0b44cb8f4f105e72f86332.vega-embed details,\n",
       "  #altair-viz-04b0c3cd9e0b44cb8f4f105e72f86332.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-04b0c3cd9e0b44cb8f4f105e72f86332\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-04b0c3cd9e0b44cb8f4f105e72f86332\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-04b0c3cd9e0b44cb8f4f105e72f86332\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-8232b7c328acd1a8eec0ecfe8a013878\"}, \"mark\": \"bar\", \"encoding\": {\"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"blocking_rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Total comparisons in Cartesian product\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"blocking_rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-8232b7c328acd1a8eec0ecfe8a013878\": [{\"blocking_rule\": \"(l.\\\"first_name\\\" = r.\\\"first_name\\\") AND (l.\\\"surname\\\" = r.\\\"surname\\\")\", \"row_count\": 243656, \"cumulative_rows\": 243656, \"cartesian\": 1279041753, \"match_key\": \"0\", \"start\": 0}, {\"blocking_rule\": \"(l.\\\"surname\\\" = r.\\\"surname\\\") AND (l.\\\"dob\\\" = r.\\\"dob\\\")\", \"row_count\": 25041, \"cumulative_rows\": 268697, \"cartesian\": 1279041753, \"match_key\": \"1\", \"start\": 243656}, {\"blocking_rule\": \"(l.\\\"first_name\\\" = r.\\\"first_name\\\") AND (l.\\\"dob\\\" = r.\\\"dob\\\")\", \"row_count\": 29905, \"cumulative_rows\": 298602, \"cartesian\": 1279041753, \"match_key\": \"2\", \"start\": 268697}, {\"blocking_rule\": \"(l.\\\"postcode_fake\\\" = r.\\\"postcode_fake\\\") AND (l.\\\"first_name\\\" = r.\\\"first_name\\\")\", \"row_count\": 8421, \"cumulative_rows\": 307023, \"cartesian\": 1279041753, \"match_key\": \"3\", \"start\": 298602}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import DuckDBAPI, block_on\n",
    "from splink.blocking_analysis import (\n",
    "    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n",
    ")\n",
    "\n",
    "blocking_rules =  [block_on(\"first_name\", \"surname\"),\n",
    "        block_on(\"surname\", \"dob\"),\n",
    "        block_on(\"first_name\", \"dob\"),\n",
    "        block_on(\"postcode_fake\", \"first_name\")]\n",
    "\n",
    "db_api = DuckDBAPI()\n",
    "\n",
    "cumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n",
    "    table_or_tables=df,\n",
    "    blocking_rules=blocking_rules,\n",
    "    db_api=db_api,\n",
    "    link_type=\"dedupe_only\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:05.623477Z",
     "iopub.status.busy": "2024-05-15T16:07:05.623213Z",
     "iopub.status.idle": "2024-05-15T16:07:05.768956Z",
     "shell.execute_reply": "2024-05-15T16:07:05.768275Z"
    }
   },
   "outputs": [],
   "source": [
    "import splink.comparison_library as cl\n",
    "import splink.comparison_template_library as ctl\n",
    "from splink import Linker\n",
    "from splink.settings_creator import SettingsCreator\n",
    "\n",
    "settings = SettingsCreator(\n",
    "    link_type=\"dedupe_only\",\n",
    "    blocking_rules_to_generate_predictions=blocking_rules,\n",
    "    comparisons=[\n",
    "        ctl.NameComparison(\"first_name\").configure(term_frequency_adjustments=True),\n",
    "        ctl.NameComparison(\"surname\").configure(term_frequency_adjustments=True),\n",
    "        ctl.DateComparison(\n",
    "            \"dob\",\n",
    "            input_is_string=True,\n",
    "            datetime_metrics=[\"month\", \"year\", \"year\"],\n",
    "            datetime_thresholds=[1, 1, 10],\n",
    "        ),\n",
    "        # TODO: Restore ctl.PostcodeComparison level here\n",
    "        cl.LevenshteinAtThresholds(\"postcode_fake\"),\n",
    "        cl.ExactMatch(\"birth_place\").configure(term_frequency_adjustments=True),\n",
    "        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=True),\n",
    "    ],\n",
    "    retain_intermediate_calculation_columns=True,\n",
    ")\n",
    "\n",
    "linker = Linker(df, settings, database_api=db_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:05.772775Z",
     "iopub.status.busy": "2024-05-15T16:07:05.772497Z",
     "iopub.status.idle": "2024-05-15T16:07:06.084481Z",
     "shell.execute_reply": "2024-05-15T16:07:06.083929Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.000136.\n",
      "This means that amongst all possible pairwise record comparisons, one in 7,362.31 are expected to match.  With 1,279,041,753 total possible comparisons, we expect a total of around 173,728.33 matching pairs\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_probability_two_random_records_match(\n",
    "    [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"substr(l.first_name,1,2) = substr(r.first_name,1,2) and l.surname = r.surname and substr(l.postcode_fake,1,2) = substr(r.postcode_fake,1,2)\",\n",
    "        \"l.dob = r.dob and l.postcode_fake = r.postcode_fake\",\n",
    "    ],\n",
    "    recall=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:06.087609Z",
     "iopub.status.busy": "2024-05-15T16:07:06.087384Z",
     "iopub.status.idle": "2024-05-15T16:07:13.105199Z",
     "shell.execute_reply": "2024-05-15T16:07:13.104695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated u probabilities using random sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - dob (no m values are trained).\n",
      "    - postcode_fake (no m values are trained).\n",
      "    - birth_place (no m values are trained).\n",
      "    - occupation (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=5e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:13.108034Z",
     "iopub.status.busy": "2024-05-15T16:07:13.107820Z",
     "iopub.status.idle": "2024-05-15T16:07:16.289385Z",
     "shell.execute_reply": "2024-05-15T16:07:16.288708Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "(l.\"first_name\" = r.\"first_name\") AND (l.\"surname\" = r.\"surname\")\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - dob\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - first_name\n",
      "    - surname\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.533 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was -0.034 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 0.0136 in the m_probability of birth_place, level `Exact match on birth_place`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was -0.00579 in the m_probability of birth_place, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 5: Largest change in params was 0.00268 in the m_probability of birth_place, level `Exact match on birth_place`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 6: Largest change in params was 0.00129 in the m_probability of birth_place, level `Exact match on birth_place`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 7: Largest change in params was -0.000682 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 8: Largest change in params was -0.000373 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 9: Largest change in params was -0.000203 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 10: Largest change in params was -0.000111 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 11: Largest change in params was -6.05e-05 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 11 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = block_on(\"first_name\", \"surname\")\n",
    "training_session_names = linker.estimate_parameters_using_expectation_maximisation(\n",
    "    training_blocking_rule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:16.292730Z",
     "iopub.status.busy": "2024-05-15T16:07:16.292472Z",
     "iopub.status.idle": "2024-05-15T16:07:26.076237Z",
     "shell.execute_reply": "2024-05-15T16:07:26.075402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"dob\" = r.\"dob\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - dob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.362 in the m_probability of first_name, level `Exact match on first_name`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was 0.0343 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 0.00489 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was 0.00109 in the m_probability of surname, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 5: Largest change in params was 0.000261 in the m_probability of surname, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 6: Largest change in params was 6.1e-05 in the m_probability of surname, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 6 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = block_on(\"dob\")\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(\n",
    "    training_blocking_rule\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final match weights can be viewed in the match weights chart:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:26.079934Z",
     "iopub.status.busy": "2024-05-15T16:07:26.079660Z",
     "iopub.status.idle": "2024-05-15T16:07:26.364087Z",
     "shell.execute_reply": "2024-05-15T16:07:26.363559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-20e10ae7d241495db29eb27e561afdd0.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-20e10ae7d241495db29eb27e561afdd0.vega-embed details,\n",
       "  #altair-viz-20e10ae7d241495db29eb27e561afdd0.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-20e10ae7d241495db29eb27e561afdd0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-20e10ae7d241495db29eb27e561afdd0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-20e10ae7d241495db29eb27e561afdd0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": 60, \"discreteWidth\": 400}, \"header\": {\"title\": null}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}}, \"vconcat\": [{\"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\", \"type\": \"nominal\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Equivalent match weight\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"domain\": false, \"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-13, 13]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAlign\": \"right\", \"titleAngle\": 0, \"titleFontWeight\": \"normal\"}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": 20, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}]}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"row\": {\"field\": \"comparison_name\", \"header\": {\"labelAlign\": \"left\", \"labelAnchor\": \"middle\", \"labelAngle\": 0}, \"sort\": {\"field\": \"comparison_sort_order\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\", \"type\": \"quantitative\"}, {\"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-13, 13]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": {\"step\": 12}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}]}], \"data\": {\"name\": \"data-0b40f85da57276d3e859720bda94ee1f\"}, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\", \"views\": []}], \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-0b40f85da57276d3e859720bda94ee1f\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.00013584539607096294, \"log2_bayes_factor\": -12.845746707461347, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.000 or one in  7,362.3 records.This is equivalent to a starting match weight of -12.846.\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": -1}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"m_probability_description\": \"Amongst matching record comparisons, 55.20% of records are in the exact match on first_name comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.23% of records are in the exact match on first_name comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"first_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"m_probability_description\": \"Amongst matching record comparisons, 10.05% of records are in the jaro-winkler distance of first_name >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.39% of records are in the jaro-winkler distance of first_name >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 25.877922195583377, \"log2_bayes_factor\": 4.693649879201223, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.8\", \"m_probability\": 0.11320556872916626, \"u_probability\": 0.0067978136904621065, \"m_probability_description\": \"Amongst matching record comparisons, 11.32% of records are in the jaro-winkler distance of first_name >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.68% of records are in the jaro-winkler distance of first_name >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 16.653232036647754, \"log2_bayes_factor\": 4.057730295651484, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.8` then comparison is 16.65 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"m_probability_description\": \"Amongst matching record comparisons, 23.43% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 97.70% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"m_probability_description\": \"Amongst matching record comparisons, 78.08% of records are in the exact match on surname comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.06% of records are in the exact match on surname comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.9\", \"m_probability\": 0.11742352830362798, \"u_probability\": 0.0005103765013517706, \"m_probability_description\": \"Amongst matching record comparisons, 11.74% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 230.0723642107795, \"log2_bayes_factor\": 7.8459438903705685, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.9` then comparison is 230.07 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.8\", \"m_probability\": 0.034646788261339434, \"u_probability\": 0.003281321558894355, \"m_probability_description\": \"Amongst matching record comparisons, 3.46% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.33% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 10.558790913809041, \"log2_bayes_factor\": 3.4003727361632596, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.8` then comparison is 10.56 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"m_probability_description\": \"Amongst matching record comparisons, 6.71% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.56% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"dob\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"m_probability_description\": \"Amongst matching record comparisons, 61.43% of records are in the exact match on dob comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.21% of records are in the exact match on dob comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"m_probability_description\": \"Amongst matching record comparisons, 33.87% of records are in the damerau-levenshtein distance of dob <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 2.22% of records are in the damerau-levenshtein distance of dob <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 2629800.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 1 month'\", \"m_probability\": 0.002293253593710418, \"u_probability\": 0.002016938365888285, \"m_probability_description\": \"Amongst matching record comparisons, 0.23% of records are in the abs difference of 'transformed dob <= 1 month' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.20% of records are in the abs difference of 'transformed dob <= 1 month' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1.136997358221425, \"log2_bayes_factor\": 0.18522890217626728, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 1 month'` then comparison is 1.14 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 31557600.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 1 year'\", \"m_probability\": 0.004737387766410647, \"u_probability\": 0.02614709289992004, \"m_probability_description\": \"Amongst matching record comparisons, 0.47% of records are in the abs difference of 'transformed dob <= 1 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 2.61% of records are in the abs difference of 'transformed dob <= 1 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.18118219813358807, \"log2_bayes_factor\": -2.464486883024524, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 1 year'` then comparison is  5.52 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 10 year'\", \"m_probability\": 0.013865806714415225, \"u_probability\": 0.19440936016057178, \"m_probability_description\": \"Amongst matching record comparisons, 1.39% of records are in the abs difference of 'transformed dob <= 10 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 19.44% of records are in the abs difference of 'transformed dob <= 10 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.07132273211003218, \"log2_bayes_factor\": -3.809494221443063, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 10 year'` then comparison is  14.02 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"m_probability_description\": \"Amongst matching record comparisons, 2.61% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 75.31% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"m_probability_description\": \"Amongst matching record comparisons, 68.72% of records are in the exact match on postcode_fake comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the exact match on postcode_fake comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 1\", \"label_for_charts\": \"Levenshtein distance of postcode_fake <= 1\", \"m_probability\": 0.08647875733991273, \"u_probability\": 7.066525210535341e-05, \"m_probability_description\": \"Amongst matching record comparisons, 8.65% of records are in the levenshtein distance of postcode_fake <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the levenshtein distance of postcode_fake <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1223.7804969687686, \"log2_bayes_factor\": 10.257129097322421, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of postcode_fake <= 1` then comparison is 1,223.78 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 2\", \"label_for_charts\": \"Levenshtein distance of postcode_fake <= 2\", \"m_probability\": 0.05611758855446276, \"u_probability\": 0.0005028225272029813, \"m_probability_description\": \"Amongst matching record comparisons, 5.61% of records are in the levenshtein distance of postcode_fake <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the levenshtein distance of postcode_fake <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 111.60515990925164, \"log2_bayes_factor\": 6.802259919481257, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of postcode_fake <= 2` then comparison is 111.61 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"m_probability_description\": \"Amongst matching record comparisons, 17.02% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.93% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"m_probability_description\": \"Amongst matching record comparisons, 84.41% of records are in the exact match on birth_place comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.52% of records are in the exact match on birth_place comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"birth_place\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 4}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"m_probability_description\": \"Amongst matching record comparisons, 15.59% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.48% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 4}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"m_probability_description\": \"Amongst matching record comparisons, 89.89% of records are in the exact match on occupation comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 3.74% of records are in the exact match on occupation comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"occupation\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 5}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"m_probability_description\": \"Amongst matching record comparisons, 10.11% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 96.26% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:26.367083Z",
     "iopub.status.busy": "2024-05-15T16:07:26.366860Z",
     "iopub.status.idle": "2024-05-15T16:07:28.387226Z",
     "shell.execute_reply": "2024-05-15T16:07:28.386186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-eb0e69515ad24bacb52c23b5ba466c53.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-eb0e69515ad24bacb52c23b5ba466c53.vega-embed details,\n",
       "  #altair-viz-eb0e69515ad24bacb52c23b5ba466c53.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-eb0e69515ad24bacb52c23b5ba466c53\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-eb0e69515ad24bacb52c23b5ba466c53\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-eb0e69515ad24bacb52c23b5ba466c53\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"axis\": {\"format\": \"+\", \"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"point\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"value\": 1, \"empty\": false}, \"value\": 0}, \"tooltip\": [{\"field\": \"match_weight\", \"format\": \"+.5\", \"title\": \"Match weight\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".5\", \"title\": \"Match probability\", \"type\": \"quantitative\"}, {\"field\": \"cum_prop\", \"format\": \".3%\", \"title\": \"Proportion of unlinkable records\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"name\": \"mouse_coords\"}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"x\": {\"field\": \"match_weight\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"y\": {\"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}], \"data\": {\"name\": \"data-cadc024b09ca7d8418c4e3c0eb168d33\"}, \"height\": 400, \"params\": [{\"name\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"select\": {\"type\": \"point\", \"fields\": [\"match_weight\", \"cum_prop\"], \"nearest\": true, \"on\": \"mouseover\"}, \"views\": [\"mouse_coords\"]}], \"title\": {\"text\": \"Unlinkable records\", \"subtitle\": \"Records with insufficient information to exceed a given match threshold\"}, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-cadc024b09ca7d8418c4e3c0eb168d33\": [{\"match_weight\": -12.85, \"match_probability\": 0.00014, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 3.9542883314425126e-05}, {\"match_weight\": -9.5, \"match_probability\": 0.00138, \"prop\": 5.931432679062709e-05, \"cum_prop\": 9.885721010505222e-05}, {\"match_weight\": -8.43, \"match_probability\": 0.00289, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00011862865176226478}, {\"match_weight\": -8.38, \"match_probability\": 0.00299, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00013840009341947734}, {\"match_weight\": -7.87, \"match_probability\": 0.00427, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0001581715350766899}, {\"match_weight\": -7.73, \"match_probability\": 0.00468, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00017794297673390247}, {\"match_weight\": -7.43, \"match_probability\": 0.00576, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00019771441839111503}, {\"match_weight\": -7.08, \"match_probability\": 0.00736, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0002174858600483276}, {\"match_weight\": -7.04, \"match_probability\": 0.00755, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00023725730170554016}, {\"match_weight\": -6.94, \"match_probability\": 0.0081, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0002768001850199653}, {\"match_weight\": -6.61, \"match_probability\": 0.01016, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00029657162667717785}, {\"match_weight\": -6.53, \"match_probability\": 0.01074, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0003163430683343904}, {\"match_weight\": -6.3, \"match_probability\": 0.01251, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00033611450999160297}, {\"match_weight\": -6.24, \"match_probability\": 0.01303, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00035588595164881554}, {\"match_weight\": -6.2, \"match_probability\": 0.01344, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0003756573933060281}, {\"match_weight\": -5.51, \"match_probability\": 0.02143, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00039542883496324066}, {\"match_weight\": -5.36, \"match_probability\": 0.02371, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0004152002766204532}, {\"match_weight\": -5.29, \"match_probability\": 0.02487, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0004349717182776658}, {\"match_weight\": -5.16, \"match_probability\": 0.02729, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00045474315993487835}, {\"match_weight\": -5.07, \"match_probability\": 0.02896, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0004745146015920909}, {\"match_weight\": -4.99, \"match_probability\": 0.0306, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.000533828928382718}, {\"match_weight\": -4.92, \"match_probability\": 0.03189, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0005536003700399306}, {\"match_weight\": -4.91, \"match_probability\": 0.03216, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0005733718116971431}, {\"match_weight\": -4.72, \"match_probability\": 0.0365, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0005931432533543557}, {\"match_weight\": -4.72, \"match_probability\": 0.03653, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006129146950115683}, {\"match_weight\": -4.67, \"match_probability\": 0.03792, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006326861366687808}, {\"match_weight\": -4.66, \"match_probability\": 0.03796, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006524575783259934}, {\"match_weight\": -4.65, \"match_probability\": 0.03839, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.0007315433449548436}, {\"match_weight\": -4.6, \"match_probability\": 0.03954, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0007513147866120562}, {\"match_weight\": -4.57, \"match_probability\": 0.04036, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0007710862282692688}, {\"match_weight\": -4.44, \"match_probability\": 0.04415, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0007908576699264813}, {\"match_weight\": -4.32, \"match_probability\": 0.04767, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0008106291115836939}, {\"match_weight\": -4.25, \"match_probability\": 0.04998, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.000850171994898119}, {\"match_weight\": -4.15, \"match_probability\": 0.05322, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0008699434365553316}, {\"match_weight\": -3.92, \"match_probability\": 0.06204, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0008897148782125441}, {\"match_weight\": -3.81, \"match_probability\": 0.0667, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0009094863198697567}, {\"match_weight\": -3.81, \"match_probability\": 0.06673, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0009292577615269693}, {\"match_weight\": -3.7, \"match_probability\": 0.0715, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0009490292031841818}, {\"match_weight\": -3.66, \"match_probability\": 0.07314, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0009688006448413944}, {\"match_weight\": -3.4, \"match_probability\": 0.08651, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0010083435281558195}, {\"match_weight\": -3.32, \"match_probability\": 0.09084, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001028114969813032}, {\"match_weight\": -3.22, \"match_probability\": 0.09679, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0010478864114702446}, {\"match_weight\": -3.02, \"match_probability\": 0.10993, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0010676578531274572}, {\"match_weight\": -2.96, \"match_probability\": 0.11376, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0010874292947846698}, {\"match_weight\": -2.94, \"match_probability\": 0.11553, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0011269721780990949}, {\"match_weight\": -2.72, \"match_probability\": 0.13158, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0011467436197563075}, {\"match_weight\": -2.63, \"match_probability\": 0.13901, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00116651506141352}, {\"match_weight\": -2.51, \"match_probability\": 0.14932, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0012060579447279451}, {\"match_weight\": -2.4, \"match_probability\": 0.15947, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0012258293863851577}, {\"match_weight\": -2.32, \"match_probability\": 0.16651, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0012456008280423703}, {\"match_weight\": -1.99, \"match_probability\": 0.20085, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0012653722696995828}, {\"match_weight\": -1.99, \"match_probability\": 0.20161, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.00132468659649021}, {\"match_weight\": -1.83, \"match_probability\": 0.21945, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0013444580381474225}, {\"match_weight\": -1.78, \"match_probability\": 0.22563, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0013840009214618476}, {\"match_weight\": -1.76, \"match_probability\": 0.22798, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0014235438047762727}, {\"match_weight\": -1.66, \"match_probability\": 0.23992, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0014433152464334853}, {\"match_weight\": -1.53, \"match_probability\": 0.25784, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0014630866880906979}, {\"match_weight\": -1.48, \"match_probability\": 0.26336, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0014828581297479104}, {\"match_weight\": -1.3, \"match_probability\": 0.28919, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.0015817153434909414}, {\"match_weight\": -1.28, \"match_probability\": 0.292, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001601486785148154}, {\"match_weight\": -1.26, \"match_probability\": 0.29433, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0016212582268053666}, {\"match_weight\": -1.25, \"match_probability\": 0.29621, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0016410296684625791}, {\"match_weight\": -1.24, \"match_probability\": 0.297, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0016608011101197917}, {\"match_weight\": -1.16, \"match_probability\": 0.30859, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0016805725517770043}, {\"match_weight\": -1.14, \"match_probability\": 0.31215, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017003439934342168}, {\"match_weight\": -1.08, \"match_probability\": 0.32134, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017201154350914294}, {\"match_weight\": -0.96, \"match_probability\": 0.33959, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001739886876748642}, {\"match_weight\": -0.9, \"match_probability\": 0.34829, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017596583184058545}, {\"match_weight\": -0.89, \"match_probability\": 0.35112, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001779429760063067}, {\"match_weight\": -0.88, \"match_probability\": 0.35255, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017992012017202796}, {\"match_weight\": -0.86, \"match_probability\": 0.35543, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018189726433774922}, {\"match_weight\": -0.82, \"match_probability\": 0.36137, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018387440850347048}, {\"match_weight\": -0.75, \"match_probability\": 0.37252, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018585155266919173}, {\"match_weight\": -0.71, \"match_probability\": 0.37874, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00187828696834913}, {\"match_weight\": -0.69, \"match_probability\": 0.38185, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018980584100063425}, {\"match_weight\": -0.66, \"match_probability\": 0.387, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001917829851663555}, {\"match_weight\": -0.62, \"match_probability\": 0.39463, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0019376012933207676}, {\"match_weight\": -0.61, \"match_probability\": 0.39515, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00195737273497798}, {\"match_weight\": -0.56, \"match_probability\": 0.40484, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0019969156182924053}, {\"match_weight\": -0.55, \"match_probability\": 0.40512, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002016687059949618}, {\"match_weight\": -0.5, \"match_probability\": 0.4142, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0020364585016068304}, {\"match_weight\": -0.45, \"match_probability\": 0.42296, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002056229943264043}, {\"match_weight\": -0.41, \"match_probability\": 0.43022, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0020760013849212555}, {\"match_weight\": -0.38, \"match_probability\": 0.43462, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.0021550871515501058}, {\"match_weight\": -0.35, \"match_probability\": 0.44029, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0021748585932073183}, {\"match_weight\": -0.31, \"match_probability\": 0.44724, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002194630034864531}, {\"match_weight\": -0.28, \"match_probability\": 0.45169, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0022144014765217435}, {\"match_weight\": -0.28, \"match_probability\": 0.45215, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002234172918178956}, {\"match_weight\": -0.19, \"match_probability\": 0.4667, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0022539443598361686}, {\"match_weight\": -0.17, \"match_probability\": 0.47067, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002273715801493381}, {\"match_weight\": -0.14, \"match_probability\": 0.47547, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0022934872431505937}, {\"match_weight\": -0.13, \"match_probability\": 0.47791, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0023132586848078063}, {\"match_weight\": -0.12, \"match_probability\": 0.4793, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002333030126465019}, {\"match_weight\": -0.08, \"match_probability\": 0.48638, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0023528015681222314}, {\"match_weight\": -0.04, \"match_probability\": 0.4924, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002372573009779444}, {\"match_weight\": 0.02, \"match_probability\": 0.50412, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0023923444514366565}, {\"match_weight\": 0.04, \"match_probability\": 0.5077, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002412115893093869}, {\"match_weight\": 0.25, \"match_probability\": 0.54245, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0024318873347510817}, {\"match_weight\": 0.25, \"match_probability\": 0.54246, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002451658776408294}, {\"match_weight\": 0.29, \"match_probability\": 0.54993, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0024714302180655068}, {\"match_weight\": 0.33, \"match_probability\": 0.55685, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0024912016597227193}, {\"match_weight\": 0.33, \"match_probability\": 0.55736, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002510973101379932}, {\"match_weight\": 0.34, \"match_probability\": 0.55804, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.002570287428170559}, {\"match_weight\": 0.35, \"match_probability\": 0.56085, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0025900588698277716}, {\"match_weight\": 0.48, \"match_probability\": 0.58253, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002609830311484984}, {\"match_weight\": 0.53, \"match_probability\": 0.5904, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0026493731947994092}, {\"match_weight\": 0.54, \"match_probability\": 0.59273, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002669144636456622}, {\"match_weight\": 0.58, \"match_probability\": 0.5993, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0026889160781138344}, {\"match_weight\": 0.63, \"match_probability\": 0.60693, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002708687519771047}, {\"match_weight\": 0.63, \"match_probability\": 0.60719, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0027284589614282595}, {\"match_weight\": 0.65, \"match_probability\": 0.61156, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002748230403085472}, {\"match_weight\": 0.69, \"match_probability\": 0.61728, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0027680018447426846}, {\"match_weight\": 0.71, \"match_probability\": 0.62029, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002787773286399897}, {\"match_weight\": 0.74, \"match_probability\": 0.62524, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0028075447280571098}, {\"match_weight\": 0.77, \"match_probability\": 0.62991, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0028273161697143223}, {\"match_weight\": 0.78, \"match_probability\": 0.6325, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002847087611371535}, {\"match_weight\": 0.83, \"match_probability\": 0.63955, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00288663049468596}, {\"match_weight\": 0.83, \"match_probability\": 0.64005, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0029064019363431726}, {\"match_weight\": 0.92, \"match_probability\": 0.65445, \"prop\": 0.0002768001868389547, \"cum_prop\": 0.0031832021231821273}, {\"match_weight\": 0.95, \"match_probability\": 0.65889, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00320297356483934}, {\"match_weight\": 1.02, \"match_probability\": 0.66898, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0032227450064965524}, {\"match_weight\": 1.08, \"match_probability\": 0.67816, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003242516448153765}, {\"match_weight\": 1.08, \"match_probability\": 0.67882, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0032622878898109775}, {\"match_weight\": 1.09, \"match_probability\": 0.68059, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00328205933146819}, {\"match_weight\": 1.11, \"match_probability\": 0.68404, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0033018307731254026}, {\"match_weight\": 1.12, \"match_probability\": 0.68487, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0033413736564398278}, {\"match_weight\": 1.12, \"match_probability\": 0.6849, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0033611450980970403}, {\"match_weight\": 1.13, \"match_probability\": 0.68621, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0034006879814114654}, {\"match_weight\": 1.15, \"match_probability\": 0.69003, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003420459423068678}, {\"match_weight\": 1.16, \"match_probability\": 0.6909, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0034402308647258906}, {\"match_weight\": 1.16, \"match_probability\": 0.69151, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003460002306383103}, {\"match_weight\": 1.19, \"match_probability\": 0.69573, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0034797737480403157}, {\"match_weight\": 1.23, \"match_probability\": 0.70121, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0034995451896975283}, {\"match_weight\": 1.23, \"match_probability\": 0.70135, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003519316631354741}, {\"match_weight\": 1.26, \"match_probability\": 0.70506, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0035390880730119534}, {\"match_weight\": 1.26, \"match_probability\": 0.70534, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0035786309563263785}, {\"match_weight\": 1.27, \"match_probability\": 0.70658, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003598402397983591}, {\"match_weight\": 1.28, \"match_probability\": 0.70893, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0036181738396408036}, {\"match_weight\": 1.29, \"match_probability\": 0.70929, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003637945281298016}, {\"match_weight\": 1.37, \"match_probability\": 0.72055, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0036577167229552288}, {\"match_weight\": 1.43, \"match_probability\": 0.72887, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0036774881646124413}, {\"match_weight\": 1.47, \"match_probability\": 0.73471, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003697259606269654}, {\"match_weight\": 1.48, \"match_probability\": 0.73582, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0037170310479268664}, {\"match_weight\": 1.5, \"match_probability\": 0.73834, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003736802489584079}, {\"match_weight\": 1.5, \"match_probability\": 0.73903, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0037565739312412916}, {\"match_weight\": 1.51, \"match_probability\": 0.74034, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003776345372898504}, {\"match_weight\": 1.52, \"match_probability\": 0.74091, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0037961168145557167}, {\"match_weight\": 1.52, \"match_probability\": 0.74179, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0038158882562129293}, {\"match_weight\": 1.52, \"match_probability\": 0.742, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003835659697870142}, {\"match_weight\": 1.53, \"match_probability\": 0.74245, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0038554311395273544}, {\"match_weight\": 1.55, \"match_probability\": 0.74549, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003875202581184567}, {\"match_weight\": 1.57, \"match_probability\": 0.74821, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0038949740228417795}, {\"match_weight\": 1.57, \"match_probability\": 0.7484, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.003934516906156205}, {\"match_weight\": 1.58, \"match_probability\": 0.74948, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003954288347813417}, {\"match_weight\": 1.58, \"match_probability\": 0.74992, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.003993831231127842}, {\"match_weight\": 1.59, \"match_probability\": 0.75127, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004013602672785055}, {\"match_weight\": 1.64, \"match_probability\": 0.75682, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00405314555609948}, {\"match_weight\": 1.65, \"match_probability\": 0.75788, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004072916997756693}, {\"match_weight\": 1.65, \"match_probability\": 0.75876, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004092688439413905}, {\"match_weight\": 1.7, \"match_probability\": 0.76479, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004112459881071118}, {\"match_weight\": 1.78, \"match_probability\": 0.77471, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00413223132272833}, {\"match_weight\": 1.81, \"match_probability\": 0.77864, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004152002764385543}, {\"match_weight\": 1.87, \"match_probability\": 0.78483, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004171774206042755}, {\"match_weight\": 1.87, \"match_probability\": 0.78541, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004191545647699968}, {\"match_weight\": 1.9, \"match_probability\": 0.78879, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0042113170893571805}, {\"match_weight\": 1.91, \"match_probability\": 0.78958, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004231088531014393}, {\"match_weight\": 1.91, \"match_probability\": 0.79035, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.004270631414328818}, {\"match_weight\": 1.92, \"match_probability\": 0.79113, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004290402855986031}, {\"match_weight\": 1.92, \"match_probability\": 0.79114, \"prop\": 0.0006722290418110788, \"cum_prop\": 0.0049626318977971096}, {\"match_weight\": 1.95, \"match_probability\": 0.79405, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004982403339454322}, {\"match_weight\": 2.0, \"match_probability\": 0.80016, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005002174781111535}, {\"match_weight\": 2.0, \"match_probability\": 0.80024, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005021946222768747}, {\"match_weight\": 2.02, \"match_probability\": 0.80251, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00504171766442596}, {\"match_weight\": 2.03, \"match_probability\": 0.8033, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005061489106083172}, {\"match_weight\": 2.04, \"match_probability\": 0.80461, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005081260547740385}, {\"match_weight\": 2.09, \"match_probability\": 0.80943, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0051010319893975975}, {\"match_weight\": 2.12, \"match_probability\": 0.81326, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00512080343105481}, {\"match_weight\": 2.13, \"match_probability\": 0.81421, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005140574872712023}, {\"match_weight\": 2.17, \"match_probability\": 0.81855, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005160346314369235}, {\"match_weight\": 2.23, \"match_probability\": 0.82426, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005180117756026448}, {\"match_weight\": 2.23, \"match_probability\": 0.82437, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00519988919768366}, {\"match_weight\": 2.26, \"match_probability\": 0.82691, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005219660639340873}, {\"match_weight\": 2.3, \"match_probability\": 0.83101, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0052394320809980854}, {\"match_weight\": 2.3, \"match_probability\": 0.83116, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005259203522655298}, {\"match_weight\": 2.34, \"match_probability\": 0.8348, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0052789749643125106}, {\"match_weight\": 2.35, \"match_probability\": 0.83609, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005298746405969723}, {\"match_weight\": 2.39, \"match_probability\": 0.83941, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005318517847626936}, {\"match_weight\": 2.39, \"match_probability\": 0.83954, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005338289289284148}, {\"match_weight\": 2.42, \"match_probability\": 0.84286, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005358060730941361}, {\"match_weight\": 2.43, \"match_probability\": 0.84338, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005377832172598573}, {\"match_weight\": 2.45, \"match_probability\": 0.84573, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005397603614255786}, {\"match_weight\": 2.47, \"match_probability\": 0.84685, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0054173750559129985}, {\"match_weight\": 2.47, \"match_probability\": 0.84697, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005437146497570211}, {\"match_weight\": 2.51, \"match_probability\": 0.85073, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005456917939227424}, {\"match_weight\": 2.55, \"match_probability\": 0.85395, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005476689380884636}, {\"match_weight\": 2.56, \"match_probability\": 0.85535, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005496460822541849}, {\"match_weight\": 2.57, \"match_probability\": 0.85571, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005516232264199061}, {\"match_weight\": 2.6, \"match_probability\": 0.85801, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005536003705856274}, {\"match_weight\": 2.61, \"match_probability\": 0.85967, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0055557751475134864}, {\"match_weight\": 2.62, \"match_probability\": 0.86014, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005575546589170699}, {\"match_weight\": 2.64, \"match_probability\": 0.86158, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005595318030827912}, {\"match_weight\": 2.64, \"match_probability\": 0.86164, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005615089472485124}, {\"match_weight\": 2.65, \"match_probability\": 0.86256, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005634860914142337}, {\"match_weight\": 2.66, \"match_probability\": 0.86374, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005654632355799549}, {\"match_weight\": 2.67, \"match_probability\": 0.86414, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005674403797456762}, {\"match_weight\": 2.68, \"match_probability\": 0.86488, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005694175239113974}, {\"match_weight\": 2.69, \"match_probability\": 0.86608, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005713946680771187}, {\"match_weight\": 2.7, \"match_probability\": 0.86633, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0057337181224283995}, {\"match_weight\": 2.71, \"match_probability\": 0.86755, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005753489564085612}, {\"match_weight\": 2.74, \"match_probability\": 0.86968, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005773261005742825}, {\"match_weight\": 2.74, \"match_probability\": 0.87014, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005793032447400037}, {\"match_weight\": 2.75, \"match_probability\": 0.87046, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00581280388905725}, {\"match_weight\": 2.77, \"match_probability\": 0.872, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005832575330714462}, {\"match_weight\": 2.77, \"match_probability\": 0.87217, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.005891889657505089}, {\"match_weight\": 2.79, \"match_probability\": 0.87393, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005911661099162302}, {\"match_weight\": 2.84, \"match_probability\": 0.87741, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0059314325408195145}, {\"match_weight\": 2.84, \"match_probability\": 0.87777, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005951203982476727}, {\"match_weight\": 2.85, \"match_probability\": 0.878, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00597097542413394}, {\"match_weight\": 2.86, \"match_probability\": 0.87879, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005990746865791152}, {\"match_weight\": 2.87, \"match_probability\": 0.87933, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006010518307448365}, {\"match_weight\": 2.89, \"match_probability\": 0.88104, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006030289749105577}, {\"match_weight\": 2.9, \"match_probability\": 0.88181, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00605006119076279}, {\"match_weight\": 2.91, \"match_probability\": 0.88259, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0060698326324200025}, {\"match_weight\": 2.91, \"match_probability\": 0.88272, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006089604074077215}, {\"match_weight\": 2.98, \"match_probability\": 0.88739, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006109375515734428}, {\"match_weight\": 3.0, \"match_probability\": 0.88892, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.006148918399048853}, {\"match_weight\": 3.0, \"match_probability\": 0.88899, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006168689840706065}, {\"match_weight\": 3.0, \"match_probability\": 0.88904, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006188461282363278}, {\"match_weight\": 3.02, \"match_probability\": 0.89024, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00620823272402049}, {\"match_weight\": 3.04, \"match_probability\": 0.89166, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006228004165677703}, {\"match_weight\": 3.04, \"match_probability\": 0.89184, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0062477756073349155}, {\"match_weight\": 3.05, \"match_probability\": 0.89229, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006267547048992128}, {\"match_weight\": 3.08, \"match_probability\": 0.89399, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006287318490649341}, {\"match_weight\": 3.09, \"match_probability\": 0.89497, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006307089932306553}, {\"match_weight\": 3.1, \"match_probability\": 0.89533, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006326861373963766}, {\"match_weight\": 3.1, \"match_probability\": 0.89568, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006346632815620978}, {\"match_weight\": 3.11, \"match_probability\": 0.89639, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006366404257278191}, {\"match_weight\": 3.13, \"match_probability\": 0.89747, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0063861756989354035}, {\"match_weight\": 3.14, \"match_probability\": 0.89826, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006405947140592616}, {\"match_weight\": 3.18, \"match_probability\": 0.90049, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006425718582249829}, {\"match_weight\": 3.19, \"match_probability\": 0.90121, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006445490023907041}, {\"match_weight\": 3.19, \"match_probability\": 0.90137, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006465261465564254}, {\"match_weight\": 3.21, \"match_probability\": 0.90271, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006485032907221466}, {\"match_weight\": 3.23, \"match_probability\": 0.90393, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006504804348878679}, {\"match_weight\": 3.24, \"match_probability\": 0.90415, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006524575790535891}, {\"match_weight\": 3.28, \"match_probability\": 0.90638, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006544347232193104}, {\"match_weight\": 3.29, \"match_probability\": 0.90753, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0065641186738503166}, {\"match_weight\": 3.31, \"match_probability\": 0.90838, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006583890115507529}, {\"match_weight\": 3.31, \"match_probability\": 0.90846, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006603661557164742}, {\"match_weight\": 3.34, \"match_probability\": 0.90993, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006623432998821954}, {\"match_weight\": 3.34, \"match_probability\": 0.90999, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006643204440479167}, {\"match_weight\": 3.34, \"match_probability\": 0.91033, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006662975882136379}, {\"match_weight\": 3.34, \"match_probability\": 0.9104, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006682747323793592}, {\"match_weight\": 3.35, \"match_probability\": 0.9106, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0067025187654508045}, {\"match_weight\": 3.38, \"match_probability\": 0.9123, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006722290207108017}, {\"match_weight\": 3.38, \"match_probability\": 0.9124, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00674206164876523}, {\"match_weight\": 3.38, \"match_probability\": 0.91252, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006761833090422442}, {\"match_weight\": 3.39, \"match_probability\": 0.91304, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006781604532079655}, {\"match_weight\": 3.41, \"match_probability\": 0.91412, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006801375973736867}, {\"match_weight\": 3.42, \"match_probability\": 0.91452, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00682114741539408}, {\"match_weight\": 3.43, \"match_probability\": 0.91521, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0068409188570512924}, {\"match_weight\": 3.43, \"match_probability\": 0.91522, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006860690298708505}, {\"match_weight\": 3.44, \"match_probability\": 0.9156, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0068804617403657176}, {\"match_weight\": 3.45, \"match_probability\": 0.91606, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00690023318202293}, {\"match_weight\": 3.46, \"match_probability\": 0.91658, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006920004623680143}, {\"match_weight\": 3.46, \"match_probability\": 0.91681, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006939776065337355}, {\"match_weight\": 3.49, \"match_probability\": 0.91849, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006959547506994568}, {\"match_weight\": 3.53, \"match_probability\": 0.92024, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00697931894865178}, {\"match_weight\": 3.53, \"match_probability\": 0.92029, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006999090390308993}, {\"match_weight\": 3.54, \"match_probability\": 0.92058, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0070188618319662055}, {\"match_weight\": 3.54, \"match_probability\": 0.9206, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007038633273623418}, {\"match_weight\": 3.58, \"match_probability\": 0.9226, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007058404715280631}, {\"match_weight\": 3.58, \"match_probability\": 0.92265, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007078176156937843}, {\"match_weight\": 3.59, \"match_probability\": 0.92316, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007097947598595056}, {\"match_weight\": 3.59, \"match_probability\": 0.9232, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007117719040252268}, {\"match_weight\": 3.6, \"match_probability\": 0.92404, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007137490481909481}, {\"match_weight\": 3.61, \"match_probability\": 0.92443, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0071572619235666934}, {\"match_weight\": 3.61, \"match_probability\": 0.92454, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007177033365223906}, {\"match_weight\": 3.62, \"match_probability\": 0.92455, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0071968048068811186}, {\"match_weight\": 3.64, \"match_probability\": 0.92564, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007216576248538331}, {\"match_weight\": 3.65, \"match_probability\": 0.9262, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007236347690195544}, {\"match_weight\": 3.7, \"match_probability\": 0.92871, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007256119131852756}, {\"match_weight\": 3.7, \"match_probability\": 0.92877, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007275890573509969}, {\"match_weight\": 3.71, \"match_probability\": 0.92907, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007295662015167181}, {\"match_weight\": 3.72, \"match_probability\": 0.92964, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007315433456824394}, {\"match_weight\": 3.74, \"match_probability\": 0.93056, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0073352048984816065}, {\"match_weight\": 3.74, \"match_probability\": 0.93058, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007354976340138819}, {\"match_weight\": 3.76, \"match_probability\": 0.93134, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007374747781796032}, {\"match_weight\": 3.77, \"match_probability\": 0.93171, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007394519223453244}, {\"match_weight\": 3.78, \"match_probability\": 0.93222, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007414290665110457}, {\"match_weight\": 3.79, \"match_probability\": 0.93278, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007434062106767669}, {\"match_weight\": 3.8, \"match_probability\": 0.93317, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007453833548424882}, {\"match_weight\": 3.81, \"match_probability\": 0.93364, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0074736049900820944}, {\"match_weight\": 3.82, \"match_probability\": 0.93384, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007493376431739307}, {\"match_weight\": 3.84, \"match_probability\": 0.93486, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00751314787339652}, {\"match_weight\": 3.87, \"match_probability\": 0.93583, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007532919315053732}, {\"match_weight\": 3.87, \"match_probability\": 0.93609, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007552690756710945}, {\"match_weight\": 3.89, \"match_probability\": 0.93664, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007572462198368157}, {\"match_weight\": 3.9, \"match_probability\": 0.93732, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00759223364002537}, {\"match_weight\": 3.91, \"match_probability\": 0.9376, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007612005081682582}, {\"match_weight\": 3.91, \"match_probability\": 0.93761, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007631776523339795}, {\"match_weight\": 3.96, \"match_probability\": 0.93975, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00767131940665422}, {\"match_weight\": 3.97, \"match_probability\": 0.94004, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.007710862289968645}, {\"match_weight\": 3.97, \"match_probability\": 0.94006, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00775040517328307}, {\"match_weight\": 3.99, \"match_probability\": 0.94083, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007770176614940283}, {\"match_weight\": 4.0, \"match_probability\": 0.94113, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0077899480565974955}, {\"match_weight\": 4.0, \"match_probability\": 0.9412, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007809719498254708}, {\"match_weight\": 4.0, \"match_probability\": 0.94134, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00782949093991192}, {\"match_weight\": 4.01, \"match_probability\": 0.94149, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007849262381569133}, {\"match_weight\": 4.03, \"match_probability\": 0.9423, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.007888805264883558}, {\"match_weight\": 4.03, \"match_probability\": 0.94232, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00790857670654077}, {\"match_weight\": 4.05, \"match_probability\": 0.94318, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007928348148197983}, {\"match_weight\": 4.06, \"match_probability\": 0.94359, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007948119589855196}, {\"match_weight\": 4.07, \"match_probability\": 0.9438, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007967891031512409}, {\"match_weight\": 4.12, \"match_probability\": 0.94553, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008007433914826834}, {\"match_weight\": 4.17, \"match_probability\": 0.94723, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008027205356484046}, {\"match_weight\": 4.17, \"match_probability\": 0.94749, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008046976798141259}, {\"match_weight\": 4.18, \"match_probability\": 0.94784, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008066748239798471}, {\"match_weight\": 4.19, \"match_probability\": 0.9479, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008086519681455684}, {\"match_weight\": 4.19, \"match_probability\": 0.94802, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008106291123112896}, {\"match_weight\": 4.19, \"match_probability\": 0.94822, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008126062564770109}, {\"match_weight\": 4.2, \"match_probability\": 0.94829, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008145834006427322}, {\"match_weight\": 4.23, \"match_probability\": 0.94954, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008185376889741747}, {\"match_weight\": 4.24, \"match_probability\": 0.94957, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00820514833139896}, {\"match_weight\": 4.24, \"match_probability\": 0.94966, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008244691214713384}, {\"match_weight\": 4.24, \"match_probability\": 0.94984, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008264462656370597}, {\"match_weight\": 4.25, \"match_probability\": 0.94996, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008304005539685022}, {\"match_weight\": 4.26, \"match_probability\": 0.95031, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008323776981342235}, {\"match_weight\": 4.27, \"match_probability\": 0.95067, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008343548422999447}, {\"match_weight\": 4.27, \"match_probability\": 0.95084, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00836331986465666}, {\"match_weight\": 4.29, \"match_probability\": 0.95146, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008383091306313872}, {\"match_weight\": 4.34, \"match_probability\": 0.95281, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008402862747971085}, {\"match_weight\": 4.34, \"match_probability\": 0.95291, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008422634189628297}, {\"match_weight\": 4.36, \"match_probability\": 0.95342, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00844240563128551}, {\"match_weight\": 4.36, \"match_probability\": 0.95368, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008462177072942723}, {\"match_weight\": 4.38, \"match_probability\": 0.95403, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008481948514599935}, {\"match_weight\": 4.39, \"match_probability\": 0.95455, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008501719956257148}, {\"match_weight\": 4.39, \"match_probability\": 0.9546, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00852149139791436}, {\"match_weight\": 4.4, \"match_probability\": 0.95481, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008541262839571573}, {\"match_weight\": 4.42, \"match_probability\": 0.95537, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008561034281228785}, {\"match_weight\": 4.44, \"match_probability\": 0.95607, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008580805722885998}, {\"match_weight\": 4.45, \"match_probability\": 0.9562, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00860057716454321}, {\"match_weight\": 4.46, \"match_probability\": 0.95643, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008620348606200423}, {\"match_weight\": 4.47, \"match_probability\": 0.95679, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008640120047857636}, {\"match_weight\": 4.47, \"match_probability\": 0.95696, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008659891489514848}, {\"match_weight\": 4.48, \"match_probability\": 0.95709, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008699434372829273}, {\"match_weight\": 4.51, \"match_probability\": 0.958, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008719205814486486}, {\"match_weight\": 4.52, \"match_probability\": 0.95822, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008738977256143698}, {\"match_weight\": 4.57, \"match_probability\": 0.95966, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008758748697800911}, {\"match_weight\": 4.57, \"match_probability\": 0.95971, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008778520139458124}, {\"match_weight\": 4.58, \"match_probability\": 0.95994, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008798291581115336}, {\"match_weight\": 4.6, \"match_probability\": 0.96029, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008818063022772549}, {\"match_weight\": 4.6, \"match_probability\": 0.96031, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008837834464429761}, {\"match_weight\": 4.6, \"match_probability\": 0.96053, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008877377347744186}, {\"match_weight\": 4.61, \"match_probability\": 0.96063, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008897148789401399}, {\"match_weight\": 4.64, \"match_probability\": 0.96139, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008916920231058612}, {\"match_weight\": 4.64, \"match_probability\": 0.96152, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008936691672715824}, {\"match_weight\": 4.66, \"match_probability\": 0.96192, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008956463114373037}, {\"match_weight\": 4.67, \"match_probability\": 0.96227, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00897623455603025}, {\"match_weight\": 4.69, \"match_probability\": 0.96277, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008996005997687462}, {\"match_weight\": 4.7, \"match_probability\": 0.96307, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009015777439344674}, {\"match_weight\": 4.72, \"match_probability\": 0.96334, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009035548881001887}, {\"match_weight\": 4.73, \"match_probability\": 0.96378, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009075091764316312}, {\"match_weight\": 4.76, \"match_probability\": 0.96433, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009094863205973525}, {\"match_weight\": 4.76, \"match_probability\": 0.96441, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009114634647630737}, {\"match_weight\": 4.79, \"match_probability\": 0.96509, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00913440608928795}, {\"match_weight\": 4.8, \"match_probability\": 0.9653, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009154177530945162}, {\"match_weight\": 4.81, \"match_probability\": 0.96547, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009173948972602375}, {\"match_weight\": 4.81, \"match_probability\": 0.96553, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009193720414259587}, {\"match_weight\": 4.81, \"match_probability\": 0.96557, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0092134918559168}, {\"match_weight\": 4.81, \"match_probability\": 0.96568, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009233263297574013}, {\"match_weight\": 4.82, \"match_probability\": 0.96572, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009253034739231225}, {\"match_weight\": 4.85, \"match_probability\": 0.96647, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009272806180888438}, {\"match_weight\": 4.86, \"match_probability\": 0.96667, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00929257762254565}, {\"match_weight\": 4.88, \"match_probability\": 0.9672, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009312349064202863}, {\"match_weight\": 4.89, \"match_probability\": 0.96741, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009351891947517288}, {\"match_weight\": 4.9, \"match_probability\": 0.96765, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0093716633891745}, {\"match_weight\": 4.91, \"match_probability\": 0.96778, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009391434830831713}, {\"match_weight\": 4.91, \"match_probability\": 0.9678, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009411206272488926}, {\"match_weight\": 4.92, \"match_probability\": 0.96805, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009430977714146138}, {\"match_weight\": 4.93, \"match_probability\": 0.96816, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009470520597460563}, {\"match_weight\": 4.94, \"match_probability\": 0.96852, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009490292039117776}, {\"match_weight\": 4.96, \"match_probability\": 0.96885, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009510063480774988}, {\"match_weight\": 4.96, \"match_probability\": 0.96892, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009529834922432201}, {\"match_weight\": 4.97, \"match_probability\": 0.96913, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009549606364089414}, {\"match_weight\": 5.0, \"match_probability\": 0.96961, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009569377805746626}, {\"match_weight\": 5.0, \"match_probability\": 0.96965, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009589149247403839}, {\"match_weight\": 5.0, \"match_probability\": 0.96966, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009608920689061051}, {\"match_weight\": 5.01, \"match_probability\": 0.96982, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009628692130718264}, {\"match_weight\": 5.02, \"match_probability\": 0.97011, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009648463572375476}, {\"match_weight\": 5.02, \"match_probability\": 0.97016, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009668235014032689}, {\"match_weight\": 5.02, \"match_probability\": 0.9702, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009707777897347114}, {\"match_weight\": 5.03, \"match_probability\": 0.9703, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009727549339004327}, {\"match_weight\": 5.07, \"match_probability\": 0.97107, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00974732078066154}, {\"match_weight\": 5.11, \"match_probability\": 0.97182, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009767092222318752}, {\"match_weight\": 5.13, \"match_probability\": 0.97223, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009786863663975964}, {\"match_weight\": 5.13, \"match_probability\": 0.97225, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00982640654729039}, {\"match_weight\": 5.14, \"match_probability\": 0.97236, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009846177988947602}, {\"match_weight\": 5.16, \"match_probability\": 0.97282, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009865949430604815}, {\"match_weight\": 5.17, \"match_probability\": 0.97304, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.009945035197233665}, {\"match_weight\": 5.19, \"match_probability\": 0.97325, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009964806638890877}, {\"match_weight\": 5.2, \"match_probability\": 0.97343, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00998457808054809}, {\"match_weight\": 5.21, \"match_probability\": 0.97377, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010004349522205302}, {\"match_weight\": 5.22, \"match_probability\": 0.97387, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010043892405519728}, {\"match_weight\": 5.23, \"match_probability\": 0.97411, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01006366384717694}, {\"match_weight\": 5.24, \"match_probability\": 0.97417, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010103206730491365}, {\"match_weight\": 5.25, \"match_probability\": 0.97442, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01014274961380579}, {\"match_weight\": 5.26, \"match_probability\": 0.97451, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010162521055463003}, {\"match_weight\": 5.26, \"match_probability\": 0.97456, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010182292497120216}, {\"match_weight\": 5.27, \"match_probability\": 0.9747, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010202063938777428}, {\"match_weight\": 5.31, \"match_probability\": 0.97534, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01022183538043464}, {\"match_weight\": 5.31, \"match_probability\": 0.97542, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010241606822091853}, {\"match_weight\": 5.31, \"match_probability\": 0.97543, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010261378263749066}, {\"match_weight\": 5.37, \"match_probability\": 0.97635, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010281149705406278}, {\"match_weight\": 5.38, \"match_probability\": 0.97652, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010300921147063491}, {\"match_weight\": 5.38, \"match_probability\": 0.97656, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010340464030377916}, {\"match_weight\": 5.39, \"match_probability\": 0.97671, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010360235472035129}, {\"match_weight\": 5.39, \"match_probability\": 0.97677, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010399778355349554}, {\"match_weight\": 5.4, \"match_probability\": 0.97681, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010419549797006766}, {\"match_weight\": 5.41, \"match_probability\": 0.97698, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010439321238663979}, {\"match_weight\": 5.42, \"match_probability\": 0.97718, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010478864121978404}, {\"match_weight\": 5.43, \"match_probability\": 0.97731, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010498635563635617}, {\"match_weight\": 5.43, \"match_probability\": 0.97736, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010518407005292829}, {\"match_weight\": 5.45, \"match_probability\": 0.9777, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010538178446950042}, {\"match_weight\": 5.47, \"match_probability\": 0.97789, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010557949888607254}, {\"match_weight\": 5.47, \"match_probability\": 0.97793, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010577721330264467}, {\"match_weight\": 5.48, \"match_probability\": 0.97802, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01059749277192168}, {\"match_weight\": 5.48, \"match_probability\": 0.9781, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010617264213578892}, {\"match_weight\": 5.48, \"match_probability\": 0.97812, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010656807096893317}, {\"match_weight\": 5.48, \"match_probability\": 0.97813, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010696349980207742}, {\"match_weight\": 5.5, \"match_probability\": 0.97839, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010716121421864955}, {\"match_weight\": 5.52, \"match_probability\": 0.97863, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01075566430517938}, {\"match_weight\": 5.52, \"match_probability\": 0.97874, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010775435746836592}, {\"match_weight\": 5.54, \"match_probability\": 0.97889, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010795207188493805}, {\"match_weight\": 5.55, \"match_probability\": 0.97905, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010814978630151018}, {\"match_weight\": 5.59, \"match_probability\": 0.97959, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01083475007180823}, {\"match_weight\": 5.6, \"match_probability\": 0.97974, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010854521513465443}, {\"match_weight\": 5.6, \"match_probability\": 0.97981, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010874292955122655}, {\"match_weight\": 5.6, \"match_probability\": 0.97986, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010894064396779868}, {\"match_weight\": 5.61, \"match_probability\": 0.98, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010933607280094293}, {\"match_weight\": 5.62, \"match_probability\": 0.98003, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010953378721751506}, {\"match_weight\": 5.63, \"match_probability\": 0.98015, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010973150163408718}, {\"match_weight\": 5.64, \"match_probability\": 0.98031, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.011131321696666419}, {\"match_weight\": 5.65, \"match_probability\": 0.98042, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011151093138323631}, {\"match_weight\": 5.66, \"match_probability\": 0.98062, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.011190636021638056}, {\"match_weight\": 5.67, \"match_probability\": 0.98072, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011210407463295269}, {\"match_weight\": 5.67, \"match_probability\": 0.98074, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.011249950346609694}, {\"match_weight\": 5.69, \"match_probability\": 0.98098, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.011309264673400321}, {\"match_weight\": 5.7, \"match_probability\": 0.9811, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.011348807556714746}, {\"match_weight\": 5.7, \"match_probability\": 0.98116, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011368578998371959}, {\"match_weight\": 5.73, \"match_probability\": 0.98156, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011388350440029171}, {\"match_weight\": 5.74, \"match_probability\": 0.9816, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011408121881686384}, {\"match_weight\": 5.75, \"match_probability\": 0.98181, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011427893323343596}, {\"match_weight\": 5.76, \"match_probability\": 0.98193, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011447664765000809}, {\"match_weight\": 5.78, \"match_probability\": 0.98208, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011467436206658022}, {\"match_weight\": 5.83, \"match_probability\": 0.98275, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011487207648315234}, {\"match_weight\": 5.83, \"match_probability\": 0.98276, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011506979089972447}, {\"match_weight\": 5.84, \"match_probability\": 0.98286, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01152675053162966}, {\"match_weight\": 5.85, \"match_probability\": 0.98297, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011546521973286872}, {\"match_weight\": 5.86, \"match_probability\": 0.98309, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011566293414944084}, {\"match_weight\": 5.87, \"match_probability\": 0.98315, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011586064856601297}, {\"match_weight\": 5.87, \"match_probability\": 0.98322, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.011625607739915722}, {\"match_weight\": 5.88, \"match_probability\": 0.98326, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011645379181572935}, {\"match_weight\": 5.89, \"match_probability\": 0.9834, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011665150623230147}, {\"match_weight\": 5.9, \"match_probability\": 0.98351, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01168492206488736}, {\"match_weight\": 5.91, \"match_probability\": 0.98363, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.011744236391677987}, {\"match_weight\": 5.92, \"match_probability\": 0.98376, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0117640078333352}, {\"match_weight\": 5.92, \"match_probability\": 0.9838, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011783779274992412}, {\"match_weight\": 5.94, \"match_probability\": 0.98395, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011803550716649625}, {\"match_weight\": 5.95, \"match_probability\": 0.98405, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011823322158306837}, {\"match_weight\": 5.95, \"match_probability\": 0.98411, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01184309359996405}, {\"match_weight\": 5.96, \"match_probability\": 0.98414, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011862865041621262}, {\"match_weight\": 5.96, \"match_probability\": 0.98418, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011882636483278475}, {\"match_weight\": 5.96, \"match_probability\": 0.9842, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011902407924935687}, {\"match_weight\": 5.96, \"match_probability\": 0.98422, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0119221793665929}, {\"match_weight\": 5.97, \"match_probability\": 0.98432, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011941950808250112}, {\"match_weight\": 5.98, \"match_probability\": 0.98439, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011961722249907325}, {\"match_weight\": 5.99, \"match_probability\": 0.9845, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011981493691564538}, {\"match_weight\": 6.0, \"match_probability\": 0.98459, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01200126513322175}, {\"match_weight\": 6.01, \"match_probability\": 0.98473, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012021036574878963}, {\"match_weight\": 6.02, \"match_probability\": 0.98482, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012040808016536175}, {\"match_weight\": 6.03, \"match_probability\": 0.98492, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012060579458193388}, {\"match_weight\": 6.03, \"match_probability\": 0.98493, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0120803508998506}, {\"match_weight\": 6.03, \"match_probability\": 0.98496, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012100122341507813}, {\"match_weight\": 6.04, \"match_probability\": 0.98505, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012119893783165026}, {\"match_weight\": 6.04, \"match_probability\": 0.98507, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012139665224822238}, {\"match_weight\": 6.05, \"match_probability\": 0.9851, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01215943666647945}, {\"match_weight\": 6.06, \"match_probability\": 0.98519, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012179208108136663}, {\"match_weight\": 6.07, \"match_probability\": 0.9853, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012218750991451088}, {\"match_weight\": 6.07, \"match_probability\": 0.98537, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012238522433108301}, {\"match_weight\": 6.08, \"match_probability\": 0.98545, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012258293874765513}, {\"match_weight\": 6.09, \"match_probability\": 0.98554, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012278065316422726}, {\"match_weight\": 6.09, \"match_probability\": 0.98555, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012317608199737151}, {\"match_weight\": 6.12, \"match_probability\": 0.9858, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012337379641394364}, {\"match_weight\": 6.12, \"match_probability\": 0.98583, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012357151083051576}, {\"match_weight\": 6.12, \"match_probability\": 0.98586, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012376922524708789}, {\"match_weight\": 6.13, \"match_probability\": 0.98592, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012416465408023214}, {\"match_weight\": 6.13, \"match_probability\": 0.98593, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012436236849680427}, {\"match_weight\": 6.15, \"match_probability\": 0.98615, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012475779732994852}, {\"match_weight\": 6.16, \"match_probability\": 0.98622, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012495551174652064}, {\"match_weight\": 6.17, \"match_probability\": 0.98631, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012515322616309277}, {\"match_weight\": 6.18, \"match_probability\": 0.98635, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01253509405796649}, {\"match_weight\": 6.18, \"match_probability\": 0.98643, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012554865499623702}, {\"match_weight\": 6.19, \"match_probability\": 0.98653, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012594408382938127}, {\"match_weight\": 6.2, \"match_probability\": 0.98656, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01261417982459534}, {\"match_weight\": 6.21, \"match_probability\": 0.98668, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012633951266252552}, {\"match_weight\": 6.21, \"match_probability\": 0.9867, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.01269326559304318}, {\"match_weight\": 6.22, \"match_probability\": 0.98677, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012713037034700392}, {\"match_weight\": 6.23, \"match_probability\": 0.98689, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012732808476357604}, {\"match_weight\": 6.24, \"match_probability\": 0.98693, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012752579918014817}, {\"match_weight\": 6.24, \"match_probability\": 0.98695, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01277235135967203}, {\"match_weight\": 6.24, \"match_probability\": 0.98696, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012792122801329242}, {\"match_weight\": 6.26, \"match_probability\": 0.98712, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012831665684643667}, {\"match_weight\": 6.27, \"match_probability\": 0.98717, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01285143712630088}, {\"match_weight\": 6.29, \"match_probability\": 0.98736, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012871208567958092}, {\"match_weight\": 6.3, \"match_probability\": 0.98743, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012890980009615305}, {\"match_weight\": 6.3, \"match_probability\": 0.98748, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012910751451272517}, {\"match_weight\": 6.3, \"match_probability\": 0.9875, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01293052289292973}, {\"match_weight\": 6.31, \"match_probability\": 0.98751, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012950294334586943}, {\"match_weight\": 6.31, \"match_probability\": 0.98758, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012970065776244155}, {\"match_weight\": 6.33, \"match_probability\": 0.98775, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012989837217901368}, {\"match_weight\": 6.34, \"match_probability\": 0.98783, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013029380101215793}, {\"match_weight\": 6.34, \"match_probability\": 0.98785, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013049151542873005}, {\"match_weight\": 6.35, \"match_probability\": 0.98791, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013068922984530218}, {\"match_weight\": 6.36, \"match_probability\": 0.98793, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013108465867844643}, {\"match_weight\": 6.37, \"match_probability\": 0.98808, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013128237309501856}, {\"match_weight\": 6.39, \"match_probability\": 0.98821, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013148008751159068}, {\"match_weight\": 6.4, \"match_probability\": 0.98828, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01316778019281628}, {\"match_weight\": 6.4, \"match_probability\": 0.9883, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013187551634473493}, {\"match_weight\": 6.41, \"match_probability\": 0.98834, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013207323076130706}, {\"match_weight\": 6.41, \"match_probability\": 0.98839, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013227094517787918}, {\"match_weight\": 6.42, \"match_probability\": 0.98843, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013246865959445131}, {\"match_weight\": 6.42, \"match_probability\": 0.98846, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013266637401102344}, {\"match_weight\": 6.43, \"match_probability\": 0.98851, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013286408842759556}, {\"match_weight\": 6.43, \"match_probability\": 0.98854, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013306180284416769}, {\"match_weight\": 6.46, \"match_probability\": 0.98874, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013325951726073981}, {\"match_weight\": 6.46, \"match_probability\": 0.98879, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013365494609388406}, {\"match_weight\": 6.46, \"match_probability\": 0.9888, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013385266051045619}, {\"match_weight\": 6.47, \"match_probability\": 0.98885, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013405037492702832}, {\"match_weight\": 6.47, \"match_probability\": 0.98887, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013424808934360044}, {\"match_weight\": 6.48, \"match_probability\": 0.98889, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013444580376017257}, {\"match_weight\": 6.49, \"match_probability\": 0.98897, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01346435181767447}, {\"match_weight\": 6.51, \"match_probability\": 0.98911, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013484123259331682}, {\"match_weight\": 6.51, \"match_probability\": 0.98912, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013503894700988894}, {\"match_weight\": 6.51, \"match_probability\": 0.98914, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013523666142646107}, {\"match_weight\": 6.51, \"match_probability\": 0.98916, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01354343758430332}, {\"match_weight\": 6.51, \"match_probability\": 0.98918, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013563209025960532}, {\"match_weight\": 6.53, \"match_probability\": 0.98926, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013582980467617745}, {\"match_weight\": 6.54, \"match_probability\": 0.98933, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.013642294794408372}, {\"match_weight\": 6.54, \"match_probability\": 0.9894, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013662066236065584}, {\"match_weight\": 6.55, \"match_probability\": 0.98941, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013681837677722797}, {\"match_weight\": 6.56, \"match_probability\": 0.98948, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01370160911938001}, {\"match_weight\": 6.56, \"match_probability\": 0.9895, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013721380561037222}, {\"match_weight\": 6.56, \"match_probability\": 0.98952, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013741152002694434}, {\"match_weight\": 6.58, \"match_probability\": 0.98968, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013760923444351647}, {\"match_weight\": 6.59, \"match_probability\": 0.98972, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.013820237771142274}, {\"match_weight\": 6.59, \"match_probability\": 0.98975, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013840009212799487}, {\"match_weight\": 6.6, \"match_probability\": 0.98977, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0138597806544567}, {\"match_weight\": 6.6, \"match_probability\": 0.9898, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013879552096113912}, {\"match_weight\": 6.62, \"match_probability\": 0.98993, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013919094979428337}, {\"match_weight\": 6.63, \"match_probability\": 0.98998, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013958637862742762}, {\"match_weight\": 6.63, \"match_probability\": 0.98999, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013978409304399975}, {\"match_weight\": 6.64, \"match_probability\": 0.99005, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.014037723631190602}, {\"match_weight\": 6.64, \"match_probability\": 0.99008, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014077266514505027}, {\"match_weight\": 6.64, \"match_probability\": 0.99009, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01409703795616224}, {\"match_weight\": 6.65, \"match_probability\": 0.99014, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014116809397819452}, {\"match_weight\": 6.66, \"match_probability\": 0.99021, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014156352281133877}, {\"match_weight\": 6.68, \"match_probability\": 0.99035, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01417612372279109}, {\"match_weight\": 6.7, \"match_probability\": 0.99046, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014195895164448302}, {\"match_weight\": 6.71, \"match_probability\": 0.99054, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014215666606105515}, {\"match_weight\": 6.72, \"match_probability\": 0.99061, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014235438047762727}, {\"match_weight\": 6.72, \"match_probability\": 0.99063, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014274980931077152}, {\"match_weight\": 6.74, \"match_probability\": 0.99071, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014294752372734365}, {\"match_weight\": 6.75, \"match_probability\": 0.9908, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01433429525604879}, {\"match_weight\": 6.76, \"match_probability\": 0.99085, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014354066697706003}, {\"match_weight\": 6.76, \"match_probability\": 0.99086, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014393609581020428}, {\"match_weight\": 6.76, \"match_probability\": 0.99088, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01441338102267764}, {\"match_weight\": 6.77, \"match_probability\": 0.9909, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014433152464334853}, {\"match_weight\": 6.77, \"match_probability\": 0.99091, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014452923905992066}, {\"match_weight\": 6.78, \"match_probability\": 0.99096, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01449246678930649}, {\"match_weight\": 6.78, \"match_probability\": 0.99098, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014512238230963703}, {\"match_weight\": 6.79, \"match_probability\": 0.99102, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014532009672620916}, {\"match_weight\": 6.8, \"match_probability\": 0.9911, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014551781114278128}, {\"match_weight\": 6.81, \"match_probability\": 0.99115, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014571552555935341}, {\"match_weight\": 6.81, \"match_probability\": 0.99116, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014611095439249766}, {\"match_weight\": 6.83, \"match_probability\": 0.99127, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014630866880906979}, {\"match_weight\": 6.83, \"match_probability\": 0.9913, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014650638322564191}, {\"match_weight\": 6.83, \"match_probability\": 0.99131, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014670409764221404}, {\"match_weight\": 6.84, \"match_probability\": 0.99132, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014690181205878616}, {\"match_weight\": 6.85, \"match_probability\": 0.99143, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014709952647535829}, {\"match_weight\": 6.88, \"match_probability\": 0.99156, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014729724089193041}, {\"match_weight\": 6.88, \"match_probability\": 0.99158, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014749495530850254}, {\"match_weight\": 6.9, \"match_probability\": 0.9917, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014769266972507467}, {\"match_weight\": 6.9, \"match_probability\": 0.99172, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014789038414164679}, {\"match_weight\": 6.93, \"match_probability\": 0.99185, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014808809855821892}, {\"match_weight\": 6.93, \"match_probability\": 0.99188, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014828581297479104}, {\"match_weight\": 6.94, \"match_probability\": 0.99192, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014848352739136317}, {\"match_weight\": 6.94, \"match_probability\": 0.99193, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01486812418079353}, {\"match_weight\": 6.94, \"match_probability\": 0.99195, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014887895622450742}, {\"match_weight\": 6.95, \"match_probability\": 0.99198, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014907667064107955}, {\"match_weight\": 6.96, \"match_probability\": 0.99201, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014927438505765167}, {\"match_weight\": 6.96, \"match_probability\": 0.99203, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014966981389079592}, {\"match_weight\": 6.96, \"match_probability\": 0.99205, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014986752830736805}, {\"match_weight\": 6.97, \"match_probability\": 0.99207, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015006524272394017}, {\"match_weight\": 6.97, \"match_probability\": 0.9921, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01502629571405123}, {\"match_weight\": 6.98, \"match_probability\": 0.99212, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015046067155708442}, {\"match_weight\": 6.98, \"match_probability\": 0.99214, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015085610039022868}, {\"match_weight\": 6.99, \"match_probability\": 0.99219, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01510538148068008}, {\"match_weight\": 6.99, \"match_probability\": 0.99221, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015125152922337293}, {\"match_weight\": 7.0, \"match_probability\": 0.99224, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015144924363994505}, {\"match_weight\": 7.01, \"match_probability\": 0.99231, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01518446724730893}, {\"match_weight\": 7.01, \"match_probability\": 0.99232, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015224010130623356}, {\"match_weight\": 7.03, \"match_probability\": 0.9924, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015243781572280568}, {\"match_weight\": 7.03, \"match_probability\": 0.99241, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01526355301393778}, {\"match_weight\": 7.03, \"match_probability\": 0.99242, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015283324455594993}, {\"match_weight\": 7.05, \"match_probability\": 0.99249, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015303095897252206}, {\"match_weight\": 7.06, \"match_probability\": 0.99255, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015322867338909418}, {\"match_weight\": 7.06, \"match_probability\": 0.99258, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015342638780566631}, {\"match_weight\": 7.07, \"match_probability\": 0.9926, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015362410222223843}, {\"match_weight\": 7.07, \"match_probability\": 0.99262, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015382181663881056}, {\"match_weight\": 7.07, \"match_probability\": 0.99263, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015401953105538269}, {\"match_weight\": 7.08, \"match_probability\": 0.99265, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015421724547195481}, {\"match_weight\": 7.09, \"match_probability\": 0.99272, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015441495988852694}, {\"match_weight\": 7.1, \"match_probability\": 0.99277, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015461267430509906}, {\"match_weight\": 7.11, \"match_probability\": 0.99283, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015500810313824331}, {\"match_weight\": 7.12, \"match_probability\": 0.99286, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015520581755481544}, {\"match_weight\": 7.15, \"match_probability\": 0.99299, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015540353197138757}, {\"match_weight\": 7.15, \"match_probability\": 0.993, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015579896080453182}, {\"match_weight\": 7.15, \"match_probability\": 0.99303, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015599667522110394}, {\"match_weight\": 7.17, \"match_probability\": 0.99309, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015619438963767607}, {\"match_weight\": 7.18, \"match_probability\": 0.99314, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01563921040542482}, {\"match_weight\": 7.2, \"match_probability\": 0.99325, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015678753288739244}, {\"match_weight\": 7.21, \"match_probability\": 0.99329, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01571829617205367}, {\"match_weight\": 7.21, \"match_probability\": 0.9933, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015738067613710882}, {\"match_weight\": 7.21, \"match_probability\": 0.99331, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015757839055368095}, {\"match_weight\": 7.23, \"match_probability\": 0.9934, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015777610497025307}, {\"match_weight\": 7.24, \"match_probability\": 0.99342, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01579738193868252}, {\"match_weight\": 7.24, \"match_probability\": 0.99344, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015817153380339732}, {\"match_weight\": 7.24, \"match_probability\": 0.99345, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015836924821996945}, {\"match_weight\": 7.25, \"match_probability\": 0.99347, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015856696263654158}, {\"match_weight\": 7.26, \"match_probability\": 0.99352, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01587646770531137}, {\"match_weight\": 7.27, \"match_probability\": 0.99355, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.015935782032101997}, {\"match_weight\": 7.27, \"match_probability\": 0.99358, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01595555347375921}, {\"match_weight\": 7.28, \"match_probability\": 0.99359, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015975324915416422}, {\"match_weight\": 7.28, \"match_probability\": 0.99362, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015995096357073635}, {\"match_weight\": 7.3, \"match_probability\": 0.99367, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016014867798730847}, {\"match_weight\": 7.3, \"match_probability\": 0.9937, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01603463924038806}, {\"match_weight\": 7.3, \"match_probability\": 0.99371, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016054410682045273}, {\"match_weight\": 7.31, \"match_probability\": 0.99373, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016074182123702485}, {\"match_weight\": 7.31, \"match_probability\": 0.99375, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01611372500701691}, {\"match_weight\": 7.31, \"match_probability\": 0.99376, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016133496448674123}, {\"match_weight\": 7.32, \"match_probability\": 0.99377, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016153267890331335}, {\"match_weight\": 7.32, \"match_probability\": 0.99379, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016173039331988548}, {\"match_weight\": 7.34, \"match_probability\": 0.99385, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016212582215302973}, {\"match_weight\": 7.35, \"match_probability\": 0.99392, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016232353656960186}, {\"match_weight\": 7.36, \"match_probability\": 0.99393, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016252125098617398}, {\"match_weight\": 7.36, \"match_probability\": 0.99395, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01627189654027461}, {\"match_weight\": 7.36, \"match_probability\": 0.99396, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016311439423589036}, {\"match_weight\": 7.37, \"match_probability\": 0.99397, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01633121086524625}, {\"match_weight\": 7.37, \"match_probability\": 0.99399, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01635098230690346}, {\"match_weight\": 7.38, \"match_probability\": 0.99402, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016370753748560674}, {\"match_weight\": 7.38, \"match_probability\": 0.99405, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0164102966318751}, {\"match_weight\": 7.39, \"match_probability\": 0.99406, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016449839515189524}, {\"match_weight\": 7.39, \"match_probability\": 0.99409, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016469610956846736}, {\"match_weight\": 7.4, \"match_probability\": 0.9941, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01648938239850395}, {\"match_weight\": 7.4, \"match_probability\": 0.99412, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016528925281818374}, {\"match_weight\": 7.4, \"match_probability\": 0.99413, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016548696723475587}, {\"match_weight\": 7.41, \"match_probability\": 0.99415, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0165684681651328}, {\"match_weight\": 7.42, \"match_probability\": 0.99421, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016588239606790012}, {\"match_weight\": 7.43, \"match_probability\": 0.99422, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016627782490104437}, {\"match_weight\": 7.44, \"match_probability\": 0.99429, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01664755393176165}, {\"match_weight\": 7.46, \"match_probability\": 0.99437, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016667325373418862}, {\"match_weight\": 7.48, \"match_probability\": 0.99442, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016706868256733287}, {\"match_weight\": 7.48, \"match_probability\": 0.99444, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0167266396983905}, {\"match_weight\": 7.49, \"match_probability\": 0.99447, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016746411140047712}, {\"match_weight\": 7.5, \"match_probability\": 0.99451, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016766182581704925}, {\"match_weight\": 7.51, \"match_probability\": 0.99453, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016785954023362137}, {\"match_weight\": 7.51, \"match_probability\": 0.99454, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016825496906676563}, {\"match_weight\": 7.54, \"match_probability\": 0.99467, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016845268348333775}, {\"match_weight\": 7.55, \"match_probability\": 0.99468, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016865039789990988}, {\"match_weight\": 7.56, \"match_probability\": 0.99474, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0168848112316482}, {\"match_weight\": 7.58, \"match_probability\": 0.99481, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016904582673305413}, {\"match_weight\": 7.6, \"match_probability\": 0.99487, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016944125556619838}, {\"match_weight\": 7.6, \"match_probability\": 0.99489, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01696389699827705}, {\"match_weight\": 7.61, \"match_probability\": 0.99491, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016983668439934263}, {\"match_weight\": 7.61, \"match_probability\": 0.99492, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017003439881591476}, {\"match_weight\": 7.62, \"match_probability\": 0.99494, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017023211323248688}, {\"match_weight\": 7.62, \"match_probability\": 0.99495, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0170429827649059}, {\"match_weight\": 7.64, \"match_probability\": 0.99502, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.017102297091696528}, {\"match_weight\": 7.64, \"match_probability\": 0.99503, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01712206853335374}, {\"match_weight\": 7.65, \"match_probability\": 0.99504, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017141839975010953}, {\"match_weight\": 7.65, \"match_probability\": 0.99505, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017181382858325378}, {\"match_weight\": 7.67, \"match_probability\": 0.9951, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01720115429998259}, {\"match_weight\": 7.67, \"match_probability\": 0.99512, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017220925741639803}, {\"match_weight\": 7.68, \"match_probability\": 0.99514, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017240697183297016}, {\"match_weight\": 7.68, \"match_probability\": 0.99516, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01726046862495423}, {\"match_weight\": 7.69, \"match_probability\": 0.99517, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01728024006661144}, {\"match_weight\": 7.69, \"match_probability\": 0.99518, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017300011508268653}, {\"match_weight\": 7.7, \"match_probability\": 0.99521, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.01735932583505928}, {\"match_weight\": 7.72, \"match_probability\": 0.99528, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017379097276716493}, {\"match_weight\": 7.73, \"match_probability\": 0.99532, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017398868718373706}, {\"match_weight\": 7.74, \"match_probability\": 0.99533, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017418640160030918}, {\"match_weight\": 7.74, \"match_probability\": 0.99534, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.017477954486821545}, {\"match_weight\": 7.75, \"match_probability\": 0.99538, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01751749737013597}, {\"match_weight\": 7.76, \"match_probability\": 0.9954, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017557040253450396}, {\"match_weight\": 7.77, \"match_probability\": 0.99543, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01759658313676482}, {\"match_weight\": 7.77, \"match_probability\": 0.99544, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017616354578422033}, {\"match_weight\": 7.77, \"match_probability\": 0.99545, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017636126020079246}, {\"match_weight\": 7.78, \"match_probability\": 0.99547, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01765589746173646}, {\"match_weight\": 7.79, \"match_probability\": 0.9955, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.017715211788527085}, {\"match_weight\": 7.8, \"match_probability\": 0.99552, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017734983230184298}, {\"match_weight\": 7.8, \"match_probability\": 0.99553, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.01783384044392733}, {\"match_weight\": 7.8, \"match_probability\": 0.99554, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01785361188558454}, {\"match_weight\": 7.81, \"match_probability\": 0.99555, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017873383327241754}, {\"match_weight\": 7.81, \"match_probability\": 0.99557, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017893154768898967}, {\"match_weight\": 7.82, \"match_probability\": 0.99558, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017932697652213392}, {\"match_weight\": 7.82, \"match_probability\": 0.9956, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017952469093870604}, {\"match_weight\": 7.82, \"match_probability\": 0.99561, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01799201197718503}, {\"match_weight\": 7.84, \"match_probability\": 0.99565, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.018051326303975657}, {\"match_weight\": 7.85, \"match_probability\": 0.99567, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018090869187290082}, {\"match_weight\": 7.85, \"match_probability\": 0.99569, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018130412070604507}, {\"match_weight\": 7.86, \"match_probability\": 0.99572, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01815018351226172}, {\"match_weight\": 7.89, \"match_probability\": 0.9958, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018169954953918932}, {\"match_weight\": 7.9, \"match_probability\": 0.99582, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018189726395576145}, {\"match_weight\": 7.91, \"match_probability\": 0.99585, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018209497837233357}, {\"match_weight\": 7.91, \"match_probability\": 0.99586, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018249040720547782}, {\"match_weight\": 7.92, \"match_probability\": 0.99588, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018268812162204995}, {\"match_weight\": 7.93, \"match_probability\": 0.9959, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01830835504551942}, {\"match_weight\": 7.93, \"match_probability\": 0.99591, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018347897928833845}, {\"match_weight\": 7.94, \"match_probability\": 0.99595, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01838744081214827}, {\"match_weight\": 7.95, \"match_probability\": 0.99596, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018407212253805483}, {\"match_weight\": 7.95, \"match_probability\": 0.99597, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018426983695462695}, {\"match_weight\": 7.95, \"match_probability\": 0.99598, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018446755137119908}, {\"match_weight\": 7.98, \"match_probability\": 0.99605, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018486298020434333}, {\"match_weight\": 7.98, \"match_probability\": 0.99606, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018506069462091546}, {\"match_weight\": 7.99, \"match_probability\": 0.99608, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018525840903748758}, {\"match_weight\": 8.0, \"match_probability\": 0.99611, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018565383787063183}, {\"match_weight\": 8.01, \"match_probability\": 0.99612, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01860492667037761}, {\"match_weight\": 8.01, \"match_probability\": 0.99614, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01862469811203482}, {\"match_weight\": 8.02, \"match_probability\": 0.99616, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018644469553692034}, {\"match_weight\": 8.03, \"match_probability\": 0.99618, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018664240995349246}, {\"match_weight\": 8.03, \"match_probability\": 0.99619, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01868401243700646}, {\"match_weight\": 8.04, \"match_probability\": 0.99622, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018723555320320884}, {\"match_weight\": 8.05, \"match_probability\": 0.99625, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01876309820363531}, {\"match_weight\": 8.06, \"match_probability\": 0.99626, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.018822412530425936}, {\"match_weight\": 8.06, \"match_probability\": 0.99628, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01884218397208315}, {\"match_weight\": 8.07, \"match_probability\": 0.9963, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01886195541374036}, {\"match_weight\": 8.08, \"match_probability\": 0.99631, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018901498297054786}, {\"match_weight\": 8.08, \"match_probability\": 0.99632, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018921269738712}, {\"match_weight\": 8.08, \"match_probability\": 0.99633, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01894104118036921}, {\"match_weight\": 8.1, \"match_probability\": 0.99636, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018980584063683636}, {\"match_weight\": 8.11, \"match_probability\": 0.99639, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.019039898390474264}, {\"match_weight\": 8.11, \"match_probability\": 0.9964, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019059669832131476}, {\"match_weight\": 8.12, \"match_probability\": 0.99642, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.019158527045874507}, {\"match_weight\": 8.12, \"match_probability\": 0.99643, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01917829848753172}, {\"match_weight\": 8.13, \"match_probability\": 0.99644, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019198069929188932}, {\"match_weight\": 8.14, \"match_probability\": 0.99646, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019217841370846145}, {\"match_weight\": 8.14, \"match_probability\": 0.99647, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019237612812503357}, {\"match_weight\": 8.15, \"match_probability\": 0.99649, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01925738425416057}, {\"match_weight\": 8.16, \"match_probability\": 0.99652, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019277155695817783}, {\"match_weight\": 8.17, \"match_probability\": 0.99653, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019296927137474995}, {\"match_weight\": 8.17, \"match_probability\": 0.99654, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019316698579132208}, {\"match_weight\": 8.17, \"match_probability\": 0.99655, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01933647002078942}, {\"match_weight\": 8.19, \"match_probability\": 0.99658, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.019395784347580047}, {\"match_weight\": 8.2, \"match_probability\": 0.99662, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.019435327230894472}, {\"match_weight\": 8.21, \"match_probability\": 0.99663, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019455098672551685}, {\"match_weight\": 8.22, \"match_probability\": 0.99665, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019474870114208898}, {\"match_weight\": 8.22, \"match_probability\": 0.99666, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01949464155586611}, {\"match_weight\": 8.23, \"match_probability\": 0.99667, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019514412997523323}, {\"match_weight\": 8.23, \"match_probability\": 0.99668, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019534184439180535}, {\"match_weight\": 8.24, \"match_probability\": 0.9967, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019553955880837748}, {\"match_weight\": 8.25, \"match_probability\": 0.99673, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.019633041647466598}, {\"match_weight\": 8.26, \"match_probability\": 0.99674, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01965281308912381}, {\"match_weight\": 8.27, \"match_probability\": 0.99677, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019672584530781023}, {\"match_weight\": 8.28, \"match_probability\": 0.99679, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019692355972438236}, {\"match_weight\": 8.28, \"match_probability\": 0.9968, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01973189885575266}, {\"match_weight\": 8.29, \"match_probability\": 0.99682, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019751670297409873}, {\"match_weight\": 8.3, \"match_probability\": 0.99685, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019771441739067086}, {\"match_weight\": 8.31, \"match_probability\": 0.99686, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.019830756065857713}, {\"match_weight\": 8.31, \"match_probability\": 0.99687, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.019870298949172138}, {\"match_weight\": 8.33, \"match_probability\": 0.99689, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01989007039082935}, {\"match_weight\": 8.33, \"match_probability\": 0.9969, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019909841832486563}, {\"match_weight\": 8.34, \"match_probability\": 0.99692, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019929613274143776}, {\"match_weight\": 8.34, \"match_probability\": 0.99693, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0199691561574582}, {\"match_weight\": 8.36, \"match_probability\": 0.99696, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019988927599115414}, {\"match_weight\": 8.36, \"match_probability\": 0.99697, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020008699040772626}, {\"match_weight\": 8.37, \"match_probability\": 0.99698, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02002847048242984}, {\"match_weight\": 8.38, \"match_probability\": 0.997, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020068013365744264}, {\"match_weight\": 8.38, \"match_probability\": 0.99701, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020087784807401476}, {\"match_weight\": 8.39, \"match_probability\": 0.99703, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02010755624905869}, {\"match_weight\": 8.4, \"match_probability\": 0.99704, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0201273276907159}, {\"match_weight\": 8.41, \"match_probability\": 0.99707, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020147099132373114}, {\"match_weight\": 8.42, \"match_probability\": 0.99709, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020166870574030327}, {\"match_weight\": 8.46, \"match_probability\": 0.99717, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02018664201568754}, {\"match_weight\": 8.47, \"match_probability\": 0.99719, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020206413457344752}, {\"match_weight\": 8.47, \"match_probability\": 0.9972, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020226184899001964}, {\"match_weight\": 8.48, \"match_probability\": 0.99721, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02026572778231639}, {\"match_weight\": 8.49, \"match_probability\": 0.99722, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020285499223973602}, {\"match_weight\": 8.49, \"match_probability\": 0.99723, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020305270665630815}, {\"match_weight\": 8.5, \"match_probability\": 0.99724, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020325042107288027}, {\"match_weight\": 8.5, \"match_probability\": 0.99725, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020364584990602452}, {\"match_weight\": 8.51, \"match_probability\": 0.99726, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020384356432259665}, {\"match_weight\": 8.51, \"match_probability\": 0.99727, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020404127873916877}, {\"match_weight\": 8.52, \"match_probability\": 0.99728, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02042389931557409}, {\"match_weight\": 8.53, \"match_probability\": 0.9973, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020463442198888515}, {\"match_weight\": 8.54, \"match_probability\": 0.99731, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.02058207085246977}, {\"match_weight\": 8.54, \"match_probability\": 0.99732, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020621613735784194}, {\"match_weight\": 8.55, \"match_probability\": 0.99733, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02068092806257482}, {\"match_weight\": 8.55, \"match_probability\": 0.99734, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020700699504232034}, {\"match_weight\": 8.56, \"match_probability\": 0.99735, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02074024238754646}, {\"match_weight\": 8.56, \"match_probability\": 0.99736, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020760013829203672}, {\"match_weight\": 8.57, \"match_probability\": 0.99737, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020779785270860884}, {\"match_weight\": 8.6, \"match_probability\": 0.99742, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02081932815417531}, {\"match_weight\": 8.6, \"match_probability\": 0.99743, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020858871037489735}, {\"match_weight\": 8.61, \"match_probability\": 0.99744, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020878642479146947}, {\"match_weight\": 8.61, \"match_probability\": 0.99746, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020918185362461372}, {\"match_weight\": 8.62, \"match_probability\": 0.99747, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020937956804118585}, {\"match_weight\": 8.63, \"match_probability\": 0.99748, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020957728245775797}, {\"match_weight\": 8.64, \"match_probability\": 0.9975, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020997271129090223}, {\"match_weight\": 8.65, \"match_probability\": 0.99752, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021017042570747435}, {\"match_weight\": 8.66, \"match_probability\": 0.99753, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021036814012404648}, {\"match_weight\": 8.68, \"match_probability\": 0.99757, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021076356895719073}, {\"match_weight\": 8.7, \"match_probability\": 0.9976, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021096128337376285}, {\"match_weight\": 8.73, \"match_probability\": 0.99764, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02113567122069071}, {\"match_weight\": 8.73, \"match_probability\": 0.99765, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021155442662347923}, {\"match_weight\": 8.73, \"match_probability\": 0.99766, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021175214104005136}, {\"match_weight\": 8.75, \"match_probability\": 0.99768, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021194985545662348}, {\"match_weight\": 8.75, \"match_probability\": 0.99769, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02121475698731956}, {\"match_weight\": 8.76, \"match_probability\": 0.9977, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021234528428976773}, {\"match_weight\": 8.77, \"match_probability\": 0.99771, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021254299870633986}, {\"match_weight\": 8.78, \"match_probability\": 0.99772, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.021313614197424613}, {\"match_weight\": 8.79, \"match_probability\": 0.99774, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.021392699964053463}, {\"match_weight\": 8.79, \"match_probability\": 0.99775, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021412471405710676}, {\"match_weight\": 8.8, \"match_probability\": 0.99776, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02143224284736789}, {\"match_weight\": 8.81, \"match_probability\": 0.99778, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.021491557174158515}, {\"match_weight\": 8.82, \"match_probability\": 0.99779, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02153110005747294}, {\"match_weight\": 8.82, \"match_probability\": 0.9978, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021550871499130153}, {\"match_weight\": 8.83, \"match_probability\": 0.99781, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.021629957265759003}, {\"match_weight\": 8.85, \"match_probability\": 0.99783, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02166950014907343}, {\"match_weight\": 8.85, \"match_probability\": 0.99784, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02168927159073064}, {\"match_weight\": 8.86, \"match_probability\": 0.99785, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021709043032387854}, {\"match_weight\": 8.87, \"match_probability\": 0.99786, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02176835735917848}, {\"match_weight\": 8.88, \"match_probability\": 0.99788, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021788128800835693}, {\"match_weight\": 8.89, \"match_probability\": 0.99789, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02184744312762632}, {\"match_weight\": 8.89, \"match_probability\": 0.9979, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021886986010940745}, {\"match_weight\": 8.9, \"match_probability\": 0.99791, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02192652889425517}, {\"match_weight\": 8.91, \"match_probability\": 0.99792, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.021985843221045798}, {\"match_weight\": 8.91, \"match_probability\": 0.99793, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02200561466270301}, {\"match_weight\": 8.92, \"match_probability\": 0.99794, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.022045157546017435}, {\"match_weight\": 8.94, \"match_probability\": 0.99796, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02208470042933186}, {\"match_weight\": 8.94, \"match_probability\": 0.99797, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.022144014756122488}, {\"match_weight\": 8.95, \"match_probability\": 0.99799, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0221637861977797}, {\"match_weight\": 8.97, \"match_probability\": 0.998, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.022282414851360954}, {\"match_weight\": 8.97, \"match_probability\": 0.99801, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02232195773467538}, {\"match_weight\": 8.98, \"match_probability\": 0.99802, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02242081494841841}, {\"match_weight\": 8.98, \"match_probability\": 0.99803, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022440586390075623}, {\"match_weight\": 9.02, \"match_probability\": 0.99807, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02249990071686625}, {\"match_weight\": 9.02, \"match_probability\": 0.99808, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.0225789864834951}, {\"match_weight\": 9.03, \"match_probability\": 0.99809, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.022697615137076355}, {\"match_weight\": 9.03, \"match_probability\": 0.9981, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022717386578733567}, {\"match_weight\": 9.06, \"match_probability\": 0.99813, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02273715802039078}, {\"match_weight\": 9.07, \"match_probability\": 0.99814, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022756929462047992}, {\"match_weight\": 9.08, \"match_probability\": 0.99815, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022776700903705205}, {\"match_weight\": 9.09, \"match_probability\": 0.99817, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.022836015230495832}, {\"match_weight\": 9.1, \"match_probability\": 0.99818, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022855786672153044}, {\"match_weight\": 9.12, \"match_probability\": 0.9982, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02289532955546747}, {\"match_weight\": 9.12, \"match_probability\": 0.99821, \"prop\": 0.0003361145209055394, \"cum_prop\": 0.02323144407637301}, {\"match_weight\": 9.13, \"match_probability\": 0.99822, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023270986959687434}, {\"match_weight\": 9.14, \"match_probability\": 0.99823, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.023350072726316284}, {\"match_weight\": 9.14, \"match_probability\": 0.99824, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02338961560963071}, {\"match_weight\": 9.16, \"match_probability\": 0.99825, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023429158492945135}, {\"match_weight\": 9.17, \"match_probability\": 0.99826, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.023508244259573985}, {\"match_weight\": 9.17, \"match_probability\": 0.99827, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02354778714288841}, {\"match_weight\": 9.18, \"match_probability\": 0.99828, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02362687290951726}, {\"match_weight\": 9.19, \"match_probability\": 0.99829, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.023646644351174473}, {\"match_weight\": 9.2, \"match_probability\": 0.9983, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023686187234488898}, {\"match_weight\": 9.21, \"match_probability\": 0.99831, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023725730117803323}, {\"match_weight\": 9.23, \"match_probability\": 0.99833, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02378504444459395}, {\"match_weight\": 9.23, \"match_probability\": 0.99834, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.023804815886251163}, {\"match_weight\": 9.24, \"match_probability\": 0.99835, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.023824587327908375}, {\"match_weight\": 9.25, \"match_probability\": 0.99836, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0238641302112228}, {\"match_weight\": 9.26, \"match_probability\": 0.99837, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.023883901652880013}, {\"match_weight\": 9.28, \"match_probability\": 0.99839, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023923444536194438}, {\"match_weight\": 9.28, \"match_probability\": 0.9984, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02394321597785165}, {\"match_weight\": 9.3, \"match_probability\": 0.99841, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.024002530304642278}, {\"match_weight\": 9.31, \"match_probability\": 0.99842, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024042073187956703}, {\"match_weight\": 9.31, \"match_probability\": 0.99843, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.024061844629613915}, {\"match_weight\": 9.33, \"match_probability\": 0.99844, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02410138751292834}, {\"match_weight\": 9.34, \"match_probability\": 0.99845, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02418047327955719}, {\"match_weight\": 9.34, \"match_probability\": 0.99846, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.024239787606347818}, {\"match_weight\": 9.35, \"match_probability\": 0.99847, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024279330489662243}, {\"match_weight\": 9.36, \"match_probability\": 0.99848, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.024299101931319456}, {\"match_weight\": 9.39, \"match_probability\": 0.99851, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.024358416258110083}, {\"match_weight\": 9.4, \"match_probability\": 0.99852, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.024457273471853114}, {\"match_weight\": 9.41, \"match_probability\": 0.99853, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.024536359238481964}, {\"match_weight\": 9.42, \"match_probability\": 0.99854, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02457590212179639}, {\"match_weight\": 9.43, \"match_probability\": 0.99855, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0245956735634536}, {\"match_weight\": 9.44, \"match_probability\": 0.99856, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024635216446768027}, {\"match_weight\": 9.45, \"match_probability\": 0.99857, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02465498788842524}, {\"match_weight\": 9.46, \"match_probability\": 0.99859, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.024674759330082452}, {\"match_weight\": 9.48, \"match_probability\": 0.9986, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024714302213396877}, {\"match_weight\": 9.49, \"match_probability\": 0.99861, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024753845096711302}, {\"match_weight\": 9.5, \"match_probability\": 0.99862, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02481315942350193}, {\"match_weight\": 9.51, \"match_probability\": 0.99863, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024852702306816354}, {\"match_weight\": 9.52, \"match_probability\": 0.99864, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.024931788073445205}, {\"match_weight\": 9.53, \"match_probability\": 0.99865, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.024951559515102417}, {\"match_weight\": 9.54, \"match_probability\": 0.99866, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.025010873841893044}, {\"match_weight\": 9.56, \"match_probability\": 0.99867, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.02514927393531252}, {\"match_weight\": 9.57, \"match_probability\": 0.99868, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.025248131149055553}, {\"match_weight\": 9.58, \"match_probability\": 0.99869, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.025287674032369978}, {\"match_weight\": 9.59, \"match_probability\": 0.9987, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.025426074125789455}, {\"match_weight\": 9.6, \"match_probability\": 0.99871, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.025445845567446668}, {\"match_weight\": 9.61, \"match_probability\": 0.99872, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.025505159894237295}, {\"match_weight\": 9.62, \"match_probability\": 0.99873, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.025564474221027922}, {\"match_weight\": 9.63, \"match_probability\": 0.99874, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.025643559987656772}, {\"match_weight\": 9.64, \"match_probability\": 0.99875, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.025742417201399803}, {\"match_weight\": 9.65, \"match_probability\": 0.99876, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.025841274415142834}, {\"match_weight\": 9.66, \"match_probability\": 0.99877, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02588081729845726}, {\"match_weight\": 9.68, \"match_probability\": 0.99878, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02597967451220029}, {\"match_weight\": 9.69, \"match_probability\": 0.99879, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.026019217395514715}, {\"match_weight\": 9.71, \"match_probability\": 0.9988, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.026078531722305343}, {\"match_weight\": 9.72, \"match_probability\": 0.99881, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.026157617488934193}, {\"match_weight\": 9.74, \"match_probability\": 0.99883, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.026197160372248618}, {\"match_weight\": 9.75, \"match_probability\": 0.99884, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02621693181390583}, {\"match_weight\": 9.77, \"match_probability\": 0.99885, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.026276246140696458}, {\"match_weight\": 9.78, \"match_probability\": 0.99886, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.026394874794277712}, {\"match_weight\": 9.79, \"match_probability\": 0.99887, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.026493732008020743}, {\"match_weight\": 9.81, \"match_probability\": 0.99888, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.026572817774649593}, {\"match_weight\": 9.81, \"match_probability\": 0.99889, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02663213210144022}, {\"match_weight\": 9.83, \"match_probability\": 0.9989, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02671121786806907}, {\"match_weight\": 9.84, \"match_probability\": 0.99891, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.026829846521650325}, {\"match_weight\": 9.85, \"match_probability\": 0.99892, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.026849617963307537}, {\"match_weight\": 9.87, \"match_probability\": 0.99893, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02686938940496475}, {\"match_weight\": 9.89, \"match_probability\": 0.99894, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.0269484751715936}, {\"match_weight\": 9.9, \"match_probability\": 0.99895, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.027086875265013077}, {\"match_weight\": 9.91, \"match_probability\": 0.99896, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.027146189591803704}, {\"match_weight\": 9.93, \"match_probability\": 0.99897, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.027225275358432555}, {\"match_weight\": 9.94, \"match_probability\": 0.99898, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02726481824174698}, {\"match_weight\": 9.95, \"match_probability\": 0.99899, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.027304361125061405}, {\"match_weight\": 9.96, \"match_probability\": 0.999, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.027324132566718617}, {\"match_weight\": 9.98, \"match_probability\": 0.99901, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.027363675450033043}, {\"match_weight\": 10.0, \"match_probability\": 0.99902, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.027442761216661893}, {\"match_weight\": 10.01, \"match_probability\": 0.99903, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.027561389870243147}, {\"match_weight\": 10.03, \"match_probability\": 0.99904, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.0276800185238244}, {\"match_weight\": 10.04, \"match_probability\": 0.99905, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02775910429045325}, {\"match_weight\": 10.06, \"match_probability\": 0.99906, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.027857961504196282}, {\"match_weight\": 10.07, \"match_probability\": 0.99907, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02791727583098691}, {\"match_weight\": 10.09, \"match_probability\": 0.99908, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02801613304472994}, {\"match_weight\": 10.11, \"match_probability\": 0.99909, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02811499025847297}, {\"match_weight\": 10.12, \"match_probability\": 0.9991, \"prop\": 0.0009094863198697567, \"cum_prop\": 0.02902447657834273}, {\"match_weight\": 10.14, \"match_probability\": 0.99911, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02912333379208576}, {\"match_weight\": 10.15, \"match_probability\": 0.99912, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02922219100582879}, {\"match_weight\": 10.16, \"match_probability\": 0.99913, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.029281505332619417}, {\"match_weight\": 10.19, \"match_probability\": 0.99914, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.029340819659410045}, {\"match_weight\": 10.2, \"match_probability\": 0.99915, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.029479219752829522}, {\"match_weight\": 10.22, \"match_probability\": 0.99916, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.029518762636143947}, {\"match_weight\": 10.24, \"match_probability\": 0.99917, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.029578076962934574}, {\"match_weight\": 10.26, \"match_probability\": 0.99918, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.029676934176677605}, {\"match_weight\": 10.28, \"match_probability\": 0.99919, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.029736248503468232}, {\"match_weight\": 10.3, \"match_probability\": 0.9992, \"prop\": 0.00019771442748606205, \"cum_prop\": 0.029933962930954294}, {\"match_weight\": 10.31, \"match_probability\": 0.99921, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.030092134464211995}, {\"match_weight\": 10.32, \"match_probability\": 0.99922, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.030111905905869207}, {\"match_weight\": 10.34, \"match_probability\": 0.99923, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.03023053455945046}, {\"match_weight\": 10.37, \"match_probability\": 0.99924, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.030329391773193493}, {\"match_weight\": 10.38, \"match_probability\": 0.99925, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.030368934656507918}, {\"match_weight\": 10.4, \"match_probability\": 0.99926, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.030428248983298545}, {\"match_weight\": 10.43, \"match_probability\": 0.99927, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.030527106197041576}, {\"match_weight\": 10.45, \"match_probability\": 0.99928, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.030625963410784607}, {\"match_weight\": 10.47, \"match_probability\": 0.99929, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.030705049177413457}, {\"match_weight\": 10.48, \"match_probability\": 0.9993, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.03072482061907067}, {\"match_weight\": 10.51, \"match_probability\": 0.99931, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.030902763592166593}, {\"match_weight\": 10.53, \"match_probability\": 0.99932, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.031021392245747847}, {\"match_weight\": 10.55, \"match_probability\": 0.99933, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.03112024945949088}, {\"match_weight\": 10.57, \"match_probability\": 0.99934, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.031258649552910356}, {\"match_weight\": 10.59, \"match_probability\": 0.99935, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.03135750676665339}, {\"match_weight\": 10.62, \"match_probability\": 0.99936, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.03147613542023464}, {\"match_weight\": 10.64, \"match_probability\": 0.99937, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.03171339272739715}, {\"match_weight\": 10.66, \"match_probability\": 0.99938, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.03187156426065485}, {\"match_weight\": 10.68, \"match_probability\": 0.99939, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.031990192914236104}, {\"match_weight\": 10.7, \"match_probability\": 0.9994, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.03212859300765558}, {\"match_weight\": 10.72, \"match_probability\": 0.99941, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.03220767877428443}, {\"match_weight\": 10.76, \"match_probability\": 0.99942, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.032326307427865686}, {\"match_weight\": 10.79, \"match_probability\": 0.99943, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.03250425040096161}, {\"match_weight\": 10.81, \"match_probability\": 0.99944, \"prop\": 0.0002174858673242852, \"cum_prop\": 0.032721736268285895}, {\"match_weight\": 10.84, \"match_probability\": 0.99945, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.032879907801543595}, {\"match_weight\": 10.87, \"match_probability\": 0.99946, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.03305785077463952}, {\"match_weight\": 10.89, \"match_probability\": 0.99947, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.033196250868058996}, {\"match_weight\": 10.92, \"match_probability\": 0.99948, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.033334650961478474}, {\"match_weight\": 10.95, \"match_probability\": 0.99949, \"prop\": 0.0002174858673242852, \"cum_prop\": 0.03355213682880276}, {\"match_weight\": 10.98, \"match_probability\": 0.9995, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.03378939413596527}, {\"match_weight\": 11.01, \"match_probability\": 0.99951, \"prop\": 0.00025702876155264676, \"cum_prop\": 0.034046422897517914}, {\"match_weight\": 11.03, \"match_probability\": 0.99952, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.03416505155109917}, {\"match_weight\": 11.07, \"match_probability\": 0.99953, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.03446162319232826}, {\"match_weight\": 11.1, \"match_probability\": 0.99954, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.03461979472558596}, {\"match_weight\": 11.13, \"match_probability\": 0.99955, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.03475819481900544}, {\"match_weight\": 11.16, \"match_probability\": 0.99956, \"prop\": 0.000316343066515401, \"cum_prop\": 0.03507453788552084}, {\"match_weight\": 11.2, \"match_probability\": 0.99957, \"prop\": 0.00019771442748606205, \"cum_prop\": 0.0352722523130069}, {\"match_weight\": 11.23, \"match_probability\": 0.99958, \"prop\": 0.0003361145209055394, \"cum_prop\": 0.03560836683391244}, {\"match_weight\": 11.26, \"match_probability\": 0.99959, \"prop\": 0.0002174858673242852, \"cum_prop\": 0.03582585270123673}, {\"match_weight\": 11.3, \"match_probability\": 0.9996, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.036063110008399235}, {\"match_weight\": 11.34, \"match_probability\": 0.99961, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.03635968164962833}, {\"match_weight\": 11.38, \"match_probability\": 0.99962, \"prop\": 0.00025702876155264676, \"cum_prop\": 0.036616710411180975}, {\"match_weight\": 11.42, \"match_probability\": 0.99963, \"prop\": 0.0003558859461918473, \"cum_prop\": 0.03697259635737282}, {\"match_weight\": 11.46, \"match_probability\": 0.99964, \"prop\": 0.000316343066515401, \"cum_prop\": 0.03728893942388822}, {\"match_weight\": 11.49, \"match_probability\": 0.99965, \"prop\": 0.0002768001868389547, \"cum_prop\": 0.03756573961072718}, {\"match_weight\": 11.54, \"match_probability\": 0.99966, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.0377436825838231}, {\"match_weight\": 11.58, \"match_probability\": 0.99967, \"prop\": 0.0002174858673242852, \"cum_prop\": 0.03796116845114739}, {\"match_weight\": 11.63, \"match_probability\": 0.99968, \"prop\": 0.00041520028025843203, \"cum_prop\": 0.03837636873140582}, {\"match_weight\": 11.67, \"match_probability\": 0.99969, \"prop\": 0.0002174858673242852, \"cum_prop\": 0.038593854598730104}, {\"match_weight\": 11.73, \"match_probability\": 0.9997, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.03877179757182603}, {\"match_weight\": 11.78, \"match_probability\": 0.99971, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.03906836921305512}, {\"match_weight\": 11.83, \"match_probability\": 0.99972, \"prop\": 0.0002768001868389547, \"cum_prop\": 0.039345169399894075}, {\"match_weight\": 11.88, \"match_probability\": 0.99973, \"prop\": 0.00045474315993487835, \"cum_prop\": 0.039799912559828954}, {\"match_weight\": 11.93, \"match_probability\": 0.99974, \"prop\": 0.0005931432824581861, \"cum_prop\": 0.04039305584228714}, {\"match_weight\": 11.99, \"match_probability\": 0.99975, \"prop\": 0.00045474315993487835, \"cum_prop\": 0.04084779900222202}, {\"match_weight\": 12.05, \"match_probability\": 0.99976, \"prop\": 0.00045474315993487835, \"cum_prop\": 0.0413025421621569}, {\"match_weight\": 12.11, \"match_probability\": 0.99977, \"prop\": 0.0006524575874209404, \"cum_prop\": 0.04195499974957784}, {\"match_weight\": 12.18, \"match_probability\": 0.99978, \"prop\": 0.0006524575874209404, \"cum_prop\": 0.04260745733699878}, {\"match_weight\": 12.25, \"match_probability\": 0.99979, \"prop\": 0.0007710862555541098, \"cum_prop\": 0.04337854359255289}, {\"match_weight\": 12.32, \"match_probability\": 0.9998, \"prop\": 0.0005931432824581861, \"cum_prop\": 0.04397168687501107}, {\"match_weight\": 12.4, \"match_probability\": 0.99981, \"prop\": 0.0005140575231052935, \"cum_prop\": 0.04448574439811637}, {\"match_weight\": 12.48, \"match_probability\": 0.99982, \"prop\": 0.00047451461432501674, \"cum_prop\": 0.044960259012441384}, {\"match_weight\": 12.56, \"match_probability\": 0.99983, \"prop\": 0.00045474315993487835, \"cum_prop\": 0.04541500217237626}, {\"match_weight\": 12.65, \"match_probability\": 0.99984, \"prop\": 0.001265372266061604, \"cum_prop\": 0.046680374438437866}, {\"match_weight\": 12.74, \"match_probability\": 0.99985, \"prop\": 0.000731543346773833, \"cum_prop\": 0.0474119177852117}, {\"match_weight\": 12.84, \"match_probability\": 0.99986, \"prop\": 0.0008501720149070024, \"cum_prop\": 0.0482620898001187}, {\"match_weight\": 12.96, \"match_probability\": 0.99987, \"prop\": 0.0009490292286500335, \"cum_prop\": 0.049211119028768735}, {\"match_weight\": 13.08, \"match_probability\": 0.99988, \"prop\": 0.001028115046210587, \"cum_prop\": 0.05023923407497932}, {\"match_weight\": 13.22, \"match_probability\": 0.99989, \"prop\": 0.0016805726336315274, \"cum_prop\": 0.05191980670861085}, {\"match_weight\": 13.36, \"match_probability\": 0.9999, \"prop\": 0.0009490292286500335, \"cum_prop\": 0.05286883593726088}, {\"match_weight\": 13.52, \"match_probability\": 0.99991, \"prop\": 0.0014037723885849118, \"cum_prop\": 0.054272608325845795}, {\"match_weight\": 13.7, \"match_probability\": 0.99992, \"prop\": 0.0016014868160709739, \"cum_prop\": 0.05587409514191677}, {\"match_weight\": 13.91, \"match_probability\": 0.99993, \"prop\": 0.002333030104637146, \"cum_prop\": 0.058207125246553915}, {\"match_weight\": 14.15, \"match_probability\": 0.99994, \"prop\": 0.002135315677151084, \"cum_prop\": 0.060342440923705}, {\"match_weight\": 14.43, \"match_probability\": 0.99995, \"prop\": 0.0036774883046746254, \"cum_prop\": 0.06401992922837962}, {\"match_weight\": 14.8, \"match_probability\": 0.99996, \"prop\": 0.00340068805962801, \"cum_prop\": 0.06742061728800763}, {\"match_weight\": 15.29, \"match_probability\": 0.99997, \"prop\": 0.005140575114637613, \"cum_prop\": 0.07256119240264525}, {\"match_weight\": 16.02, \"match_probability\": 0.99998, \"prop\": 0.00836331956088543, \"cum_prop\": 0.08092451196353068}, {\"match_weight\": 17.61, \"match_probability\": 0.99999, \"prop\": 0.019929613918066025, \"cum_prop\": 0.1008541258815967}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.unlinkables_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:28.393039Z",
     "iopub.status.busy": "2024-05-15T16:07:28.392726Z",
     "iopub.status.idle": "2024-05-15T16:07:30.731337Z",
     "shell.execute_reply": "2024-05-15T16:07:30.730612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>unique_id_l</th>\n",
       "      <th>unique_id_r</th>\n",
       "      <th>first_name_l</th>\n",
       "      <th>first_name_r</th>\n",
       "      <th>gamma_first_name</th>\n",
       "      <th>tf_first_name_l</th>\n",
       "      <th>tf_first_name_r</th>\n",
       "      <th>bf_first_name</th>\n",
       "      <th>...</th>\n",
       "      <th>bf_birth_place</th>\n",
       "      <th>bf_tf_adj_birth_place</th>\n",
       "      <th>occupation_l</th>\n",
       "      <th>occupation_r</th>\n",
       "      <th>gamma_occupation</th>\n",
       "      <th>tf_occupation_l</th>\n",
       "      <th>tf_occupation_r</th>\n",
       "      <th>bf_occupation</th>\n",
       "      <th>bf_tf_adj_occupation</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.840427</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q5971253-3</td>\n",
       "      <td>Q75867928-4</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>44.906565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>naval officer</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15.840427</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q5971253-3</td>\n",
       "      <td>Q75867928-7</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>44.906565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>naval officer</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.840427</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q5971253-2</td>\n",
       "      <td>Q75867928-4</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>44.906565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>naval officer</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.840427</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q5971253-2</td>\n",
       "      <td>Q75867928-7</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>44.906565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>naval officer</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.840427</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q5971253-1</td>\n",
       "      <td>Q75867928-4</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>44.906565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>naval officer</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_weight  match_probability unique_id_l  unique_id_r first_name_l  \\\n",
       "0    -15.840427           0.000017  Q5971253-3  Q75867928-4          sir   \n",
       "1    -15.840427           0.000017  Q5971253-3  Q75867928-7          sir   \n",
       "2    -15.840427           0.000017  Q5971253-2  Q75867928-4          sir   \n",
       "3    -15.840427           0.000017  Q5971253-2  Q75867928-7          sir   \n",
       "4    -15.840427           0.000017  Q5971253-1  Q75867928-4          sir   \n",
       "\n",
       "  first_name_r  gamma_first_name  tf_first_name_l  tf_first_name_r  \\\n",
       "0          sir                 3         0.024985         0.024985   \n",
       "1          sir                 3         0.024985         0.024985   \n",
       "2          sir                 3         0.024985         0.024985   \n",
       "3          sir                 3         0.024985         0.024985   \n",
       "4          sir                 3         0.024985         0.024985   \n",
       "\n",
       "   bf_first_name  ...  bf_birth_place bf_tf_adj_birth_place   occupation_l  \\\n",
       "0      44.906565  ...        0.156756                   1.0  naval officer   \n",
       "1      44.906565  ...        0.156756                   1.0  naval officer   \n",
       "2      44.906565  ...        0.156756                   1.0  naval officer   \n",
       "3      44.906565  ...        0.156756                   1.0  naval officer   \n",
       "4      44.906565  ...        0.156756                   1.0  naval officer   \n",
       "\n",
       "       occupation_r  gamma_occupation  tf_occupation_l  tf_occupation_r  \\\n",
       "0  military officer                 0         0.009451         0.010756   \n",
       "1  military officer                 0         0.009451         0.010756   \n",
       "2  military officer                 0         0.009451         0.010756   \n",
       "3  military officer                 0         0.009451         0.010756   \n",
       "4  military officer                 0         0.009451         0.010756   \n",
       "\n",
       "   bf_occupation bf_tf_adj_occupation match_key  \n",
       "0       0.104989                  1.0         0  \n",
       "1       0.104989                  1.0         0  \n",
       "2       0.104989                  1.0         0  \n",
       "3       0.104989                  1.0         0  \n",
       "4       0.104989                  1.0         0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = linker.predict()\n",
    "df_e = df_predict.as_pandas_dataframe(limit=5)\n",
    "df_e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view rows in this dataset as a waterfall chart as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:30.735380Z",
     "iopub.status.busy": "2024-05-15T16:07:30.735079Z",
     "iopub.status.idle": "2024-05-15T16:07:31.361460Z",
     "shell.execute_reply": "2024-05-15T16:07:31.360879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-0531003e68ce486abd3723470580dfeb.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-0531003e68ce486abd3723470580dfeb.vega-embed details,\n",
       "  #altair-viz-0531003e68ce486abd3723470580dfeb.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-0531003e68ce486abd3723470580dfeb\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0531003e68ce486abd3723470580dfeb\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0531003e68ce486abd3723470580dfeb\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-3e05b22e020896920103139cc5cba906\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 4, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-3e05b22e020896920103139cc5cba906\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.4920190705300853, \"log2_bayes_factor\": -1.0232138597578537, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.03 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.04669857363849754, \"log2_bayes_factor\": -4.420477704852477, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  21.41 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1862-09-05\", \"value_r\": \"1848-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me4 5ey\", \"value_r\": \"nw2 1tj\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"gillingham\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"naval officer\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.840426791627847, \"bayes_factor\": 1.7043406075413756e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.4920190705300853, \"log2_bayes_factor\": -1.0232138597578537, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.03 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.04669857363849754, \"log2_bayes_factor\": -4.420477704852477, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  21.41 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1862-09-05\", \"value_r\": \"1858-03-45\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me4 5ey\", \"value_r\": \"w2 2lp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"gillingham\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"naval officer\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.840426791627847, \"bayes_factor\": 1.7043406075413756e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.4920190705300853, \"log2_bayes_factor\": -1.0232138597578537, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.03 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.04669857363849754, \"log2_bayes_factor\": -4.420477704852477, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  21.41 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1862-09-05\", \"value_r\": \"1848-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me4 5ey\", \"value_r\": \"nw2 1tj\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"gillingham\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"naval officer\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.840426791627847, \"bayes_factor\": 1.7043406075413756e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.4920190705300853, \"log2_bayes_factor\": -1.0232138597578537, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.03 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.04669857363849754, \"log2_bayes_factor\": -4.420477704852477, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  21.41 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1862-09-05\", \"value_r\": \"1858-03-45\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me4 5ey\", \"value_r\": \"w2 2lp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"gillingham\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"naval officer\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.840426791627847, \"bayes_factor\": 1.7043406075413756e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.4920190705300853, \"log2_bayes_factor\": -1.0232138597578537, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.03 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.04669857363849754, \"log2_bayes_factor\": -4.420477704852477, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  21.41 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1862-09-05\", \"value_r\": \"1848-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me4 5ey\", \"value_r\": \"nw2 1tj\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"gillingham\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"naval officer\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.840426791627847, \"bayes_factor\": 1.7043406075413756e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "records_to_plot = df_e.to_dict(orient=\"records\")\n",
    "linker.waterfall_chart(records_to_plot, filter_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:31.364481Z",
     "iopub.status.busy": "2024-05-15T16:07:31.364255Z",
     "iopub.status.idle": "2024-05-15T16:07:31.746356Z",
     "shell.execute_reply": "2024-05-15T16:07:31.745671Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 1, root rows count 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 2, root rows count 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 3, root rows count 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 4, root rows count 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 5, root rows count 0\n"
     ]
    }
   ],
   "source": [
    "clusters = linker.cluster_pairwise_predictions_at_threshold(\n",
    "    df_predict, threshold_match_probability=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:31.749625Z",
     "iopub.status.busy": "2024-05-15T16:07:31.749370Z",
     "iopub.status.idle": "2024-05-15T16:07:31.898014Z",
     "shell.execute_reply": "2024-05-15T16:07:31.897301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"./dashboards/50k_cluster.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12b838ca0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "linker.cluster_studio_dashboard(\n",
    "    df_predict,\n",
    "    clusters,\n",
    "    \"dashboards/50k_cluster.html\",\n",
    "    sampling_method=\"by_cluster_size\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "\n",
    "IFrame(src=\"./dashboards/50k_cluster.html\", width=\"100%\", height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:31.901400Z",
     "iopub.status.busy": "2024-05-15T16:07:31.901154Z",
     "iopub.status.idle": "2024-05-15T16:07:44.228710Z",
     "shell.execute_reply": "2024-05-15T16:07:44.227315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-71296cea16554d339cdb18eb244e7549.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-71296cea16554d339cdb18eb244e7549.vega-embed details,\n",
       "  #altair-viz-71296cea16554d339cdb18eb244e7549.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-71296cea16554d339cdb18eb244e7549\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-71296cea16554d339cdb18eb244e7549\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-71296cea16554d339cdb18eb244e7549\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-46994a7d72ba8170ebf493bf61ee34c0\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-46994a7d72ba8170ebf493bf61ee34c0\": [{\"truth_threshold\": -15.83999964594841, \"match_probability\": 1.704816230115347e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278563923.0, \"fp\": 173869.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998640307644868, \"fp_rate\": 0.0001359692355131395, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4336938926399651, \"recall\": 0.43806277779057184, \"specificity\": 0.9998640307644868, \"npv\": 0.9998664249933995, \"accuracy\": 0.9997305201341617, \"f1\": 0.43586738768936667, \"f2\": 0.4371819732123685, \"f0_5\": 0.43456068425831224, \"p4\": 0.607088869043114, \"phi\": 0.43573809360359683}, {\"truth_threshold\": -15.359999656677246, \"match_probability\": 2.377765620022284e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278579234.0, \"fp\": 158558.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998760042903307, \"fp_rate\": 0.0001239957096693049, \"fn_rate\": 0.5619372222094282, \"precision\": 0.45645705353225097, \"recall\": 0.43806277779057184, \"specificity\": 0.9998760042903307, \"npv\": 0.999866426592748, \"accuracy\": 0.9997424908145278, \"f1\": 0.4470707921963896, \"f2\": 0.44162206909726737, \"f0_5\": 0.4526556473342222, \"p4\": 0.6178730232711644, \"phi\": 0.4470366306253448}, {\"truth_threshold\": -14.799999669194221, \"match_probability\": 3.50542709838138e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278579253.0, \"fp\": 158539.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998760191487326, \"fp_rate\": 0.00012398085126743481, \"fn_rate\": 0.5619372222094282, \"precision\": 0.45648678576448526, \"recall\": 0.43806277779057184, \"specificity\": 0.9998760191487326, \"npv\": 0.9998664265947327, \"accuracy\": 0.9997425056693986, \"f1\": 0.44708505273195515, \"f2\": 0.44162763500995333, \"f0_5\": 0.4526790382754722, \"p4\": 0.6178866437592794, \"phi\": 0.4470512015418176}, {\"truth_threshold\": -14.699999671429396, \"match_probability\": 3.757014280558493e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589482.0, \"fp\": 148310.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840184430867, \"fp_rate\": 0.00011598155691327217, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4730764858028025, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840184430867, \"npv\": 0.9998664276632069, \"accuracy\": 0.9997505030627409, \"f1\": 0.45489686979544774, \"f2\": 0.4446446556085989, \"f0_5\": 0.4656330145745924, \"p4\": 0.6253077184774316, \"phi\": 0.4551085955613794}, {\"truth_threshold\": -14.579999674111605, \"match_probability\": 4.08286508550847e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589502.0, \"fp\": 148290.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840340835098, \"fp_rate\": 0.00011596591649025103, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4731101036085331, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840340835098, \"npv\": 0.999866427665296, \"accuracy\": 0.999750518699447, \"f1\": 0.4549124110658433, \"f2\": 0.4446505949423224, \"f0_5\": 0.465659068765794, \"p4\": 0.6253224029651865, \"phi\": 0.45512477845381616}, {\"truth_threshold\": -14.55999967455864, \"match_probability\": 4.139857397374142e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589526.0, \"fp\": 148266.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840528520174, \"fp_rate\": 0.00011594714798262567, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47315045128278016, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840528520174, \"npv\": 0.9998664276678029, \"accuracy\": 0.9997505374634944, \"f1\": 0.4549310619921043, \"f2\": 0.44465772235223716, \"f0_5\": 0.4656903376442058, \"p4\": 0.6253400252609084, \"phi\": 0.45514420020127366}, {\"truth_threshold\": -14.539999675005674, \"match_probability\": 4.1976452259158474e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589554.0, \"fp\": 148238.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840747486096, \"fp_rate\": 0.00011592525139039607, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4731975322681526, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840747486096, \"npv\": 0.9998664276707276, \"accuracy\": 0.9997505593548829, \"f1\": 0.45495282333907916, \"f2\": 0.4446660379526007, \"f0_5\": 0.4657268233103351, \"p4\": 0.6253605858612942, \"phi\": 0.4551668620461665}, {\"truth_threshold\": -14.51999967545271, \"match_probability\": 4.256239674267579e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589560.0, \"fp\": 148232.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840794407365, \"fp_rate\": 0.00011592055926348973, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47320762226976465, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840794407365, \"npv\": 0.9998664276713544, \"accuracy\": 0.9997505640458948, \"f1\": 0.45495748675571923, \"f2\": 0.44466781990742904, \"f0_5\": 0.4657346424111843, \"p4\": 0.6253649918801367, \"phi\": 0.4551717185957406}, {\"truth_threshold\": -14.439999677240849, \"match_probability\": 4.498911197010261e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589596.0, \"fp\": 148196.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884107593498, \"fp_rate\": 0.00011589240650205167, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732681713168651, \"recall\": 0.43806277779057184, \"specificity\": 0.999884107593498, \"npv\": 0.9998664276751147, \"accuracy\": 0.9997505921919657, \"f1\": 0.4549854692633489, \"f2\": 0.4446785119363289, \"f0_5\": 0.46578156253038944, \"p4\": 0.6253914292970484, \"phi\": 0.45520086115469766}, {\"truth_threshold\": -14.299999680370092, \"match_probability\": 4.9573505255363516e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589603.0, \"fp\": 148189.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884113067646, \"fp_rate\": 0.00011588693235399427, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732799465421212, \"recall\": 0.43806277779057184, \"specificity\": 0.999884113067646, \"npv\": 0.9998664276758459, \"accuracy\": 0.9997505976648129, \"f1\": 0.45499091070623127, \"f2\": 0.44468059100165847, \"f0_5\": 0.46579068698476844, \"p4\": 0.6253965701654712, \"phi\": 0.4552065284127607}, {\"truth_threshold\": -14.05999968573451, \"match_probability\": 5.854542039493212e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589608.0, \"fp\": 148184.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841169777518, \"fp_rate\": 0.00011588302224823899, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732883577760558, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841169777518, \"npv\": 0.9998664276763681, \"accuracy\": 0.9997506015739894, \"f1\": 0.45499479753083466, \"f2\": 0.44468207606022514, \"f0_5\": 0.46579720467105523, \"p4\": 0.625400242266091, \"phi\": 0.4552105765836965}, {\"truth_threshold\": -14.039999686181545, \"match_probability\": 5.936263547441892e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589612.0, \"fp\": 148180.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841201058364, \"fp_rate\": 0.00011587989416363476, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732950869784669, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841201058364, \"npv\": 0.9998664276767859, \"accuracy\": 0.9997506047013307, \"f1\": 0.4549979070383311, \"f2\": 0.4446832641142202, \"f0_5\": 0.46580241895141455, \"p4\": 0.6254031799776352, \"phi\": 0.45521381519812626}, {\"truth_threshold\": -13.999999687075615, \"match_probability\": 6.103144442413431e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589618.0, \"fp\": 148174.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841247979633, \"fp_rate\": 0.00011587520203672842, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4733051811408747, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841247979633, \"npv\": 0.9998664276774126, \"accuracy\": 0.9997506093923425, \"f1\": 0.45500257137926736, \"f2\": 0.4446850462071158, \"f0_5\": 0.46581024059084586, \"p4\": 0.6254075865966994, \"phi\": 0.45521867324924503}, {\"truth_threshold\": -13.919999688863754, \"match_probability\": 6.451111322608078e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589638.0, \"fp\": 148154.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841404383862, \"fp_rate\": 0.00011585956161370727, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47333883145875694, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841404383862, \"npv\": 0.9998664276795017, \"accuracy\": 0.9997506250290487, \"f1\": 0.455018119873084, \"f2\": 0.44469098661992906, \"f0_5\": 0.46583631461950903, \"p4\": 0.6254222757754132, \"phi\": 0.4552348678751837}, {\"truth_threshold\": -13.799999691545963, \"match_probability\": 7.010608336386497e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589644.0, \"fp\": 148148.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841451305132, \"fp_rate\": 0.00011585486948680094, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4733489274871846, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841451305132, \"npv\": 0.9998664276801285, \"accuracy\": 0.9997506297200605, \"f1\": 0.4550227846284491, \"f2\": 0.444692768774722, \"f0_5\": 0.4658441373973267, \"p4\": 0.6254266826635821, \"phi\": 0.45523972659965994}, {\"truth_threshold\": -13.759999692440033, \"match_probability\": 7.207689153445872e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589649.0, \"fp\": 148143.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884149040619, \"fp_rate\": 0.00011585095938104565, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4733573411732084, \"recall\": 0.43806277779057184, \"specificity\": 0.999884149040619, \"npv\": 0.9998664276806508, \"accuracy\": 0.999750633629237, \"f1\": 0.4550266719976489, \"f2\": 0.44469425391462797, \"f0_5\": 0.4658506565795449, \"p4\": 0.6254303551178306, \"phi\": 0.45524377565544094}, {\"truth_threshold\": -13.719999693334103, \"match_probability\": 7.410309856369675e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589657.0, \"fp\": 148135.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841552967882, \"fp_rate\": 0.00011584470321183719, \"fn_rate\": 0.5619372222094282, \"precision\": 0.473370803692999, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841552967882, \"npv\": 0.9998664276814864, \"accuracy\": 0.9997506398839194, \"f1\": 0.4550328919265271, \"f2\": 0.44469663015911076, \"f0_5\": 0.4658610876506262, \"p4\": 0.6254362311343368, \"phi\": 0.45525025436918676}, {\"truth_threshold\": -13.699999693781137, \"match_probability\": 7.513746152194597e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589669.0, \"fp\": 148123.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884164681042, \"fp_rate\": 0.00011583531895802451, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47339099890854924, \"recall\": 0.43806277779057184, \"specificity\": 0.999884164681042, \"npv\": 0.9998664276827398, \"accuracy\": 0.999750649265943, \"f1\": 0.45504222213868545, \"f2\": 0.44470019457345134, \"f0_5\": 0.46587673513315314, \"p4\": 0.6254450453661217, \"phi\": 0.45525997295791254}, {\"truth_threshold\": -13.659999694675207, \"match_probability\": 7.724969986029392e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278590597.0, \"fp\": 147195.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998848903966702, \"fp_rate\": 0.00011510960332984356, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47495612595773823, \"recall\": 0.4380594878948286, \"specificity\": 0.9998848903966702, \"npv\": 0.9998664269977713, \"accuracy\": 0.9997513740272715, \"f1\": 0.4557622764667325, \"f2\": 0.44497297138335185, \"f0_5\": 0.46708780210937223, \"p4\": 0.6261249385865014, \"phi\": 0.45601081977611335}, {\"truth_threshold\": -13.639999695122242, \"match_probability\": 7.832798099380851e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278591477.0, \"fp\": 146315.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.999885578575283, \"fp_rate\": 0.00011442142471691335, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47645168677630356, \"recall\": 0.4380594878948286, \"specificity\": 0.999885578575283, \"npv\": 0.9998664270896916, \"accuracy\": 0.9997520620423406, \"f1\": 0.45644971367552867, \"f2\": 0.4452348406218903, \"f0_5\": 0.4682441608824665, \"p4\": 0.6267734065496591, \"phi\": 0.45672876856835015}, {\"truth_threshold\": -13.599999696016312, \"match_probability\": 8.05299028890447e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278591479.0, \"fp\": 146313.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998855801393254, \"fp_rate\": 0.00011441986067461123, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4764550965054783, \"recall\": 0.4380594878948286, \"specificity\": 0.9998855801393254, \"npv\": 0.9998664270899006, \"accuracy\": 0.9997520636060111, \"f1\": 0.4564512783947263, \"f2\": 0.44523543613030075, \"f0_5\": 0.4682467954917096, \"p4\": 0.6267748818703395, \"phi\": 0.4567304041303908}, {\"truth_threshold\": -13.539999697357416, \"match_probability\": 8.394937932062662e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278591527.0, \"fp\": 146265.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998856176763407, \"fp_rate\": 0.00011438232365936049, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4765369446492352, \"recall\": 0.4380594878948286, \"specificity\": 0.9998856176763407, \"npv\": 0.9998664270949144, \"accuracy\": 0.9997521011341058, \"f1\": 0.4564888348740699, \"f2\": 0.4452497288100681, \"f0_5\": 0.4683100350090354, \"p4\": 0.6268102916503824, \"phi\": 0.456769662885959}, {\"truth_threshold\": -13.499999698251486, \"match_probability\": 8.63093138633307e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278591529.0, \"fp\": 146263.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.999885619240383, \"fp_rate\": 0.00011438075961705838, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4765403555988204, \"recall\": 0.4380594878948286, \"specificity\": 0.999885619240383, \"npv\": 0.9998664270951233, \"accuracy\": 0.9997521026977765, \"f1\": 0.4564903998614961, \"f2\": 0.4452503243583056, \"f0_5\": 0.46831267035962365, \"p4\": 0.6268117671447109, \"phi\": 0.45677129888691625}, {\"truth_threshold\": -13.47999969869852, \"match_probability\": 8.75140415189664e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278591543.0, \"fp\": 146249.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.999885630188679, \"fp_rate\": 0.00011436981132094358, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4765642336132168, \"recall\": 0.4380594878948286, \"specificity\": 0.999885630188679, \"npv\": 0.9998664270965857, \"accuracy\": 0.9997521136434707, \"f1\": 0.45650135507394196, \"f2\": 0.44525449324057714, \"f0_5\": 0.4683311186442586, \"p4\": 0.626822095799517, \"phi\": 0.4567827513853364}, {\"truth_threshold\": -13.459999699145555, \"match_probability\": 8.873558358153138e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278591560.0, \"fp\": 146232.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998856434830387, \"fp_rate\": 0.00011435651696137562, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4765932315621812, \"recall\": 0.4380594878948286, \"specificity\": 0.9998856434830387, \"npv\": 0.9998664270983614, \"accuracy\": 0.9997521269346709, \"f1\": 0.45651465853884315, \"f2\": 0.4452595555597169, \"f0_5\": 0.46835352208686454, \"p4\": 0.6268346381951247, \"phi\": 0.4567966591475304}, {\"truth_threshold\": -13.39999970048666, \"match_probability\": 9.250345899225926e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593017.0, \"fp\": 144775.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998867828878557, \"fp_rate\": 0.00011321711214428549, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4790917072047437, \"recall\": 0.4380594878948286, \"specificity\": 0.9998867828878557, \"npv\": 0.999866427250552, \"accuracy\": 0.9997532660687114, \"f1\": 0.4576577319729364, \"f2\": 0.4456938542160383, \"f0_5\": 0.4702816257709231, \"p4\": 0.6279114634685323, \"phi\": 0.45799337205436524}, {\"truth_threshold\": -13.379999700933695, \"match_probability\": 9.379463801247722e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593022.0, \"fp\": 144770.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998867867979615, \"fp_rate\": 0.0001132132020385302, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47910032634938454, \"recall\": 0.4380594878948286, \"specificity\": 0.9998867867979615, \"npv\": 0.9998664272510742, \"accuracy\": 0.9997532699778879, \"f1\": 0.4576616645242007, \"f2\": 0.44569534606133354, \"f0_5\": 0.47028826979492855, \"p4\": 0.6279151651894882, \"phi\": 0.4579974950160977}, {\"truth_threshold\": -13.339999701827765, \"match_probability\": 9.643130986482657e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593028.0, \"fp\": 144764.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998867914900884, \"fp_rate\": 0.00011320850991162385, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47911066973233013, \"recall\": 0.4380594878948286, \"specificity\": 0.9998867914900884, \"npv\": 0.9998664272517009, \"accuracy\": 0.9997532746688997, \"f1\": 0.4576663836749284, \"f2\": 0.44569713628887087, \"f0_5\": 0.4702962428715433, \"p4\": 0.6279196073122477, \"phi\": 0.45800244271700663}, {\"truth_threshold\": -13.279999703168869, \"match_probability\": 0.00010052592705712347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593053.0, \"fp\": 144739.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998868110406172, \"fp_rate\": 0.00011318895938284743, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47915377196896636, \"recall\": 0.4380594878948286, \"specificity\": 0.9998868110406172, \"npv\": 0.9998664272543123, \"accuracy\": 0.9997532942147823, \"f1\": 0.45768604785057393, \"f2\": 0.44570459572508125, \"f0_5\": 0.4703294669342698, \"p4\": 0.6279381168336168, \"phi\": 0.4580230598617877}, {\"truth_threshold\": -13.179999705404043, \"match_probability\": 0.00010774024339380982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278596363.0, \"fp\": 141429.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998893995306272, \"fp_rate\": 0.00011060046937284856, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4849298206000393, \"recall\": 0.4380594878948286, \"specificity\": 0.9998893995306272, \"npv\": 0.9998664276000561, \"accuracy\": 0.9997558820896444, \"f1\": 0.46030459274418667, \"f2\": 0.44669443501388195, \"f0_5\": 0.4747701793282269, \"p4\": 0.6303984519602139, \"phi\": 0.46077757923673635}, {\"truth_threshold\": -13.159999705851078, \"match_probability\": 0.00010924407680734595, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278596365.0, \"fp\": 141427.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998894010946695, \"fp_rate\": 0.00011059890533054645, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4849333527569379, \"recall\": 0.4380594878948286, \"specificity\": 0.9998894010946695, \"npv\": 0.999866427600265, \"accuracy\": 0.9997558836533149, \"f1\": 0.46030618400424517, \"f2\": 0.4466950344331546, \"f0_5\": 0.47477288788766303, \"p4\": 0.6303999443957757, \"phi\": 0.46077925863670305}, {\"truth_threshold\": -13.079999707639217, \"match_probability\": 0.0001154722406036322, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597597.0, \"fp\": 140195.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998903645447276, \"fp_rate\": 0.00010963545527244415, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48711898385940267, \"recall\": 0.4380594878948286, \"specificity\": 0.9998903645447276, \"npv\": 0.9998664277289522, \"accuracy\": 0.9997568468744116, \"f1\": 0.46128849541579986, \"f2\": 0.44706458267302, \"f0_5\": 0.4764472542013364, \"p4\": 0.6313206295575949, \"phi\": 0.46181726813246876}, {\"truth_threshold\": -13.039999708533287, \"match_probability\": 0.00011871822168312209, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597609.0, \"fp\": 140183.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998903739289814, \"fp_rate\": 0.00010962607101863147, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48714036936225014, \"recall\": 0.4380594878948286, \"specificity\": 0.9998903739289814, \"npv\": 0.9998664277302056, \"accuracy\": 0.9997568562564353, \"f1\": 0.46129808400182226, \"f2\": 0.4470681851757343, \"f0_5\": 0.4764636210419343, \"p4\": 0.6313296104951126, \"phi\": 0.46182741310352865}, {\"truth_threshold\": -12.999999709427357, \"match_probability\": 0.00012205543773770849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597633.0, \"fp\": 140159.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.999890392697489, \"fp_rate\": 0.00010960730251100611, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48718314600163914, \"recall\": 0.4380594878948286, \"specificity\": 0.999890392697489, \"npv\": 0.9998664277327125, \"accuracy\": 0.9997568750204826, \"f1\": 0.4613172623697973, \"f2\": 0.4470753903553422, \"f0_5\": 0.47649635809674856, \"p4\": 0.631347573136727, \"phi\": 0.4618477050495092}, {\"truth_threshold\": -12.979999709874392, \"match_probability\": 0.00012375905725128174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597635.0, \"fp\": 140157.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998903942615313, \"fp_rate\": 0.00010960573846870398, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48718671106070033, \"recall\": 0.4380594878948286, \"specificity\": 0.9998903942615313, \"npv\": 0.9998664277329214, \"accuracy\": 0.9997568765841532, \"f1\": 0.4613188606391106, \"f2\": 0.4470759907974595, \"f0_5\": 0.4764990863877137, \"p4\": 0.6313490700696669, \"phi\": 0.46184939616562437}, {\"truth_threshold\": -12.959999710321426, \"match_probability\": 0.00012548645247902702, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597641.0, \"fp\": 140151.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998903989536582, \"fp_rate\": 0.00010960104634179765, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48719740655094695, \"recall\": 0.4380594878948286, \"specificity\": 0.9998903989536582, \"npv\": 0.9998664277335482, \"accuracy\": 0.999756881275165, \"f1\": 0.461323655513499, \"f2\": 0.4470777921334884, \"f0_5\": 0.4765072714480699, \"p4\": 0.6313535609110782, \"phi\": 0.46185446962531906}, {\"truth_threshold\": -12.919999711215496, \"match_probability\": 0.00012901390162305674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597677.0, \"fp\": 140115.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904271064196, \"fp_rate\": 0.0001095728935803596, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4872615893555045, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904271064196, \"npv\": 0.9998664277373085, \"accuracy\": 0.9997569094212361, \"f1\": 0.46135242685312067, \"f2\": 0.44708860045449905, \"f0_5\": 0.47655638771596665, \"p4\": 0.63138050730124, \"phi\": 0.4618849138914628}, {\"truth_threshold\": -12.799999713897705, \"match_probability\": 0.0001402023355190992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597683.0, \"fp\": 140109.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904317985465, \"fp_rate\": 0.00010956820145345325, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48727228813373247, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904317985465, \"npv\": 0.9998664277379352, \"accuracy\": 0.9997569141122479, \"f1\": 0.46135722242530186, \"f2\": 0.447090401892142, \"f0_5\": 0.4765645747450446, \"p4\": 0.6313849985898955, \"phi\": 0.4618899885205684}, {\"truth_threshold\": -12.77999971434474, \"match_probability\": 0.00014215920891711648, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597702.0, \"fp\": 140090.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904466569484, \"fp_rate\": 0.00010955334305158317, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48730617069787696, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904466569484, \"npv\": 0.9998664277399198, \"accuracy\": 0.9997569289671188, \"f1\": 0.46137240906161425, \"f2\": 0.4470961065404506, \"f0_5\": 0.4765905021930186, \"p4\": 0.6313992214255236, \"phi\": 0.4619060592818114}, {\"truth_threshold\": -12.73999971523881, \"match_probability\": 0.00014615526405373252, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597733.0, \"fp\": 140059.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904708996041, \"fp_rate\": 0.0001095291003959004, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48736146289328436, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904708996041, \"npv\": 0.9998664277431579, \"accuracy\": 0.9997569532040131, \"f1\": 0.46139718940421676, \"f2\": 0.4471054144370662, \"f0_5\": 0.47663281092833737, \"p4\": 0.6314224284803899, \"phi\": 0.4619322835954728}, {\"truth_threshold\": -12.719999715685844, \"match_probability\": 0.00014819521310708466, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133151.0, \"tn\": 1278597873.0, \"fp\": 139919.0, \"fn\": 170810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380529081033422, \"tn_rate\": 0.9998905803825653, \"fp_rate\": 0.0001094196174347524, \"fn_rate\": 0.5619470918966578, \"precision\": 0.48760757314974185, \"recall\": 0.4380529081033422, \"specificity\": 0.9998905803825653, \"npv\": 0.9998664261939859, \"accuracy\": 0.9997570610972853, \"f1\": 0.46150380135555974, \"f2\": 0.44714133925800953, \"f0_5\": 0.4768195461958215, \"p4\": 0.6315222630979505, \"phi\": 0.46204552137075094}, {\"truth_threshold\": -12.679999716579914, \"match_probability\": 0.00015236091275869646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133151.0, \"tn\": 1278598408.0, \"fp\": 139384.0, \"fn\": 170810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380529081033422, \"tn_rate\": 0.9998909987638811, \"fp_rate\": 0.00010900123611893688, \"fn_rate\": 0.5619470918966578, \"precision\": 0.48856477149723887, \"recall\": 0.4380529081033422, \"specificity\": 0.9998909987638811, \"npv\": 0.9998664262498693, \"accuracy\": 0.9997574793791739, \"f1\": 0.4619320862590547, \"f2\": 0.44730206486385526, \"f0_5\": 0.477551482998721, \"p4\": 0.6319231736996332, \"phi\": 0.46249915348809656}, {\"truth_threshold\": -12.619999717921019, \"match_probability\": 0.0001588300070442831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133151.0, \"tn\": 1278598429.0, \"fp\": 139363.0, \"fn\": 170810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380529081033422, \"tn_rate\": 0.9998910151863253, \"fp_rate\": 0.00010898481367476469, \"fn_rate\": 0.5619470918966578, \"precision\": 0.4886024204261066, \"recall\": 0.4380529081033422, \"specificity\": 0.9998910151863253, \"npv\": 0.9998664262520628, \"accuracy\": 0.9997574957977153, \"f1\": 0.46194891365627305, \"f2\": 0.44730837607618595, \"f0_5\": 0.47758025906427254, \"p4\": 0.6319389207599991, \"phi\": 0.4625169868437445}, {\"truth_threshold\": -12.599999718368053, \"match_probability\": 0.00016104683419726568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133151.0, \"tn\": 1278598459.0, \"fp\": 139333.0, \"fn\": 170810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380529081033422, \"tn_rate\": 0.9998910386469597, \"fp_rate\": 0.00010896135304023297, \"fn_rate\": 0.5619470918966578, \"precision\": 0.4886562146768251, \"recall\": 0.4380529081033422, \"specificity\": 0.9998910386469597, \"npv\": 0.9998664262551965, \"accuracy\": 0.9997575192527746, \"f1\": 0.4619729549219787, \"f2\": 0.4473173924027499, \"f0_5\": 0.47762137374569286, \"p4\": 0.6319614179219759, \"phi\": 0.4625424666413346}, {\"truth_threshold\": -12.579999718815088, \"match_probability\": 0.00016329459706641318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133151.0, \"tn\": 1278598646.0, \"fp\": 139146.0, \"fn\": 170810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380529081033422, \"tn_rate\": 0.999891184884915, \"fp_rate\": 0.0001088151150849853, \"fn_rate\": 0.5619470918966578, \"precision\": 0.48899179939551296, \"recall\": 0.4380529081033422, \"specificity\": 0.999891184884915, \"npv\": 0.9998664262747295, \"accuracy\": 0.9997576654559767, \"f1\": 0.46212286857622803, \"f2\": 0.44737360236698, \"f0_5\": 0.4778778149358037, \"p4\": 0.6321016863506168, \"phi\": 0.4627013856052337}, {\"truth_threshold\": -12.559999719262123, \"match_probability\": 0.00016557372721611217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620686.0, \"fp\": 117106.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999084206310843, \"fp_rate\": 9.157936891568776e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5320551755002877, \"recall\": 0.438049618207599, \"specificity\": 0.9999084206310843, \"npv\": 0.9998664277949918, \"accuracy\": 0.9997748963242797, \"f1\": 0.4804977111853299, \"f2\": 0.45409590068890254, \"f0_5\": 0.5101591206029188, \"p4\": 0.6490792256966452, \"phi\": 0.482658618689368}, {\"truth_threshold\": -12.499999720603228, \"match_probability\": 0.00017260372774342275, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620925.0, \"fp\": 116867.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999086075341395, \"fp_rate\": 9.139246586058513e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5325637856625749, \"recall\": 0.438049618207599, \"specificity\": 0.9999086075341395, \"npv\": 0.9998664278199558, \"accuracy\": 0.9997750831829177, \"f1\": 0.4807050099462434, \"f2\": 0.45416993835022557, \"f0_5\": 0.5105331246467678, \"p4\": 0.649268357219397, \"phi\": 0.482889419668835}, {\"truth_threshold\": -12.479999721050262, \"match_probability\": 0.00017501276425237197, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621194.0, \"fp\": 116598.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.999908817897829, \"fp_rate\": 9.118210217095077e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5331374025017217, \"recall\": 0.438049618207599, \"specificity\": 0.999908817897829, \"npv\": 0.9998664278480534, \"accuracy\": 0.9997752934966151, \"f1\": 0.4809385435309883, \"f2\": 0.4542532983258642, \"f0_5\": 0.5109547312911518, \"p4\": 0.6494813609848458, \"phi\": 0.4831495875794477}, {\"truth_threshold\": -12.419999722391367, \"match_probability\": 0.00018244345834475073, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621202.0, \"fp\": 116590.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999088241539983, \"fp_rate\": 9.117584600174231e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5331544806598862, \"recall\": 0.438049618207599, \"specificity\": 0.9999088241539983, \"npv\": 0.999866427848889, \"accuracy\": 0.9997752997512975, \"f1\": 0.4809454922422029, \"f2\": 0.45425577790150545, \"f0_5\": 0.5109672804414082, \"p4\": 0.6494876978093495, \"phi\": 0.48315733134939254}, {\"truth_threshold\": -12.399999722838402, \"match_probability\": 0.00018498980292207934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621212.0, \"fp\": 116580.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999088319742098, \"fp_rate\": 9.116802579023174e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.533175829896288, \"recall\": 0.438049618207599, \"specificity\": 0.9999088319742098, \"npv\": 0.9998664278499335, \"accuracy\": 0.9997753075696505, \"f1\": 0.48095417841359167, \"f2\": 0.45425887740912435, \"f0_5\": 0.510982967746095, \"p4\": 0.649495619013869, \"phi\": 0.4831670115849668}, {\"truth_threshold\": -12.359999723732471, \"match_probability\": 0.00019018958492420193, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621216.0, \"fp\": 116576.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999088351022943, \"fp_rate\": 9.116489770562752e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5331843700695963, \"recall\": 0.438049618207599, \"specificity\": 0.9999088351022943, \"npv\": 0.9998664278503513, \"accuracy\": 0.9997753106969918, \"f1\": 0.4809576529699993, \"f2\": 0.4542601172240152, \"f0_5\": 0.5109892429376797, \"p4\": 0.6494987875497773, \"phi\": 0.48317088384196405}, {\"truth_threshold\": -12.319999724626541, \"match_probability\": 0.00019553549630550054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621217.0, \"fp\": 116575.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999088358843156, \"fp_rate\": 9.116411568447647e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5331865051556712, \"recall\": 0.438049618207599, \"specificity\": 0.9999088358843156, \"npv\": 0.9998664278504558, \"accuracy\": 0.999775311478827, \"f1\": 0.48095852161694536, \"f2\": 0.4542604271787954, \"f0_5\": 0.5109908117596582, \"p4\": 0.6494995796885848, \"phi\": 0.483171851920747}, {\"truth_threshold\": -12.299999725073576, \"match_probability\": 0.00019826452887532282, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621221.0, \"fp\": 116571.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999088390124001, \"fp_rate\": 9.116098759987223e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5331950456709688, \"recall\": 0.438049618207599, \"specificity\": 0.9999088390124001, \"npv\": 0.9998664278508735, \"accuracy\": 0.9997753146061683, \"f1\": 0.48096199623610664, \"f2\": 0.45426166700214593, \"f0_5\": 0.5109970871439043, \"p4\": 0.6495027482631375, \"phi\": 0.4831757242940145}, {\"truth_threshold\": -12.27999972552061, \"match_probability\": 0.00020103164210777665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621243.0, \"fp\": 116549.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999088562168654, \"fp_rate\": 9.114378313454898e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.533242023396169, \"recall\": 0.438049618207599, \"specificity\": 0.9999088562168654, \"npv\": 0.9998664278531715, \"accuracy\": 0.999775331806545, \"f1\": 0.4809811075389228, \"f2\": 0.4542684861515493, \"f0_5\": 0.5110316045125837, \"p4\": 0.649520175975809, \"phi\": 0.4831970240098237}, {\"truth_threshold\": -12.23999972641468, \"match_probability\": 0.00020668224259808178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621259.0, \"fp\": 116533.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999088687292038, \"fp_rate\": 9.113127079613206e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5332761942142636, \"recall\": 0.438049618207599, \"specificity\": 0.9999088687292038, \"npv\": 0.9998664278548427, \"accuracy\": 0.9997753443159099, \"f1\": 0.4809950076222266, \"f2\": 0.45427344566152655, \"f0_5\": 0.5110567109825569, \"p4\": 0.6495328512633779, \"phi\": 0.4832125164799704}, {\"truth_threshold\": -12.219999726861715, \"match_probability\": 0.0002095668144843976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278623770.0, \"fp\": 114022.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999108323843142, \"fp_rate\": 8.91676156858278e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.538693703170262, \"recall\": 0.438049618207599, \"specificity\": 0.9999108323843142, \"npv\": 0.9998664281171207, \"accuracy\": 0.9997773075043626, \"f1\": 0.4831864540864002, \"f2\": 0.4550531231374093, \"f0_5\": 0.5150276679903052, \"p4\": 0.6515282290923087, \"phi\": 0.4856624730916133}, {\"truth_threshold\": -12.15999972820282, \"match_probability\": 0.00021846428430133036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278623780.0, \"fp\": 114012.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999108402045257, \"fp_rate\": 8.915979547431723e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5387154983371231, \"recall\": 0.438049618207599, \"specificity\": 0.9999108402045257, \"npv\": 0.9998664281181652, \"accuracy\": 0.9997773153227156, \"f1\": 0.4831952213934095, \"f2\": 0.4550562335356109, \"f0_5\": 0.5150436056069546, \"p4\": 0.6515362001482868, \"phi\": 0.4856723045458154}, {\"truth_threshold\": -12.11999972909689, \"match_probability\": 0.00022460477168891795, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278623789.0, \"fp\": 114003.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999108472427161, \"fp_rate\": 8.915275728395771e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.53873511549526, \"recall\": 0.438049618207599, \"specificity\": 0.9999108472427161, \"npv\": 0.9998664281191053, \"accuracy\": 0.9997773223592334, \"f1\": 0.48320311224175033, \"f2\": 0.4550590329303478, \"f0_5\": 0.5150579503053212, \"p4\": 0.65154337426543, \"phi\": 0.4856811533646386}, {\"truth_threshold\": -12.099999729543924, \"match_probability\": 0.0002277394233431091, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624672.0, \"fp\": 113120.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115377673924, \"fp_rate\": 8.846223260757432e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5406667478783449, \"recall\": 0.438049618207599, \"specificity\": 0.9999115377673924, \"npv\": 0.9998664282113358, \"accuracy\": 0.9997780127198084, \"f1\": 0.48397854719199757, \"f2\": 0.4553338522167218, \"f0_5\": 0.5164692201411747, \"p4\": 0.6522480038376709, \"phi\": 0.4865516772585109}, {\"truth_threshold\": -12.07999972999096, \"match_probability\": 0.00023091781303279083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624675.0, \"fp\": 113117.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115401134558, \"fp_rate\": 8.845988654412116e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5406733342266726, \"recall\": 0.438049618207599, \"specificity\": 0.9999115401134558, \"npv\": 0.9998664282116492, \"accuracy\": 0.9997780150653143, \"f1\": 0.4839811859810842, \"f2\": 0.45533478648337916, \"f0_5\": 0.5164740281250461, \"p4\": 0.6522504004204743, \"phi\": 0.4865546428471064}, {\"truth_threshold\": -12.039999730885029, \"match_probability\": 0.0002374082550026568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624874.0, \"fp\": 112918.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.999911695735665, \"fp_rate\": 8.83042643350608e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5411105873173269, \"recall\": 0.438049618207599, \"specificity\": 0.999911695735665, \"npv\": 0.999866428232435, \"accuracy\": 0.9997781706505401, \"f1\": 0.48415628994107585, \"f2\": 0.455396768068119, \"f0_5\": 0.5167931577595047, \"p4\": 0.6524094130869377, \"phi\": 0.48675148129541346}, {\"truth_threshold\": -12.019999731332064, \"match_probability\": 0.00024072155289150756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624960.0, \"fp\": 112832.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999117629894839, \"fp_rate\": 8.82370105160699e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5412997699018628, \"recall\": 0.438049618207599, \"specificity\": 0.9999117629894839, \"npv\": 0.9998664282414178, \"accuracy\": 0.9997782378883764, \"f1\": 0.4842320022256852, \"f2\": 0.45542355930185946, \"f0_5\": 0.5169311951573466, \"p4\": 0.6524781561243457, \"phi\": 0.48683662105064096}, {\"truth_threshold\": -11.999999731779099, \"match_probability\": 0.00024408108027122293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624974.0, \"fp\": 112818.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999117739377801, \"fp_rate\": 8.822606221995509e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5413305795875887, \"recall\": 0.438049618207599, \"specificity\": 0.9999117739377801, \"npv\": 0.9998664282428801, \"accuracy\": 0.9997782488340707, \"f1\": 0.4842443297225642, \"f2\": 0.4554279209638449, \"f0_5\": 0.5169536733411864, \"p4\": 0.6524893482224866, \"phi\": 0.4868504852358121}, {\"truth_threshold\": -11.959999732673168, \"match_probability\": 0.00025094141132320783, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624992.0, \"fp\": 112800.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999117880141608, \"fp_rate\": 8.821198583923606e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5413701971945517, \"recall\": 0.438049618207599, \"specificity\": 0.9999117880141608, \"npv\": 0.9998664282447602, \"accuracy\": 0.9997782629071063, \"f1\": 0.48426018028371864, \"f2\": 0.4554335289377299, \"f0_5\": 0.5169825767359005, \"p4\": 0.6525037386271533, \"phi\": 0.4868683123557344}, {\"truth_threshold\": -11.939999733120203, \"match_probability\": 0.00025444353148560106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278625010.0, \"fp\": 112782.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999118020905415, \"fp_rate\": 8.819790945851705e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5414098206008164, \"recall\": 0.438049618207599, \"specificity\": 0.9999118020905415, \"npv\": 0.9998664282466403, \"accuracy\": 0.9997782769801417, \"f1\": 0.48427603188256624, \"f2\": 0.45543913704972583, \"f0_5\": 0.5170114833628306, \"p4\": 0.6525181296665838, \"phi\": 0.4868861414323496}, {\"truth_threshold\": -11.919999733567238, \"match_probability\": 0.00025799451437061175, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278625018.0, \"fp\": 112774.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999118083467107, \"fp_rate\": 8.819165328930859e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5414274328654382, \"recall\": 0.438049618207599, \"specificity\": 0.9999118083467107, \"npv\": 0.999866428247476, \"accuracy\": 0.9997782832348242, \"f1\": 0.48428307737072296, \"f2\": 0.4554416295882794, \"f0_5\": 0.5170243317902206, \"p4\": 0.6525245258878708, \"phi\": 0.48689406609456864}, {\"truth_threshold\": -11.899999734014273, \"match_probability\": 0.00026159504137238267, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278625040.0, \"fp\": 112752.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.999911825551176, \"fp_rate\": 8.817444882398533e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5414758725020536, \"recall\": 0.438049618207599, \"specificity\": 0.999911825551176, \"npv\": 0.9998664282497739, \"accuracy\": 0.9997783004352009, \"f1\": 0.4843024535202405, \"f2\": 0.455448484209979, \"f0_5\": 0.5170596682585554, \"p4\": 0.6525421161430016, \"phi\": 0.48691586090922057}, {\"truth_threshold\": -11.879999734461308, \"match_probability\": 0.0002652458033771831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625292.0, \"fp\": 112500.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.999912022620506, \"fp_rate\": 8.797737949391896e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5420294810888707, \"recall\": 0.4380463283118558, \"specificity\": 0.999912022620506, \"npv\": 0.9998664274942145, \"accuracy\": 0.9997784966758626, \"f1\": 0.48452175178763124, \"f2\": 0.45552390603307713, \"f0_5\": 0.5174624987466548, \"p4\": 0.6527411699229905, \"phi\": 0.4871630512467483}, {\"truth_threshold\": -11.799999736249447, \"match_probability\": 0.0002803653588169889, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625303.0, \"fp\": 112489.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120312227388, \"fp_rate\": 8.796877726125733e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5420537538980125, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120312227388, \"npv\": 0.9998664274953635, \"accuracy\": 0.9997785052760509, \"f1\": 0.48453144929303, \"f2\": 0.4555273345822939, \"f0_5\": 0.5174801964690602, \"p4\": 0.6527499708391563, \"phi\": 0.4871739665065579}, {\"truth_threshold\": -11.759999737143517, \"match_probability\": 0.00028824522974640556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625325.0, \"fp\": 112467.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.999912048427204, \"fp_rate\": 8.795157279593407e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5421023060386946, \"recall\": 0.4380463283118558, \"specificity\": 0.999912048427204, \"npv\": 0.9998664274976614, \"accuracy\": 0.9997785224764277, \"f1\": 0.4845508454684239, \"f2\": 0.4555341918355617, \"f0_5\": 0.5175155955457955, \"p4\": 0.6527675733834843, \"phi\": 0.487195799225431}, {\"truth_threshold\": -11.739999737590551, \"match_probability\": 0.0002922678071014868, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625328.0, \"fp\": 112464.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120507732675, \"fp_rate\": 8.79492267324809e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5421089274590515, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120507732675, \"npv\": 0.9998664274979748, \"accuracy\": 0.9997785248219336, \"f1\": 0.48455349052174956, \"f2\": 0.45553512693154846, \"f0_5\": 0.5175204230678639, \"p4\": 0.6527699738039948, \"phi\": 0.4871987766415917}, {\"truth_threshold\": -11.679999738931656, \"match_probability\": 0.000304675400175696, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625336.0, \"fp\": 112456.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120570294368, \"fp_rate\": 8.794297056327244e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.542126585370819, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120570294368, \"npv\": 0.9998664274988104, \"accuracy\": 0.9997785310766161, \"f1\": 0.4845605441384656, \"f2\": 0.45553762053961516, \"f0_5\": 0.517533296900374, \"p4\": 0.6527763750116657, \"phi\": 0.48720671668465865}, {\"truth_threshold\": -11.61999974027276, \"match_probability\": 0.00031760956323944125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625377.0, \"fp\": 112415.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120890923039, \"fp_rate\": 8.79109076960791e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5422171002264176, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120890923039, \"npv\": 0.999866427503093, \"accuracy\": 0.9997785631318636, \"f1\": 0.4845966971475365, \"f2\": 0.4555504007094528, \"f0_5\": 0.5175992853460963, \"p4\": 0.65280918317152, \"phi\": 0.4872474154936898}, {\"truth_threshold\": -11.599999740719795, \"match_probability\": 0.00032204179959362245, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625387.0, \"fp\": 112405.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120969125155, \"fp_rate\": 8.790308748456853e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5422391816056753, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120969125155, \"npv\": 0.9998664275041375, \"accuracy\": 0.9997785709502167, \"f1\": 0.4846055157729998, \"f2\": 0.4555535179328287, \"f0_5\": 0.5176153826417359, \"p4\": 0.6528171856620014, \"phi\": 0.487257343578352}, {\"truth_threshold\": -11.57999974116683, \"match_probability\": 0.0003265358675317006, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625390.0, \"fp\": 112402.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120992585789, \"fp_rate\": 8.790074142111536e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5422458063701634, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120992585789, \"npv\": 0.9998664275044508, \"accuracy\": 0.9997785732957226, \"f1\": 0.48460816142322644, \"f2\": 0.45555445310816034, \"f0_5\": 0.5176202120256732, \"p4\": 0.6528195864474046, \"phi\": 0.4872603221219862}, {\"truth_threshold\": -11.559999741613865, \"match_probability\": 0.00033109262906279237, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625403.0, \"fp\": 112389.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999121094248539, \"fp_rate\": 8.789057514615163e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5422745155536006, \"recall\": 0.4380463283118558, \"specificity\": 0.9999121094248539, \"npv\": 0.9998664275058087, \"accuracy\": 0.9997785834595816, \"f1\": 0.484619626241358, \"f2\": 0.45555850557896566, \"f0_5\": 0.5176411403974612, \"p4\": 0.652829990054871, \"phi\": 0.4872732297750466}, {\"truth_threshold\": -11.5399997420609, \"match_probability\": 0.0003357129581975347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625418.0, \"fp\": 112374.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999121211551711, \"fp_rate\": 8.787884482888576e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5423076453122518, \"recall\": 0.4380463283118558, \"specificity\": 0.9999121211551711, \"npv\": 0.9998664275073754, \"accuracy\": 0.9997785951871111, \"f1\": 0.484632855551754, \"f2\": 0.4555631815964094, \"f0_5\": 0.5176652906217707, \"p4\": 0.6528419946293779, \"phi\": 0.4872881244944379}, {\"truth_threshold\": -11.479999743402004, \"match_probability\": 0.0003499642748685456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133148.0, \"tn\": 1278633442.0, \"fp\": 104350.0, \"fn\": 170813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380430384161126, \"tn_rate\": 0.9999183960928872, \"fp_rate\": 8.160390711280394e-05, \"fn_rate\": 0.5619569615838874, \"precision\": 0.5606278789716124, \"recall\": 0.4380430384161126, \"specificity\": 0.9999183960928872, \"npv\": 0.9998664275636149, \"accuracy\": 0.999784867851769, \"f1\": 0.4918119377459789, \"f2\": 0.458075250009977, \"f0_5\": 0.5309130406004052, \"p4\": 0.6593250527554214, \"phi\": 0.49545422646728443}, {\"truth_threshold\": -11.459999743849039, \"match_probability\": 0.00035484786043581666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633484.0, \"fp\": 104308.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184289377755, \"fp_rate\": 8.157106222445953e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5607251900360068, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184289377755, \"npv\": 0.9998664267861258, \"accuracy\": 0.9997848999070166, \"f1\": 0.4918473041062695, \"f2\": 0.4580853630257779, \"f0_5\": 0.5309818859912536, \"p4\": 0.6593568360368685, \"phi\": 0.4954953913022158}, {\"truth_threshold\": -11.439999744296074, \"match_probability\": 0.00035979956959653455, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633489.0, \"fp\": 104303.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184328478813, \"fp_rate\": 8.156715211870426e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5607369972625816, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184328478813, \"npv\": 0.999866426786648, \"accuracy\": 0.9997849038161931, \"f1\": 0.4918518463791833, \"f2\": 0.4580869390501853, \"f0_5\": 0.5309903562162166, \"p4\": 0.6593609179858644, \"phi\": 0.4955006115691633}, {\"truth_threshold\": -11.399999745190144, \"match_probability\": 0.00036991117031967156, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633494.0, \"fp\": 104298.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184367579871, \"fp_rate\": 8.156324201294897e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5607488049864179, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184367579871, \"npv\": 0.9998664267871703, \"accuracy\": 0.9997849077253697, \"f1\": 0.4918563887359948, \"f2\": 0.45808851508543724, \"f0_5\": 0.5309988267114181, \"p4\": 0.6593649999854017, \"phi\": 0.49550583200096227}, {\"truth_threshold\": -11.339999746531248, \"match_probability\": 0.0003856136718173716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633506.0, \"fp\": 104286.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184461422409, \"fp_rate\": 8.155385775913629e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5607771455526401, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184461422409, \"npv\": 0.9998664267884237, \"accuracy\": 0.9997849171073933, \"f1\": 0.49186729073465907, \"f2\": 0.45809229761428827, \"f0_5\": 0.5310191570025516, \"p4\": 0.6593747969905056, \"phi\": 0.4955183617099258}, {\"truth_threshold\": -11.319999746978283, \"match_probability\": 0.00039099453324437826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633589.0, \"fp\": 104203.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999185110499964, \"fp_rate\": 8.148895000359855e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5609732462607963, \"recall\": 0.43803974852036937, \"specificity\": 0.9999185110499964, \"npv\": 0.9998664267970933, \"accuracy\": 0.9997849819997237, \"f1\": 0.49194270945907254, \"f2\": 0.45811846181583465, \"f0_5\": 0.5311598174827524, \"p4\": 0.6594425675807248, \"phi\": 0.49560505153846673}, {\"truth_threshold\": -11.299999747425318, \"match_probability\": 0.00039645044954803596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633638.0, \"fp\": 104154.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999185493690328, \"fp_rate\": 8.145063096719676e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5610890809562539, \"recall\": 0.43803974852036937, \"specificity\": 0.9999185493690328, \"npv\": 0.9998664268022114, \"accuracy\": 0.9997850203096537, \"f1\": 0.49198724462459953, \"f2\": 0.4581339095547932, \"f0_5\": 0.5312428929949368, \"p4\": 0.6594825832645379, \"phi\": 0.49565625121608503}, {\"truth_threshold\": -11.279999747872353, \"match_probability\": 0.0004019824667934741, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633679.0, \"fp\": 104113.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999185814319, \"fp_rate\": 8.141856810000341e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5611860406305319, \"recall\": 0.43803974852036937, \"specificity\": 0.9999185814319, \"npv\": 0.9998664268064938, \"accuracy\": 0.9997850523649012, \"f1\": 0.49202451493936855, \"f2\": 0.45814683601449036, \"f0_5\": 0.5313124251297485, \"p4\": 0.6595160695074673, \"phi\": 0.4956991039474651}, {\"truth_threshold\": -11.259999748319387, \"match_probability\": 0.0004075916456016671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633715.0, \"fp\": 104077.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999186095846614, \"fp_rate\": 8.139041533856536e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5612712035881698, \"recall\": 0.43803974852036937, \"specificity\": 0.9999186095846614, \"npv\": 0.9998664268102542, \"accuracy\": 0.9997850805109721, \"f1\": 0.4920572447499469, \"f2\": 0.4581581866781183, \"f0_5\": 0.531373492744982, \"p4\": 0.659545474866211, \"phi\": 0.49573673989350575}, {\"truth_threshold\": -11.239999748766422, \"match_probability\": 0.0004132790613513162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633851.0, \"fp\": 103941.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.999918715939538, \"fp_rate\": 8.12840604620216e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5615931637198003, \"recall\": 0.43803974852036937, \"specificity\": 0.999918715939538, \"npv\": 0.9998664268244596, \"accuracy\": 0.9997851868405737, \"f1\": 0.4921809300081878, \"f2\": 0.45820107203915944, \"f0_5\": 0.5316043193674425, \"p4\": 0.6596565854451024, \"phi\": 0.49587899746919345}, {\"truth_threshold\": -11.219999749213457, \"match_probability\": 0.0004190458043835117, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634182.0, \"fp\": 103610.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.999918974788539, \"fp_rate\": 8.102521146102171e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5623783034926105, \"recall\": 0.43803974852036937, \"specificity\": 0.999918974788539, \"npv\": 0.999866426859033, \"accuracy\": 0.9997854456280599, \"f1\": 0.4924822180878018, \"f2\": 0.4583054809958137, \"f0_5\": 0.532166949509548, \"p4\": 0.6599271654852458, \"phi\": 0.4962257392477412}, {\"truth_threshold\": -11.199999749660492, \"match_probability\": 0.00042489298020921594, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634185.0, \"fp\": 103607.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999189771346024, \"fp_rate\": 8.102286539756854e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5623854296020342, \"recall\": 0.43803974852036937, \"specificity\": 0.9999189771346024, \"npv\": 0.9998664268593463, \"accuracy\": 0.9997854479735658, \"f1\": 0.49248495048223184, \"f2\": 0.4583064275181434, \"f0_5\": 0.5321720543223416, \"p4\": 0.6599296188873653, \"phi\": 0.4962288852464841}, {\"truth_threshold\": -11.179999750107527, \"match_probability\": 0.000430821709719602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634315.0, \"fp\": 103477.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999190787973521, \"fp_rate\": 8.092120264793113e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5626944012441679, \"recall\": 0.43803974852036937, \"specificity\": 0.9999190787973521, \"npv\": 0.999866426872925, \"accuracy\": 0.9997855496121556, \"f1\": 0.49260338337171766, \"f2\": 0.4583474472415227, \"f0_5\": 0.532393356988685, \"p4\": 0.6600359505044517, \"phi\": 0.4963652693098584}, {\"truth_threshold\": -11.159999750554562, \"match_probability\": 0.0004368331293992898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634335.0, \"fp\": 103457.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.999919094437775, \"fp_rate\": 8.090556222490998e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.562741965478183, \"recall\": 0.43803974852036937, \"specificity\": 0.999919094437775, \"npv\": 0.9998664268750141, \"accuracy\": 0.9997855652488618, \"f1\": 0.4926216088721985, \"f2\": 0.45835375861992994, \"f0_5\": 0.5324274198901612, \"p4\": 0.6600523122561655, \"phi\": 0.4963862614472201}, {\"truth_threshold\": -11.139999751001596, \"match_probability\": 0.00044292839154251796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634339.0, \"fp\": 103453.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999190975658597, \"fp_rate\": 8.090243414030576e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5627514792899408, \"recall\": 0.43803974852036937, \"specificity\": 0.9999190975658597, \"npv\": 0.9998664268754319, \"accuracy\": 0.9997855683762029, \"f1\": 0.492625254134131, \"f2\": 0.45835502091646907, \"f0_5\": 0.5324342329935114, \"p4\": 0.6600555847038513, \"phi\": 0.49639046019402605}, {\"truth_threshold\": -11.119999751448631, \"match_probability\": 0.0004491086644722898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634493.0, \"fp\": 103299.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999192179971169, \"fp_rate\": 8.078200288304297e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5631106148653793, \"recall\": 0.4380265889373966, \"specificity\": 0.9999192179971169, \"npv\": 0.9998664237640158, \"accuracy\": 0.9997856856514988, \"f1\": 0.4927544813777866, \"f2\": 0.45839111579950503, \"f0_5\": 0.5326874866471051, \"p4\": 0.6601715857826084, \"phi\": 0.4965414720525902}, {\"truth_threshold\": -11.099999751895666, \"match_probability\": 0.0004553751327625365, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634679.0, \"fp\": 103113.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999193634530511, \"fp_rate\": 8.063654694894636e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5635539414872003, \"recall\": 0.4380265889373966, \"specificity\": 0.9999193634530511, \"npv\": 0.9998664237834443, \"accuracy\": 0.9997858310728657, \"f1\": 0.4929241397438437, \"f2\": 0.45844983127883754, \"f0_5\": 0.5330047998975168, \"p4\": 0.660323848527734, \"phi\": 0.49673702143551396}, {\"truth_threshold\": -11.079999752342701, \"match_probability\": 0.00046172899746333644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634778.0, \"fp\": 103014.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.999919440873145, \"fp_rate\": 8.05591268549917e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.563790190424167, \"recall\": 0.4380265889373966, \"specificity\": 0.999919440873145, \"npv\": 0.9998664237937851, \"accuracy\": 0.999785908474561, \"f1\": 0.4930144894263846, \"f2\": 0.4584810892003518, \"f0_5\": 0.5331738466380851, \"p4\": 0.6604049202460343, \"phi\": 0.49684119834531054}, {\"truth_threshold\": -11.059999752789736, \"match_probability\": 0.0004681714763292323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634782.0, \"fp\": 103010.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999194440012296, \"fp_rate\": 8.055599877038748e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5637997399990684, \"recall\": 0.4380265889373966, \"specificity\": 0.9999194440012296, \"npv\": 0.999866423794203, \"accuracy\": 0.9997859116019022, \"f1\": 0.4930181406147591, \"f2\": 0.45848235223626493, \"f0_5\": 0.5331806790632185, \"p4\": 0.6604081962894345, \"phi\": 0.49684540888992534}, {\"truth_threshold\": -11.03999975323677, \"match_probability\": 0.0004747038040506886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634793.0, \"fp\": 102999.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999194526034623, \"fp_rate\": 8.054739653772585e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.563826002998196, \"recall\": 0.4380265889373966, \"specificity\": 0.9999194526034623, \"npv\": 0.999866423795352, \"accuracy\": 0.9997859202020906, \"f1\": 0.493028181661646, \"f2\": 0.45848582562090817, \"f0_5\": 0.5331994691352784, \"p4\": 0.6604172055763792, \"phi\": 0.4968569884391229}, {\"truth_threshold\": -11.019999753683805, \"match_probability\": 0.0004813272324887312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634859.0, \"fp\": 102933.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999195042168583, \"fp_rate\": 8.049578314175608e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5639836323895695, \"recall\": 0.4380265889373966, \"specificity\": 0.9999195042168583, \"npv\": 0.9998664238022459, \"accuracy\": 0.9997859718032207, \"f1\": 0.49308843653305234, \"f2\": 0.45850666703399634, \"f0_5\": 0.533312237385491, \"p4\": 0.6604712664604654, \"phi\": 0.4969264827255764}, {\"truth_threshold\": -10.99999975413084, \"match_probability\": 0.0004880430309128137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634907.0, \"fp\": 102885.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999195417538735, \"fp_rate\": 8.045824612650535e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.564098327317098, \"recall\": 0.4380265889373966, \"specificity\": 0.9999195417538735, \"npv\": 0.9998664238072597, \"accuracy\": 0.9997860093313153, \"f1\": 0.49313226750915296, \"f2\": 0.45852182561548127, \"f0_5\": 0.5333942806230084, \"p4\": 0.6605105890265252, \"phi\": 0.4969770423280914}, {\"truth_threshold\": -10.979999754577875, \"match_probability\": 0.0004948524862419515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634982.0, \"fp\": 102810.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999196004054598, \"fp_rate\": 8.039959454017607e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5642776315622179, \"recall\": 0.4380265889373966, \"specificity\": 0.9999196004054598, \"npv\": 0.9998664238150937, \"accuracy\": 0.9997860679689633, \"f1\": 0.49320076901136106, \"f2\": 0.4585455129057299, \"f0_5\": 0.5335225237282742, \"p4\": 0.6605720399106217, \"phi\": 0.49705607258429}, {\"truth_threshold\": -10.95999975502491, \"match_probability\": 0.0005017569032891706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640314.0, \"fp\": 97478.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999237701422372, \"fp_rate\": 7.622985776273984e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5773238343429262, \"recall\": 0.4380265889373966, \"specificity\": 0.9999237701422372, \"npv\": 0.9998664243720393, \"accuracy\": 0.9997902367148135, \"f1\": 0.498120026487985, \"f2\": 0.46023581628314547, \"f0_5\": 0.5428005332485354, \"p4\": 0.6649702854128012, \"phi\": 0.5027729915791876}, {\"truth_threshold\": -10.939999755471945, \"match_probability\": 0.0005087576050093137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640358.0, \"fp\": 97434.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999238045511679, \"fp_rate\": 7.619544883209333e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5774340025241026, \"recall\": 0.4380265889373966, \"specificity\": 0.9999238045511679, \"npv\": 0.9998664243766353, \"accuracy\": 0.999790271115567, \"f1\": 0.4981610287762516, \"f2\": 0.460249816616324, \"f0_5\": 0.5428784385807681, \"p4\": 0.6650068236774525, \"phi\": 0.5028209911313314}, {\"truth_threshold\": -10.91999975591898, \"match_probability\": 0.0005158559327502502, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640382.0, \"fp\": 97410.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999238233196756, \"fp_rate\": 7.617668032446795e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.577494111982928, \"recall\": 0.4380265889373966, \"specificity\": 0.9999238233196756, \"npv\": 0.9998664243791421, \"accuracy\": 0.9997902898796143, \"f1\": 0.49818339650598487, \"f2\": 0.4602574535207139, \"f0_5\": 0.5429209418246854, \"p4\": 0.6650267553324611, \"phi\": 0.5028471784953485}, {\"truth_threshold\": -10.899999756366014, \"match_probability\": 0.0005230532465075366, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640387.0, \"fp\": 97405.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999238272297812, \"fp_rate\": 7.617277021871268e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5775066363620591, \"recall\": 0.4380265889373966, \"specificity\": 0.9999238272297812, \"npv\": 0.9998664243796644, \"accuracy\": 0.9997902937887908, \"f1\": 0.49818805670250643, \"f2\": 0.46025904457436156, \"f0_5\": 0.5429297975048791, \"p4\": 0.6650309079109744, \"phi\": 0.502852634710762}, {\"truth_threshold\": -10.839999757707119, \"match_probability\": 0.0005452529889944806, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640693.0, \"fp\": 97099.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999240665282535, \"fp_rate\": 7.593347174648921e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5782741637060137, \"recall\": 0.4380265889373966, \"specificity\": 0.9999240665282535, \"npv\": 0.999866424411627, \"accuracy\": 0.9997905330303943, \"f1\": 0.49847342676847567, \"f2\": 0.46035643799884657, \"f0_5\": 0.5434723155382883, \"p4\": 0.6652851444585429, \"phi\": 0.5031868932289644}, {\"truth_threshold\": -10.819999758154154, \"match_probability\": 0.0005528602288366581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640716.0, \"fp\": 97076.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.99992408451474, \"fp_rate\": 7.59154852600149e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5783319361130055, \"recall\": 0.4380265889373966, \"specificity\": 0.99992408451474, \"npv\": 0.9998664244140294, \"accuracy\": 0.9997905510126064, \"f1\": 0.498494889363136, \"f2\": 0.4603637600851415, \"f0_5\": 0.5435131368500462, \"p4\": 0.6653042615961915, \"phi\": 0.5032120441540884}, {\"truth_threshold\": -10.799999758601189, \"match_probability\": 0.0005605735435487402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640723.0, \"fp\": 97069.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.999924089988888, \"fp_rate\": 7.59100111119575e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5783495213107918, \"recall\": 0.4380265889373966, \"specificity\": 0.999924089988888, \"npv\": 0.9998664244147606, \"accuracy\": 0.9997905564854536, \"f1\": 0.4985014218240158, \"f2\": 0.4603659885924197, \"f0_5\": 0.5435255619447603, \"p4\": 0.6653100800735505, \"phi\": 0.5032196995314367}, {\"truth_threshold\": -10.779999759048223, \"match_probability\": 0.000568394410559373, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640815.0, \"fp\": 96977.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999241619348339, \"fp_rate\": 7.583806516606025e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5785807404832262, \"recall\": 0.4380265889373966, \"specificity\": 0.9999241619348339, \"npv\": 0.9998664244243702, \"accuracy\": 0.9997906284143017, \"f1\": 0.49858729293871157, \"f2\": 0.4603952795505282, \"f0_5\": 0.5436889160033027, \"p4\": 0.665386560949923, \"phi\": 0.5033203455168436}, {\"truth_threshold\": -10.699999760836363, \"match_probability\": 0.0006007836747320541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640940.0, \"fp\": 96852.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999242596874778, \"fp_rate\": 7.574031252217812e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.578895193373769, \"recall\": 0.4380265889373966, \"specificity\": 0.9999242596874778, \"npv\": 0.9998664244374269, \"accuracy\": 0.9997907261437149, \"f1\": 0.49870401306474693, \"f2\": 0.4604350830210003, \"f0_5\": 0.5439110218548117, \"p4\": 0.6654905033642882, \"phi\": 0.5034571895125924}, {\"truth_threshold\": -10.639999762177467, \"match_probability\": 0.0006262804318714204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278641029.0, \"fp\": 96763.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999243292873603, \"fp_rate\": 7.567071263973405e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5791192922324776, \"recall\": 0.4380265889373966, \"specificity\": 0.9999243292873603, \"npv\": 0.9998664244467231, \"accuracy\": 0.9997907957270571, \"f1\": 0.4987871511069236, \"f2\": 0.46046342728687534, \"f0_5\": 0.5440692718527932, \"p4\": 0.665564530157774, \"phi\": 0.5035546904345892}, {\"truth_threshold\": -10.619999762624502, \"match_probability\": 0.000635017429035367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278641043.0, \"fp\": 96749.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999243402356564, \"fp_rate\": 7.565976434361924e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5791545595323021, \"recall\": 0.4380265889373966, \"specificity\": 0.9999243402356564, \"npv\": 0.9998664244481855, \"accuracy\": 0.9997908066727513, \"f1\": 0.4988002315244084, \"f2\": 0.4604678862530919, \"f0_5\": 0.5440941734932314, \"p4\": 0.6655761763210116, \"phi\": 0.5035700328106806}, {\"truth_threshold\": -10.599999763071537, \"match_probability\": 0.0006438762341536904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278641984.0, \"fp\": 95808.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250761175595, \"fp_rate\": 7.492388244047455e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5815349135841293, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250761175595, \"npv\": 0.9998664245464756, \"accuracy\": 0.9997915423797741, \"f1\": 0.49968099798841087, \"f2\": 0.46076779058620776, \"f0_5\": 0.5457731612236784, \"p4\": 0.666359900320763, \"phi\": 0.5046044828372792}, {\"truth_threshold\": -10.579999763518572, \"match_probability\": 0.0006528585432211498, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278641986.0, \"fp\": 95806.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250776816019, \"fp_rate\": 7.492231839817244e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.581539993623034, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250776816019, \"npv\": 0.9998664245466845, \"accuracy\": 0.9997915439434447, \"f1\": 0.4996828732806665, \"f2\": 0.4607684284184655, \"f0_5\": 0.5457767407770564, \"p4\": 0.666361568012172, \"phi\": 0.5046066882438346}, {\"truth_threshold\": -10.559999763965607, \"match_probability\": 0.0006619660757847269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278642008.0, \"fp\": 95784.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250948860672, \"fp_rate\": 7.490511393284919e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.581595879909316, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250948860672, \"npv\": 0.9998664245489824, \"accuracy\": 0.9997915611438214, \"f1\": 0.4997035024245245, \"f2\": 0.4607754446898505, \"f0_5\": 0.5458161189634236, \"p4\": 0.6663799131686156, \"phi\": 0.5046309496229728}, {\"truth_threshold\": -10.519999764859676, \"match_probability\": 0.0006805638093056732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278642009.0, \"fp\": 95783.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250956680883, \"fp_rate\": 7.490433191169813e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5815984204502765, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250956680883, \"npv\": 0.9998664245490869, \"accuracy\": 0.9997915619256567, \"f1\": 0.49970444015335336, \"f2\": 0.46077576361635414, \"f0_5\": 0.5458179090160002, \"p4\": 0.6663807470633633, \"phi\": 0.5046320524960125}, {\"truth_threshold\": -10.499999765306711, \"match_probability\": 0.0006900575700683387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278642012.0, \"fp\": 95780.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250980141517, \"fp_rate\": 7.490198584824495e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5816060422063314, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250980141517, \"npv\": 0.9998664245494002, \"accuracy\": 0.9997915642711627, \"f1\": 0.4997072533609566, \"f2\": 0.4607767203985141, \"f0_5\": 0.5458232792441785, \"p4\": 0.6663832487601286, \"phi\": 0.5046353611584812}, {\"truth_threshold\": -10.479999765753746, \"match_probability\": 0.0006996836746108304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278642021.0, \"fp\": 95771.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999251050523421, \"fp_rate\": 7.489494765788544e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5816289086731261, \"recall\": 0.4380265889373966, \"specificity\": 0.9999251050523421, \"npv\": 0.9998664245503404, \"accuracy\": 0.9997915713076804, \"f1\": 0.49971569317382125, \"f2\": 0.4607795907688346, \"f0_5\": 0.5458393905627751, \"p4\": 0.6663907539631271, \"phi\": 0.5046452875360522}, {\"truth_threshold\": -10.45999976620078, \"match_probability\": 0.0007094439652109307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278642030.0, \"fp\": 95762.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999251120905325, \"fp_rate\": 7.488790946752592e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.581651776938031, \"recall\": 0.4380265889373966, \"specificity\": 0.9999251120905325, \"npv\": 0.9998664245512804, \"accuracy\": 0.9997915783441981, \"f1\": 0.4997241332717794, \"f2\": 0.4607824611749169, \"f0_5\": 0.5458555028325301, \"p4\": 0.6663982593351835, \"phi\": 0.504655214498915}, {\"truth_threshold\": -10.439999766647816, \"match_probability\": 0.0007193403097184756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278642040.0, \"fp\": 95752.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.999925119910744, \"fp_rate\": 7.488008925601535e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5816771882304114, \"recall\": 0.4380265889373966, \"specificity\": 0.999925119910744, \"npv\": 0.9998664245523249, \"accuracy\": 0.9997915861625511, \"f1\": 0.49973351149278605, \"f2\": 0.4607856505569518, \"f0_5\": 0.5458734064701392, \"p4\": 0.6664065988357532, \"phi\": 0.5046662451441751}, {\"truth_threshold\": -10.41999976709485, \"match_probability\": 0.0007293746019082532, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133140.0, \"tn\": 1278644247.0, \"fp\": 93545.0, \"fn\": 170821.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43801671925016694, \"tn_rate\": 0.9999268458314243, \"fp_rate\": 7.315416857563243e-05, \"fn_rate\": 0.5619832807498331, \"precision\": 0.5873348479167126, \"recall\": 0.43801671925016694, \"specificity\": 0.9999268458314243, \"npv\": 0.9998664224372433, \"accuracy\": 0.999793309327565, \"f1\": 0.5018034621951357, \"f2\": 0.46148119032615637, \"f0_5\": 0.5498467416810592, \"p4\": 0.6682447366411067, \"phi\": 0.5071104591302085}, {\"truth_threshold\": -10.399999767541885, \"match_probability\": 0.0007395487618377182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645880.0, \"fp\": 91912.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281228719641, \"fp_rate\": 7.187712803595626e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5915947940688999, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281228719641, \"npv\": 0.9998664218259483, \"accuracy\": 0.999794585282784, \"f1\": 0.503349640461842, \"f2\": 0.462001047959775, \"f0_5\": 0.552827062736419, \"p4\": 0.6696144566618408, \"phi\": 0.5089454223889792}, {\"truth_threshold\": -10.37999976798892, \"match_probability\": 0.0007498647362095799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645885.0, \"fp\": 91907.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281267820698, \"fp_rate\": 7.187321793020097e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5916079379326893, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281267820698, \"npv\": 0.9998664218264706, \"accuracy\": 0.9997945891919605, \"f1\": 0.5033543979569268, \"f2\": 0.46200265113922645, \"f0_5\": 0.5528362448044047, \"p4\": 0.6696186668579291, \"phi\": 0.5089510796999674}, {\"truth_threshold\": -10.359999768435955, \"match_probability\": 0.0007603244987393332, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645907.0, \"fp\": 91885.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281439865351, \"fp_rate\": 7.185601346487772e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5916657778725825, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281439865351, \"npv\": 0.9998664218287685, \"accuracy\": 0.9997946063923372, \"f1\": 0.5033753320037431, \"f2\": 0.46200970526099544, \"f0_5\": 0.5528766495273895, \"p4\": 0.6696371923496997, \"phi\": 0.5089759741078629}, {\"truth_threshold\": -10.33999976888299, \"match_probability\": 0.0007709300505277953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645915.0, \"fp\": 91877.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281502427043, \"fp_rate\": 7.184975729566926e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5916868133821594, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281502427043, \"npv\": 0.9998664218296042, \"accuracy\": 0.9997946126470196, \"f1\": 0.5033829448161262, \"f2\": 0.4620122704495926, \"f0_5\": 0.5528913436182804, \"p4\": 0.669643929146307, \"phi\": 0.5089850275248097}, {\"truth_threshold\": -10.319999769330025, \"match_probability\": 0.0007816834204387144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645926.0, \"fp\": 91866.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.999928158844937, \"fp_rate\": 7.184115506300763e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5917157396502299, \"recall\": 0.4380134293544238, \"specificity\": 0.999928158844937, \"npv\": 0.9998664218307531, \"accuracy\": 0.999794621247208, \"f1\": 0.5033934128091408, \"f2\": 0.46201579763042483, \"f0_5\": 0.5529115492686346, \"p4\": 0.6696531924629717, \"phi\": 0.508997476761322}, {\"truth_threshold\": -10.29999976977706, \"match_probability\": 0.0007925866654815217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645949.0, \"fp\": 91843.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281768314234, \"fp_rate\": 7.182316857653331e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5917762309873679, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281768314234, \"npv\": 0.9998664218331557, \"accuracy\": 0.99979463922942, \"f1\": 0.5034153018378161, \"f2\": 0.4620231728189247, \"f0_5\": 0.5529538022193076, \"p4\": 0.6696725620441747, \"phi\": 0.5090235099327688}, {\"truth_threshold\": -10.279999770224094, \"match_probability\": 0.0008036418711992888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645951.0, \"fp\": 91841.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281783954658, \"fp_rate\": 7.18216045342312e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5917814916881501, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281783954658, \"npv\": 0.9998664218333646, \"accuracy\": 0.9997946407930907, \"f1\": 0.5034172053215765, \"f2\": 0.46202381415079147, \"f0_5\": 0.5529574766941251, \"p4\": 0.6696742464085386, \"phi\": 0.5090257738754294}, {\"truth_threshold\": -10.25999977067113, \"match_probability\": 0.0008148511520619635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645966.0, \"fp\": 91826.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.999928190125783, \"fp_rate\": 7.180987421696536e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.591820949925544, \"recall\": 0.4380134293544238, \"specificity\": 0.999928190125783, \"npv\": 0.9998664218349314, \"accuracy\": 0.9997946525206203, \"f1\": 0.5034314819086224, \"f2\": 0.4620286241965451, \"f0_5\": 0.5529850368119513, \"p4\": 0.6696868794113506, \"phi\": 0.5090427544074955}, {\"truth_threshold\": -10.239999771118164, \"match_probability\": 0.0008262166518649536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645969.0, \"fp\": 91823.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281924718465, \"fp_rate\": 7.180752815351218e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5918288422044612, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281924718465, \"npv\": 0.9998664218352448, \"accuracy\": 0.9997946548661262, \"f1\": 0.5034343373232021, \"f2\": 0.4620295862177142, \"f0_5\": 0.5529905491651915, \"p4\": 0.6696894060691087, \"phi\": 0.5090461507176653}, {\"truth_threshold\": -10.219999771565199, \"match_probability\": 0.0008377405441331278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278646066.0, \"fp\": 91726.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999282683278982, \"fp_rate\": 7.173167210185965e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5920841393725124, \"recall\": 0.4380134293544238, \"specificity\": 0.9999282683278982, \"npv\": 0.9998664218453768, \"accuracy\": 0.9997947307041508, \"f1\": 0.5035266798531086, \"f2\": 0.46206069372787983, \"f0_5\": 0.5531688411619874, \"p4\": 0.6697711116121237, \"phi\": 0.5091560013628098}, {\"truth_threshold\": -10.199999772012234, \"match_probability\": 0.0008494250325303055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278646080.0, \"fp\": 91712.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999282792761942, \"fp_rate\": 7.172072380574484e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5921210045763639, \"recall\": 0.4380134293544238, \"specificity\": 0.9999282792761942, \"npv\": 0.9998664218468392, \"accuracy\": 0.999794741649845, \"f1\": 0.5035400104384923, \"f2\": 0.46206518381753253, \"f0_5\": 0.5531945835220403, \"p4\": 0.6697829058111595, \"phi\": 0.509171861963738}, {\"truth_threshold\": -10.179999772459269, \"match_probability\": 0.0008612723512743095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647018.0, \"fp\": 90774.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.999929012812034, \"fp_rate\": 7.098718796605333e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.594601474679898, \"recall\": 0.4380134293544238, \"specificity\": 0.999929012812034, \"npv\": 0.9998664219448175, \"accuracy\": 0.9997954750113619, \"f1\": 0.5044347704186984, \"f2\": 0.46236621874385747, \"f0_5\": 0.5549247965802304, \"p4\": 0.6705740644887375, \"phi\": 0.5102379076836463}, {\"truth_threshold\": -10.159999772906303, \"match_probability\": 0.0008732847655576527, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647082.0, \"fp\": 90710.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999290628613876, \"fp_rate\": 7.093713861238568e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5947714754142301, \"recall\": 0.4380134293544238, \"specificity\": 0.9999290628613876, \"npv\": 0.9998664219515024, \"accuracy\": 0.9997955250488214, \"f1\": 0.5044959360375892, \"f2\": 0.46238677273557627, \"f0_5\": 0.5550432440049127, \"p4\": 0.6706281135838985, \"phi\": 0.5103108883203638}, {\"truth_threshold\": -10.139999773353338, \"match_probability\": 0.0008854645719739357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647180.0, \"fp\": 90612.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999291394994604, \"fp_rate\": 7.086050053958208e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.595031977510715, \"recall\": 0.4380134293544238, \"specificity\": 0.9999291394994604, \"npv\": 0.999866421961739, \"accuracy\": 0.9997956016686814, \"f1\": 0.5045896246437451, \"f2\": 0.462418249577138, \"f0_5\": 0.5552247146497187, \"p4\": 0.6707108931483428, \"phi\": 0.5104227005845554}, {\"truth_threshold\": -10.119999773800373, \"match_probability\": 0.0008978140989500266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647230.0, \"fp\": 90562.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.999929178600518, \"fp_rate\": 7.082139948202924e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5951649746760185, \"recall\": 0.4380134293544238, \"specificity\": 0.999929178600518, \"npv\": 0.9998664219669617, \"accuracy\": 0.9997956407604467, \"f1\": 0.5046374383601624, \"f2\": 0.4624343108412728, \"f0_5\": 0.555317347436737, \"p4\": 0.6707531354935629, \"phi\": 0.5104797759567936}, {\"truth_threshold\": -10.099999774247408, \"match_probability\": 0.0009103357071841042, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647284.0, \"fp\": 90508.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999292208296602, \"fp_rate\": 7.077917033987215e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5953086784083846, \"recall\": 0.4380134293544238, \"specificity\": 0.9999292208296602, \"npv\": 0.9998664219726022, \"accuracy\": 0.9997956829795532, \"f1\": 0.5046890873527315, \"f2\": 0.46245165825975987, \"f0_5\": 0.5554174255704188, \"p4\": 0.6707987632033184, \"phi\": 0.5105414388513704}, {\"truth_threshold\": -10.079999774694443, \"match_probability\": 0.0009230317900896363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647326.0, \"fp\": 90466.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999292536745484, \"fp_rate\": 7.074632545152775e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5954204959638648, \"recall\": 0.4380134293544238, \"specificity\": 0.9999292536745484, \"npv\": 0.9998664219769894, \"accuracy\": 0.9997957158166361, \"f1\": 0.504729266101303, \"f2\": 0.46246515159620105, \"f0_5\": 0.5554952890608246, \"p4\": 0.670834255713927, \"phi\": 0.5105894143194366}, {\"truth_threshold\": -10.039999775588512, \"match_probability\": 0.0009489571198514448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647354.0, \"fp\": 90438.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999292755711408, \"fp_rate\": 7.072442885929815e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5954950643402497, \"recall\": 0.4380134293544238, \"specificity\": 0.9999292755711408, \"npv\": 0.999866421979914, \"accuracy\": 0.9997957377080247, \"f1\": 0.5047560554879459, \"f2\": 0.46247414759128846, \"f0_5\": 0.5555472101840238, \"p4\": 0.6708579194743369, \"phi\": 0.510621405473328}, {\"truth_threshold\": -10.019999776035547, \"match_probability\": 0.0009621913211916086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656824.0, \"fp\": 80968.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.9999366813114412, \"fp_rate\": 6.331868855878782e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.621830410312697, \"recall\": 0.43800684956293734, \"specificity\": 0.9999366813114412, \"npv\": 0.9998664214053652, \"accuracy\": 0.9998031401246993, \"f1\": 0.5139769836275687, \"f2\": 0.4655305888531689, \"f0_5\": 0.5736779557748705, \"p4\": 0.6789532597225263, \"phi\": 0.5217931636348089}, {\"truth_threshold\": -9.999999776482582, \"match_probability\": 0.0009756099071017838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656830.0, \"fp\": 80962.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.9999366860035681, \"fp_rate\": 6.331399643188147e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.6218478367484201, \"recall\": 0.43800684956293734, \"specificity\": 0.9999366860035681, \"npv\": 0.9998664214059919, \"accuracy\": 0.9998031448157111, \"f1\": 0.5139829363394202, \"f2\": 0.4655325422062278, \"f0_5\": 0.573689821322231, \"p4\": 0.6789584539479876, \"phi\": 0.5218004794250867}, {\"truth_threshold\": -9.959999777376652, \"match_probability\": 0.0010030105235921652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133136.0, \"tn\": 1278656902.0, \"fp\": 80890.0, \"fn\": 170825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380035596671941, \"tn_rate\": 0.999936742309091, \"fp_rate\": 6.325769090900538e-05, \"fn_rate\": 0.5619964403328058, \"precision\": 0.6220552643136815, \"recall\": 0.4380035596671941, \"specificity\": 0.999936742309091, \"npv\": 0.9998664206316509, \"accuracy\": 0.9998032003260178, \"f1\": 0.5140515109452554, \"f2\": 0.46555281249344344, \"f0_5\": 0.5738299147030554, \"p4\": 0.6790182880969741, \"phi\": 0.5218855913996467}, {\"truth_threshold\": -9.939999777823687, \"match_probability\": 0.0010169977889108628, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133136.0, \"tn\": 1278656904.0, \"fp\": 80888.0, \"fn\": 170825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380035596671941, \"tn_rate\": 0.9999367438731332, \"fp_rate\": 6.325612686670325e-05, \"fn_rate\": 0.5619964403328058, \"precision\": 0.6220610772623631, \"recall\": 0.4380035596671941, \"specificity\": 0.9999367438731332, \"npv\": 0.9998664206318598, \"accuracy\": 0.9998032018896884, \"f1\": 0.5140534957575992, \"f2\": 0.46555346367636735, \"f0_5\": 0.5738338719562918, \"p4\": 0.6790200198413108, \"phi\": 0.5218880312939475}, {\"truth_threshold\": -9.919999778270721, \"match_probability\": 0.001031179909258699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133136.0, \"tn\": 1278656925.0, \"fp\": 80867.0, \"fn\": 170825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380035596671941, \"tn_rate\": 0.9999367602955774, \"fp_rate\": 6.323970442253106e-05, \"fn_rate\": 0.5619964403328058, \"precision\": 0.6221221197833675, \"recall\": 0.4380035596671941, \"specificity\": 0.9999367602955774, \"npv\": 0.9998664206340533, \"accuracy\": 0.9998032183082298, \"f1\": 0.5140743372126249, \"f2\": 0.4655603012070522, \"f0_5\": 0.5738754264107871, \"p4\": 0.679038203690162, \"phi\": 0.5219136522487055}, {\"truth_threshold\": -9.899999778717756, \"match_probability\": 0.0010455595934848532, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133135.0, \"tn\": 1278661598.0, \"fp\": 76194.0, \"fn\": 170826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800026977145096, \"tn_rate\": 0.9999404146804164, \"fp_rate\": 5.958531958364143e-05, \"fn_rate\": 0.5619997302285491, \"precision\": 0.6360083887086835, \"recall\": 0.43800026977145096, \"specificity\": 0.9999404146804164, \"npv\": 0.9998664203403088, \"accuracy\": 0.9998068710427782, \"f1\": 0.5187515829258315, \"f2\": 0.46708364528376556, \"f0_5\": 0.5832720715479239, \"p4\": 0.6831064069388962, \"phi\": 0.5277077307569182}, {\"truth_threshold\": -9.879999779164791, \"match_probability\": 0.001060139587937777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133135.0, \"tn\": 1278661604.0, \"fp\": 76188.0, \"fn\": 170826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800026977145096, \"tn_rate\": 0.9999404193725433, \"fp_rate\": 5.9580627456735084e-05, \"fn_rate\": 0.5619997302285491, \"precision\": 0.6360266191483974, \"recall\": 0.43800026977145096, \"specificity\": 0.9999404193725433, \"npv\": 0.9998664203409355, \"accuracy\": 0.99980687573379, \"f1\": 0.5187576468387871, \"f2\": 0.46708561172129304, \"f0_5\": 0.5832843374781929, \"p4\": 0.683111664983937, \"phi\": 0.5277152981824835}, {\"truth_threshold\": -9.859999779611826, \"match_probability\": 0.001074922676979845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133134.0, \"tn\": 1278661616.0, \"fp\": 76176.0, \"fn\": 170827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43799697987570774, \"tn_rate\": 0.9999404287567971, \"fp_rate\": 5.95712432029224e-05, \"fn_rate\": 0.5620030201242923, \"precision\": 0.6360613444173714, \"recall\": 0.43799697987570774, \"specificity\": 0.9999404287567971, \"npv\": 0.9998664195603302, \"accuracy\": 0.9998068843339785, \"f1\": 0.5187668892261593, \"f2\": 0.46708636399996073, \"f0_5\": 0.5833065340812004, \"p4\": 0.6831196791864026, \"phi\": 0.5277277300217014}, {\"truth_threshold\": -9.819999780505896, \"match_probability\": 0.001105109469487079, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133134.0, \"tn\": 1278661644.0, \"fp\": 76148.0, \"fn\": 170827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43799697987570774, \"tn_rate\": 0.9999404506533893, \"fp_rate\": 5.9549346610692806e-05, \"fn_rate\": 0.5620030201242923, \"precision\": 0.6361464435546297, \"recall\": 0.43799697987570774, \"specificity\": 0.9999404506533893, \"npv\": 0.999866419563255, \"accuracy\": 0.9998069062253669, \"f1\": 0.5187951905822388, \"f2\": 0.46709554102584616, \"f0_5\": 0.5833637866984959, \"p4\": 0.6831442185603284, \"phi\": 0.5277630520008962}, {\"truth_threshold\": -9.79999978095293, \"match_probability\": 0.0011205189364761256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133132.0, \"tn\": 1278661657.0, \"fp\": 76135.0, \"fn\": 170829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43799040008422135, \"tn_rate\": 0.9999404608196643, \"fp_rate\": 5.9539180335729064e-05, \"fn_rate\": 0.5620095999157787, \"precision\": 0.6361824845771192, \"recall\": 0.43799040008422135, \"specificity\": 0.9999404608196643, \"npv\": 0.9998664180008953, \"accuracy\": 0.9998069148255554, \"f1\": 0.5188025594862322, \"f2\": 0.4670934404407797, \"f0_5\": 0.5833856983477195, \"p4\": 0.6831506081349987, \"phi\": 0.5277740458595529}, {\"truth_threshold\": -9.779999781399965, \"match_probability\": 0.0011361430261807566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661721.0, \"fp\": 76071.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999405108690179, \"fp_rate\": 5.948913098206141e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6363753692603321, \"recall\": 0.43798711018847813, \"specificity\": 0.9999405108690179, \"npv\": 0.9998664172257217, \"accuracy\": 0.9998069640811796, \"f1\": 0.5188643764262038, \"f2\": 0.4671112371109424, \"f0_5\": 0.5835142785261521, \"p4\": 0.6832042044744057, \"phi\": 0.5278521118393001}, {\"truth_threshold\": -9.759999781847, \"match_probability\": 0.0011519847209986987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661735.0, \"fp\": 76057.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999405218173141, \"fp_rate\": 5.947818268594661e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6364179589651414, \"recall\": 0.43798711018847813, \"specificity\": 0.9999405218173141, \"npv\": 0.9998664172271841, \"accuracy\": 0.9998069750268739, \"f1\": 0.5188785323560993, \"f2\": 0.46711582617092107, \"f0_5\": 0.5835429244691697, \"p4\": 0.6832164772540417, \"phi\": 0.52786978521998}, {\"truth_threshold\": -9.739999782294035, \"match_probability\": 0.0011680470445783785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661752.0, \"fp\": 76040.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999405351116736, \"fp_rate\": 5.946488832637864e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6364696826998006, \"recall\": 0.43798711018847813, \"specificity\": 0.9999405351116736, \"npv\": 0.9998664172289599, \"accuracy\": 0.9998069883180741, \"f1\": 0.5188957227380089, \"f2\": 0.4671213987221187, \"f0_5\": 0.5835777126099707, \"p4\": 0.6832313805078161, \"phi\": 0.5278912481385575}, {\"truth_threshold\": -9.71999978274107, \"match_probability\": 0.0011843330623840628, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661775.0, \"fp\": 76017.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999405530981601, \"fp_rate\": 5.944690183990433e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6365396752538872, \"recall\": 0.43798711018847813, \"specificity\": 0.9999405530981601, \"npv\": 0.9998664172313624, \"accuracy\": 0.9998070063002861, \"f1\": 0.5189189821266047, \"f2\": 0.4671289382677236, \"f0_5\": 0.583624785520708, \"p4\": 0.6832515447684306, \"phi\": 0.5279202903691479}, {\"truth_threshold\": -9.699999783188105, \"match_probability\": 0.0012008458822685877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661784.0, \"fp\": 76008.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999405601363505, \"fp_rate\": 5.9439863649544815e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6365670678352675, \"recall\": 0.43798711018847813, \"specificity\": 0.9999405601363505, \"npv\": 0.9998664172323024, \"accuracy\": 0.9998070133368039, \"f1\": 0.5189280841941142, \"f2\": 0.4671318885909516, \"f0_5\": 0.5836432074225987, \"p4\": 0.683259435455275, \"phi\": 0.5279316560241036}, {\"truth_threshold\": -9.67999978363514, \"match_probability\": 0.0012175886550537785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661793.0, \"fp\": 75999.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999405671745408, \"fp_rate\": 5.94328254591853e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6365944627743508, \"recall\": 0.43798711018847813, \"specificity\": 0.9999405671745408, \"npv\": 0.9998664172332425, \"accuracy\": 0.9998070203733216, \"f1\": 0.5189371865809379, \"f2\": 0.46713483895144753, \"f0_5\": 0.5836616304874873, \"p4\": 0.6832673263243763, \"phi\": 0.5279430224125976}, {\"truth_threshold\": -9.659999784082174, \"match_probability\": 0.0012345645751186526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661842.0, \"fp\": 75950.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999406054935772, \"fp_rate\": 5.9394506422783504e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6367436543731855, \"recall\": 0.43798711018847813, \"specificity\": 0.9999406054935772, \"npv\": 0.999866417238361, \"accuracy\": 0.9998070586832516, \"f1\": 0.5189867496228379, \"f2\": 0.4671509026790884, \"f0_5\": 0.58376195424828, \"p4\": 0.6833102909204624, \"phi\": 0.5280049189553391}, {\"truth_threshold\": -9.63999978452921, \"match_probability\": 0.0012517768809955122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661847.0, \"fp\": 75945.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.999940609403683, \"fp_rate\": 5.939059631702822e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6367588819376686, \"recall\": 0.43798711018847813, \"specificity\": 0.999940609403683, \"npv\": 0.9998664172388833, \"accuracy\": 0.9998070625924281, \"f1\": 0.5189918076084181, \"f2\": 0.46715254189708894, \"f0_5\": 0.583772193305942, \"p4\": 0.6833146753667323, \"phi\": 0.5280112361522855}, {\"truth_threshold\": -9.619999784976244, \"match_probability\": 0.001269228855974021, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661886.0, \"fp\": 75906.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999406399025078, \"fp_rate\": 5.9360097492137e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6368776819414744, \"recall\": 0.43798711018847813, \"specificity\": 0.9999406399025078, \"npv\": 0.9998664172429571, \"accuracy\": 0.9998070930840051, \"f1\": 0.5190312632797789, \"f2\": 0.4671653281923192, \"f0_5\": 0.5838520702845079, \"p4\": 0.6833488759787636, \"phi\": 0.5280605180654483}, {\"truth_threshold\": -9.579999785870314, \"match_probability\": 0.0013048651738626527, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278661894.0, \"fp\": 75898.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999406461586771, \"fp_rate\": 5.935384132292854e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6369020566524263, \"recall\": 0.43798711018847813, \"specificity\": 0.9999406461586771, \"npv\": 0.9998664172437927, \"accuracy\": 0.9998070993386875, \"f1\": 0.5190393574923488, \"f2\": 0.46716795110862513, \"f0_5\": 0.5838684580076609, \"p4\": 0.6833558919120891, \"phi\": 0.5280706288802409}, {\"truth_threshold\": -9.559999786317348, \"match_probability\": 0.0013230563126894958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662339.0, \"fp\": 75453.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999409941580893, \"fp_rate\": 5.900584191070815e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6382608445518352, \"recall\": 0.43798711018847813, \"specificity\": 0.9999409941580893, \"npv\": 0.9998664172902759, \"accuracy\": 0.9998074472553985, \"f1\": 0.5194899960003512, \"f2\": 0.4673138972275187, \"f0_5\": 0.5847814761876733, \"p4\": 0.6837463802184162, \"phi\": 0.5286339585293224}, {\"truth_threshold\": -9.539999786764383, \"match_probability\": 0.0013415007137171481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662357.0, \"fp\": 75435.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.99994100823447, \"fp_rate\": 5.899176552998912e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6383159287707488, \"recall\": 0.43798711018847813, \"specificity\": 0.99994100823447, \"npv\": 0.9998664172921562, \"accuracy\": 0.999807461328434, \"f1\": 0.5195082405414739, \"f2\": 0.4673198025849299, \"f0_5\": 0.5848184673504799, \"p4\": 0.6837621846420482, \"phi\": 0.5286567828204523}, {\"truth_threshold\": -9.519999787211418, \"match_probability\": 0.0013602018933700395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662396.0, \"fp\": 75396.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999410387332949, \"fp_rate\": 5.8961266705097894e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6384353105353263, \"recall\": 0.43798711018847813, \"specificity\": 0.9999410387332949, \"npv\": 0.99986641729623, \"accuracy\": 0.9998074918200109, \"f1\": 0.5195477747771655, \"f2\": 0.46733259803801114, \"f0_5\": 0.5848986309265959, \"p4\": 0.6837964300664797, \"phi\": 0.528706245587134}, {\"truth_threshold\": -9.499999787658453, \"match_probability\": 0.0013791634166279733, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662449.0, \"fp\": 75343.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999410801804159, \"fp_rate\": 5.8919819584091874e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.638597618887727, \"recall\": 0.43798711018847813, \"specificity\": 0.9999410801804159, \"npv\": 0.9998664173017662, \"accuracy\": 0.9998075332572822, \"f1\": 0.5196015104354699, \"f2\": 0.467349987853836, \"f0_5\": 0.5850076064039682, \"p4\": 0.6838429742189451, \"phi\": 0.5287734864609656}, {\"truth_threshold\": -9.479999788105488, \"match_probability\": 0.0013983888976890446, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278662910.0, \"fp\": 74882.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999414406921665, \"fp_rate\": 5.855930783345457e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6400076919378876, \"recall\": 0.43797724050124853, \"specificity\": 0.9999414406921665, \"npv\": 0.9998664150043467, \"accuracy\": 0.9998078913378522, \"f1\": 0.5200607065634577, \"f2\": 0.4674917512610141, \"f0_5\": 0.5859501884241299, \"p4\": 0.6842405819043036, \"phi\": 0.5293513247758596}, {\"truth_threshold\": -9.459999788552523, \"match_probability\": 0.0014178820006413976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278662949.0, \"fp\": 74843.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999414711909914, \"fp_rate\": 5.8528809008563346e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6401277101134293, \"recall\": 0.43797724050124853, \"specificity\": 0.9999414711909914, \"npv\": 0.9998664150084206, \"accuracy\": 0.9998079218294291, \"f1\": 0.5201003258245236, \"f2\": 0.4675045564206024, \"f0_5\": 0.58603066439523, \"p4\": 0.6842748760393743, \"phi\": 0.5294009848536011}, {\"truth_threshold\": -9.439999788999557, \"match_probability\": 0.001437646440143931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663270.0, \"fp\": 74522.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.999941722219781, \"fp_rate\": 5.827778021907403e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6411172646279798, \"recall\": 0.43797724050124853, \"specificity\": 0.999941722219781, \"npv\": 0.9998664150419517, \"accuracy\": 0.9998081727985623, \"f1\": 0.5204266522807367, \"f2\": 0.4676099793887435, \"f0_5\": 0.5866938842424515, \"p4\": 0.6845572737947785, \"phi\": 0.5298102567166524}, {\"truth_threshold\": -9.419999789446592, \"match_probability\": 0.0014576859821160684, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663298.0, \"fp\": 74494.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999417441163732, \"fp_rate\": 5.8255883626844435e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6412037260020614, \"recall\": 0.43797724050124853, \"specificity\": 0.9999417441163732, \"npv\": 0.9998664150448765, \"accuracy\": 0.9998081946899509, \"f1\": 0.5204551363121918, \"f2\": 0.4676191774162502, \"f0_5\": 0.5867518063835395, \"p4\": 0.6845819176738133, \"phi\": 0.5298460014343324}, {\"truth_threshold\": -9.399999789893627, \"match_probability\": 0.0014780044444367049, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663330.0, \"fp\": 74462.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.99994176914105, \"fp_rate\": 5.823085895001061e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6413025675610579, \"recall\": 0.43797724050124853, \"specificity\": 0.99994176914105, \"npv\": 0.9998664150482192, \"accuracy\": 0.9998082197086806, \"f1\": 0.5204876933091716, \"f2\": 0.46762968989078524, \"f0_5\": 0.5868180171221374, \"p4\": 0.6846100842797539, \"phi\": 0.5298868613936514}, {\"truth_threshold\": -9.379999790340662, \"match_probability\": 0.0014986056976524496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663337.0, \"fp\": 74455.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999417746151981, \"fp_rate\": 5.8225384801953206e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6413241932142806, \"recall\": 0.43797724050124853, \"specificity\": 0.9999417746151981, \"npv\": 0.9998664150489504, \"accuracy\": 0.9998082251815278, \"f1\": 0.5204948156952286, \"f2\": 0.4676319895575959, \"f0_5\": 0.5868325027131438, \"p4\": 0.684616246033769, \"phi\": 0.5298958007689336}, {\"truth_threshold\": -9.359999790787697, \"match_probability\": 0.001519493665695272, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663342.0, \"fp\": 74450.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999417785253037, \"fp_rate\": 5.822147469619792e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6413396410024184, \"recall\": 0.43797724050124853, \"specificity\": 0.9999417785253037, \"npv\": 0.9998664150494727, \"accuracy\": 0.9998082290907043, \"f1\": 0.5204999032331845, \"f2\": 0.46763363219059423, \"f0_5\": 0.5868428500017192, \"p4\": 0.6846206473545453, \"phi\": 0.5299021863137844}, {\"truth_threshold\": -9.339999791234732, \"match_probability\": 0.0015406723266096838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663369.0, \"fp\": 74423.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999417996398748, \"fp_rate\": 5.820036012511938e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6414230719196727, \"recall\": 0.43797724050124853, \"specificity\": 0.9999417996398748, \"npv\": 0.9998664150522931, \"accuracy\": 0.9998082502002575, \"f1\": 0.5205273776568292, \"f2\": 0.46764250260820084, \"f0_5\": 0.5868987316660275, \"p4\": 0.6846444154646673, \"phi\": 0.5299366722424074}, {\"truth_threshold\": -9.299999792128801, \"match_probability\": 0.001583917914224747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663953.0, \"fp\": 73839.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.999942256340227, \"fp_rate\": 5.7743659772902055e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6432329791705924, \"recall\": 0.43797724050124853, \"specificity\": 0.999942256340227, \"npv\": 0.9998664151132968, \"accuracy\": 0.9998087067920761, \"f1\": 0.5211223499201453, \"f2\": 0.46783444884809017, \"f0_5\": 0.5881100413578376, \"p4\": 0.6851589150796398, \"phi\": 0.5306842405459752}, {\"truth_threshold\": -9.279999792575836, \"match_probability\": 0.001605993074257518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133123.0, \"tn\": 1278664152.0, \"fp\": 73640.0, \"fn\": 170838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379607910225325, \"tn_rate\": 0.9999424119624362, \"fp_rate\": 5.7588037563841704e-05, \"fn_rate\": 0.5620392089774675, \"precision\": 0.6438434342701547, \"recall\": 0.4379607910225325, \"specificity\": 0.9999424119624362, \"npv\": 0.9998664112247977, \"accuracy\": 0.9998088584681254, \"f1\": 0.5213109233167034, \"f2\": 0.4678839623311287, \"f0_5\": 0.5885122452173406, \"p4\": 0.6853218999518472, \"phi\": 0.5309261748446754}, {\"truth_threshold\": -9.259999793022871, \"match_probability\": 0.0016283753953490986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133123.0, \"tn\": 1278664164.0, \"fp\": 73628.0, \"fn\": 170838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379607910225325, \"tn_rate\": 0.99994242134669, \"fp_rate\": 5.757865331002902e-05, \"fn_rate\": 0.5620392089774675, \"precision\": 0.6438808034785806, \"recall\": 0.4379607910225325, \"specificity\": 0.99994242134669, \"npv\": 0.9998664112260512, \"accuracy\": 0.9998088678501491, \"f1\": 0.5213231723554567, \"f2\": 0.46788790906758426, \"f0_5\": 0.5885372226373053, \"p4\": 0.6853324854014353, \"phi\": 0.5309415912065072}, {\"truth_threshold\": -9.239999793469906, \"match_probability\": 0.0016510691373562859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133123.0, \"tn\": 1278668615.0, \"fp\": 69177.0, \"fn\": 170838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379607910225325, \"tn_rate\": 0.9999459021228333, \"fp_rate\": 5.4097877166674054e-05, \"fn_rate\": 0.5620392089774675, \"precision\": 0.658047454275828, \"recall\": 0.4379607910225325, \"specificity\": 0.9999459021228333, \"npv\": 0.9998664116910069, \"accuracy\": 0.9998123477990949, \"f1\": 0.5259065975850401, \"f2\": 0.46935642642778164, \"f0_5\": 0.5979503414151233, \"p4\": 0.689281490207458, \"phi\": 0.536754026924829}, {\"truth_threshold\": -9.199999794363976, \"match_probability\": 0.001697408217754341, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133122.0, \"tn\": 1278669073.0, \"fp\": 68719.0, \"fn\": 170839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379575011267893, \"tn_rate\": 0.9999462602885205, \"fp_rate\": 5.373971147948992e-05, \"fn_rate\": 0.5620424988732107, \"precision\": 0.6595389440202932, \"recall\": 0.4379575011267893, \"specificity\": 0.9999462602885205, \"npv\": 0.9998664109569956, \"accuracy\": 0.9998127050978296, \"f1\": 0.5263798877821756, \"f2\": 0.46950486179934187, \"f0_5\": 0.5989337052617372, \"p4\": 0.6896879187892183, \"phi\": 0.5373602936968382}, {\"truth_threshold\": -9.17999979481101, \"match_probability\": 0.0017210623724708569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133122.0, \"tn\": 1278669116.0, \"fp\": 68676.0, \"fn\": 170839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379575011267893, \"tn_rate\": 0.99994629391543, \"fp_rate\": 5.370608456999447e-05, \"fn_rate\": 0.5620424988732107, \"precision\": 0.6596794814616597, \"recall\": 0.4379575011267893, \"specificity\": 0.99994629391543, \"npv\": 0.9998664109614873, \"accuracy\": 0.9998127387167477, \"f1\": 0.5264246409851332, \"f2\": 0.4695191028482508, \"f0_5\": 0.5990264167040903, \"p4\": 0.6897263366588958, \"phi\": 0.5374175744210486}, {\"truth_threshold\": -9.159999795258045, \"match_probability\": 0.001745045582380546, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133122.0, \"tn\": 1278669144.0, \"fp\": 68648.0, \"fn\": 170839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379575011267893, \"tn_rate\": 0.9999463158120222, \"fp_rate\": 5.3684187977764874e-05, \"fn_rate\": 0.5620424988732107, \"precision\": 0.6597710264162164, \"recall\": 0.4379575011267893, \"specificity\": 0.9999463158120222, \"npv\": 0.9998664109644123, \"accuracy\": 0.9998127606081363, \"f1\": 0.5264537866968804, \"f2\": 0.4695283765538433, \"f0_5\": 0.59908680237723, \"p4\": 0.6897513552470881, \"phi\": 0.5374548833387912}, {\"truth_threshold\": -9.13999979570508, \"match_probability\": 0.0017693624088313273, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133122.0, \"tn\": 1278669148.0, \"fp\": 68644.0, \"fn\": 170839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379575011267893, \"tn_rate\": 0.9999463189401069, \"fp_rate\": 5.3681059893160645e-05, \"fn_rate\": 0.5620424988732107, \"precision\": 0.6597841063410089, \"recall\": 0.4379575011267893, \"specificity\": 0.9999463189401069, \"npv\": 0.9998664109648301, \"accuracy\": 0.9998127637354776, \"f1\": 0.5264579506334445, \"f2\": 0.46952970139883327, \"f0_5\": 0.5990954298958169, \"p4\": 0.6897549294792803, \"phi\": 0.537460213818038}, {\"truth_threshold\": -9.119999796152115, \"match_probability\": 0.0017940174759465434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133122.0, \"tn\": 1278669162.0, \"fp\": 68630.0, \"fn\": 170839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379575011267893, \"tn_rate\": 0.9999463298884029, \"fp_rate\": 5.367011159704585e-05, \"fn_rate\": 0.5620424988732107, \"precision\": 0.6598298901621793, \"recall\": 0.4379575011267893, \"specificity\": 0.9999463298884029, \"npv\": 0.9998664109662926, \"accuracy\": 0.9998127746811718, \"f1\": 0.5264725249301482, \"f2\": 0.4695343384151761, \"f0_5\": 0.5991256281678426, \"p4\": 0.6897674395836698, \"phi\": 0.5374788717435409}, {\"truth_threshold\": -9.09999979659915, \"match_probability\": 0.0018190154714761667, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133122.0, \"tn\": 1278669199.0, \"fp\": 68593.0, \"fn\": 170839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379575011267893, \"tn_rate\": 0.9999463588231855, \"fp_rate\": 5.3641176814456736e-05, \"fn_rate\": 0.5620424988732107, \"precision\": 0.6599509208536797, \"recall\": 0.4379575011267893, \"specificity\": 0.9999463588231855, \"npv\": 0.9998664109701576, \"accuracy\": 0.9998128036090781, \"f1\": 0.526511046599008, \"f2\": 0.4695465938278407, \"f0_5\": 0.5992054525436592, \"p4\": 0.6898005041869721, \"phi\": 0.5375281913235358}, {\"truth_threshold\": -9.079999797046185, \"match_probability\": 0.0018443611476591784, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278669236.0, \"fp\": 68556.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999463877579682, \"fp_rate\": 5.3612242031867625e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6600703104469027, \"recall\": 0.4379542112310461, \"specificity\": 0.9999463877579682, \"npv\": 0.9998664101921686, \"accuracy\": 0.9998128317551491, \"f1\": 0.5265466598633806, \"f2\": 0.4695556538492199, \"f0_5\": 0.5992829546876702, \"p4\": 0.6898310710799138, \"phi\": 0.5375748182929471}, {\"truth_threshold\": -9.05999979749322, \"match_probability\": 0.0018700593220972754, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278669243.0, \"fp\": 68549.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999463932321162, \"fp_rate\": 5.360676788381022e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.660093221599643, \"recall\": 0.4379542112310461, \"specificity\": 0.9999463932321162, \"npv\": 0.9998664101928998, \"accuracy\": 0.9998128372279963, \"f1\": 0.5265539494216138, \"f2\": 0.46955797261967075, \"f0_5\": 0.5992980630104597, \"p4\": 0.6898373275034305, \"phi\": 0.5375841531176682}, {\"truth_threshold\": -9.039999797940254, \"match_probability\": 0.001896114878640028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278669255.0, \"fp\": 68537.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.99994640261637, \"fp_rate\": 5.359738362999754e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6601325015620506, \"recall\": 0.4379542112310461, \"specificity\": 0.99994640261637, \"npv\": 0.9998664101941533, \"accuracy\": 0.9998128466100199, \"f1\": 0.526566446276742, \"f2\": 0.4695619477080103, \"f0_5\": 0.5993239647647698, \"p4\": 0.6898480530649187, \"phi\": 0.5376001568049141}, {\"truth_threshold\": -9.019999798387289, \"match_probability\": 0.0019225327682816397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278669320.0, \"fp\": 68472.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999464534477448, \"fp_rate\": 5.3546552255178835e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6603453492928822, \"recall\": 0.4379542112310461, \"specificity\": 0.9999464534477448, \"npv\": 0.9998664102009434, \"accuracy\": 0.9998128974293148, \"f1\": 0.5266341478852902, \"f2\": 0.4695834806061927, \"f0_5\": 0.5994643048526883, \"p4\": 0.6899061556528889, \"phi\": 0.5376868682710229}, {\"truth_threshold\": -8.999999798834324, \"match_probability\": 0.0019493180100694405, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278669321.0, \"fp\": 68471.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.999946454229766, \"fp_rate\": 5.354577023402777e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6603486249454343, \"recall\": 0.4379542112310461, \"specificity\": 0.999946454229766, \"npv\": 0.9998664102010478, \"accuracy\": 0.9998128982111502, \"f1\": 0.5266351895844749, \"f2\": 0.4695838118969745, \"f0_5\": 0.5994664644443224, \"p4\": 0.6899070496153038, \"phi\": 0.5376882026210711}, {\"truth_threshold\": -8.979999799281359, \"match_probability\": 0.001976475692024266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672413.0, \"fp\": 65379.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488722391651, \"fp_rate\": 5.112776083495935e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6706347607052897, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488722391651, \"npv\": 0.9998664105240426, \"accuracy\": 0.9998153156459154, \"f1\": 0.5298759505712881, \"f2\": 0.4706104031268206, \"f0_5\": 0.6062191644329807, \"p4\": 0.6926823041318807, \"phi\": 0.5418620953265808}, {\"truth_threshold\": -8.939999800175428, \"match_probability\": 0.0020319290789924103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672426.0, \"fp\": 65366.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.99994888240544, \"fp_rate\": 5.111759455999561e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6706786842463235, \"recall\": 0.4379542112310461, \"specificity\": 0.99994888240544, \"npv\": 0.9998664105254005, \"accuracy\": 0.9998153258097744, \"f1\": 0.5298896602235456, \"f2\": 0.4706147288011081, \"f0_5\": 0.6062478766455144, \"p4\": 0.692694019543188, \"phi\": 0.5418798496191832}, {\"truth_threshold\": -8.919999800622463, \"match_probability\": 0.0020602353133675005, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672430.0, \"fp\": 65362.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488855335246, \"fp_rate\": 5.111446647539138e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6706922003395757, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488855335246, \"npv\": 0.9998664105258184, \"accuracy\": 0.9998153289371157, \"f1\": 0.5298938787208126, \"f2\": 0.47061605979381005, \"f0_5\": 0.6062567117196302, \"p4\": 0.6926976243648556, \"phi\": 0.5418853128292966}, {\"truth_threshold\": -8.899999801069498, \"match_probability\": 0.0020889350485593884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672468.0, \"fp\": 65324.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999489152503284, \"fp_rate\": 5.1084749671651214e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6708206304013706, \"recall\": 0.4379542112310461, \"specificity\": 0.9999489152503284, \"npv\": 0.9998664105297879, \"accuracy\": 0.9998153586468572, \"f1\": 0.52993395779509, \"f2\": 0.4706287045999792, \"f0_5\": 0.6063406577690001, \"p4\": 0.6927318720420721, \"phi\": 0.541937221561959}, {\"truth_threshold\": -8.879999801516533, \"match_probability\": 0.0021180337316879963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672506.0, \"fp\": 65286.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.999948944967132, \"fp_rate\": 5.105503286791105e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6709491096584294, \"recall\": 0.4379542112310461, \"specificity\": 0.999948944967132, \"npv\": 0.9998664105337575, \"accuracy\": 0.9998153883565989, \"f1\": 0.5299740429326709, \"f2\": 0.4706413500856637, \"f0_5\": 0.6064246270689666, \"p4\": 0.692766123105936, \"phi\": 0.541989145203925}, {\"truth_threshold\": -8.859999801963568, \"match_probability\": 0.002147536884626629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278674026.0, \"fp\": 63766.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999501336392816, \"fp_rate\": 4.986636071830432e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6761289470610046, \"recall\": 0.4379542112310461, \"specificity\": 0.9999501336392816, \"npv\": 0.9998664106925382, \"accuracy\": 0.9998165767462636, \"f1\": 0.5315824361882248, \"f2\": 0.4711477273451209, \"f0_5\": 0.6098025760667113, \"p4\": 0.6941389484897045, \"phi\": 0.5440783990129069}, {\"truth_threshold\": -8.839999802410603, \"match_probability\": 0.0021774501050096083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133119.0, \"tn\": 1278674042.0, \"fp\": 63750.0, \"fn\": 170842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43794763143955967, \"tn_rate\": 0.9999501461516201, \"fp_rate\": 4.9853848379887404e-05, \"fn_rate\": 0.5620523685604403, \"precision\": 0.6761806074089877, \"recall\": 0.43794763143955967, \"specificity\": 0.9999501461516201, \"npv\": 0.9998664091305072, \"accuracy\": 0.9998165876919578, \"f1\": 0.5315935546991993, \"f2\": 0.47114665186771837, \"f0_5\": 0.609833641337063, \"p4\": 0.6941484288642803, \"phi\": 0.5440951075775193}, {\"truth_threshold\": -8.819999802857637, \"match_probability\": 0.0022077790672529775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133119.0, \"tn\": 1278674057.0, \"fp\": 63735.0, \"fn\": 170842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43794763143955967, \"tn_rate\": 0.9999501578819374, \"fp_rate\": 4.984211806262155e-05, \"fn_rate\": 0.5620523685604403, \"precision\": 0.6762321314273523, \"recall\": 0.43794763143955967, \"specificity\": 0.9999501578819374, \"npv\": 0.9998664091320741, \"accuracy\": 0.9998165994194874, \"f1\": 0.5316094765532182, \"f2\": 0.47115165449374175, \"f0_5\": 0.6098671678072747, \"p4\": 0.694162004170151, \"phi\": 0.5441158482110803}, {\"truth_threshold\": -8.799999803304672, \"match_probability\": 0.0022385295235884278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133113.0, \"tn\": 1278674402.0, \"fp\": 63390.0, \"fn\": 170848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792789206510047, \"tn_rate\": 0.9999504276792345, \"fp_rate\": 4.957232076550687e-05, \"fn_rate\": 0.5620721079348996, \"precision\": 0.6774095051983939, \"recall\": 0.43792789206510047, \"specificity\": 0.9999504276792345, \"npv\": 0.9998664044770077, \"accuracy\": 0.9998168644616561, \"f1\": 0.5319583426580133, \"f2\": 0.4712475050394839, \"f0_5\": 0.610625217321897, \"p4\": 0.6944593848873605, \"phi\": 0.5445773015210795}, {\"truth_threshold\": -8.779999803751707, \"match_probability\": 0.002269707305110611, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674430.0, \"fp\": 63362.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999504495758267, \"fp_rate\": 4.955042417327727e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6775044026181581, \"recall\": 0.43792460216935725, \"specificity\": 0.9999504495758267, \"npv\": 0.9998664036980818, \"accuracy\": 0.9998168855712093, \"f1\": 0.5319851728995774, \"f2\": 0.47125364117712865, \"f0_5\": 0.6106856220586737, \"p4\": 0.6944822500242384, \"phi\": 0.5446134196532441}, {\"truth_threshold\": -8.759999804198742, \"match_probability\": 0.002301318322837974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674611.0, \"fp\": 63181.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999505911216551, \"fp_rate\": 4.940887834493594e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6781291233003724, \"recall\": 0.43792460216935725, \"specificity\": 0.9999505911216551, \"npv\": 0.9998664037169902, \"accuracy\": 0.9998170270833997, \"f1\": 0.5321776537518941, \"f2\": 0.4713140438923419, \"f0_5\": 0.6110915746745347, \"p4\": 0.6946462604453886, \"phi\": 0.5448645909243593}, {\"truth_threshold\": -8.739999804645777, \"match_probability\": 0.0023333685687873104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674647.0, \"fp\": 63145.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999506192744165, \"fp_rate\": 4.9380725583497885e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6782535145243227, \"recall\": 0.43792460216935725, \"specificity\": 0.9999506192744165, \"npv\": 0.999866403720751, \"accuracy\": 0.9998170552294707, \"f1\": 0.532215953844124, \"f2\": 0.47132605953823414, \"f0_5\": 0.6111723809882377, \"p4\": 0.6946788905391288, \"phi\": 0.5449145890568496}, {\"truth_threshold\": -8.719999805092812, \"match_probability\": 0.0023658641170621482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674670.0, \"fp\": 63122.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999506372609029, \"fp_rate\": 4.936273909702357e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6783330105893983, \"recall\": 0.43792460216935725, \"specificity\": 0.9999506372609029, \"npv\": 0.9998664037231537, \"accuracy\": 0.9998170732116827, \"f1\": 0.5322404262337689, \"f2\": 0.4713337365216369, \"f0_5\": 0.6112240184333321, \"p4\": 0.6946997391484102, \"phi\": 0.5449465395096761}, {\"truth_threshold\": -8.699999805539846, \"match_probability\": 0.002398811124955169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674674.0, \"fp\": 63118.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999506403889876, \"fp_rate\": 4.9359611012419344e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6783468378943077, \"recall\": 0.43792460216935725, \"specificity\": 0.9999506403889876, \"npv\": 0.9998664037235715, \"accuracy\": 0.999817076339024, \"f1\": 0.5322446825312731, \"f2\": 0.47133507167471395, \"f0_5\": 0.6112329997492839, \"p4\": 0.6947033651212465, \"phi\": 0.5449520966834702}, {\"truth_threshold\": -8.679999805986881, \"match_probability\": 0.002432215834064805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674746.0, \"fp\": 63046.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999506966945104, \"fp_rate\": 4.930330548954324e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6785958258138848, \"recall\": 0.43792460216935725, \"specificity\": 0.9999506966945104, \"npv\": 0.9998664037310931, \"accuracy\": 0.999817132631166, \"f1\": 0.5323213075288081, \"f2\": 0.4713591057236463, \"f0_5\": 0.6113947085825464, \"p4\": 0.6947686391054988, \"phi\": 0.5450521548713051}, {\"truth_threshold\": -8.659999806433916, \"match_probability\": 0.002466084571426181, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674754.0, \"fp\": 63038.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999507029506797, \"fp_rate\": 4.929704932033478e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6786235024216161, \"recall\": 0.43792460216935725, \"specificity\": 0.9999507029506797, \"npv\": 0.9998664037319288, \"accuracy\": 0.9998171388858484, \"f1\": 0.5323298227793429, \"f2\": 0.47136177632482856, \"f0_5\": 0.6114126815125657, \"p4\": 0.6947758925275977, \"phi\": 0.5450632758477209}, {\"truth_threshold\": -8.639999806880951, \"match_probability\": 0.0025004237506565706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675002.0, \"fp\": 62790.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999508968919252, \"fp_rate\": 4.910310807487263e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6794825984420781, \"recall\": 0.43792460216935725, \"specificity\": 0.9999508968919252, \"npv\": 0.9998664037578365, \"accuracy\": 0.9998173327810043, \"f1\": 0.532593930737022, \"f2\": 0.471444579974018, \"f0_5\": 0.611970366937638, \"p4\": 0.6950008237572912, \"phi\": 0.5454083638660778}, {\"truth_threshold\": -8.619999807327986, \"match_probability\": 0.0025352398731155307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675019.0, \"fp\": 62773.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999509101862847, \"fp_rate\": 4.908981371530466e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6795415677565919, \"recall\": 0.43792460216935725, \"specificity\": 0.9999509101862847, \"npv\": 0.9998664037596124, \"accuracy\": 0.9998173460722044, \"f1\": 0.532612044509709, \"f2\": 0.47145025709608573, \"f0_5\": 0.6120086326357401, \"p4\": 0.6950162477643289, \"phi\": 0.5454320430870975}, {\"truth_threshold\": -8.59999980777502, \"match_probability\": 0.0025705395290798855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675061.0, \"fp\": 62731.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.999950943031173, \"fp_rate\": 4.9056968826960266e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6796873005417605, \"recall\": 0.43792460216935725, \"specificity\": 0.999950943031173, \"npv\": 0.999866403764, \"accuracy\": 0.9998173789092872, \"f1\": 0.5326568014661748, \"f2\": 0.4714642835132717, \"f0_5\": 0.6121031919384402, \"p4\": 0.6950543570698481, \"phi\": 0.5454905579072151}, {\"truth_threshold\": -8.579999808222055, \"match_probability\": 0.0026063293989337295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675081.0, \"fp\": 62711.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999509586715961, \"fp_rate\": 4.904132840393913e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6797567190779429, \"recall\": 0.43792460216935725, \"specificity\": 0.9999509586715961, \"npv\": 0.9998664037660894, \"accuracy\": 0.9998173945459934, \"f1\": 0.5326781169465209, \"f2\": 0.47147096305290126, \"f0_5\": 0.6121482304486628, \"p4\": 0.6950725058271221, \"phi\": 0.5455184287224499}, {\"truth_threshold\": -8.55999980866909, \"match_probability\": 0.002642616254373618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675143.0, \"fp\": 62649.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510071569074, \"fp_rate\": 4.8992843092573587e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6799720066816168, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510071569074, \"npv\": 0.9998664037725662, \"accuracy\": 0.9998174430197824, \"f1\": 0.5327442057784127, \"f2\": 0.47149167082859583, \"f0_5\": 0.6122878919600185, \"p4\": 0.6951287729982654, \"phi\": 0.545604855386226}, {\"truth_threshold\": -8.539999809116125, \"match_probability\": 0.0026794069596291262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675159.0, \"fp\": 62633.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510196692458, \"fp_rate\": 4.898033075415668e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6800275869115431, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510196692458, \"npv\": 0.9998664037742376, \"accuracy\": 0.9998174555291472, \"f1\": 0.5327612636230104, \"f2\": 0.4714970150660001, \"f0_5\": 0.6123239439859202, \"p4\": 0.6951432950373974, \"phi\": 0.5456271657055446}, {\"truth_threshold\": -8.51999980956316, \"match_probability\": 0.002716708472698939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675174.0, \"fp\": 62618.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510313995631, \"fp_rate\": 4.8968600436890816e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6800797016297961, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510313995631, \"npv\": 0.9998664037758047, \"accuracy\": 0.9998174672566768, \"f1\": 0.5327772563444209, \"f2\": 0.4715020253985976, \"f0_5\": 0.6123577466162349, \"p4\": 0.6951569100001596, \"phi\": 0.5456480841139254}, {\"truth_threshold\": -8.499999810010195, \"match_probability\": 0.0027545278466026574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675204.0, \"fp\": 62588.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510548601976, \"fp_rate\": 4.894513980235911e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.680183955033214, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510548601976, \"npv\": 0.9998664037789387, \"accuracy\": 0.999817490711736, \"f1\": 0.5328092446678848, \"f2\": 0.4715120463832512, \"f0_5\": 0.6124253630743098, \"p4\": 0.6951841415257091, \"phi\": 0.5456899281442309}, {\"truth_threshold\": -8.47999981045723, \"match_probability\": 0.0027928722306484947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675214.0, \"fp\": 62578.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510626804091, \"fp_rate\": 4.893731959084854e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6802187132709898, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510626804091, \"npv\": 0.9998664037799834, \"accuracy\": 0.999817498530089, \"f1\": 0.5328199082959906, \"f2\": 0.47151538680612726, \"f0_5\": 0.6124479052121014, \"p4\": 0.6951932191750078, \"phi\": 0.5457038782921797}, {\"truth_threshold\": -8.459999810904264, \"match_probability\": 0.0028317488717170386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675232.0, \"fp\": 62560.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510767567898, \"fp_rate\": 4.892324321012951e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.680281287051801, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510767567898, \"npv\": 0.9998664037818638, \"accuracy\": 0.9998175126031246, \"f1\": 0.5328391039022643, \"f2\": 0.47152139968657814, \"f0_5\": 0.6124884852422448, \"p4\": 0.6952095595411764, \"phi\": 0.5457289912528399}, {\"truth_threshold\": -8.4399998113513, \"match_probability\": 0.002871165115561265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675258.0, \"fp\": 62534.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510970893398, \"fp_rate\": 4.8902910660202026e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.680371691728939, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510970893398, \"npv\": 0.9998664037845798, \"accuracy\": 0.9998175329308425, \"f1\": 0.5328668333309982, \"f2\": 0.4715300852290842, \"f0_5\": 0.6125471103359732, \"p4\": 0.6952331636484776, \"phi\": 0.5457652716465078}, {\"truth_threshold\": -8.419999811798334, \"match_probability\": 0.002911128408122972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278676960.0, \"fp\": 60832.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999524280893389, \"fp_rate\": 4.757191066110291e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6863424493668275, \"recall\": 0.43792460216935725, \"specificity\": 0.9999524280893389, \"npv\": 0.9998664039623811, \"accuracy\": 0.9998188636145329, \"f1\": 0.5346883441620389, \"f2\": 0.47209935110810985, \"f0_5\": 0.6164093663549549, \"p4\": 0.6967818193045553, \"phi\": 0.5481560861953638}, {\"truth_threshold\": -8.399999812245369, \"match_probability\": 0.002951646296865832, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278677008.0, \"fp\": 60784.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999524656263542, \"fp_rate\": 4.7534373645852176e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6865123571399101, \"recall\": 0.43792460216935725, \"specificity\": 0.9999524656263542, \"npv\": 0.9998664039673955, \"accuracy\": 0.9998189011426275, \"f1\": 0.5347398951907877, \"f2\": 0.4721154255394612, \"f0_5\": 0.6165189964290512, \"p4\": 0.6968255947080951, \"phi\": 0.5482239682017925}, {\"truth_threshold\": -8.379999812692404, \"match_probability\": 0.0029927264321252347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278677028.0, \"fp\": 60764.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999524812667772, \"fp_rate\": 4.751873322283103e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6865831768759413, \"recall\": 0.43792460216935725, \"specificity\": 0.9999524812667772, \"npv\": 0.9998664039694848, \"accuracy\": 0.9998189167793337, \"f1\": 0.5347613777200168, \"f2\": 0.47212212354226374, \"f0_5\": 0.6165646871366834, \"p4\": 0.6968438360829916, \"phi\": 0.5482522598097996}, {\"truth_threshold\": -8.359999813139439, \"match_probability\": 0.0030343765684751074, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278677062.0, \"fp\": 60730.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999525078554963, \"fp_rate\": 4.7492144503695094e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6867036039661167, \"recall\": 0.43792460216935725, \"specificity\": 0.9999525078554963, \"npv\": 0.9998664039730366, \"accuracy\": 0.999818943361734, \"f1\": 0.5347979019813058, \"f2\": 0.4721335105832079, \"f0_5\": 0.6166423768841567, \"p4\": 0.696874848612227, \"phi\": 0.5483003655900087}, {\"truth_threshold\": -8.339999813586473, \"match_probability\": 0.0030766045661118962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278677099.0, \"fp\": 60693.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999525367902788, \"fp_rate\": 4.746320972110598e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6868347049869714, \"recall\": 0.43792460216935725, \"specificity\": 0.9999525367902788, \"npv\": 0.9998664039769019, \"accuracy\": 0.9998189722896403, \"f1\": 0.5348376546409357, \"f2\": 0.4721459029871975, \"f0_5\": 0.6167269438583518, \"p4\": 0.6969086006777228, \"phi\": 0.5483527303784583}, {\"truth_threshold\": -8.319999814033508, \"match_probability\": 0.003119418392255908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278677104.0, \"fp\": 60688.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999525407003846, \"fp_rate\": 4.74592996153507e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6868524251805985, \"recall\": 0.43792460216935725, \"specificity\": 0.9999525407003846, \"npv\": 0.9998664039774242, \"accuracy\": 0.9998189761988169, \"f1\": 0.5348430270752429, \"f2\": 0.4721475776862811, \"f0_5\": 0.6167383736069039, \"p4\": 0.6969131620184182, \"phi\": 0.5483598078511676}, {\"truth_threshold\": -8.299999814480543, \"match_probability\": 0.0031628261225701785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278677916.0, \"fp\": 59876.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999531757015593, \"fp_rate\": 4.682429844069237e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.6897407597402934, \"recall\": 0.437921312273614, \"specificity\": 0.9999531757015593, \"npv\": 0.9998664032804017, \"accuracy\": 0.9998196102672499, \"f1\": 0.5357139982452892, \"f2\": 0.4724164928227729, \"f0_5\": 0.6185978553948336, \"p4\": 0.6976522181264778, \"phi\": 0.5495101303995211}, {\"truth_threshold\": -8.279999814927578, \"match_probability\": 0.003206835942597077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278677918.0, \"fp\": 59874.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999531772656016, \"fp_rate\": 4.682273439839025e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.6897479078684872, \"recall\": 0.437921312273614, \"specificity\": 0.9999531772656016, \"npv\": 0.9998664032806106, \"accuracy\": 0.9998196118309204, \"f1\": 0.5357161542702829, \"f2\": 0.4724171634740625, \"f0_5\": 0.6186024550585973, \"p4\": 0.6976540465650365, \"phi\": 0.5495129793493043}, {\"truth_threshold\": -8.259999815374613, \"match_probability\": 0.0032514561492128285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278678025.0, \"fp\": 59767.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999532609418648, \"fp_rate\": 4.673905813522715e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.6901305488443472, \"recall\": 0.437921312273614, \"specificity\": 0.9999532609418648, \"npv\": 0.9998664032917884, \"accuracy\": 0.9998196954872981, \"f1\": 0.535831526913145, \"f2\": 0.4724530460942613, \"f0_5\": 0.6188486368323519, \"p4\": 0.6977518820023229, \"phi\": 0.5496654627467434}, {\"truth_threshold\": -8.239999815821648, \"match_probability\": 0.003296695152100145, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278678042.0, \"fp\": 59750.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999532742362244, \"fp_rate\": 4.672576377565918e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.6901913813575581, \"recall\": 0.437921312273614, \"specificity\": 0.9999532742362244, \"npv\": 0.9998664032935645, \"accuracy\": 0.9998197087784984, \"f1\": 0.5358498617210993, \"f2\": 0.47245874757312567, \"f0_5\": 0.6188877678642, \"p4\": 0.6977674284764868, \"phi\": 0.5496897007603521}, {\"truth_threshold\": -8.219999816268682, \"match_probability\": 0.0033425614752391583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278678049.0, \"fp\": 59743.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999532797103724, \"fp_rate\": 4.6720289627601775e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.6902164331566885, \"recall\": 0.437921312273614, \"specificity\": 0.9999532797103724, \"npv\": 0.9998664032942957, \"accuracy\": 0.9998197142513455, \"f1\": 0.5358574117126094, \"f2\": 0.4724610952808906, \"f0_5\": 0.6189038820804239, \"p4\": 0.6977738301672107, \"phi\": 0.5496996820502326}, {\"truth_threshold\": -8.199999816715717, \"match_probability\": 0.0033890637584168535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278678130.0, \"fp\": 59662.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999533430540857, \"fp_rate\": 4.665694591436616e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.6905064505921472, \"recall\": 0.437921312273614, \"specificity\": 0.9999533430540857, \"npv\": 0.9998664033027574, \"accuracy\": 0.9998197775800053, \"f1\": 0.5359447913772764, \"f2\": 0.4724882633107509, \"f0_5\": 0.6190904076357165, \"p4\": 0.6978479154188506, \"phi\": 0.5498152193663174}, {\"truth_threshold\": -8.179999817162752, \"match_probability\": 0.003436210758755191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685850.0, \"fp\": 51942.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999593802573717, \"fp_rate\": 4.061974262820567e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7193128455091244, \"recall\": 0.437921312273614, \"specificity\": 0.9999593802573717, \"npv\": 0.9998664041092329, \"accuracy\": 0.9998258133485655, \"f1\": 0.5444056816369266, \"f2\": 0.4750920303205732, \"f0_5\": 0.6373991666131953, \"p4\": 0.7049818197617275, \"phi\": 0.5611726186092841}, {\"truth_threshold\": -8.159999817609787, \"match_probability\": 0.0034840113522581137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685858.0, \"fp\": 51934.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.999959386513541, \"fp_rate\": 4.0613486458997215e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7193439433651274, \"recall\": 0.437921312273614, \"specificity\": 0.999959386513541, \"npv\": 0.9998664041100686, \"accuracy\": 0.9998258196032479, \"f1\": 0.5444145879600659, \"f2\": 0.47509474340936364, \"f0_5\": 0.6374187011141216, \"p4\": 0.7049892880607911, \"phi\": 0.5611847552521286}, {\"truth_threshold\": -8.139999818056822, \"match_probability\": 0.003532474535377645, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133110.0, \"tn\": 1278685859.0, \"fp\": 51933.0, \"fn\": 170851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791802237787086, \"tn_rate\": 0.9999593872955621, \"fp_rate\": 4.061270443784616e-05, \"fn_rate\": 0.5620819776221292, \"precision\": 0.719346314099966, \"recall\": 0.43791802237787086, \"specificity\": 0.9999593872955621, \"npv\": 0.9998664033283291, \"accuracy\": 0.9998258196032479, \"f1\": 0.5444127246402892, \"f2\": 0.4750918525191539, \"f0_5\": 0.6374187962644605, \"p4\": 0.7049877257643422, \"phi\": 0.5611835722040449}, {\"truth_threshold\": -8.119999818503857, \"match_probability\": 0.00358160942659926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133110.0, \"tn\": 1278685901.0, \"fp\": 51891.0, \"fn\": 170851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791802237787086, \"tn_rate\": 0.9999594201404505, \"fp_rate\": 4.0579859549501764e-05, \"fn_rate\": 0.5620819776221292, \"precision\": 0.7195096242723013, \"recall\": 0.43791802237787086, \"specificity\": 0.9999594201404505, \"npv\": 0.9998664033327167, \"accuracy\": 0.9998258524403307, \"f1\": 0.5444594876493469, \"f2\": 0.4751060966773626, \"f0_5\": 0.6375213728429593, \"p4\": 0.7050269370513398, \"phi\": 0.5612473030462369}, {\"truth_threshold\": -8.099999818950891, \"match_probability\": 0.003631425268046746, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133110.0, \"tn\": 1278685933.0, \"fp\": 51859.0, \"fn\": 170851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791802237787086, \"tn_rate\": 0.9999594451651274, \"fp_rate\": 4.055483487266794e-05, \"fn_rate\": 0.5620819776221292, \"precision\": 0.7196341008493315, \"recall\": 0.43791802237787086, \"specificity\": 0.9999594451651274, \"npv\": 0.9998664033360596, \"accuracy\": 0.9998258774590606, \"f1\": 0.5444951220011045, \"f2\": 0.4751169499426405, \"f0_5\": 0.6375995485885249, \"p4\": 0.7050568152454285, \"phi\": 0.5612958744446723}, {\"truth_threshold\": -8.079999819397926, \"match_probability\": 0.00368193142710673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133110.0, \"tn\": 1278685934.0, \"fp\": 51858.0, \"fn\": 170851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791802237787086, \"tn_rate\": 0.9999594459471485, \"fp_rate\": 4.055405285151688e-05, \"fn_rate\": 0.5620819776221292, \"precision\": 0.7196379914363565, \"recall\": 0.43791802237787086, \"specificity\": 0.9999594459471485, \"npv\": 0.9998664033361641, \"accuracy\": 0.9998258782408959, \"f1\": 0.5444962356497569, \"f2\": 0.47511728911517037, \"f0_5\": 0.6376019918895073, \"p4\": 0.7050577489797992, \"phi\": 0.5612973925039351}, {\"truth_threshold\": -8.059999819844961, \"match_probability\": 0.0037331373980731015, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685946.0, \"fp\": 51846.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594553314023, \"fp_rate\": 4.0544668597704196e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7196831661755562, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594553314023, \"npv\": 0.9998664025555737, \"accuracy\": 0.9998258868410842, \"f1\": 0.544506622814553, \"f2\": 0.4751181290106575, \"f0_5\": 0.637628966229506, \"p4\": 0.7050664581554371, \"phi\": 0.561312910059727}, {\"truth_threshold\": -8.039999820291996, \"match_probability\": 0.003785052803811502, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685955.0, \"fp\": 51837.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594623695927, \"fp_rate\": 4.053763040734468e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7197181880116358, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594623695927, \"npv\": 0.9998664025565139, \"accuracy\": 0.999825893877602, \"f1\": 0.5445166463151478, \"f2\": 0.4751211816189436, \"f0_5\": 0.6376509588069883, \"p4\": 0.7050748621468117, \"phi\": 0.5613265744847054}, {\"truth_threshold\": -8.01999982073903, \"match_probability\": 0.0038376873974441095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685958.0, \"fp\": 51834.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594647156561, \"fp_rate\": 4.053528434389151e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7197298627144579, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594647156561, \"npv\": 0.9998664025568273, \"accuracy\": 0.9998258962231079, \"f1\": 0.5445199875640208, \"f2\": 0.4751221991637558, \"f0_5\": 0.6376582900032863, \"p4\": 0.7050776635217905, \"phi\": 0.5613311295146454}, {\"truth_threshold\": -7.999999821186066, \"match_probability\": 0.0038910510640548955, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278686001.0, \"fp\": 51791.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594983425656, \"fp_rate\": 4.050165743439606e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7198972417522985, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594983425656, \"npv\": 0.9998664025613193, \"accuracy\": 0.999825929842026, \"f1\": 0.5445678833042521, \"f2\": 0.4751367844516914, \"f0_5\": 0.6377633890112796, \"p4\": 0.7051178190094864, \"phi\": 0.5613964304565924}, {\"truth_threshold\": -7.9799998216331005, \"match_probability\": 0.003945153822415584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278686121.0, \"fp\": 51671.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999595921851038, \"fp_rate\": 4.040781489626921e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7203647580907024, \"recall\": 0.43791473248212764, \"specificity\": 0.9999595921851038, \"npv\": 0.9998664025738553, \"accuracy\": 0.9998260236622627, \"f1\": 0.5447015904129181, \"f2\": 0.47517749231770984, \"f0_5\": 0.6380568719016069, \"p4\": 0.7052299050321843, \"phi\": 0.5615787861736672}, {\"truth_threshold\": -7.959999822080135, \"match_probability\": 0.004000005826732493, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278686140.0, \"fp\": 51652.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999596070435056, \"fp_rate\": 4.039295649439913e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7204388372004914, \"recall\": 0.43791473248212764, \"specificity\": 0.9999596070435056, \"npv\": 0.9998664025758401, \"accuracy\": 0.9998260385171336, \"f1\": 0.544722766726278, \"f2\": 0.47518393836949036, \"f0_5\": 0.6381033647969089, \"p4\": 0.7052476552535974, \"phi\": 0.5616076754496097}, {\"truth_threshold\": -7.93999982252717, \"match_probability\": 0.004055617368414475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133106.0, \"tn\": 1278686286.0, \"fp\": 51506.0, \"fn\": 170855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43790486279489804, \"tn_rate\": 0.9999597212185937, \"fp_rate\": 4.02787814063448e-05, \"fn_rate\": 0.562095137205102, \"precision\": 0.7210040517409486, \"recall\": 0.43790486279489804, \"specificity\": 0.9999597212185937, \"npv\": 0.9998664002455612, \"accuracy\": 0.9998261503195822, \"f1\": 0.5448766100459911, \"f2\": 0.475223784253129, \"f0_5\": 0.6384538122752201, \"p4\": 0.705376594315938, \"phi\": 0.5618217160155797}, {\"truth_threshold\": -7.919999822974205, \"match_probability\": 0.004111998877862162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133106.0, \"tn\": 1278686322.0, \"fp\": 51470.0, \"fn\": 170855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43790486279489804, \"tn_rate\": 0.9999597493713551, \"fp_rate\": 4.025062864490674e-05, \"fn_rate\": 0.562095137205102, \"precision\": 0.7211446775312067, \"recall\": 0.43790486279489804, \"specificity\": 0.9999597493713551, \"npv\": 0.9998664002493219, \"accuracy\": 0.9998261784656532, \"f1\": 0.5449167616782352, \"f2\": 0.4752360006283829, \"f0_5\": 0.6385420214628718, \"p4\": 0.7054102418232708, \"phi\": 0.5618765308677195}, {\"truth_threshold\": -7.89999982342124, \"match_probability\": 0.0041691609262787125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133102.0, \"tn\": 1278686322.0, \"fp\": 51470.0, \"fn\": 170859.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378917032119252, \"tn_rate\": 0.9999597493713551, \"fp_rate\": 4.025062864490674e-05, \"fn_rate\": 0.5621082967880748, \"precision\": 0.7211386342457144, \"recall\": 0.4378917032119252, \"specificity\": 0.9999597493713551, \"npv\": 0.9998663971219472, \"accuracy\": 0.9998261753383121, \"f1\": 0.5449048477789628, \"f2\": 0.475223076571533, \"f0_5\": 0.6385326347158884, \"p4\": 0.7054002586779183, \"phi\": 0.5618657315624296}, {\"truth_threshold\": -7.879999823868275, \"match_probability\": 0.004227114227502277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133101.0, \"tn\": 1278686363.0, \"fp\": 51429.0, \"fn\": 170860.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437888413316182, \"tn_rate\": 0.9999597814342223, \"fp_rate\": 4.02185657777134e-05, \"fn_rate\": 0.562111586683818, \"precision\": 0.7212973500243863, \"recall\": 0.437888413316182, \"specificity\": 0.9999597814342223, \"npv\": 0.9998663963443869, \"accuracy\": 0.9998262066117243, \"f1\": 0.5449476039476674, \"f2\": 0.4752337589815292, \"f0_5\": 0.6386307782216546, \"p4\": 0.7054360876078116, \"phi\": 0.5619254794605827}, {\"truth_threshold\": -7.8599998243153095, \"match_probability\": 0.004285869639860376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133094.0, \"tn\": 1278686780.0, \"fp\": 51012.0, \"fn\": 170867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378653840459796, \"tn_rate\": 0.9999601075370422, \"fp_rate\": 3.989246295772261e-05, \"fn_rate\": 0.5621346159540204, \"precision\": 0.722920491456009, \"recall\": 0.4378653840459796, \"specificity\": 0.9999601075370422, \"npv\": 0.9998663909150476, \"accuracy\": 0.9998265271641996, \"f1\": 0.5453923334296316, \"f2\": 0.4753526911675417, \"f0_5\": 0.6396382108546356, \"p4\": 0.7058086451259884, \"phi\": 0.5625429068825486}, {\"truth_threshold\": -7.839999824762344, \"match_probability\": 0.004345438168046409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133091.0, \"tn\": 1278687530.0, \"fp\": 50262.0, \"fn\": 170870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785551435875, \"tn_rate\": 0.9999606940529056, \"fp_rate\": 3.9305947094429816e-05, \"fn_rate\": 0.5621444856412501, \"precision\": 0.7258730427099639, \"recall\": 0.43785551435875, \"specificity\": 0.9999606940529056, \"npv\": 0.9998663886478754, \"accuracy\": 0.999827111195173, \"f1\": 0.5462227639673803, \"f2\": 0.47559778930343616, \"f0_5\": 0.6414809330877129, \"p4\": 0.7065037357666657, \"phi\": 0.563684740020448}, {\"truth_threshold\": -7.819999825209379, \"match_probability\": 0.004405830965018488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133091.0, \"tn\": 1278687535.0, \"fp\": 50257.0, \"fn\": 170870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785551435875, \"tn_rate\": 0.9999606979630113, \"fp_rate\": 3.930203698867453e-05, \"fn_rate\": 0.5621444856412501, \"precision\": 0.725892837663896, \"recall\": 0.43785551435875, \"specificity\": 0.9999606979630113, \"npv\": 0.9998663886483977, \"accuracy\": 0.9998271151043495, \"f1\": 0.5462283684479458, \"f2\": 0.4755994888478493, \"f0_5\": 0.6414933007375503, \"p4\": 0.7065084243143864, \"phi\": 0.5636924298956129}, {\"truth_threshold\": -7.799999825656414, \"match_probability\": 0.004467059333920819, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133091.0, \"tn\": 1278687557.0, \"fp\": 50235.0, \"fn\": 170870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785551435875, \"tn_rate\": 0.9999607151674766, \"fp_rate\": 3.9284832523351275e-05, \"fn_rate\": 0.5621444856412501, \"precision\": 0.7259799482888406, \"recall\": 0.43785551435875, \"specificity\": 0.9999607151674766, \"npv\": 0.9998663886506962, \"accuracy\": 0.9998271323047263, \"f1\": 0.5462530295287993, \"f2\": 0.4756069669875712, \"f0_5\": 0.6415477240627998, \"p4\": 0.7065290546636588, \"phi\": 0.5637262690830462}, {\"truth_threshold\": -7.779999826103449, \"match_probability\": 0.004529134730027815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133091.0, \"tn\": 1278687561.0, \"fp\": 50231.0, \"fn\": 170870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785551435875, \"tn_rate\": 0.9999607182955612, \"fp_rate\": 3.9281704438747046e-05, \"fn_rate\": 0.5621444856412501, \"precision\": 0.7259957888305822, \"recall\": 0.43785551435875, \"specificity\": 0.9999607182955612, \"npv\": 0.9998663886511141, \"accuracy\": 0.9998271354320675, \"f1\": 0.546257513600926, \"f2\": 0.47560832667460473, \"f0_5\": 0.6415576202049845, \"p4\": 0.706532805765699, \"phi\": 0.5637324223169103}, {\"truth_threshold\": -7.759999826550484, \"match_probability\": 0.00459206876271118, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133091.0, \"tn\": 1278687628.0, \"fp\": 50164.0, \"fn\": 170870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785551435875, \"tn_rate\": 0.9999607706909783, \"fp_rate\": 3.922930902162623e-05, \"fn_rate\": 0.5621444856412501, \"precision\": 0.7262612207033915, \"recall\": 0.43785551435875, \"specificity\": 0.9999607706909783, \"npv\": 0.9998663886581141, \"accuracy\": 0.999827187815033, \"f1\": 0.5463326327542609, \"f2\": 0.47563110258816566, \"f0_5\": 0.6417234259836969, \"p4\": 0.7065956426464786, \"phi\": 0.5638355189261268}, {\"truth_threshold\": -7.7399998269975185, \"match_probability\": 0.004655873197430131, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133091.0, \"tn\": 1278687889.0, \"fp\": 49903.0, \"fn\": 170870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785551435875, \"tn_rate\": 0.9999609747984988, \"fp_rate\": 3.9025201501200335e-05, \"fn_rate\": 0.5621444856412501, \"precision\": 0.7272970698492847, \"recall\": 0.43785551435875, \"specificity\": 0.9999609747984988, \"npv\": 0.9998663886853826, \"accuracy\": 0.9998273918740478, \"f1\": 0.5466254582045569, \"f2\": 0.4757198474734029, \"f0_5\": 0.6423701441303863, \"p4\": 0.7068405317358294, \"phi\": 0.5642376737325243}, {\"truth_threshold\": -7.719999827444553, \"match_probability\": 0.004720559957745, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133090.0, \"tn\": 1278696012.0, \"fp\": 41780.0, \"fn\": 170871.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785222446300676, \"tn_rate\": 0.9999673271563089, \"fp_rate\": 3.2672843691163856e-05, \"fn_rate\": 0.5621477755369932, \"precision\": 0.7610796591753874, \"recall\": 0.43785222446300676, \"specificity\": 0.9999673271563089, \"npv\": 0.999866388752206, \"accuracy\": 0.9998337419404009, \"f1\": 0.5558955038416477, \"f2\": 0.47849521900261305, \"f0_5\": 0.663168038778563, \"p4\": 0.7145454023834199, \"phi\": 0.5771975896607237}, {\"truth_threshold\": -7.699999827891588, \"match_probability\": 0.004786141127354402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133090.0, \"tn\": 1278696057.0, \"fp\": 41735.0, \"fn\": 170871.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785222446300676, \"tn_rate\": 0.9999673623472606, \"fp_rate\": 3.263765273936629e-05, \"fn_rate\": 0.5621477755369932, \"precision\": 0.7612755612755613, \"recall\": 0.43785222446300676, \"specificity\": 0.9999673623472606, \"npv\": 0.9998663887569075, \"accuracy\": 0.9998337771229897, \"f1\": 0.555947751187378, \"f2\": 0.4785107024029442, \"f0_5\": 0.6632870210244393, \"p4\": 0.7145885680248015, \"phi\": 0.5772719065286103}, {\"truth_threshold\": -7.679999828338623, \"match_probability\": 0.004852628952156185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133089.0, \"tn\": 1278696221.0, \"fp\": 41571.0, \"fn\": 170872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43784893456726354, \"tn_rate\": 0.9999674905987294, \"fp_rate\": 3.250940127059293e-05, \"fn_rate\": 0.5621510654327364, \"precision\": 0.7619890072140159, \"recall\": 0.43784893456726354, \"specificity\": 0.9999674905987294, \"npv\": 0.999866387992204, \"accuracy\": 0.9998339045621445, \"f1\": 0.5561352301716808, \"f2\": 0.47856388762635704, \"f0_5\": 0.6637186677451947, \"p4\": 0.7147434354596274, \"phi\": 0.5775403064917737}, {\"truth_threshold\": -7.659999828785658, \"match_probability\": 0.004920035842332357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133086.0, \"tn\": 1278696223.0, \"fp\": 41569.0, \"fn\": 170875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43783906488003393, \"tn_rate\": 0.9999674921627717, \"fp_rate\": 3.250783722829082e-05, \"fn_rate\": 0.562160935119966, \"precision\": 0.7619936446136669, \"recall\": 0.43783906488003393, \"specificity\": 0.9999674921627717, \"npv\": 0.9998663856469001, \"accuracy\": 0.9998339037803092, \"f1\": 0.5561285038527755, \"f2\": 0.4785548209671492, \"f0_5\": 0.6637169465609263, \"p4\": 0.7147378802982906, \"phi\": 0.5775355545738345}, {\"truth_threshold\": -7.639999829232693, \"match_probability\": 0.004988374374458207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133086.0, \"tn\": 1278696247.0, \"fp\": 41545.0, \"fn\": 170875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43783906488003393, \"tn_rate\": 0.9999675109312793, \"fp_rate\": 3.248906872066545e-05, \"fn_rate\": 0.562160935119966, \"precision\": 0.7620983674147201, \"recall\": 0.43783906488003393, \"specificity\": 0.9999675109312793, \"npv\": 0.9998663856494076, \"accuracy\": 0.9998339225443565, \"f1\": 0.5561563920834448, \"f2\": 0.47856308096154193, \"f0_5\": 0.6637805054439717, \"p4\": 0.7147609144212088, \"phi\": 0.5775752586701743}, {\"truth_threshold\": -7.6199998296797276, \"match_probability\": 0.005057657293635818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133085.0, \"tn\": 1278696534.0, \"fp\": 41258.0, \"fn\": 170876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43783577498429077, \"tn_rate\": 0.9999677353713496, \"fp_rate\": 3.226462865031207e-05, \"fn_rate\": 0.5621642250157093, \"precision\": 0.7633515541203261, \"recall\": 0.43783577498429077, \"specificity\": 0.9999677353713496, \"npv\": 0.9998663848975555, \"accuracy\": 0.9998341461492539, \"f1\": 0.5564870877099083, \"f2\": 0.4786586265013268, \"f0_5\": 0.66453916928734, \"p4\": 0.7150339878049784, \"phi\": 0.5780480022181771}, {\"truth_threshold\": -7.599999830126762, \"match_probability\": 0.005127897515652181, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133083.0, \"tn\": 1278696534.0, \"fp\": 41258.0, \"fn\": 170878.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43782919519280433, \"tn_rate\": 0.9999677353713496, \"fp_rate\": 3.226462865031207e-05, \"fn_rate\": 0.5621708048071956, \"precision\": 0.7633488393435852, \"recall\": 0.43782919519280433, \"specificity\": 0.9999677353713496, \"npv\": 0.9998663833338808, \"accuracy\": 0.9998341445855834, \"f1\": 0.5564810517204611, \"f2\": 0.478652121839899, \"f0_5\": 0.6645344917983672, \"p4\": 0.715029004921027, \"phi\": 0.5780426297843715}, {\"truth_threshold\": -7.579999830573797, \"match_probability\": 0.005199108129162101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133081.0, \"tn\": 1278696543.0, \"fp\": 41249.0, \"fn\": 170880.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43782261540131795, \"tn_rate\": 0.99996774240954, \"fp_rate\": 3.225759045995256e-05, \"fn_rate\": 0.562177384598682, \"precision\": 0.7633855331841909, \"recall\": 0.43782261540131795, \"specificity\": 0.99996774240954, \"npv\": 0.9998663817711463, \"accuracy\": 0.9998341500584305, \"f1\": 0.5564854868688727, \"f2\": 0.4786487159161371, \"f0_5\": 0.6645537067017151, \"p4\": 0.715032666821114, \"phi\": 0.5780521853155817}, {\"truth_threshold\": -7.559999831020832, \"match_probability\": 0.005271302397896121, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133081.0, \"tn\": 1278696618.0, \"fp\": 41174.0, \"fn\": 170880.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43782261540131795, \"tn_rate\": 0.9999678010611264, \"fp_rate\": 3.219893887362328e-05, \"fn_rate\": 0.562177384598682, \"precision\": 0.7637140971564661, \"recall\": 0.43782261540131795, \"specificity\": 0.9999678010611264, \"npv\": 0.9998663817789823, \"accuracy\": 0.9998342086960784, \"f1\": 0.5565727620991351, \"f2\": 0.47867454044639984, \"f0_5\": 0.6647528774272439, \"p4\": 0.715104715487456, \"phi\": 0.5781766303438274}, {\"truth_threshold\": -7.539999831467867, \"match_probability\": 0.005344493762893631, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133080.0, \"tn\": 1278696685.0, \"fp\": 41107.0, \"fn\": 170881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781932550557473, \"tn_rate\": 0.9999678534565435, \"fp_rate\": 3.2146543456502456e-05, \"fn_rate\": 0.5621806744944253, \"precision\": 0.7640064987628239, \"recall\": 0.43781932550557473, \"specificity\": 0.9999678534565435, \"npv\": 0.9998663810041454, \"accuracy\": 0.9998342602972086, \"f1\": 0.5566477325012339, \"f2\": 0.47869436005384053, \"f0_5\": 0.6649285656469563, \"p4\": 0.7151665998097769, \"phi\": 0.5782851832088133}, {\"truth_threshold\": -7.519999831914902, \"match_probability\": 0.005418695844761402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133080.0, \"tn\": 1278696703.0, \"fp\": 41089.0, \"fn\": 170881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781932550557473, \"tn_rate\": 0.9999678675329242, \"fp_rate\": 3.213246707578343e-05, \"fn_rate\": 0.5621806744944253, \"precision\": 0.7640854572283242, \"recall\": 0.43781932550557473, \"specificity\": 0.9999678675329242, \"npv\": 0.999866381006026, \"accuracy\": 0.9998342743702441, \"f1\": 0.5566686884320164, \"f2\": 0.47870055891563607, \"f0_5\": 0.664976410026813, \"p4\": 0.71518389677358, \"phi\": 0.578315079240735}, {\"truth_threshold\": -7.499999832361937, \"match_probability\": 0.005493922445957709, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133080.0, \"tn\": 1278696967.0, \"fp\": 40825.0, \"fn\": 170881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781932550557473, \"tn_rate\": 0.9999680739865081, \"fp_rate\": 3.192601349190437e-05, \"fn_rate\": 0.5621806744944253, \"precision\": 0.7652453925994077, \"recall\": 0.43781932550557473, \"specificity\": 0.9999680739865081, \"npv\": 0.9998663810336094, \"accuracy\": 0.9998344807747648, \"f1\": 0.5569762234601332, \"f2\": 0.47879149400359344, \"f0_5\": 0.6656789194672568, \"p4\": 0.7154376817360595, \"phi\": 0.5787540874150037}, {\"truth_threshold\": -7.479999832808971, \"match_probability\": 0.0055701875531022705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133079.0, \"tn\": 1278696995.0, \"fp\": 40797.0, \"fn\": 170882.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378160356098315, \"tn_rate\": 0.9999680958831003, \"fp_rate\": 3.1904116899674766e-05, \"fn_rate\": 0.5621839643901685, \"precision\": 0.7653672732291978, \"recall\": 0.4378160356098315, \"specificity\": 0.9999680958831003, \"npv\": 0.9998663802546978, \"accuracy\": 0.9998345018843181, \"f1\": 0.5570058409039066, \"f2\": 0.47879788734421325, \"f0_5\": 0.6657511768796306, \"p4\": 0.71546211759783, \"phi\": 0.578798022093727}, {\"truth_threshold\": -7.459999833256006, \"match_probability\": 0.00564750533931217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278697019.0, \"fp\": 40773.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.999968114651608, \"fp_rate\": 3.18853483920494e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7654715819868738, \"recall\": 0.43781274571408835, \"specificity\": 0.999968114651608, \"npv\": 0.9998663794753682, \"accuracy\": 0.9998345198665302, \"f1\": 0.5570307987241844, \"f2\": 0.47880290279521764, \"f0_5\": 0.6658127911223627, \"p4\": 0.7154827083422337, \"phi\": 0.5788353057990403}, {\"truth_threshold\": -7.439999833703041, \"match_probability\": 0.005725890166563975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278697024.0, \"fp\": 40768.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999681185617137, \"fp_rate\": 3.1881438286294114e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7654935977819449, \"recall\": 0.43781274571408835, \"specificity\": 0.9999681185617137, \"npv\": 0.9998663794758906, \"accuracy\": 0.9998345237757066, \"f1\": 0.557036627759744, \"f2\": 0.4788046254920162, \"f0_5\": 0.6658261161060495, \"p4\": 0.7154875172910502, \"phi\": 0.5788436337440739}, {\"truth_threshold\": -7.419999834150076, \"match_probability\": 0.005805356588082265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278697061.0, \"fp\": 40731.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999681474964963, \"fp_rate\": 3.1852503503705e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7656565540334506, \"recall\": 0.43781274571408835, \"specificity\": 0.9999681474964963, \"npv\": 0.9998663794797565, \"accuracy\": 0.999834552703613, \"f1\": 0.5570797664148021, \"f2\": 0.4788173738336117, \"f0_5\": 0.6659247375642641, \"p4\": 0.7155231055215412, \"phi\": 0.5789052717039281}, {\"truth_threshold\": -7.399999834597111, \"match_probability\": 0.005885919350754696, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133077.0, \"tn\": 1278697061.0, \"fp\": 40731.0, \"fn\": 170884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43780945581834513, \"tn_rate\": 0.9999681474964963, \"fp_rate\": 3.1852503503705e-05, \"fn_rate\": 0.5621905441816549, \"precision\": 0.7656552057442695, \"recall\": 0.43780945581834513, \"specificity\": 0.9999681474964963, \"npv\": 0.9998663786979194, \"accuracy\": 0.9998345519217776, \"f1\": 0.557076746293711, \"f2\": 0.47881412036970405, \"f0_5\": 0.6659223993762967, \"p4\": 0.715520614226246, \"phi\": 0.5789025863846883}, {\"truth_threshold\": -7.379999835044146, \"match_probability\": 0.005967593397573865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133077.0, \"tn\": 1278697067.0, \"fp\": 40725.0, \"fn\": 170884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43780945581834513, \"tn_rate\": 0.9999681521886232, \"fp_rate\": 3.184781137679866e-05, \"fn_rate\": 0.5621905441816549, \"precision\": 0.7656816377256879, \"recall\": 0.43780945581834513, \"specificity\": 0.9999681521886232, \"npv\": 0.9998663786985463, \"accuracy\": 0.9998345566127895, \"f1\": 0.5570837423576125, \"f2\": 0.4788161877197502, \"f0_5\": 0.6659383948060839, \"p4\": 0.7155263856274282, \"phi\": 0.578912583595037}, {\"truth_threshold\": -7.35999983549118, \"match_probability\": 0.006050393870106122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133076.0, \"tn\": 1278697086.0, \"fp\": 40706.0, \"fn\": 170885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378061659226019, \"tn_rate\": 0.9999681670470251, \"fp_rate\": 3.183295297492858e-05, \"fn_rate\": 0.5621938340773981, \"precision\": 0.7657640031763934, \"recall\": 0.4378061659226019, \"specificity\": 0.9999681670470251, \"npv\": 0.9998663779186945, \"accuracy\": 0.9998345706858249, \"f1\": 0.5571028774885242, \"f2\": 0.4788194809250834, \"f0_5\": 0.6659867138963596, \"p4\": 0.7155421710432619, \"phi\": 0.5789415595594976}, {\"truth_threshold\": -7.339999835938215, \"match_probability\": 0.006134336110987506, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133069.0, \"tn\": 1278698939.0, \"fp\": 38853.0, \"fn\": 170892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377831366523995, \"tn_rate\": 0.999969616132218, \"fp_rate\": 3.038386778201985e-05, \"fn_rate\": 0.5622168633476005, \"precision\": 0.774007980363188, \"recall\": 0.4377831366523995, \"specificity\": 0.999969616132218, \"npv\": 0.9998663726394528, \"accuracy\": 0.9998360139537994, \"f1\": 0.5592509083114967, \"f2\": 0.4794360144289455, \"f0_5\": 0.6709480874785332, \"p4\": 0.7173116973988951, \"phi\": 0.5820357620767995}, {\"truth_threshold\": -7.31999983638525, \"match_probability\": 0.006219435666447021, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133069.0, \"tn\": 1278698952.0, \"fp\": 38840.0, \"fn\": 170892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377831366523995, \"tn_rate\": 0.999969626298493, \"fp_rate\": 3.0373701507056107e-05, \"fn_rate\": 0.5622168633476005, \"precision\": 0.7740665119336393, \"recall\": 0.4377831366523995, \"specificity\": 0.999969626298493, \"npv\": 0.9998663726408111, \"accuracy\": 0.9998360241176584, \"f1\": 0.5592661861432744, \"f2\": 0.4794405056231188, \"f0_5\": 0.670983272438299, \"p4\": 0.7173242656573658, \"phi\": 0.5820577794008253}, {\"truth_threshold\": -7.299999836832285, \"match_probability\": 0.006305708288857409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133068.0, \"tn\": 1278699038.0, \"fp\": 38754.0, \"fn\": 170893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43777984675665627, \"tn_rate\": 0.9999696935523119, \"fp_rate\": 3.0306447688065202e-05, \"fn_rate\": 0.5622201532433437, \"precision\": 0.7744526312113699, \"recall\": 0.43777984675665627, \"specificity\": 0.9999696935523119, \"npv\": 0.9998663718679613, \"accuracy\": 0.9998360905736593, \"f1\": 0.5593642479870025, \"f2\": 0.4794669610698828, \"f0_5\": 0.6712137918928544, \"p4\": 0.7174049302091785, \"phi\": 0.5822008138524677}, {\"truth_threshold\": -7.27999983727932, \"match_probability\": 0.006393169939313586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133067.0, \"tn\": 1278699040.0, \"fp\": 38752.0, \"fn\": 170894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377765568609131, \"tn_rate\": 0.9999696951163543, \"fp_rate\": 3.0304883645763088e-05, \"fn_rate\": 0.5622234431390869, \"precision\": 0.7744603332576723, \"recall\": 0.4377765568609131, \"specificity\": 0.9999696951163543, \"npv\": 0.9998663710863344, \"accuracy\": 0.9998360913554947, \"f1\": 0.5593635713985455, \"f2\": 0.4794643944531201, \"f0_5\": 0.6712168734621488, \"p4\": 0.7174043738496688, \"phi\": 0.5822015223550163}, {\"truth_threshold\": -7.259999837726355, \"match_probability\": 0.006481836790238961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133066.0, \"tn\": 1278699050.0, \"fp\": 38742.0, \"fn\": 170895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377732669651699, \"tn_rate\": 0.9999697029365657, \"fp_rate\": 3.0297063434252515e-05, \"fn_rate\": 0.5622267330348302, \"precision\": 0.774504097597318, \"recall\": 0.4377732669651699, \"specificity\": 0.9999697029365657, \"npv\": 0.9998663703055435, \"accuracy\": 0.9998360983920124, \"f1\": 0.5593723004231045, \"f2\": 0.47946459198704, \"f0_5\": 0.6712416249912984, \"p4\": 0.71741155390451, \"phi\": 0.5822157919740714}, {\"truth_threshold\": -7.239999838173389, \"match_probability\": 0.006571725228019751, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133066.0, \"tn\": 1278699051.0, \"fp\": 38741.0, \"fn\": 170895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377732669651699, \"tn_rate\": 0.9999697037185868, \"fp_rate\": 3.029628141310146e-05, \"fn_rate\": 0.5622267330348302, \"precision\": 0.7745086055865011, \"recall\": 0.4377732669651699, \"specificity\": 0.9999697037185868, \"npv\": 0.999866370305648, \"accuracy\": 0.9998360991738476, \"f1\": 0.5593734761480386, \"f2\": 0.4794649375095035, \"f0_5\": 0.671244333825335, \"p4\": 0.7174125209689736, \"phi\": 0.5822174871731284}, {\"truth_threshold\": -7.219999838620424, \"match_probability\": 0.006662851855667506, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133066.0, \"tn\": 1278699078.0, \"fp\": 38714.0, \"fn\": 170895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377732669651699, \"tn_rate\": 0.9999697248331579, \"fp_rate\": 3.0275166842022918e-05, \"fn_rate\": 0.5622267330348302, \"precision\": 0.7746303411340086, \"recall\": 0.4377732669651699, \"specificity\": 0.9999697248331579, \"npv\": 0.9998663703084691, \"accuracy\": 0.999836120283401, \"f1\": 0.5594052225896023, \"f2\": 0.47947426680426397, \"f0_5\": 0.6713174806095566, \"p4\": 0.7174386326950456, \"phi\": 0.5822632631420227}, {\"truth_threshold\": -7.199999839067459, \"match_probability\": 0.006755233495509978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133066.0, \"tn\": 1278699155.0, \"fp\": 38637.0, \"fn\": 170895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377732669651699, \"tn_rate\": 0.9999697850487866, \"fp_rate\": 3.0214951213391527e-05, \"fn_rate\": 0.5622267330348302, \"precision\": 0.7749777231615056, \"recall\": 0.4377732669651699, \"specificity\": 0.9999697850487866, \"npv\": 0.9998663703165149, \"accuracy\": 0.9998361804847195, \"f1\": 0.5594957785327458, \"f2\": 0.4795008745649697, \"f0_5\": 0.6715261719889419, \"p4\": 0.7175131099104401, \"phi\": 0.5823938687126231}, {\"truth_threshold\": -7.179999839514494, \"match_probability\": 0.006848887191910523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133066.0, \"tn\": 1278699161.0, \"fp\": 38631.0, \"fn\": 170895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377732669651699, \"tn_rate\": 0.9999697897409136, \"fp_rate\": 3.0210259086485183e-05, \"fn_rate\": 0.5622267330348302, \"precision\": 0.775004804976208, \"recall\": 0.4377732669651699, \"specificity\": 0.9999697897409136, \"npv\": 0.9998663703171419, \"accuracy\": 0.9998361851757314, \"f1\": 0.5595028360712949, \"f2\": 0.4795029480209954, \"f0_5\": 0.6715424391041526, \"p4\": 0.7175189139792233, \"phi\": 0.5824040494590902}, {\"truth_threshold\": -7.159999839961529, \"match_probability\": 0.006943830214016168, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699224.0, \"fp\": 38568.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.999969839008246, \"fp_rate\": 3.0160991753968587e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7752801132688912, \"recall\": 0.43775023769496746, \"specificity\": 0.999969839008246, \"npv\": 0.9998663648508747, \"accuracy\": 0.9998362289585084, \"f1\": 0.5595557499348175, \"f2\": 0.4795019139138764, \"f0_5\": 0.6716969435691577, \"p4\": 0.7175624293953097, \"phi\": 0.5824922109855287}, {\"truth_threshold\": -7.139999840408564, \"match_probability\": 0.0070400800585345, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699240.0, \"fp\": 38552.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999698515205845, \"fp_rate\": 3.0148479415551674e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7753523958254425, \"recall\": 0.43775023769496746, \"specificity\": 0.9999698515205845, \"npv\": 0.9998663648525465, \"accuracy\": 0.9998362414678733, \"f1\": 0.5595745754586057, \"f2\": 0.4795074434846536, \"f0_5\": 0.6717403486452512, \"p4\": 0.7175779100629064, \"phi\": 0.5825193774335228}, {\"truth_threshold\": -7.1199998408555984, \"match_probability\": 0.00713765445253955, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699252.0, \"fp\": 38540.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999698609048383, \"fp_rate\": 3.013909516173899e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7754066165886747, \"recall\": 0.43775023769496746, \"specificity\": 0.9999698609048383, \"npv\": 0.9998663648538004, \"accuracy\": 0.999836250849897, \"f1\": 0.5595886954327529, \"f2\": 0.4795115907464307, \"f0_5\": 0.6717729061338487, \"p4\": 0.7175895210019588, \"phi\": 0.5825397547625103}, {\"truth_threshold\": -7.099999841302633, \"match_probability\": 0.007236571356306779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699271.0, \"fp\": 38521.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999698757632401, \"fp_rate\": 3.0124236759868907e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.775492481641217, \"recall\": 0.43775023769496746, \"specificity\": 0.9999698757632401, \"npv\": 0.9998663648557858, \"accuracy\": 0.9998362657047678, \"f1\": 0.5596110535158904, \"f2\": 0.4795181573909634, \"f0_5\": 0.6718244619456498, \"p4\": 0.7176079057572666, \"phi\": 0.5825720232378937}, {\"truth_threshold\": -7.079999841749668, \"match_probability\": 0.007336848966177337, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699290.0, \"fp\": 38502.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.999969890621642, \"fp_rate\": 3.0109378357998824e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7755783657124871, \"recall\": 0.43775023769496746, \"specificity\": 0.999969890621642, \"npv\": 0.9998663648577713, \"accuracy\": 0.9998362805596386, \"f1\": 0.5596334133857108, \"f2\": 0.4795247242153517, \"f0_5\": 0.6718760256714519, \"p4\": 0.7176262914546391, \"phi\": 0.5826042970727663}, {\"truth_threshold\": -7.059999842196703, \"match_probability\": 0.007438505717451711, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699325.0, \"fp\": 38467.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999699179923823, \"fp_rate\": 3.0082007617711825e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7757366230192507, \"recall\": 0.43775023769496746, \"specificity\": 0.9999699179923823, \"npv\": 0.9998663648614285, \"accuracy\": 0.9998363079238743, \"f1\": 0.5596746072973604, \"f2\": 0.47953682146795734, \"f0_5\": 0.6719710322049562, \"p4\": 0.7176601623108481, \"phi\": 0.5826637629085103}, {\"truth_threshold\": -7.039999842643738, \"match_probability\": 0.007541560287312903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699472.0, \"fp\": 38320.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999700329494915, \"fp_rate\": 2.9967050508506438e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7764020095811038, \"recall\": 0.43775023769496746, \"specificity\": 0.9999700329494915, \"npv\": 0.9998663648767893, \"accuracy\": 0.9998364228536643, \"f1\": 0.5598476879707157, \"f2\": 0.47958763659483733, \"f0_5\": 0.6723703532270078, \"p4\": 0.7178024548284117, \"phi\": 0.5829137182812248}, {\"truth_threshold\": -7.019999843090773, \"match_probability\": 0.007646031597779248, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699482.0, \"fp\": 38310.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.999970040769703, \"fp_rate\": 2.995923029699587e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7764473154421161, \"recall\": 0.43775023769496746, \"specificity\": 0.999970040769703, \"npv\": 0.9998663648778342, \"accuracy\": 0.9998364306720173, \"f1\": 0.5598594660551617, \"f2\": 0.4795910937974197, \"f0_5\": 0.6723975351639366, \"p4\": 0.717812136641333, \"phi\": 0.5829307337287869}, {\"truth_threshold\": -6.9999998435378075, \"match_probability\": 0.007751938818687018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133057.0, \"tn\": 1278699486.0, \"fp\": 38306.0, \"fn\": 170904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437743657903481, \"tn_rate\": 0.9999700438977877, \"fp_rate\": 2.995610221239164e-05, \"fn_rate\": 0.562256342096519, \"precision\": 0.7764628303659483, \"recall\": 0.437743657903481, \"specificity\": 0.9999700438977877, \"npv\": 0.9998663633145811, \"accuracy\": 0.999836432235688, \"f1\": 0.5598581178312056, \"f2\": 0.47958595941341126, \"f0_5\": 0.6724037383782101, \"p4\": 0.7178110286994792, \"phi\": 0.582932178887303}, {\"truth_threshold\": -6.979999843984842, \"match_probability\": 0.00785930137070288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133056.0, \"tn\": 1278699504.0, \"fp\": 38288.0, \"fn\": 170905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43774036800773786, \"tn_rate\": 0.9999700579741684, \"fp_rate\": 2.9942025831672612e-05, \"fn_rate\": 0.5622596319922621, \"precision\": 0.7765430945933327, \"recall\": 0.43774036800773786, \"specificity\": 0.9999700579741684, \"npv\": 0.9998663625346265, \"accuracy\": 0.9998364455268881, \"f1\": 0.5598762899611828, \"f2\": 0.4795889237796175, \"f0_5\": 0.6724503379535992, \"p4\": 0.7178259664388, \"phi\": 0.5829601308973534}, {\"truth_threshold\": -6.959999844431877, \"match_probability\": 0.007968138928366363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133056.0, \"tn\": 1278699511.0, \"fp\": 38281.0, \"fn\": 170905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43774036800773786, \"tn_rate\": 0.9999700634483164, \"fp_rate\": 2.9936551683615213e-05, \"fn_rate\": 0.5622596319922621, \"precision\": 0.7765748203832213, \"recall\": 0.43774036800773786, \"specificity\": 0.9999700634483164, \"npv\": 0.9998663625353579, \"accuracy\": 0.9998364509997353, \"f1\": 0.5598845355966152, \"f2\": 0.47959134388374697, \"f0_5\": 0.6724693700350447, \"p4\": 0.7178327442772089, \"phi\": 0.5829720449348669}, {\"truth_threshold\": -6.939999844878912, \"match_probability\": 0.0080784714231624, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133055.0, \"tn\": 1278699528.0, \"fp\": 38264.0, \"fn\": 170906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43773707811199464, \"tn_rate\": 0.9999700767426759, \"fp_rate\": 2.9923257324047244e-05, \"fn_rate\": 0.5622629218880054, \"precision\": 0.7766505758263824, \"recall\": 0.43773707811199464, \"specificity\": 0.9999700767426759, \"npv\": 0.9998663617552989, \"accuracy\": 0.9998364635091002, \"f1\": 0.5599015317286652, \"f2\": 0.47959396264173715, \"f0_5\": 0.6725132602197451, \"p4\": 0.7178467148777804, \"phi\": 0.5829983014086229}, {\"truth_threshold\": -6.919999845325947, \"match_probability\": 0.00819031904662406, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133053.0, \"tn\": 1278699700.0, \"fp\": 38092.0, \"fn\": 170908.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377304983205082, \"tn_rate\": 0.9999702112503139, \"fp_rate\": 2.978874968606543e-05, \"fn_rate\": 0.5622695016794917, \"precision\": 0.7774284963043033, \"recall\": 0.4377304983205082, \"specificity\": 0.9999702112503139, \"npv\": 0.9998663602096014, \"accuracy\": 0.9998365964211021, \"f1\": 0.5600981675668166, \"f2\": 0.479646918612909, \"f0_5\": 0.6729766393098516, \"p4\": 0.7180083233456932, \"phi\": 0.5832859592360222}, {\"truth_threshold\": -6.899999845772982, \"match_probability\": 0.008303702253465536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133050.0, \"tn\": 1278699835.0, \"fp\": 37957.0, \"fn\": 170911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377206286332786, \"tn_rate\": 0.9999703168231693, \"fp_rate\": 2.9683176830672728e-05, \"fn_rate\": 0.5622793713667213, \"precision\": 0.7780383259164829, \"recall\": 0.4377206286332786, \"specificity\": 0.9999703168231693, \"npv\": 0.9998663578782027, \"accuracy\": 0.9998366996233625, \"f1\": 0.5602482693570935, \"f2\": 0.47968383049080254, \"f0_5\": 0.6733374561862531, \"p4\": 0.7181316598458107, \"phi\": 0.5835082146166368}, {\"truth_threshold\": -6.8799998462200165, \"match_probability\": 0.008418641764745485, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133050.0, \"tn\": 1278699868.0, \"fp\": 37924.0, \"fn\": 170911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377206286332786, \"tn_rate\": 0.9999703426298673, \"fp_rate\": 2.9657370132687843e-05, \"fn_rate\": 0.5622793713667213, \"precision\": 0.7781884964965433, \"recall\": 0.4377206286332786, \"specificity\": 0.9999703426298673, \"npv\": 0.9998663578816511, \"accuracy\": 0.9998367254239275, \"f1\": 0.5602871971954057, \"f2\": 0.47969524479780334, \"f0_5\": 0.6734274292736702, \"p4\": 0.7181636422974517, \"phi\": 0.5835645507643499}, {\"truth_threshold\": -6.859999846667051, \"match_probability\": 0.008535158571060781, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133050.0, \"tn\": 1278700210.0, \"fp\": 37582.0, \"fn\": 170911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377206286332786, \"tn_rate\": 0.999970610081101, \"fp_rate\": 2.938991889902633e-05, \"fn_rate\": 0.5622793713667213, \"precision\": 0.779748230109241, \"recall\": 0.4377206286332786, \"specificity\": 0.999970610081101, \"npv\": 0.9998663579173902, \"accuracy\": 0.9998369928116021, \"f1\": 0.5606909499297292, \"f2\": 0.4798135705197926, \"f0_5\": 0.6743612954630006, \"p4\": 0.7184952646184701, \"phi\": 0.5841493599698427}, {\"truth_threshold\": -6.839999847114086, \"match_probability\": 0.008653273935770752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133049.0, \"tn\": 1278701161.0, \"fp\": 36631.0, \"fn\": 170912.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43771733873753543, \"tn_rate\": 0.9999713537832157, \"fp_rate\": 2.8646216784371067e-05, \"fn_rate\": 0.5622826612624646, \"precision\": 0.7841171617161716, \"recall\": 0.43771733873753543, \"specificity\": 0.9999713537832157, \"npv\": 0.9998663572349351, \"accuracy\": 0.9998377355551425, \"f1\": 0.5618136943381169, \"f2\": 0.4801396439181133, \"f0_5\": 0.67696943362088, \"p4\": 0.7194165297378221, \"phi\": 0.5857821449715989}, {\"truth_threshold\": -6.819999847561121, \"match_probability\": 0.008773009398251957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133047.0, \"tn\": 1278701164.0, \"fp\": 36628.0, \"fn\": 170914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437710758946049, \"tn_rate\": 0.9999713561292791, \"fp_rate\": 2.8643870720917897e-05, \"fn_rate\": 0.562289241053951, \"precision\": 0.7841284809194048, \"recall\": 0.437710758946049, \"specificity\": 0.9999713561292791, \"npv\": 0.9998663556715796, \"accuracy\": 0.9998377363369779, \"f1\": 0.5618111798934202, \"f2\": 0.4801341591129389, \"f0_5\": 0.6769730354618734, \"p4\": 0.7194144683123118, \"phi\": 0.5857819716304679}, {\"truth_threshold\": -6.799999848008156, \"match_probability\": 0.00889438677718353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133046.0, \"tn\": 1278701231.0, \"fp\": 36561.0, \"fn\": 170915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377074690503058, \"tn_rate\": 0.9999714085246962, \"fp_rate\": 2.8591475303797075e-05, \"fn_rate\": 0.5622925309496942, \"precision\": 0.784436963097042, \"recall\": 0.4377074690503058, \"specificity\": 0.9999714085246962, \"npv\": 0.9998663548967467, \"accuracy\": 0.9998377879381081, \"f1\": 0.5618876275424015, \"f2\": 0.4801541158799553, \"f0_5\": 0.6771553834580802, \"p4\": 0.7194771494327823, \"phi\": 0.5858950382942931}, {\"truth_threshold\": -6.779999848455191, \"match_probability\": 0.009017428173863171, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133046.0, \"tn\": 1278701356.0, \"fp\": 36436.0, \"fn\": 170915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377074690503058, \"tn_rate\": 0.9999715062773401, \"fp_rate\": 2.849372265991494e-05, \"fn_rate\": 0.5622925309496942, \"precision\": 0.7850155178721044, \"recall\": 0.4377074690503058, \"specificity\": 0.9999715062773401, \"npv\": 0.9998663549098095, \"accuracy\": 0.9998378856675213, \"f1\": 0.5620359789879669, \"f2\": 0.4801974408911693, \"f0_5\": 0.6775002062351243, \"p4\": 0.7195987682592624, \"phi\": 0.5861111616685284}, {\"truth_threshold\": -6.7599998489022255, \"match_probability\": 0.009142155975553755, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133045.0, \"tn\": 1278701371.0, \"fp\": 36421.0, \"fn\": 170916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377041791545626, \"tn_rate\": 0.9999715180076574, \"fp_rate\": 2.8481992342649087e-05, \"fn_rate\": 0.5622958208454374, \"precision\": 0.7850837336102817, \"recall\": 0.4377041791545626, \"specificity\": 0.9999715180076574, \"npv\": 0.9998663541295426, \"accuracy\": 0.9998378966132155, \"f1\": 0.5620507491123236, \"f2\": 0.4801993777566032, \"f0_5\": 0.6775392763476179, \"p4\": 0.7196108757317291, \"phi\": 0.5861344358498939}, {\"truth_threshold\": -6.73999984934926, \"match_probability\": 0.009268592858860633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133045.0, \"tn\": 1278701399.0, \"fp\": 36393.0, \"fn\": 170916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377041791545626, \"tn_rate\": 0.9999715399042496, \"fp_rate\": 2.846009575041949e-05, \"fn_rate\": 0.5622958208454374, \"precision\": 0.7852134704139567, \"recall\": 0.4377041791545626, \"specificity\": 0.9999715399042496, \"npv\": 0.9998663541324686, \"accuracy\": 0.9998379185046041, \"f1\": 0.5620839925728613, \"f2\": 0.48020908378221905, \"f0_5\": 0.6776165742941165, \"p4\": 0.7196381251073765, \"phi\": 0.5861828867571305}, {\"truth_threshold\": -6.719999849796295, \"match_probability\": 0.009396761793139606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133038.0, \"tn\": 1278701489.0, \"fp\": 36303.0, \"fn\": 170923.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376811498843602, \"tn_rate\": 0.9999716102861532, \"fp_rate\": 2.8389713846824353e-05, \"fn_rate\": 0.5623188501156399, \"precision\": 0.7856219108189983, \"recall\": 0.4376811498843602, \"specificity\": 0.9999716102861532, \"npv\": 0.9998663486690336, \"accuracy\": 0.9998379833969345, \"f1\": 0.5621696084106976, \"f2\": 0.4802174438793374, \"f0_5\": 0.6778488268412606, \"p4\": 0.7197082994310722, \"phi\": 0.5863199679752257}, {\"truth_threshold\": -6.69999985024333, \"match_probability\": 0.009526686043935558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133038.0, \"tn\": 1278701490.0, \"fp\": 36302.0, \"fn\": 170923.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376811498843602, \"tn_rate\": 0.9999716110681743, \"fp_rate\": 2.8388931825673297e-05, \"fn_rate\": 0.5623188501156399, \"precision\": 0.7856265501358214, \"recall\": 0.4376811498843602, \"specificity\": 0.9999716110681743, \"npv\": 0.9998663486691381, \"accuracy\": 0.9998379841787698, \"f1\": 0.5621707961741048, \"f2\": 0.4802177905606764, \"f0_5\": 0.6778515898467474, \"p4\": 0.7197092729022554, \"phi\": 0.5863216999826976}, {\"truth_threshold\": -6.679999850690365, \"match_probability\": 0.009658389176451789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133035.0, \"tn\": 1278702688.0, \"fp\": 35104.0, \"fn\": 170926.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43767128019713053, \"tn_rate\": 0.9999725479295133, \"fp_rate\": 2.7452070486706943e-05, \"fn_rate\": 0.5623287198028695, \"precision\": 0.7912203593455415, \"recall\": 0.43767128019713053, \"specificity\": 0.9999725479295133, \"npv\": 0.9998663464488368, \"accuracy\": 0.9998389184719602, \"f1\": 0.5635882228341453, \"f2\": 0.48062367818101814, \"f0_5\": 0.6811709371163022, \"p4\": 0.7208699189014757, \"phi\": 0.588399706240535}, {\"truth_threshold\": -6.6599998511374, \"match_probability\": 0.00979189505904994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133030.0, \"tn\": 1278702767.0, \"fp\": 35025.0, \"fn\": 170931.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43765483071841454, \"tn_rate\": 0.9999726097091842, \"fp_rate\": 2.7390290815773434e-05, \"fn_rate\": 0.5623451692815855, \"precision\": 0.7915860878878939, \"recall\": 0.43765483071841454, \"specificity\": 0.9999726097091842, \"npv\": 0.9998663425479253, \"accuracy\": 0.9998389763277727, \"f1\": 0.5636673333107353, \"f2\": 0.4806347862091092, \"f0_5\": 0.6813797851013286, \"p4\": 0.7209346365146833, \"phi\": 0.5885246820243223}, {\"truth_threshold\": -6.6399998515844345, \"match_probability\": 0.009927227866780578, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133029.0, \"tn\": 1278702794.0, \"fp\": 34998.0, \"fn\": 170932.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376515408226713, \"tn_rate\": 0.9999726308237553, \"fp_rate\": 2.7369176244694893e-05, \"fn_rate\": 0.5623484591773287, \"precision\": 0.7917120462782767, \"recall\": 0.4376515408226713, \"specificity\": 0.9999726308237553, \"npv\": 0.9998663417689136, \"accuracy\": 0.9998389966554907, \"f1\": 0.5636965346576608, \"f2\": 0.4806408978871586, \"f0_5\": 0.6814528481080743, \"p4\": 0.720958523364343, \"phi\": 0.5885693131334366}, {\"truth_threshold\": -6.619999852031469, \"match_probability\": 0.010064412084944284, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133029.0, \"tn\": 1278702837.0, \"fp\": 34955.0, \"fn\": 170932.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376515408226713, \"tn_rate\": 0.9999726644506648, \"fp_rate\": 2.7335549335199442e-05, \"fn_rate\": 0.5623484591773287, \"precision\": 0.7919147061624917, \"recall\": 0.4376515408226713, \"specificity\": 0.9999726644506648, \"npv\": 0.9998663417734076, \"accuracy\": 0.9998390302744089, \"f1\": 0.5637478943520962, \"f2\": 0.48065583295033776, \"f0_5\": 0.6815729528833473, \"p4\": 0.721000533413609, \"phi\": 0.5886446736813621}, {\"truth_threshold\": -6.599999852478504, \"match_probability\": 0.010203472512683304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133019.0, \"tn\": 1278702914.0, \"fp\": 34878.0, \"fn\": 170942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376186418652393, \"tn_rate\": 0.9999727246662934, \"fp_rate\": 2.7275333706568047e-05, \"fn_rate\": 0.5623813581347608, \"precision\": 0.7922654961077327, \"recall\": 0.4376186418652393, \"specificity\": 0.9999727246662934, \"npv\": 0.9998663339631207, \"accuracy\": 0.9998390826573743, \"f1\": 0.5638094511484387, \"f2\": 0.480649919312935, \"f0_5\": 0.6817648319049069, \"p4\": 0.7210508821973307, \"phi\": 0.5887529617707487}, {\"truth_threshold\": -6.579999852925539, \"match_probability\": 0.010344434266603562, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133019.0, \"tn\": 1278702915.0, \"fp\": 34877.0, \"fn\": 170942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376186418652393, \"tn_rate\": 0.9999727254483146, \"fp_rate\": 2.7274551685416988e-05, \"fn_rate\": 0.5623813581347608, \"precision\": 0.792270214894935, \"recall\": 0.4376186418652393, \"specificity\": 0.9999727254483146, \"npv\": 0.9998663339632252, \"accuracy\": 0.9998390834392097, \"f1\": 0.5638106460219939, \"f2\": 0.4806502666685938, \"f0_5\": 0.6817676273262637, \"p4\": 0.7210518594433877, \"phi\": 0.588754715916469}, {\"truth_threshold\": -6.539999853819609, \"match_probability\": 0.010632163828674601, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133018.0, \"tn\": 1278703161.0, \"fp\": 34631.0, \"fn\": 170943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376153519694961, \"tn_rate\": 0.9999729178255178, \"fp_rate\": 2.7082174482256953e-05, \"fn_rate\": 0.5623846480305039, \"precision\": 0.7934315146526374, \"recall\": 0.4376153519694961, \"specificity\": 0.9999729178255178, \"npv\": 0.9998663332071035, \"accuracy\": 0.9998392749888596, \"f1\": 0.5641016941964759, \"f2\": 0.4807324648552613, \"f0_5\": 0.6824536686925444, \"p4\": 0.7212898534397992, \"phi\": 0.5891840397338103}, {\"truth_threshold\": -6.5199998542666435, \"match_probability\": 0.010778983490378357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133016.0, \"tn\": 1278703255.0, \"fp\": 34537.0, \"fn\": 170945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376087721780097, \"tn_rate\": 0.999972991335506, \"fp_rate\": 2.700866449405759e-05, \"fn_rate\": 0.5623912278219904, \"precision\": 0.7938741771260437, \"recall\": 0.4376087721780097, \"specificity\": 0.999972991335506, \"npv\": 0.9998663316532619, \"accuracy\": 0.9998393469177077, \"f1\": 0.5642080616906391, \"f2\": 0.48075859641158686, \"f0_5\": 0.6827124135035564, \"p4\": 0.7213768097280885, \"phi\": 0.5893440180435903}, {\"truth_threshold\": -6.499999854713678, \"match_probability\": 0.010927808192824842, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133014.0, \"tn\": 1278703295.0, \"fp\": 34497.0, \"fn\": 170947.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43760219238652326, \"tn_rate\": 0.999973022616352, \"fp_rate\": 2.697738364801531e-05, \"fn_rate\": 0.5623978076134767, \"precision\": 0.7940612855275176, \"recall\": 0.43760219238652326, \"specificity\": 0.999973022616352, \"npv\": 0.9998663300937763, \"accuracy\": 0.9998393766274493, \"f1\": 0.5642498388027285, \"f2\": 0.48076596390658943, \"f0_5\": 0.6828199033885863, \"p4\": 0.721410959812507, \"phi\": 0.5894090660163005}, {\"truth_threshold\": -6.479999855160713, \"match_probability\": 0.011078664695327443, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133012.0, \"tn\": 1278703324.0, \"fp\": 34468.0, \"fn\": 170949.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375956125950369, \"tn_rate\": 0.9999730452949653, \"fp_rate\": 2.6954705034634654e-05, \"fn_rate\": 0.5624043874049631, \"precision\": 0.7941963219488894, \"recall\": 0.4375956125950369, \"specificity\": 0.9999730452949653, \"npv\": 0.9998663285331412, \"accuracy\": 0.9998393977370026, \"f1\": 0.5642784569012878, \"f2\": 0.48076950880632446, \"f0_5\": 0.6828965756596546, \"p4\": 0.7214343523017006, \"phi\": 0.5894547720156315}, {\"truth_threshold\": -6.459999855607748, \"match_probability\": 0.01123158009702879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133008.0, \"tn\": 1278703423.0, \"fp\": 34369.0, \"fn\": 170953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43758245301206405, \"tn_rate\": 0.9999731227150593, \"fp_rate\": 2.6877284940680006e-05, \"fn_rate\": 0.562417546987936, \"precision\": 0.7946611541609659, \"recall\": 0.43758245301206405, \"specificity\": 0.9999731227150593, \"npv\": 0.9998663254161564, \"accuracy\": 0.9998394720113566, \"f1\": 0.5643847939270756, \"f2\": 0.48079084976298075, \"f0_5\": 0.6831650519944652, \"p4\": 0.7215212643557195, \"phi\": 0.5896184603261571}, {\"truth_threshold\": -6.439999856054783, \"match_probability\": 0.011386581840732598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133006.0, \"tn\": 1278703426.0, \"fp\": 34366.0, \"fn\": 170955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375758732205776, \"tn_rate\": 0.9999731250611228, \"fp_rate\": 2.6874938877226832e-05, \"fn_rate\": 0.5624241267794223, \"precision\": 0.7946729441005664, \"recall\": 0.4375758732205776, \"specificity\": 0.9999731250611228, \"npv\": 0.9998663238528038, \"accuracy\": 0.999839472793192, \"f1\": 0.5643822944712125, \"f2\": 0.48078535817977813, \"f0_5\": 0.6831688152127128, \"p4\": 0.7215192219492401, \"phi\": 0.5896184026881052}, {\"truth_threshold\": -6.419999856501818, \"match_probability\": 0.0115436977167649, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133006.0, \"tn\": 1278703483.0, \"fp\": 34309.0, \"fn\": 170955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375758732205776, \"tn_rate\": 0.9999731696363284, \"fp_rate\": 2.683036367161658e-05, \"fn_rate\": 0.5624241267794223, \"precision\": 0.7949436691270956, \"recall\": 0.4375758732205776, \"specificity\": 0.9999731696363284, \"npv\": 0.9998663238587618, \"accuracy\": 0.9998395173578043, \"f1\": 0.5644505555131176, \"f2\": 0.48080517135050993, \"f0_5\": 0.6833288636393995, \"p4\": 0.7215750070469463, \"phi\": 0.5897188751295536}, {\"truth_threshold\": -6.3999998569488525, \"match_probability\": 0.011702955866864343, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133006.0, \"tn\": 1278703495.0, \"fp\": 34297.0, \"fn\": 170955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375758732205776, \"tn_rate\": 0.9999731790205822, \"fp_rate\": 2.6820979417803896e-05, \"fn_rate\": 0.5624241267794223, \"precision\": 0.7950006873755999, \"recall\": 0.4375758732205776, \"specificity\": 0.9999731790205822, \"npv\": 0.9998663238600162, \"accuracy\": 0.999839526739828, \"f1\": 0.5644649283628709, \"f2\": 0.4808093427524334, \"f0_5\": 0.6833625676010329, \"p4\": 0.721586752377241, \"phi\": 0.5897400337639519}, {\"truth_threshold\": -6.379999857395887, \"match_probability\": 0.011864384788101447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133006.0, \"tn\": 1278703520.0, \"fp\": 34272.0, \"fn\": 170955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375758732205776, \"tn_rate\": 0.999973198571111, \"fp_rate\": 2.680142888902747e-05, \"fn_rate\": 0.5624241267794223, \"precision\": 0.7951195016678823, \"recall\": 0.4375758732205776, \"specificity\": 0.999973198571111, \"npv\": 0.9998663238626293, \"accuracy\": 0.9998395462857107, \"f1\": 0.5644948741509086, \"f2\": 0.4808180334055853, \"f0_5\": 0.6834327948673943, \"p4\": 0.7216112230434808, \"phi\": 0.589784121563496}, {\"truth_threshold\": -6.359999857842922, \"match_probability\": 0.012028013336826474, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133006.0, \"tn\": 1278703523.0, \"fp\": 34269.0, \"fn\": 170955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375758732205776, \"tn_rate\": 0.9999732009171745, \"fp_rate\": 2.67990828255743e-05, \"fn_rate\": 0.5624241267794223, \"precision\": 0.7951337617695412, \"recall\": 0.4375758732205776, \"specificity\": 0.9999732009171745, \"npv\": 0.9998663238629428, \"accuracy\": 0.9998395486312166, \"f1\": 0.564498467858992, \"f2\": 0.4808190763050757, \"f0_5\": 0.6834412231093426, \"p4\": 0.7216141596349628, \"phi\": 0.5897894127635109}, {\"truth_threshold\": -6.339999858289957, \"match_probability\": 0.012193870732645717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133006.0, \"tn\": 1278703532.0, \"fp\": 34260.0, \"fn\": 170955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375758732205776, \"tn_rate\": 0.9999732079553648, \"fp_rate\": 2.6792044635214785e-05, \"fn_rate\": 0.5624241267794223, \"precision\": 0.7951765451436634, \"recall\": 0.4375758732205776, \"specificity\": 0.9999732079553648, \"npv\": 0.9998663238638836, \"accuracy\": 0.9998395556677343, \"f1\": 0.5645092492577887, \"f2\": 0.48082220503069173, \"f0_5\": 0.6834665090825004, \"p4\": 0.7216229695528156, \"phi\": 0.5898052872175167}, {\"truth_threshold\": -6.319999858736992, \"match_probability\": 0.01236198656242589, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133006.0, \"tn\": 1278703536.0, \"fp\": 34256.0, \"fn\": 170955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375758732205776, \"tn_rate\": 0.9999732110834494, \"fp_rate\": 2.6788916550610556e-05, \"fn_rate\": 0.5624241267794223, \"precision\": 0.7951955614544846, \"recall\": 0.4375758732205776, \"specificity\": 0.9999732110834494, \"npv\": 0.9998663238643017, \"accuracy\": 0.9998395587950756, \"f1\": 0.5645140411227805, \"f2\": 0.48082359558847987, \"f0_5\": 0.6834777478933906, \"p4\": 0.7216268851409106, \"phi\": 0.5898123429416073}, {\"truth_threshold\": -6.299999859184027, \"match_probability\": 0.012532390784326317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133004.0, \"tn\": 1278704657.0, \"fp\": 33135.0, \"fn\": 170957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43756929342909123, \"tn_rate\": 0.9999740877291597, \"fp_rate\": 2.5912270840275597e-05, \"fn_rate\": 0.5624307065709088, \"precision\": 0.800558568427642, \"recall\": 0.43756929342909123, \"specificity\": 0.9999740877291597, \"npv\": 0.999866322417811, \"accuracy\": 0.9998404336687826, \"f1\": 0.5658540736013614, \"f2\": 0.48120707707692495, \"f0_5\": 0.6866374054353201, \"p4\": 0.7227209291012705, \"phi\": 0.5917944010412259}, {\"truth_threshold\": -6.2799998596310616, \"match_probability\": 0.012705113731858605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133001.0, \"tn\": 1278704666.0, \"fp\": 33126.0, \"fn\": 170960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43755942374186163, \"tn_rate\": 0.9999740947673501, \"fp_rate\": 2.5905232649916083e-05, \"fn_rate\": 0.5624405762581384, \"precision\": 0.8005983374165548, \"recall\": 0.43755942374186163, \"specificity\": 0.9999740947673501, \"npv\": 0.9998663200732547, \"accuracy\": 0.9998404383597945, \"f1\": 0.5658557546672113, \"f2\": 0.48120040145560217, \"f0_5\": 0.6866559487190607, \"p4\": 0.7227223008693977, \"phi\": 0.5918024315882686}, {\"truth_threshold\": -6.259999860078096, \"match_probability\": 0.012880186117973461, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132987.0, \"tn\": 1278704788.0, \"fp\": 33004.0, \"fn\": 170974.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375133652014568, \"tn_rate\": 0.9999741901739305, \"fp_rate\": 2.5809826069487123e-05, \"fn_rate\": 0.5624866347985432, \"precision\": 0.8011699429487141, \"recall\": 0.4375133652014568, \"specificity\": 0.9999741901739305, \"npv\": 0.9998663091403557, \"accuracy\": 0.9998405227980075, \"f1\": 0.5659599278224159, \"f2\": 0.48119710385103864, \"f0_5\": 0.6869695482604541, \"p4\": 0.7228072746151051, \"phi\": 0.591982594079851}, {\"truth_threshold\": -6.239999860525131, \"match_probability\": 0.013057639039174252, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132986.0, \"tn\": 1278704831.0, \"fp\": 32961.0, \"fn\": 170975.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43751007530571356, \"tn_rate\": 0.99997422380084, \"fp_rate\": 2.577619915999167e-05, \"fn_rate\": 0.5624899246942865, \"precision\": 0.8013763430492868, \"recall\": 0.43751007530571356, \"specificity\": 0.99997422380084, \"npv\": 0.9998663083630186, \"accuracy\": 0.9998405556350903, \"f1\": 0.5660086655260178, \"f2\": 0.4812088079890519, \"f0_5\": 0.687089317581315, \"p4\": 0.7228470250698027, \"phi\": 0.5920566524982125}, {\"truth_threshold\": -6.219999860972166, \"match_probability\": 0.013237503979656957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132985.0, \"tn\": 1278704923.0, \"fp\": 32869.0, \"fn\": 170976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43750678540997034, \"tn_rate\": 0.9999742957467859, \"fp_rate\": 2.570425321409442e-05, \"fn_rate\": 0.5624932145900297, \"precision\": 0.8018196727242032, \"recall\": 0.43750678540997034, \"specificity\": 0.9999742957467859, \"npv\": 0.999866307590804, \"accuracy\": 0.9998406267821032, \"f1\": 0.5661164500920575, \"f2\": 0.4812375786894097, \"f0_5\": 0.6873483657353855, \"p4\": 0.7229349251510905, \"phi\": 0.5922182447513952}, {\"truth_threshold\": -6.199999861419201, \"match_probability\": 0.013419812815476096, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132985.0, \"tn\": 1278704985.0, \"fp\": 32807.0, \"fn\": 170976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43750678540997034, \"tn_rate\": 0.9999743442320973, \"fp_rate\": 2.565576790272888e-05, \"fn_rate\": 0.5624932145900297, \"precision\": 0.8021195232580582, \"recall\": 0.43750678540997034, \"specificity\": 0.9999743442320973, \"npv\": 0.9998663075972855, \"accuracy\": 0.9998406752558922, \"f1\": 0.5661911685502807, \"f2\": 0.4812591739068756, \"f0_5\": 0.6875246218446557, \"p4\": 0.722995852071043, \"phi\": 0.592329019413643}, {\"truth_threshold\": -6.179999861866236, \"match_probability\": 0.013604597818736125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132985.0, \"tn\": 1278705068.0, \"fp\": 32724.0, \"fn\": 170976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43750678540997034, \"tn_rate\": 0.9999744091398528, \"fp_rate\": 2.5590860147191144e-05, \"fn_rate\": 0.5624932145900297, \"precision\": 0.8025212873169231, \"recall\": 0.43750678540997034, \"specificity\": 0.9999744091398528, \"npv\": 0.9998663076059622, \"accuracy\": 0.9998407401482226, \"f1\": 0.566291225754253, \"f2\": 0.48128808666768486, \"f0_5\": 0.68776071915821, \"p4\": 0.7230774316063584, \"phi\": 0.5924774118216014}, {\"truth_threshold\": -6.159999862313271, \"match_probability\": 0.013791891661807958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132984.0, \"tn\": 1278705096.0, \"fp\": 32696.0, \"fn\": 170977.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375034955142272, \"tn_rate\": 0.999974431036445, \"fp_rate\": 2.5568963554961548e-05, \"fn_rate\": 0.5624965044857728, \"precision\": 0.8026557218734911, \"recall\": 0.4375034955142272, \"specificity\": 0.999974431036445, \"npv\": 0.9998663068270572, \"accuracy\": 0.9998407612577758, \"f1\": 0.5663219352654474, \"f2\": 0.4812945703440548, \"f0_5\": 0.6878380768836876, \"p4\": 0.7231024680264783, \"phi\": 0.5925248291229279}, {\"truth_threshold\": -6.139999862760305, \"match_probability\": 0.01398172742157, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132978.0, \"tn\": 1278705120.0, \"fp\": 32672.0, \"fn\": 170983.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374837561397679, \"tn_rate\": 0.9999744498049526, \"fp_rate\": 2.555019504733618e-05, \"fn_rate\": 0.562516243860232, \"precision\": 0.802764865680652, \"recall\": 0.4374837561397679, \"specificity\": 0.9999744498049526, \"npv\": 0.999866302138574, \"accuracy\": 0.9998407753308113, \"f1\": 0.5663325603531434, \"f2\": 0.481283306333578, \"f0_5\": 0.6878924351385997, \"p4\": 0.7231111309560325, \"phi\": 0.5925517620508056}, {\"truth_threshold\": -6.11999986320734, \"match_probability\": 0.01417413858367327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132976.0, \"tn\": 1278705127.0, \"fp\": 32665.0, \"fn\": 170985.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43747717634828154, \"tn_rate\": 0.9999744552791007, \"fp_rate\": 2.5544720899278777e-05, \"fn_rate\": 0.5625228236517185, \"precision\": 0.8027964091016113, \"recall\": 0.43747717634828154, \"specificity\": 0.9999744552791007, \"npv\": 0.9998663005756416, \"accuracy\": 0.9998407792399878, \"f1\": 0.5663348963590444, \"f2\": 0.4812792031762922, \"f0_5\": 0.6879077106127622, \"p4\": 0.7231130356574883, \"phi\": 0.5925589523370398}, {\"truth_threshold\": -6.099999863654375, \"match_probability\": 0.014369159046830017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132974.0, \"tn\": 1278705145.0, \"fp\": 32647.0, \"fn\": 170987.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374705965567951, \"tn_rate\": 0.9999744693554814, \"fp_rate\": 2.5530644518559753e-05, \"fn_rate\": 0.5625294034432049, \"precision\": 0.8028812771327307, \"recall\": 0.4374705965567951, \"specificity\": 0.9999744693554814, \"npv\": 0.9998662990138595, \"accuracy\": 0.9998407917493527, \"f1\": 0.5663504989543893, \"f2\": 0.4812789321481181, \"f0_5\": 0.6879543067634475, \"p4\": 0.7231257555699326, \"phi\": 0.5925858303725844}, {\"truth_threshold\": -6.07999986410141, \"match_probability\": 0.014566823127125275, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132974.0, \"tn\": 1278705208.0, \"fp\": 32584.0, \"fn\": 170987.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374705965567951, \"tn_rate\": 0.999974518622814, \"fp_rate\": 2.5481377186043157e-05, \"fn_rate\": 0.5625294034432049, \"precision\": 0.803186798584182, \"recall\": 0.4374705965567951, \"specificity\": 0.999974518622814, \"npv\": 0.9998662990204459, \"accuracy\": 0.9998408410049769, \"f1\": 0.5664264917926644, \"f2\": 0.4813008812785851, \"f0_5\": 0.6881337372553931, \"p4\": 0.7231877030801113, \"phi\": 0.5926986205290158}, {\"truth_threshold\": -6.059999864548445, \"match_probability\": 0.014767165562350774, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132974.0, \"tn\": 1278705215.0, \"fp\": 32577.0, \"fn\": 170987.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374705965567951, \"tn_rate\": 0.999974524096962, \"fp_rate\": 2.5475903037985758e-05, \"fn_rate\": 0.5625294034432049, \"precision\": 0.8032207597658727, \"recall\": 0.4374705965567951, \"specificity\": 0.999974524096962, \"npv\": 0.9998662990211776, \"accuracy\": 0.9998408464778241, \"f1\": 0.5664349367002335, \"f2\": 0.4813033201944411, \"f0_5\": 0.6881536797544933, \"p4\": 0.7231945867919662, \"phi\": 0.5927111567421117}, {\"truth_threshold\": -6.03999986499548, \"match_probability\": 0.014970221516360545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132969.0, \"tn\": 1278705242.0, \"fp\": 32550.0, \"fn\": 170992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374541470780791, \"tn_rate\": 0.9999745452115331, \"fp_rate\": 2.5454788466907216e-05, \"fn_rate\": 0.5625458529219209, \"precision\": 0.8033458394504558, \"recall\": 0.4374541470780791, \"specificity\": 0.9999745452115331, \"npv\": 0.9998662951148406, \"accuracy\": 0.9998408636782008, \"f1\": 0.5664522450370623, \"f2\": 0.4812963717719383, \"f0_5\": 0.6882189812605521, \"p4\": 0.7232086959169131, \"phi\": 0.5927461797886561}, {\"truth_threshold\": -6.019999865442514, \"match_probability\": 0.015176026583447584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132969.0, \"tn\": 1278705257.0, \"fp\": 32535.0, \"fn\": 170992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374541470780791, \"tn_rate\": 0.9999745569418503, \"fp_rate\": 2.5443058149641362e-05, \"fn_rate\": 0.5625458529219209, \"precision\": 0.8034186484918794, \"recall\": 0.4374541470780791, \"specificity\": 0.9999745569418503, \"npv\": 0.9998662951164089, \"accuracy\": 0.9998408754057304, \"f1\": 0.5664703439021014, \"f2\": 0.4813015981490544, \"f0_5\": 0.6882617287989259, \"p4\": 0.7232234482995696, \"phi\": 0.5927730525599959}, {\"truth_threshold\": -5.999999865889549, \"match_probability\": 0.015384616792740884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132964.0, \"tn\": 1278705277.0, \"fp\": 32515.0, \"fn\": 170997.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374376975993631, \"tn_rate\": 0.9999745725822734, \"fp_rate\": 2.542741772662022e-05, \"fn_rate\": 0.5625623024006369, \"precision\": 0.8035098109125629, \"recall\": 0.4374376975993631, \"specificity\": 0.9999745725822734, \"npv\": 0.9998662912093402, \"accuracy\": 0.99984088713326, \"f1\": 0.5664792092706203, \"f2\": 0.4812922104388329, \"f0_5\": 0.688307103285408, \"p4\": 0.7232306751188071, \"phi\": 0.5927955504546368}, {\"truth_threshold\": -5.979999866336584, \"match_probability\": 0.015596028612622095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132964.0, \"tn\": 1278705286.0, \"fp\": 32506.0, \"fn\": 170997.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374376975993631, \"tn_rate\": 0.9999745796204638, \"fp_rate\": 2.5420379536260707e-05, \"fn_rate\": 0.5625623024006369, \"precision\": 0.8035535142321871, \"recall\": 0.4374376975993631, \"specificity\": 0.9999745796204638, \"npv\": 0.9998662912102813, \"accuracy\": 0.9998408941697777, \"f1\": 0.5664900698931259, \"f2\": 0.4812953463151753, \"f0_5\": 0.6883327587045901, \"p4\": 0.7232395273470356, \"phi\": 0.5928116789184406}, {\"truth_threshold\": -5.959999866783619, \"match_probability\": 0.015810298955161086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132963.0, \"tn\": 1278705467.0, \"fp\": 32325.0, \"fn\": 170998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43743440770361985, \"tn_rate\": 0.999974721166292, \"fp_rate\": 2.527883370791938e-05, \"fn_rate\": 0.5625655922963801, \"precision\": 0.804432263685204, \"recall\": 0.43743440770361985, \"specificity\": 0.999974721166292, \"npv\": 0.9998662904473733, \"accuracy\": 0.9998410349001328, \"f1\": 0.5667055230804967, \"f2\": 0.4813551492543797, \"f0_5\": 0.6888467982505676, \"p4\": 0.7234151127720478, \"phi\": 0.5931336526571902}, {\"truth_threshold\": -5.939999867230654, \"match_probability\": 0.016027465180569564, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132958.0, \"tn\": 1278705482.0, \"fp\": 32310.0, \"fn\": 171003.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43741795822490387, \"tn_rate\": 0.9999747328966093, \"fp_rate\": 2.5267103390653522e-05, \"fn_rate\": 0.5625820417750962, \"precision\": 0.8044993586175182, \"recall\": 0.43741795822490387, \"specificity\": 0.9999747328966093, \"npv\": 0.9998662865397826, \"accuracy\": 0.9998410427184858, \"f1\": 0.5667083662774466, \"f2\": 0.4813440184431096, \"f0_5\": 0.6888779969182401, \"p4\": 0.7234174303174383, \"phi\": 0.5931472449409538}, {\"truth_threshold\": -5.919999867677689, \"match_probability\": 0.01624756510167204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132953.0, \"tn\": 1278705524.0, \"fp\": 32268.0, \"fn\": 171008.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43740150874618783, \"tn_rate\": 0.9999747657414977, \"fp_rate\": 2.5234258502309127e-05, \"fn_rate\": 0.5625984912538121, \"precision\": 0.8046979500184601, \"recall\": 0.43740150874618783, \"specificity\": 0.9999747657414977, \"npv\": 0.9998662826350152, \"accuracy\": 0.9998410716463921, \"f1\": 0.5667438222267691, \"f2\": 0.481342297429882, \"f0_5\": 0.6889863138638849, \"p4\": 0.7234463214727094, \"phi\": 0.5932093278632935}, {\"truth_threshold\": -5.899999868124723, \"match_probability\": 0.01647063698839313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132953.0, \"tn\": 1278705597.0, \"fp\": 32195.0, \"fn\": 171008.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43740150874618783, \"tn_rate\": 0.9999748228290417, \"fp_rate\": 2.517717095828196e-05, \"fn_rate\": 0.5625984912538121, \"precision\": 0.8050536488483058, \"recall\": 0.43740150874618783, \"specificity\": 0.9999748228290417, \"npv\": 0.9998662826426479, \"accuracy\": 0.9998411287203695, \"f1\": 0.5668320155869958, \"f2\": 0.48136774144962463, \"f0_5\": 0.6891948913123488, \"p4\": 0.7235181779045199, \"phi\": 0.5933404813825688}, {\"truth_threshold\": -5.879999868571758, \"match_probability\": 0.016696719572260398, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132950.0, \"tn\": 1278705619.0, \"fp\": 32173.0, \"fn\": 171011.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373916390589582, \"tn_rate\": 0.999974840033507, \"fp_rate\": 2.5159966492958708e-05, \"fn_rate\": 0.5626083609410418, \"precision\": 0.8051573675381383, \"recall\": 0.4373916390589582, \"specificity\": 0.999974840033507, \"npv\": 0.9998662802994531, \"accuracy\": 0.9998411435752402, \"f1\": 0.5668494342164729, \"f2\": 0.48136559381940336, \"f0_5\": 0.6892507981208, \"p4\": 0.7235323694218807, \"phi\": 0.5933720236419139}, {\"truth_threshold\": -5.839999869465828, \"match_probability\": 0.017158074092676785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132950.0, \"tn\": 1278705663.0, \"fp\": 32129.0, \"fn\": 171011.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373916390589582, \"tn_rate\": 0.9999748744424377, \"fp_rate\": 2.5125557562312195e-05, \"fn_rate\": 0.5626083609410418, \"precision\": 0.8053719734187874, \"recall\": 0.4373916390589582, \"specificity\": 0.9999748744424377, \"npv\": 0.9998662803040538, \"accuracy\": 0.9998411779759937, \"f1\": 0.5669026095855364, \"f2\": 0.4813809314494726, \"f0_5\": 0.6893766002922397, \"p4\": 0.7235756897198891, \"phi\": 0.5934511332609548}, {\"truth_threshold\": -5.819999869912863, \"match_probability\": 0.017393425841019813, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132949.0, \"tn\": 1278705888.0, \"fp\": 31904.0, \"fn\": 171012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437388349163215, \"tn_rate\": 0.9999750503971967, \"fp_rate\": 2.4949602803324358e-05, \"fn_rate\": 0.562611650836785, \"precision\": 0.8064700066119512, \"recall\": 0.437388349163215, \"specificity\": 0.9999750503971967, \"npv\": 0.9998662795457484, \"accuracy\": 0.9998413531071022, \"f1\": 0.5671716288336099, \"f2\": 0.48145610514109904, \"f0_5\": 0.6900183002845212, \"p4\": 0.7237948063314177, \"phi\": 0.5938534998657904}, {\"truth_threshold\": -5.799999870359898, \"match_probability\": 0.017631947919195687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132944.0, \"tn\": 1278705913.0, \"fp\": 31879.0, \"fn\": 171017.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437371899684499, \"tn_rate\": 0.9999750699477254, \"fp_rate\": 2.493005227454793e-05, \"fn_rate\": 0.562628100315501, \"precision\": 0.8065864594140381, \"recall\": 0.437371899684499, \"specificity\": 0.9999750699477254, \"npv\": 0.9998662756392048, \"accuracy\": 0.9998413687438084, \"f1\": 0.5671865933990922, \"f2\": 0.4814484593316129, \"f0_5\": 0.690078307568209, \"p4\": 0.7238069935588893, \"phi\": 0.5938852244560012}, {\"truth_threshold\": -5.7799998708069324, \"match_probability\": 0.01787368143476514, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132943.0, \"tn\": 1278705938.0, \"fp\": 31854.0, \"fn\": 171018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373686097887558, \"tn_rate\": 0.9999750894982542, \"fp_rate\": 2.4910501745771504e-05, \"fn_rate\": 0.5626313902112442, \"precision\": 0.8067076463770578, \"recall\": 0.4373686097887558, \"specificity\": 0.9999750894982542, \"npv\": 0.9998662748599874, \"accuracy\": 0.9998413875078557, \"f1\": 0.5672137862180485, \"f2\": 0.481453904382095, \"f0_5\": 0.6901476303251106, \"p4\": 0.7238291376857723, \"phi\": 0.5939276239258776}, {\"truth_threshold\": -5.759999871253967, \"match_probability\": 0.01811866798417982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132941.0, \"tn\": 1278705945.0, \"fp\": 31847.0, \"fn\": 171020.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43736202999726936, \"tn_rate\": 0.9999750949724023, \"fp_rate\": 2.4905027597714105e-05, \"fn_rate\": 0.5626379700027306, \"precision\": 0.8067395684151759, \"recall\": 0.43736202999726936, \"specificity\": 0.9999750949724023, \"npv\": 0.9998662732970564, \"accuracy\": 0.9998413914170322, \"f1\": 0.5672161433944393, \"f2\": 0.4814497998018299, \"f0_5\": 0.6901630442118423, \"p4\": 0.7238310574854067, \"phi\": 0.5939349120890014}, {\"truth_threshold\": -5.739999871701002, \"match_probability\": 0.018366949657365413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132941.0, \"tn\": 1278706891.0, \"fp\": 30901.0, \"fn\": 171020.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43736202999726936, \"tn_rate\": 0.9999758347644112, \"fp_rate\": 2.416523558881413e-05, \"fn_rate\": 0.5626379700027306, \"precision\": 0.8113975659476813, \"recall\": 0.43736202999726936, \"specificity\": 0.9999758347644112, \"npv\": 0.9998662733959754, \"accuracy\": 0.9998421310332314, \"f1\": 0.5683631785174529, \"f2\": 0.48177991224090116, \"f0_5\": 0.6928853396488588, \"p4\": 0.7247644223318089, \"phi\": 0.5956478785800532}, {\"truth_threshold\": -5.719999872148037, \"match_probability\": 0.018618569042311694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132940.0, \"tn\": 1278706910.0, \"fp\": 30882.0, \"fn\": 171021.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373587401015262, \"tn_rate\": 0.999975849622813, \"fp_rate\": 2.4150377186944046e-05, \"fn_rate\": 0.5626412598984738, \"precision\": 0.8114905201987523, \"recall\": 0.4373587401015262, \"specificity\": 0.999975849622813, \"npv\": 0.9998662726161314, \"accuracy\": 0.9998421451062669, \"f1\": 0.5683832033229083, \"f2\": 0.48178327218326755, \"f0_5\": 0.6929379128881031, \"p4\": 0.7247807049390497, \"phi\": 0.5956797714424696}, {\"truth_threshold\": -5.699999872595072, \"match_probability\": 0.01887356922966818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132939.0, \"tn\": 1278706951.0, \"fp\": 30841.0, \"fn\": 171022.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437355450205783, \"tn_rate\": 0.9999758816856803, \"fp_rate\": 2.4118314319750707e-05, \"fn_rate\": 0.5626445497942171, \"precision\": 0.8116925143485163, \"recall\": 0.437355450205783, \"specificity\": 0.9999758816856803, \"npv\": 0.9998662718385877, \"accuracy\": 0.9998421763796791, \"f1\": 0.5684299644461358, \"f2\": 0.4817943149727752, \"f0_5\": 0.693054079895233, \"p4\": 0.7248187256038102, \"phi\": 0.5957516973298737}, {\"truth_threshold\": -5.679999873042107, \"match_probability\": 0.01913199381734419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132938.0, \"tn\": 1278706956.0, \"fp\": 30836.0, \"fn\": 171023.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43735216031003976, \"tn_rate\": 0.999975885595786, \"fp_rate\": 2.4114404213995422e-05, \"fn_rate\": 0.5626478396899602, \"precision\": 0.8117161454199079, \"recall\": 0.43735216031003976, \"specificity\": 0.999975885595786, \"npv\": 0.9998662710572797, \"accuracy\": 0.9998421795070204, \"f1\": 0.5684329802131549, \"f2\": 0.4817927861190561, \"f0_5\": 0.69306620982903, \"p4\": 0.7248211777402211, \"phi\": 0.5957581323737818}, {\"truth_threshold\": -5.6599998734891415, \"match_probability\": 0.0193938869151118, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132937.0, \"tn\": 1278706988.0, \"fp\": 30804.0, \"fn\": 171024.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373488704142966, \"tn_rate\": 0.9999759106204629, \"fp_rate\": 2.4089379537161596e-05, \"fn_rate\": 0.5626511295857034, \"precision\": 0.8118736296956779, \"recall\": 0.4373488704142966, \"specificity\": 0.9999759106204629, \"npv\": 0.9998662702787949, \"accuracy\": 0.9998422037439149, \"f1\": 0.5684688113371335, \"f2\": 0.481800686438313, \"f0_5\": 0.6931563990927341, \"p4\": 0.7248503098011553, \"phi\": 0.5958137074736648}, {\"truth_threshold\": -5.639999873936176, \"match_probability\": 0.019659293149210413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132937.0, \"tn\": 1278708778.0, \"fp\": 29014.0, \"fn\": 171024.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373488704142966, \"tn_rate\": 0.9999773104383233, \"fp_rate\": 2.2689561676769462e-05, \"fn_rate\": 0.5626511295857034, \"precision\": 0.8208470463288279, \"recall\": 0.4373488704142966, \"specificity\": 0.9999773104383233, \"npv\": 0.9998662704659714, \"accuracy\": 0.9998436032291121, \"f1\": 0.5706528271433232, \"f2\": 0.4824266309574356, \"f0_5\": 0.6983709213934112, \"p4\": 0.7266234785815561, \"phi\": 0.5990988402665756}, {\"truth_threshold\": -5.619999874383211, \"match_probability\": 0.019928257666951374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132937.0, \"tn\": 1278708785.0, \"fp\": 29007.0, \"fn\": 171024.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373488704142966, \"tn_rate\": 0.9999773159124713, \"fp_rate\": 2.2684087528712063e-05, \"fn_rate\": 0.5626511295857034, \"precision\": 0.8208825272933854, \"recall\": 0.4373488704142966, \"specificity\": 0.9999773159124713, \"npv\": 0.9998662704667034, \"accuracy\": 0.9998436087019592, \"f1\": 0.570661400929374, \"f2\": 0.4824290819777789, \"f0_5\": 0.6983914673906763, \"p4\": 0.7266304297904134, \"phi\": 0.5991117939556017}, {\"truth_threshold\": -5.599999874830246, \"match_probability\": 0.0202008261413212, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132935.0, \"tn\": 1278708806.0, \"fp\": 28986.0, \"fn\": 171026.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43734229062281016, \"tn_rate\": 0.9999773323349155, \"fp_rate\": 2.2667665084539866e-05, \"fn_rate\": 0.5626577093771898, \"precision\": 0.8209867775026093, \"recall\": 0.43734229062281016, \"specificity\": 0.9999773323349155, \"npv\": 0.9998662689052399, \"accuracy\": 0.9998436235568301, \"f1\": 0.5706809878896373, \"f2\": 0.4824298773738627, \"f0_5\": 0.6984484760598753, \"p4\": 0.7266463099714878, \"phi\": 0.5991453452700614}, {\"truth_threshold\": -5.579999875277281, \"match_probability\": 0.020477044775581793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132933.0, \"tn\": 1278708817.0, \"fp\": 28975.0, \"fn\": 171028.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373357108313238, \"tn_rate\": 0.9999773409371481, \"fp_rate\": 2.2659062851878237e-05, \"fn_rate\": 0.5626642891686763, \"precision\": 0.8210403438990044, \"recall\": 0.4373357108313238, \"specificity\": 0.9999773409371481, \"npv\": 0.9998662673427307, \"accuracy\": 0.9998436305933478, \"f1\": 0.5706883265467331, \"f2\": 0.48242717121804213, \"f0_5\": 0.6984761342296549, \"p4\": 0.7266522598999173, \"phi\": 0.5991603920312472}, {\"truth_threshold\": -5.559999875724316, \"match_probability\": 0.02075696030786607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132931.0, \"tn\": 1278708836.0, \"fp\": 28956.0, \"fn\": 171030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43732913103983734, \"tn_rate\": 0.99997735579555, \"fp_rate\": 2.2644204450008154e-05, \"fn_rate\": 0.5626708689601626, \"precision\": 0.8211344950490157, \"recall\": 0.43732913103983734, \"specificity\": 0.99997735579555, \"npv\": 0.9998662657810581, \"accuracy\": 0.999843643884548, \"f1\": 0.5707054661606361, \"f2\": 0.4824272662805729, \"f0_5\": 0.6985272866572991, \"p4\": 0.7266661554723947, \"phi\": 0.5991902522636525}, {\"truth_threshold\": -5.5399998761713505, \"match_probability\": 0.02104062001576727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132929.0, \"tn\": 1278708867.0, \"fp\": 28925.0, \"fn\": 171032.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43732255124835095, \"tn_rate\": 0.9999773800382057, \"fp_rate\": 2.2619961794325384e-05, \"fn_rate\": 0.562677448751649, \"precision\": 0.8212895572553042, \"recall\": 0.43732255124835095, \"specificity\": 0.9999773800382057, \"npv\": 0.9998662642206405, \"accuracy\": 0.9998436665577719, \"f1\": 0.5707373098762384, \"f2\": 0.4824315633760084, \"f0_5\": 0.6986136936251349, \"p4\": 0.7266919710067753, \"phi\": 0.5992423418843053}, {\"truth_threshold\": -5.519999876618385, \"match_probability\": 0.021328071720920265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132929.0, \"tn\": 1278709298.0, \"fp\": 28494.0, \"fn\": 171032.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43732255124835095, \"tn_rate\": 0.9999777170893218, \"fp_rate\": 2.2282910678219793e-05, \"fn_rate\": 0.562677448751649, \"precision\": 0.8234824033749837, \"recall\": 0.43732255124835095, \"specificity\": 0.9999777170893218, \"npv\": 0.9998662642657112, \"accuracy\": 0.9998440035287887, \"f1\": 0.5712658793598405, \"f2\": 0.482582534831663, \"f0_5\": 0.6998819568831984, \"p4\": 0.7271203215653462, \"phi\": 0.6000421595977579}, {\"truth_threshold\": -5.49999987706542, \"match_probability\": 0.021619363793573064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132929.0, \"tn\": 1278709340.0, \"fp\": 28452.0, \"fn\": 171032.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43732255124835095, \"tn_rate\": 0.9999777499342101, \"fp_rate\": 2.2250065789875398e-05, \"fn_rate\": 0.562677448751649, \"precision\": 0.8236967177053061, \"recall\": 0.43732255124835095, \"specificity\": 0.9999777499342101, \"npv\": 0.9998662642701033, \"accuracy\": 0.9998440363658715, \"f1\": 0.5713174396465396, \"f2\": 0.4825972517199441, \"f0_5\": 0.7000057926138907, \"p4\": 0.7271620903871825, \"phi\": 0.6001202713295516}, {\"truth_threshold\": -5.479999877512455, \"match_probability\": 0.021914545157146633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132929.0, \"tn\": 1278709352.0, \"fp\": 28440.0, \"fn\": 171032.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43732255124835095, \"tn_rate\": 0.9999777593184639, \"fp_rate\": 2.224068153606271e-05, \"fn_rate\": 0.562677448751649, \"precision\": 0.8237579708618136, \"recall\": 0.43732255124835095, \"specificity\": 0.9999777593184639, \"npv\": 0.9998662642713582, \"accuracy\": 0.9998440457478951, \"f1\": 0.5713321728665678, \"f2\": 0.48260145671003685, \"f0_5\": 0.7000411823006687, \"p4\": 0.7271740252176961, \"phi\": 0.6001425945674006}, {\"truth_threshold\": -5.45999987795949, \"match_probability\": 0.022213665292781185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132921.0, \"tn\": 1278709362.0, \"fp\": 28430.0, \"fn\": 171040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372962320824053, \"tn_rate\": 0.9999777671386755, \"fp_rate\": 2.223286132455214e-05, \"fn_rate\": 0.5627037679175947, \"precision\": 0.8238002863322818, \"recall\": 0.4372962320824053, \"specificity\": 0.9999777671386755, \"npv\": 0.9998662580177688, \"accuracy\": 0.9998440473115657, \"f1\": 0.571319888590881, \"f2\": 0.48257871978913663, \"f0_5\": 0.7000521401147083, \"p4\": 0.7271640754423316, \"phi\": 0.6001399535712936}, {\"truth_threshold\": -5.439999878406525, \"match_probability\": 0.022516774243866916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132921.0, \"tn\": 1278709375.0, \"fp\": 28417.0, \"fn\": 171040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372962320824053, \"tn_rate\": 0.9999777773049504, \"fp_rate\": 2.2222695049588398e-05, \"fn_rate\": 0.5627037679175947, \"precision\": 0.8238666650138219, \"recall\": 0.4372962320824053, \"specificity\": 0.9999777773049504, \"npv\": 0.9998662580191284, \"accuracy\": 0.9998440574754247, \"f1\": 0.5713358507110482, \"f2\": 0.48258327512267807, \"f0_5\": 0.7000904864886502, \"p4\": 0.7271770057084394, \"phi\": 0.600164142480192}, {\"truth_threshold\": -5.4199998788535595, \"match_probability\": 0.022823922620557144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132919.0, \"tn\": 1278709441.0, \"fp\": 28351.0, \"fn\": 171042.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372896522909189, \"tn_rate\": 0.9999778289183464, \"fp_rate\": 2.2171081653618632e-05, \"fn_rate\": 0.5627103477090811, \"precision\": 0.8242016494078254, \"recall\": 0.4372896522909189, \"specificity\": 0.9999778289183464, \"npv\": 0.9998662564623718, \"accuracy\": 0.9998441075128843, \"f1\": 0.5714107615356673, \"f2\": 0.48259984285977775, \"f0_5\": 0.7002805990468273, \"p4\": 0.7272376847305866, \"phi\": 0.6002816818338329}, {\"truth_threshold\": -5.399999879300594, \"match_probability\": 0.023135161604261833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132914.0, \"tn\": 1278709452.0, \"fp\": 28340.0, \"fn\": 171047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372732028122029, \"tn_rate\": 0.999977837520579, \"fp_rate\": 2.2162479420957007e-05, \"fn_rate\": 0.5627267971877972, \"precision\": 0.8242524216453545, \"recall\": 0.4372732028122029, \"specificity\": 0.999977837520579, \"npv\": 0.9998662525543757, \"accuracy\": 0.9998441122038961, \"f1\": 0.5714089184570574, \"f2\": 0.482587295893248, \"f0_5\": 0.7003014825438341, \"p4\": 0.7272361926588604, \"phi\": 0.6002888868299204}, {\"truth_threshold\": -5.379999879747629, \"match_probability\": 0.02345054295211926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132914.0, \"tn\": 1278709590.0, \"fp\": 28202.0, \"fn\": 171047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372732028122029, \"tn_rate\": 0.9999779454394979, \"fp_rate\": 2.205456050211113e-05, \"fn_rate\": 0.5627267971877972, \"precision\": 0.8249584150549915, \"recall\": 0.4372732028122029, \"specificity\": 0.9999779454394979, \"npv\": 0.9998662525688079, \"accuracy\": 0.9998442200971683, \"f1\": 0.5715784698017747, \"f2\": 0.4826356611666279, \"f0_5\": 0.7007090703007618, \"p4\": 0.7273735103457359, \"phi\": 0.6005460290642457}, {\"truth_threshold\": -5.359999880194664, \"match_probability\": 0.023770119001443636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132913.0, \"tn\": 1278709608.0, \"fp\": 28184.0, \"fn\": 171048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43726991291645967, \"tn_rate\": 0.9999779595158786, \"fp_rate\": 2.2040484121392106e-05, \"fn_rate\": 0.5627300870835403, \"precision\": 0.825049504335897, \"recall\": 0.43726991291645967, \"specificity\": 0.9999779595158786, \"npv\": 0.9998662517888612, \"accuracy\": 0.9998442333883685, \"f1\": 0.5715975211694025, \"f2\": 0.4826386896751567, \"f0_5\": 0.7007599522960429, \"p4\": 0.727388938133279, \"phi\": 0.6005769387026646}, {\"truth_threshold\": -5.339999880641699, \"match_probability\": 0.024093942674146367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132913.0, \"tn\": 1278709621.0, \"fp\": 28171.0, \"fn\": 171048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43726991291645967, \"tn_rate\": 0.9999779696821536, \"fp_rate\": 2.2030317846428364e-05, \"fn_rate\": 0.5627300870835403, \"precision\": 0.8251160885004097, \"recall\": 0.43726991291645967, \"specificity\": 0.9999779696821536, \"npv\": 0.9998662517902208, \"accuracy\": 0.9998442435522275, \"f1\": 0.5716134997688396, \"f2\": 0.48264324641520834, \"f0_5\": 0.7007983785670523, \"p4\": 0.727401877176292, \"phi\": 0.6006011833765622}, {\"truth_threshold\": -5.319999881088734, \"match_probability\": 0.024422067481128608, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132913.0, \"tn\": 1278709650.0, \"fp\": 28142.0, \"fn\": 171048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43726991291645967, \"tn_rate\": 0.9999779923607669, \"fp_rate\": 2.2007639233047708e-05, \"fn_rate\": 0.5627300870835403, \"precision\": 0.8252646611406041, \"recall\": 0.43726991291645967, \"specificity\": 0.9999779923607669, \"npv\": 0.9998662517932536, \"accuracy\": 0.9998442662254513, \"f1\": 0.5716491475562131, \"f2\": 0.4826534117607755, \"f0_5\": 0.7008841138980848, \"p4\": 0.7274307428542027, \"phi\": 0.6006552782252188}, {\"truth_threshold\": -5.2999998815357685, \"match_probability\": 0.024754547526642672, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132913.0, \"tn\": 1278709738.0, \"fp\": 28054.0, \"fn\": 171048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43726991291645967, \"tn_rate\": 0.9999780611786282, \"fp_rate\": 2.1938821371754688e-05, \"fn_rate\": 0.5627300870835403, \"precision\": 0.8257158299527232, \"recall\": 0.43726991291645967, \"specificity\": 0.9999780611786282, \"npv\": 0.9998662518024569, \"accuracy\": 0.9998443350269582, \"f1\": 0.5717573473742171, \"f2\": 0.4826842609479442, \"f0_5\": 0.7011444047396735, \"p4\": 0.7275183492814956, \"phi\": 0.6008195175730044}, {\"truth_threshold\": -5.279999881982803, \"match_probability\": 0.02509143751261976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132911.0, \"tn\": 1278709817.0, \"fp\": 27975.0, \"fn\": 171050.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372633331249733, \"tn_rate\": 0.9999781229582991, \"fp_rate\": 2.187704170082118e-05, \"fn_rate\": 0.5627366668750268, \"precision\": 0.8261191153984809, \"recall\": 0.4372633331249733, \"specificity\": 0.9999781229582991, \"npv\": 0.9998662502470608, \"accuracy\": 0.9998443952282768, \"f1\": 0.5718483716147463, \"f2\": 0.4827053961197911, \"f0_5\": 0.7013736075271371, \"p4\": 0.7275920400846185, \"phi\": 0.6009617658206975}, {\"truth_threshold\": -5.259999882429838, \"match_probability\": 0.025432792742961483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132908.0, \"tn\": 1278709841.0, \"fp\": 27951.0, \"fn\": 171053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372534634377437, \"tn_rate\": 0.9999781417268068, \"fp_rate\": 2.185827319319581e-05, \"fn_rate\": 0.5627465365622564, \"precision\": 0.8262391286779105, \"recall\": 0.4372534634377437, \"specificity\": 0.9999781417268068, \"npv\": 0.9998662479040835, \"accuracy\": 0.9998444116468183, \"f1\": 0.5718686803493825, \"f2\": 0.48270396737713217, \"f0_5\": 0.7014377288507352, \"p4\": 0.7276084807273074, \"phi\": 0.6009986521099783}, {\"truth_threshold\": -5.239999882876873, \"match_probability\": 0.02577866912779244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132908.0, \"tn\": 1278709888.0, \"fp\": 27904.0, \"fn\": 171053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372534634377437, \"tn_rate\": 0.9999781784818009, \"fp_rate\": 2.1821518199096128e-05, \"fn_rate\": 0.5627465365622564, \"precision\": 0.826480610899684, \"recall\": 0.4372534634377437, \"specificity\": 0.9999781784818009, \"npv\": 0.999866247908999, \"accuracy\": 0.9998444483930776, \"f1\": 0.5719265103609719, \"f2\": 0.4827204472286468, \"f0_5\": 0.701576948698756, \"p4\": 0.7276552925265207, \"phi\": 0.6010865111379381}, {\"truth_threshold\": -5.219999883323908, \"match_probability\": 0.02612912318767124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132908.0, \"tn\": 1278709936.0, \"fp\": 27856.0, \"fn\": 171053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372534634377437, \"tn_rate\": 0.9999782160188162, \"fp_rate\": 2.178398118384539e-05, \"fn_rate\": 0.5627465365622564, \"precision\": 0.8267273767758951, \"recall\": 0.4372534634377437, \"specificity\": 0.9999782160188162, \"npv\": 0.9998662479140191, \"accuracy\": 0.9998444859211723, \"f1\": 0.5719855828715907, \"f2\": 0.48273727887677537, \"f0_5\": 0.7017191877231349, \"p4\": 0.7277031065388868, \"phi\": 0.6011762792652887}, {\"truth_threshold\": -5.199999883770943, \"match_probability\": 0.02648421205775701, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132904.0, \"tn\": 1278710198.0, \"fp\": 27594.0, \"fn\": 171057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43724030385477086, \"tn_rate\": 0.9999784209083578, \"fp_rate\": 2.157909164226844e-05, \"fn_rate\": 0.5627596961452291, \"precision\": 0.8280726239579309, \"recall\": 0.43724030385477086, \"specificity\": 0.9999784209083578, \"npv\": 0.9998662448141051, \"accuracy\": 0.9998446876346812, \"f1\": 0.5722959400076217, \"f2\": 0.48281604426806707, \"f0_5\": 0.7024873328801748, \"p4\": 0.727954255002826, \"phi\": 0.6016563607129378}, {\"truth_threshold\": -5.1799998842179775, \"match_probability\": 0.026843993491928626, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132904.0, \"tn\": 1278710209.0, \"fp\": 27583.0, \"fn\": 171057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43724030385477086, \"tn_rate\": 0.9999784295105903, \"fp_rate\": 2.1570489409606813e-05, \"fn_rate\": 0.5627596961452291, \"precision\": 0.8281293811959847, \"recall\": 0.43724030385477086, \"specificity\": 0.9999784295105903, \"npv\": 0.9998662448152555, \"accuracy\": 0.9998446962348695, \"f1\": 0.5723094942813834, \"f2\": 0.48281990306110956, \"f0_5\": 0.7025200098529563, \"p4\": 0.7279652211609894, \"phi\": 0.6016769887877497}, {\"truth_threshold\": -5.159999884665012, \"match_probability\": 0.02720852586685368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132872.0, \"tn\": 1278720500.0, \"fp\": 17292.0, \"fn\": 171089.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4371350271909883, \"tn_rate\": 0.9999864772902559, \"fp_rate\": 1.3522709744078637e-05, \"fn_rate\": 0.5628649728090117, \"precision\": 0.8848459018140167, \"recall\": 0.4371350271909883, \"specificity\": 0.9999864772902559, \"npv\": 0.9998662208732377, \"accuracy\": 0.9998527170832711, \"f1\": 0.585178089733003, \"f2\": 0.48635147085522196, \"f0_5\": 0.7344102531789697, \"p4\": 0.7382920339126459, \"phi\": 0.6218735354570476}, {\"truth_threshold\": -5.139999885112047, \"match_probability\": 0.027577868186004006, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132865.0, \"tn\": 1278720610.0, \"fp\": 17182.0, \"fn\": 171096.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43711199792078587, \"tn_rate\": 0.9999865633125825, \"fp_rate\": 1.3436687417462359e-05, \"fn_rate\": 0.5628880020792141, \"precision\": 0.8854892133798077, \"recall\": 0.43711199792078587, \"specificity\": 0.9999865633125825, \"npv\": 0.9998662154119874, \"accuracy\": 0.9998527976123075, \"f1\": 0.5852980564219132, \"f2\": 0.48636750663120265, \"f0_5\": 0.7347516836273668, \"p4\": 0.7383875173419433, \"phi\": 0.622083261392754}, {\"truth_threshold\": -5.119999885559082, \"match_probability\": 0.027952080083614855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132862.0, \"tn\": 1278720611.0, \"fp\": 17181.0, \"fn\": 171099.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43710212823355626, \"tn_rate\": 0.9999865640946037, \"fp_rate\": 1.3435905396311303e-05, \"fn_rate\": 0.5628978717664437, \"precision\": 0.8854928253900548, \"recall\": 0.43710212823355626, \"specificity\": 0.9999865640946037, \"npv\": 0.9998662130666247, \"accuracy\": 0.9998527960486369, \"f1\": 0.5852899974449565, \"f2\": 0.4863579490836358, \"f0_5\": 0.7347480956894616, \"p4\": 0.7383811040488173, \"phi\": 0.622077506714354}, {\"truth_threshold\": -5.099999886006117, \"match_probability\": 0.028331221828584288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132861.0, \"tn\": 1278720617.0, \"fp\": 17175.0, \"fn\": 171100.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370988383378131, \"tn_rate\": 0.9999865687867306, \"fp_rate\": 1.343121326940496e-05, \"fn_rate\": 0.562901161662187, \"precision\": 0.8855274734063825, \"recall\": 0.4370988383378131, \"specificity\": 0.9999865687867306, \"npv\": 0.9998662122854299, \"accuracy\": 0.9998527999578134, \"f1\": 0.5852946164842499, \"f2\": 0.48635678097636686, \"f0_5\": 0.7347653203997323, \"p4\": 0.7383847802757949, \"phi\": 0.6220873407939644}, {\"truth_threshold\": -5.079999886453152, \"match_probability\": 0.02871535432830961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132855.0, \"tn\": 1278720622.0, \"fp\": 17170.0, \"fn\": 171106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43707909896335384, \"tn_rate\": 0.9999865726968363, \"fp_rate\": 1.3427303163649675e-05, \"fn_rate\": 0.5629209010366462, \"precision\": 0.8855524079320113, \"recall\": 0.43707909896335384, \"specificity\": 0.9999865726968363, \"npv\": 0.9998662075950185, \"accuracy\": 0.9998527991759781, \"f1\": 0.5852823655355011, \"f2\": 0.4863387338024364, \"f0_5\": 0.7347678972989654, \"p4\": 0.7383750311821459, \"phi\": 0.6220820539894694}, {\"truth_threshold\": -5.0599998869001865, \"match_probability\": 0.029104539132457422, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132855.0, \"tn\": 1278720631.0, \"fp\": 17161.0, \"fn\": 171106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43707909896335384, \"tn_rate\": 0.9999865797350267, \"fp_rate\": 1.3420264973290161e-05, \"fn_rate\": 0.5629209010366462, \"precision\": 0.8856055354095563, \"recall\": 0.43707909896335384, \"specificity\": 0.9999865797350267, \"npv\": 0.9998662075959601, \"accuracy\": 0.9998528062124958, \"f1\": 0.5852939686371776, \"f2\": 0.4863419384124288, \"f0_5\": 0.7347971571582644, \"p4\": 0.7383842655926429, \"phi\": 0.622100722009663}, {\"truth_threshold\": -5.039999887347221, \"match_probability\": 0.029498838436663805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132850.0, \"tn\": 1278723022.0, \"fp\": 14770.0, \"fn\": 171111.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43706264948463786, \"tn_rate\": 0.9999884495475989, \"fp_rate\": 1.1550452401112738e-05, \"fn_rate\": 0.5629373505153622, \"precision\": 0.8999458068012465, \"recall\": 0.43706264948463786, \"specificity\": 0.9999884495475989, \"npv\": 0.9998662039369915, \"accuracy\": 0.9998546716715353, \"f1\": 0.5883772789377764, \"f2\": 0.4871782459969607, \"f0_5\": 0.7426426114187521, \"p4\": 0.7408333599560234, \"phi\": 0.6271075092960965}, {\"truth_threshold\": -5.019999887794256, \"match_probability\": 0.029898315086161076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132848.0, \"tn\": 1278723044.0, \"fp\": 14748.0, \"fn\": 171113.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370560696931514, \"tn_rate\": 0.9999884667520642, \"fp_rate\": 1.1533247935789481e-05, \"fn_rate\": 0.5629439303068485, \"precision\": 0.9000785929157972, \"recall\": 0.4370560696931514, \"specificity\": 0.9999884667520642, \"npv\": 0.9998662023756514, \"accuracy\": 0.9998546873082415, \"f1\": 0.5883996926190935, \"f2\": 0.48717948717948717, \"f0_5\": 0.7427111461460622, \"p4\": 0.7408511287850466, \"phi\": 0.6271490699063784}, {\"truth_threshold\": -4.999999888241291, \"match_probability\": 0.03030303257932744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132846.0, \"tn\": 1278723057.0, \"fp\": 14735.0, \"fn\": 171115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43704948990166503, \"tn_rate\": 0.9999884769183391, \"fp_rate\": 1.152308166082574e-05, \"fn_rate\": 0.562950510098335, \"precision\": 0.9001565242138215, \"recall\": 0.43704948990166503, \"specificity\": 0.9999884769183391, \"npv\": 0.9998662008133695, \"accuracy\": 0.9998546959084298, \"f1\": 0.5884103804297275, \"f2\": 0.48717751251443975, \"f0_5\": 0.7427497945285899, \"p4\": 0.7408596017101948, \"phi\": 0.6271715091086993}, {\"truth_threshold\": -4.979999888688326, \"match_probability\": 0.0307130550711558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132845.0, \"tn\": 1278723081.0, \"fp\": 14711.0, \"fn\": 171116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370462000059218, \"tn_rate\": 0.9999884956868468, \"fp_rate\": 1.150431315320037e-05, \"fn_rate\": 0.5629537999940782, \"precision\": 0.9003022581257285, \"recall\": 0.4370462000059218, \"specificity\": 0.9999884956868468, \"npv\": 0.9998662000340596, \"accuracy\": 0.9998547138906418, \"f1\": 0.5884385305536669, \"f2\": 0.487182778348247, \"f0_5\": 0.7428272672880891, \"p4\": 0.7408819169645482, \"phi\": 0.6272199360544048}, {\"truth_threshold\": -4.9399998895823956, \"match_probability\": 0.03154927497405991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132839.0, \"tn\": 1278723269.0, \"fp\": 14523.0, \"fn\": 171122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370264606314626, \"tn_rate\": 0.9999886427068232, \"fp_rate\": 1.1357293176801644e-05, \"fn_rate\": 0.5629735393685374, \"precision\": 0.9014467773238691, \"recall\": 0.4370264606314626, \"specificity\": 0.9999886427068232, \"npv\": 0.9998661953628039, \"accuracy\": 0.9998548561846675, \"f1\": 0.588664880805986, \"f2\": 0.4872301031538887, \"f0_5\": 0.7434388952876007, \"p4\": 0.7410613209972807, \"phi\": 0.627604478870892}, {\"truth_threshold\": -4.91999989002943, \"match_probability\": 0.031975604008205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132839.0, \"tn\": 1278723280.0, \"fp\": 14512.0, \"fn\": 171122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370264606314626, \"tn_rate\": 0.9999886513090559, \"fp_rate\": 1.1348690944140016e-05, \"fn_rate\": 0.5629735393685374, \"precision\": 0.9015140718420642, \"recall\": 0.4370264606314626, \"specificity\": 0.9999886513090559, \"npv\": 0.9998661953639547, \"accuracy\": 0.9998548647848559, \"f1\": 0.5886792285602864, \"f2\": 0.48723403474924715, \"f0_5\": 0.7434755111292697, \"p4\": 0.7410726911728981, \"phi\": 0.6276279139538113}, {\"truth_threshold\": -4.899999890476465, \"match_probability\": 0.03240750129345963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132837.0, \"tn\": 1278723289.0, \"fp\": 14503.0, \"fn\": 171124.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43701988083997617, \"tn_rate\": 0.9999886583472463, \"fp_rate\": 1.1341652753780502e-05, \"fn_rate\": 0.5629801191600238, \"precision\": 0.901567802361884, \"recall\": 0.43701988083997617, \"specificity\": 0.9999886583472463, \"npv\": 0.9998661938012549, \"accuracy\": 0.999854870257703, \"f1\": 0.5886847137498034, \"f2\": 0.4872306306412047, \"f0_5\": 0.7435009363935249, \"p4\": 0.7410770382710506, \"phi\": 0.6276418993637642}, {\"truth_threshold\": -4.8799998909235, \"match_probability\": 0.03284503431681841, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132832.0, \"tn\": 1278723317.0, \"fp\": 14475.0, \"fn\": 171129.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370034313612602, \"tn_rate\": 0.9999886802438385, \"fp_rate\": 1.1319756161550905e-05, \"fn_rate\": 0.5629965686387398, \"precision\": 0.9017358306122587, \"recall\": 0.4370034313612602, \"specificity\": 0.9999886802438385, \"npv\": 0.9998661898950807, \"accuracy\": 0.999854888239915, \"f1\": 0.5887056028789988, \"f2\": 0.4872240859596626, \"f0_5\": 0.7435828251355536, \"p4\": 0.7410935925638843, \"phi\": 0.627688593785904}, {\"truth_threshold\": -4.859999891370535, \"match_probability\": 0.0332882712407837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132830.0, \"tn\": 1278723353.0, \"fp\": 14439.0, \"fn\": 171131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43699685156977375, \"tn_rate\": 0.9999887083965999, \"fp_rate\": 1.1291603400112852e-05, \"fn_rate\": 0.5630031484302263, \"precision\": 0.9019549260197326, \"recall\": 0.43699685156977375, \"specificity\": 0.9999887083965999, \"npv\": 0.9998661883352059, \"accuracy\": 0.9998549148223154, \"f1\": 0.5887463156261773, \"f2\": 0.48723033233488344, \"f0_5\": 0.7436981894367198, \"p4\": 0.7411258543361816, \"phi\": 0.6277601489788054}, {\"truth_threshold\": -4.83999989181757, \"match_probability\": 0.033737280906155444, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132828.0, \"tn\": 1278723361.0, \"fp\": 14431.0, \"fn\": 171133.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43699027177828736, \"tn_rate\": 0.9999887146527691, \"fp_rate\": 1.1285347230904395e-05, \"fn_rate\": 0.5630097282217127, \"precision\": 0.9020025940689533, \"recall\": 0.43699027177828736, \"specificity\": 0.9999887146527691, \"npv\": 0.9998661867724016, \"accuracy\": 0.9998549195133273, \"f1\": 0.5887504986481096, \"f2\": 0.4872265705526288, \"f0_5\": 0.743720303651636, \"p4\": 0.7411291692402495, \"phi\": 0.6277720173326204}, {\"truth_threshold\": -4.819999892264605, \"match_probability\": 0.03419213283470654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132824.0, \"tn\": 1278723376.0, \"fp\": 14416.0, \"fn\": 171137.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43697711219531454, \"tn_rate\": 0.9999887263830863, \"fp_rate\": 1.127361691363854e-05, \"fn_rate\": 0.5630228878046855, \"precision\": 0.902091822874219, \"recall\": 0.43697711219531454, \"specificity\": 0.9999887263830863, \"npv\": 0.9998661836466883, \"accuracy\": 0.9998549281135156, \"f1\": 0.5887575603777474, \"f2\": 0.4872186893837797, \"f0_5\": 0.7437612061985327, \"p4\": 0.7411347654772364, \"phi\": 0.6277936258691315}, {\"truth_threshold\": -4.799999892711639, \"match_probability\": 0.034652897231739366, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132823.0, \"tn\": 1278723382.0, \"fp\": 14410.0, \"fn\": 171138.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369738222995713, \"tn_rate\": 0.9999887310752132, \"fp_rate\": 1.1268924786732196e-05, \"fn_rate\": 0.5630261777004286, \"precision\": 0.9021279196919169, \"recall\": 0.4369738222995713, \"specificity\": 0.9999887310752132, \"npv\": 0.9998661828654954, \"accuracy\": 0.9998549320226922, \"f1\": 0.5887622619095112, \"f2\": 0.4872175232947222, \"f0_5\": 0.7437789298381777, \"p4\": 0.7411384910416743, \"phi\": 0.6278038277857855}, {\"truth_threshold\": -4.779999893158674, \"match_probability\": 0.0351196449885184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132822.0, \"tn\": 1278723392.0, \"fp\": 14400.0, \"fn\": 171139.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369705324038281, \"tn_rate\": 0.9999887388954248, \"fp_rate\": 1.1261104575221627e-05, \"fn_rate\": 0.5630294675961719, \"precision\": 0.9021885316053307, \"recall\": 0.4369705324038281, \"specificity\": 0.9999887388954248, \"npv\": 0.9998661820847211, \"accuracy\": 0.9998549390592099, \"f1\": 0.5887721833491066, \"f2\": 0.48721778695969237, \"f0_5\": 0.74380998354705, \"p4\": 0.7411463527005832, \"phi\": 0.627822562804222}, {\"truth_threshold\": -4.759999893605709, \"match_probability\": 0.035592447684574355, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132821.0, \"tn\": 1278723413.0, \"fp\": 14379.0, \"fn\": 171140.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43696724250808494, \"tn_rate\": 0.9999887553178689, \"fp_rate\": 1.1244682131049428e-05, \"fn_rate\": 0.5630327574919151, \"precision\": 0.9023165760869565, \"recall\": 0.43696724250808494, \"specificity\": 0.9999887553178689, \"npv\": 0.9998661813050977, \"accuracy\": 0.999854954695916, \"f1\": 0.5887964606869831, \"f2\": 0.4872219825625585, \"f0_5\": 0.7438777007508168, \"p4\": 0.7411655892121632, \"phi\": 0.6278647680652383}, {\"truth_threshold\": -4.739999894052744, \"match_probability\": 0.0360713775898747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132820.0, \"tn\": 1278723438.0, \"fp\": 14354.0, \"fn\": 171141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369639526123417, \"tn_rate\": 0.9999887748683978, \"fp_rate\": 1.1225131602273e-05, \"fn_rate\": 0.5630360473876583, \"precision\": 0.9024691861334203, \"recall\": 0.4369639526123417, \"specificity\": 0.9999887748683978, \"npv\": 0.999866180525893, \"accuracy\": 0.9998549734599633, \"f1\": 0.5888259611867844, \"f2\": 0.4872276081460406, \"f0_5\": 0.7439587657969411, \"p4\": 0.7411889635507923, \"phi\": 0.627915519448373}, {\"truth_threshold\": -4.719999894499779, \"match_probability\": 0.03655650766685558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132819.0, \"tn\": 1278723465.0, \"fp\": 14327.0, \"fn\": 171142.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369606627165985, \"tn_rate\": 0.9999887959829689, \"fp_rate\": 1.1204017031194461e-05, \"fn_rate\": 0.5630393372834015, \"precision\": 0.9026341184945564, \"recall\": 0.4369606627165985, \"specificity\": 0.9999887959829689, \"npv\": 0.9998661797468976, \"accuracy\": 0.9998549937876813, \"f1\": 0.5888580758001982, \"f2\": 0.4872339488917747, \"f0_5\": 0.7440465186629246, \"p4\": 0.7412144081485115, \"phi\": 0.6279705540810027}, {\"truth_threshold\": -4.699999894946814, \"match_probability\": 0.037047911572309855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132818.0, \"tn\": 1278723478.0, \"fp\": 14314.0, \"fn\": 171143.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369573728208553, \"tn_rate\": 0.9999888061492438, \"fp_rate\": 1.1193850756230718e-05, \"fn_rate\": 0.5630426271791447, \"precision\": 0.9027132099067504, \"recall\": 0.4369573728208553, \"specificity\": 0.9999888061492438, \"npv\": 0.9998661789664373, \"accuracy\": 0.999855003169705, \"f1\": 0.5888719177641861, \"f2\": 0.4872352851407508, \"f0_5\": 0.7440876022001391, \"p4\": 0.7412253749864479, \"phi\": 0.6279957127125204}, {\"truth_threshold\": -4.679999895393848, \"match_probability\": 0.03754566365912619, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132814.0, \"tn\": 1278723538.0, \"fp\": 14254.0, \"fn\": 171147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369442132378825, \"tn_rate\": 0.9999888530705129, \"fp_rate\": 1.1146929487167296e-05, \"fn_rate\": 0.5630557867621175, \"precision\": 0.9030788478798923, \"recall\": 0.4369442132378825, \"specificity\": 0.9999888530705129, \"npv\": 0.9998661758454332, \"accuracy\": 0.9998550469524821, \"f1\": 0.5889377401453122, \"f2\": 0.4872434904087718, \"f0_5\": 0.7442786805688648, \"p4\": 0.7412775226174133, \"phi\": 0.628113475356335}, {\"truth_threshold\": -4.659999895840883, \"match_probability\": 0.03804983897787343, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132812.0, \"tn\": 1278723569.0, \"fp\": 14223.0, \"fn\": 171149.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369376334463961, \"tn_rate\": 0.9999888773131685, \"fp_rate\": 1.1122686831484527e-05, \"fn_rate\": 0.5630623665536039, \"precision\": 0.9032679294045636, \"recall\": 0.4369376334463961, \"specificity\": 0.9999888773131685, \"npv\": 0.999866174285036, \"accuracy\": 0.9998550696257059, \"f1\": 0.5889719642746277, \"f2\": 0.48724795084523276, \"f0_5\": 0.7443775985006182, \"p4\": 0.7413046348866549, \"phi\": 0.6281745240560649}, {\"truth_threshold\": -4.639999896287918, \"match_probability\": 0.03856051327822519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132809.0, \"tn\": 1278723572.0, \"fp\": 14220.0, \"fn\": 171152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369277637591665, \"tn_rate\": 0.999988879659232, \"fp_rate\": 1.1120340768031355e-05, \"fn_rate\": 0.5630722362408336, \"precision\": 0.9032843860734957, \"recall\": 0.4369277637591665, \"specificity\": 0.999988879659232, \"npv\": 0.9998661719398884, \"accuracy\": 0.9998550696257059, \"f1\": 0.5889664959311737, \"f2\": 0.48723908977578984, \"f0_5\": 0.7443808101767, \"p4\": 0.7413003034550177, \"phi\": 0.6281731531263186}, {\"truth_threshold\": -4.619999896734953, \"match_probability\": 0.03907776301021867, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132808.0, \"tn\": 1278723584.0, \"fp\": 14208.0, \"fn\": 171153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43692447386342326, \"tn_rate\": 0.9999888890434858, \"fp_rate\": 1.1110956514218671e-05, \"fn_rate\": 0.5630755261365767, \"precision\": 0.9033574576916799, \"recall\": 0.43692447386342326, \"specificity\": 0.9999888890434858, \"npv\": 0.9998661711593235, \"accuracy\": 0.9998550782258944, \"f1\": 0.5889790388423356, \"f2\": 0.4872400686791013, \"f0_5\": 0.7444185981334603, \"p4\": 0.7413102397337213, \"phi\": 0.6281962059247682}, {\"truth_threshold\": -4.599999897181988, \"match_probability\": 0.039601665325342136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132808.0, \"tn\": 1278723744.0, \"fp\": 14048.0, \"fn\": 171153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43692447386342326, \"tn_rate\": 0.9999890141668699, \"fp_rate\": 1.0985833130049542e-05, \"fn_rate\": 0.5630755261365767, \"precision\": 0.904341668028545, \"recall\": 0.43692447386342326, \"specificity\": 0.9999890141668699, \"npv\": 0.9998661711760666, \"accuracy\": 0.9998552033195433, \"f1\": 0.5891880740965847, \"f2\": 0.48729727746385854, \"f0_5\": 0.7449530786360551, \"p4\": 0.7414758082854435, \"phi\": 0.628538464162076}, {\"truth_threshold\": -4.579999897629023, \"match_probability\": 0.040132298077445214, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132807.0, \"tn\": 1278723753.0, \"fp\": 14039.0, \"fn\": 171154.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43692118396768004, \"tn_rate\": 0.9999890212050603, \"fp_rate\": 1.0978794939690028e-05, \"fn_rate\": 0.5630788160323199, \"precision\": 0.9043964425316318, \"recall\": 0.43692118396768004, \"specificity\": 0.9999890212050603, \"npv\": 0.9998661703951879, \"accuracy\": 0.9998552095742257, \"f1\": 0.5891967072383526, \"f2\": 0.48729718424586665, \"f0_5\": 0.74498089965165, \"p4\": 0.7414826454688248, \"phi\": 0.6285551397800316}, {\"truth_threshold\": -4.559999898076057, \"match_probability\": 0.04066973982346596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132805.0, \"tn\": 1278723757.0, \"fp\": 14035.0, \"fn\": 171156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43691460417619365, \"tn_rate\": 0.999989024333145, \"fp_rate\": 1.09756668550858e-05, \"fn_rate\": 0.5630853958238063, \"precision\": 0.9044197766276219, \"recall\": 0.43691460417619365, \"specificity\": 0.999989024333145, \"npv\": 0.9998661688319657, \"accuracy\": 0.9998552111378963, \"f1\": 0.5891956761409136, \"f2\": 0.48729199139345586, \"f0_5\": 0.7449897399477854, \"p4\": 0.7414818291929562, \"phi\": 0.6285585181837023}, {\"truth_threshold\": -4.539999898523092, \"match_probability\": 0.0412140698239687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132804.0, \"tn\": 1278723759.0, \"fp\": 14033.0, \"fn\": 171157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43691131428045044, \"tn_rate\": 0.9999890258971872, \"fp_rate\": 1.0974102812783686e-05, \"fn_rate\": 0.5630886857195495, \"precision\": 0.904431444390719, \"recall\": 0.43691131428045044, \"specificity\": 0.9999890258971872, \"npv\": 0.9998661680503546, \"accuracy\": 0.9998552119197316, \"f1\": 0.5891951605819015, \"f2\": 0.48728939495010204, \"f0_5\": 0.7449941602743829, \"p4\": 0.7414814210464737, \"phi\": 0.6285602075357065}, {\"truth_threshold\": -4.519999898970127, \"match_probability\": 0.041765368043486434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132804.0, \"tn\": 1278723761.0, \"fp\": 14031.0, \"fn\": 171157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43691131428045044, \"tn_rate\": 0.9999890274612295, \"fp_rate\": 1.0972538770481571e-05, \"fn_rate\": 0.5630886857195495, \"precision\": 0.9044437634079069, \"recall\": 0.43691131428045044, \"specificity\": 0.9999890274612295, \"npv\": 0.9998661680505638, \"accuracy\": 0.9998552134834022, \"f1\": 0.5891977746031465, \"f2\": 0.48729011014332796, \"f0_5\": 0.7450008470763524, \"p4\": 0.741483491215072, \"phi\": 0.6285644900044872}, {\"truth_threshold\": -4.499999899417162, \"match_probability\": 0.042323715150661426, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132801.0, \"tn\": 1278723777.0, \"fp\": 14015.0, \"fn\": 171160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43690144459322083, \"tn_rate\": 0.9999890399735679, \"fp_rate\": 1.0960026432064659e-05, \"fn_rate\": 0.5630985554067791, \"precision\": 0.904540377070619, \"recall\": 0.43690144459322083, \"specificity\": 0.9999890399735679, \"npv\": 0.9998661657067769, \"accuracy\": 0.9998552236472612, \"f1\": 0.5892092986110649, \"f2\": 0.48728589670203865, \"f0_5\": 0.745047546915762, \"p4\": 0.741492617997364, \"phi\": 0.6285909740995258}, {\"truth_threshold\": -4.479999899864197, \"match_probability\": 0.0428891925181777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132799.0, \"tn\": 1278723812.0, \"fp\": 13980.0, \"fn\": 171162.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43689486480173445, \"tn_rate\": 0.9999890673443083, \"fp_rate\": 1.0932655691777662e-05, \"fn_rate\": 0.5631051351982655, \"precision\": 0.9047547673713542, \"recall\": 0.43689486480173445, \"specificity\": 0.9999890673443083, \"npv\": 0.9998661641467989, \"accuracy\": 0.9998552494478262, \"f1\": 0.5892487908772241, \"f2\": 0.487291789438458, \"f0_5\": 0.7451600703418447, \"p4\": 0.7415238928317934, \"phi\": 0.6286607588065815}, {\"truth_threshold\": -4.459999900311232, \"match_probability\": 0.0434618822224787, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132798.0, \"tn\": 1278723835.0, \"fp\": 13957.0, \"fn\": 171163.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43689157490599123, \"tn_rate\": 0.9999890853307947, \"fp_rate\": 1.091466920530335e-05, \"fn_rate\": 0.5631084250940088, \"precision\": 0.904895914960308, \"recall\": 0.43689157490599123, \"specificity\": 0.9999890853307947, \"npv\": 0.9998661633673854, \"accuracy\": 0.999855266648203, \"f1\": 0.5892757301715492, \"f2\": 0.4872967028450777, \"f0_5\": 0.7452347468689007, \"p4\": 0.7415452257326774, \"phi\": 0.6287074471779456}, {\"truth_threshold\": -4.4399999007582664, \"match_probability\": 0.04404186704326371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132798.0, \"tn\": 1278723878.0, \"fp\": 13914.0, \"fn\": 171163.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43689157490599123, \"tn_rate\": 0.9999891189577041, \"fp_rate\": 1.0881042295807896e-05, \"fn_rate\": 0.5631084250940088, \"precision\": 0.9051611320137412, \"recall\": 0.43689157490599123, \"specificity\": 0.9999891189577041, \"npv\": 0.9998661633718854, \"accuracy\": 0.9998553002671211, \"f1\": 0.5893319546544834, \"f2\": 0.48731208111813384, \"f0_5\": 0.7453786389675003, \"p4\": 0.7415897465774135, \"phi\": 0.6287996125743528}, {\"truth_threshold\": -4.419999901205301, \"match_probability\": 0.044629230462756006, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132798.0, \"tn\": 1278723893.0, \"fp\": 13899.0, \"fn\": 171163.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43689157490599123, \"tn_rate\": 0.9999891306880214, \"fp_rate\": 1.086931197854204e-05, \"fn_rate\": 0.5631084250940088, \"precision\": 0.9052536861694513, \"recall\": 0.43689157490599123, \"specificity\": 0.9999891306880214, \"npv\": 0.9998661633734551, \"accuracy\": 0.9998553119946507, \"f1\": 0.5893515703704362, \"f2\": 0.48731744586034476, \"f0_5\": 0.7454288469591321, \"p4\": 0.7416052783623571, \"phi\": 0.6288317728259694}, {\"truth_threshold\": -4.399999901652336, \"match_probability\": 0.04522405666473612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132797.0, \"tn\": 1278723893.0, \"fp\": 13899.0, \"fn\": 171164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.436888285010248, \"tn_rate\": 0.9999891306880214, \"fp_rate\": 1.086931197854204e-05, \"fn_rate\": 0.563111714989752, \"precision\": 0.9052530403010307, \"recall\": 0.436888285010248, \"specificity\": 0.9999891306880214, \"npv\": 0.9998661625916347, \"accuracy\": 0.9998553112128155, \"f1\": 0.5893484401662462, \"f2\": 0.4873141338969865, \"f0_5\": 0.7454265811202981, \"p4\": 0.7416028000325225, \"phi\": 0.6288291805082087}, {\"truth_threshold\": -4.379999902099371, \"match_probability\": 0.04582643053333292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132792.0, \"tn\": 1278725881.0, \"fp\": 11911.0, \"fn\": 171169.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.436871835531532, \"tn_rate\": 0.9999906853460697, \"fp_rate\": 9.314653930240611e-06, \"fn_rate\": 0.563128164468468, \"precision\": 0.9176865718056986, \"recall\": 0.436871835531532, \"specificity\": 0.9999906853460697, \"npv\": 0.9998661588905846, \"accuracy\": 0.9998568615922266, \"f1\": 0.5919440828771642, \"f2\": 0.48800960202036386, \"f0_5\": 0.7521299360084642, \"p4\": 0.7436546709146531, \"phi\": 0.6331227361026498}, {\"truth_threshold\": -4.359999902546406, \"match_probability\": 0.04643643765156575, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132787.0, \"tn\": 1278725902.0, \"fp\": 11890.0, \"fn\": 171174.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.436855386052816, \"tn_rate\": 0.9999907017685139, \"fp_rate\": 9.298231486068412e-06, \"fn_rate\": 0.563144613947184, \"precision\": 0.9178169301271107, \"recall\": 0.436855386052816, \"specificity\": 0.9999907017685139, \"npv\": 0.9998661549836869, \"accuracy\": 0.9998568741015916, \"f1\": 0.5919560982351026, \"f2\": 0.4880005527294323, \"f0_5\": 0.7521902321255193, \"p4\": 0.7436641543117973, \"phi\": 0.6331557988287405}, {\"truth_threshold\": -4.339999902993441, \"match_probability\": 0.04705416429963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132786.0, \"tn\": 1278725907.0, \"fp\": 11885.0, \"fn\": 171175.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43685209615707277, \"tn_rate\": 0.9999907056786197, \"fp_rate\": 9.294321380313127e-06, \"fn_rate\": 0.5631479038429272, \"precision\": 0.9178480828915263, \"recall\": 0.43685209615707277, \"specificity\": 0.9999907056786197, \"npv\": 0.9998661542023911, \"accuracy\": 0.9998568772289328, \"f1\": 0.5919595570534425, \"f2\": 0.4879990297791645, \"f0_5\": 0.7522050201383342, \"p4\": 0.743666884171552, \"phi\": 0.6331641640337929}, {\"truth_threshold\": -4.3199999034404755, \"match_probability\": 0.04767969745291911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132783.0, \"tn\": 1278726063.0, \"fp\": 11729.0, \"fn\": 171178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43684222646984316, \"tn_rate\": 0.9999908276739192, \"fp_rate\": 9.172326080748227e-06, \"fn_rate\": 0.5631577735301568, \"precision\": 0.9188371899911426, \"recall\": 0.43684222646984316, \"specificity\": 0.9999908276739192, \"npv\": 0.9998661518732607, \"accuracy\": 0.9998569968497346, \"f1\": 0.5921560495280652, \"f2\": 0.48804504115099284, \"f0_5\": 0.7527304143155001, \"p4\": 0.743821937644943, \"phi\": 0.6334982136349782}, {\"truth_threshold\": -4.29999990388751, \"match_probability\": 0.04831312477977547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132782.0, \"tn\": 1278726306.0, \"fp\": 11486.0, \"fn\": 171179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43683893657409995, \"tn_rate\": 0.9999910177050589, \"fp_rate\": 8.98229494104136e-06, \"fn_rate\": 0.5631610634259, \"precision\": 0.9203842848032828, \"recall\": 0.43683893657409995, \"specificity\": 0.9999910177050589, \"npv\": 0.9998661511168739, \"accuracy\": 0.9998571860538785, \"f1\": 0.5924739363138039, \"f2\": 0.48812891879492276, \"f0_5\": 0.7535586067718235, \"p4\": 0.7440727025597843, \"phi\": 0.6340291443209674}, {\"truth_threshold\": -4.279999904334545, \"match_probability\": 0.04895453463896244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132781.0, \"tn\": 1278726316.0, \"fp\": 11476.0, \"fn\": 171180.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368356466783568, \"tn_rate\": 0.9999910255252704, \"fp_rate\": 8.974474729530791e-06, \"fn_rate\": 0.5631643533216433, \"precision\": 0.9204475346083726, \"recall\": 0.4368356466783568, \"specificity\": 0.9999910255252704, \"npv\": 0.9998661503361017, \"accuracy\": 0.9998571930903963, \"f1\": 0.5924840144750991, \"f2\": 0.4881291904057125, \"f0_5\": 0.7535905669650813, \"p4\": 0.744080651222039, \"phi\": 0.6340485504894339}, {\"truth_threshold\": -4.25999990478158, \"match_probability\": 0.0496040160768501, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132774.0, \"tn\": 1278726360.0, \"fp\": 11432.0, \"fn\": 171187.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43681261740815436, \"tn_rate\": 0.9999910599342011, \"fp_rate\": 8.94006579888428e-06, \"fn_rate\": 0.5631873825918456, \"precision\": 0.9207245190907452, \"recall\": 0.43681261740815436, \"specificity\": 0.9999910599342011, \"npv\": 0.9998661448679751, \"accuracy\": 0.9998572220183026, \"f1\": 0.5925201989436973, \"f2\": 0.48812176022940335, \"f0_5\": 0.7537253699824589, \"p4\": 0.7441091896502633, \"phi\": 0.6341272643123064}, {\"truth_threshold\": -4.239999905228615, \"match_probability\": 0.05026165882430686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132772.0, \"tn\": 1278726390.0, \"fp\": 11402.0, \"fn\": 171189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368060376166679, \"tn_rate\": 0.9999910833948357, \"fp_rate\": 8.916605164352568e-06, \"fn_rate\": 0.5631939623833321, \"precision\": 0.92091500547949, \"recall\": 0.4368060376166679, \"specificity\": 0.9999910833948357, \"npv\": 0.9998661433074775, \"accuracy\": 0.9998572439096912, \"f1\": 0.5925535831836388, \"f2\": 0.48812589245142346, \"f0_5\": 0.7538235658150676, \"p4\": 0.7441355177443834, \"phi\": 0.6341881068514391}, {\"truth_threshold\": -4.21999990567565, \"match_probability\": 0.05092755329328894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132769.0, \"tn\": 1278726438.0, \"fp\": 11354.0, \"fn\": 171192.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4367961679294383, \"tn_rate\": 0.9999911209318509, \"fp_rate\": 8.87906814910183e-06, \"fn_rate\": 0.5632038320705617, \"precision\": 0.9212200689688669, \"recall\": 0.4367961679294383, \"specificity\": 0.9999911209318509, \"npv\": 0.9998661409670452, \"accuracy\": 0.99985727909228, \"f1\": 0.5926076360682372, \"f2\": 0.48813316793716316, \"f0_5\": 0.7539811892287266, \"p4\": 0.7441781435501019, \"phi\": 0.6342860147011183}, {\"truth_threshold\": -4.1999999061226845, \"match_probability\": 0.051601790573119886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132767.0, \"tn\": 1278726548.0, \"fp\": 11244.0, \"fn\": 171194.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43678958813795193, \"tn_rate\": 0.9999912069541775, \"fp_rate\": 8.793045822485553e-06, \"fn_rate\": 0.5632104118620481, \"precision\": 0.9219226309101388, \"recall\": 0.43678958813795193, \"specificity\": 0.9999912069541775, \"npv\": 0.9998661394149213, \"accuracy\": 0.9998573635304929, \"f1\": 0.5927468681078282, \"f2\": 0.48816601770041657, \"f0_5\": 0.7543536684450657, \"p4\": 0.744287926990684, \"phi\": 0.6345231532494114}, {\"truth_threshold\": -4.179999906569719, \"match_probability\": 0.05228446242645182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132765.0, \"tn\": 1278726603.0, \"fp\": 11189.0, \"fn\": 171196.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4367830083464655, \"tn_rate\": 0.9999912499653408, \"fp_rate\": 8.750034659177415e-06, \"fn_rate\": 0.5632169916535344, \"precision\": 0.9222737819025522, \"recall\": 0.4367830083464655, \"specificity\": 0.9999912499653408, \"npv\": 0.9998661378570407, \"accuracy\": 0.9998574049677642, \"f1\": 0.5928133686078831, \"f2\": 0.48817912660556934, \"f0_5\": 0.754537797646449, \"p4\": 0.7443403555302031, \"phi\": 0.6346392514749657}, {\"truth_threshold\": -4.159999907016754, \"match_probability\": 0.05297566128490057, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132764.0, \"tn\": 1278726617.0, \"fp\": 11175.0, \"fn\": 171197.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4367797184507223, \"tn_rate\": 0.999991260913637, \"fp_rate\": 8.739086363062617e-06, \"fn_rate\": 0.5632202815492777, \"precision\": 0.9223629454143769, \"recall\": 0.4367797184507223, \"specificity\": 0.999991260913637, \"npv\": 0.9998661370766875, \"accuracy\": 0.9998574151316232, \"f1\": 0.5928287564188435, \"f2\": 0.48818083473613066, \"f0_5\": 0.7545835763091995, \"p4\": 0.7443524866314776, \"phi\": 0.6346675504214129}, {\"truth_threshold\": -4.119999907910824, \"match_probability\": 0.05438401305988898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132762.0, \"tn\": 1278726617.0, \"fp\": 11175.0, \"fn\": 171199.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4367731386592359, \"tn_rate\": 0.999991260913637, \"fp_rate\": 8.739086363062617e-06, \"fn_rate\": 0.5632268613407642, \"precision\": 0.9223618666499928, \"recall\": 0.4367731386592359, \"specificity\": 0.999991260913637, \"npv\": 0.9998661355130503, \"accuracy\": 0.9998574135679525, \"f1\": 0.5928224729737575, \"f2\": 0.4881741986393397, \"f0_5\": 0.7545790710337168, \"p4\": 0.744347533415098, \"phi\": 0.6346623981567141}, {\"truth_threshold\": -4.099999908357859, \"match_probability\": 0.05510135414045803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132757.0, \"tn\": 1278726690.0, \"fp\": 11102.0, \"fn\": 171204.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43675668918051985, \"tn_rate\": 0.999991318001181, \"fp_rate\": 8.681998819035451e-06, \"fn_rate\": 0.5632433108194801, \"precision\": 0.9228272127569356, \"recall\": 0.43675668918051985, \"specificity\": 0.999991318001181, \"npv\": 0.9998661316115984, \"accuracy\": 0.9998574667327533, \"f1\": 0.5929033986869724, \"f2\": 0.4881838166128927, \"f0_5\": 0.7548183584888282, \"p4\": 0.7444113284423906, \"phi\": 0.634810585444805}, {\"truth_threshold\": -4.0799999088048935, \"match_probability\": 0.05582759854305424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132755.0, \"tn\": 1278726719.0, \"fp\": 11073.0, \"fn\": 171206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43675010938903347, \"tn_rate\": 0.9999913406797943, \"fp_rate\": 8.659320205654797e-06, \"fn_rate\": 0.5632498906109665, \"precision\": 0.9230122090274494, \"recall\": 0.43675010938903347, \"specificity\": 0.9999913406797943, \"npv\": 0.9998661300509969, \"accuracy\": 0.9998574878423065, \"f1\": 0.5929355120380357, \"f2\": 0.48818759230167275, \"f0_5\": 0.7549134341666354, \"p4\": 0.7444366421140667, \"phi\": 0.6348694543339063}, {\"truth_threshold\": -4.059999909251928, \"match_probability\": 0.05656284196662854, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132719.0, \"tn\": 1278726780.0, \"fp\": 11012.0, \"fn\": 171242.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43663167314227813, \"tn_rate\": 0.9999913883830845, \"fp_rate\": 8.611616915440315e-06, \"fn_rate\": 0.5633683268577219, \"precision\": 0.9233846560588878, \"recall\": 0.43663167314227813, \"specificity\": 0.9999913883830845, \"npv\": 0.9998661019119162, \"accuracy\": 0.9998575073881892, \"f1\": 0.5929031566344719, \"f2\": 0.4880900281337918, \"f0_5\": 0.7550418996797078, \"p4\": 0.7444111432953116, \"phi\": 0.6349114682385443}, {\"truth_threshold\": -4.039999909698963, \"match_probability\": 0.05730718074558111, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132717.0, \"tn\": 1278726818.0, \"fp\": 10974.0, \"fn\": 171244.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4366250933507917, \"tn_rate\": 0.9999914180998883, \"fp_rate\": 8.581900111700147e-06, \"fn_rate\": 0.5633749066492083, \"precision\": 0.9236277846211662, \"recall\": 0.4366250933507917, \"specificity\": 0.9999914180998883, \"npv\": 0.9998661003522578, \"accuracy\": 0.9998575355342603, \"f1\": 0.5929472000571873, \"f2\": 0.4880970331767847, \"f0_5\": 0.75516799908959, \"p4\": 0.7444458606053537, \"phi\": 0.6349902978811031}, {\"truth_threshold\": -4.019999910145998, \"match_probability\": 0.0580607118428744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132715.0, \"tn\": 1278726823.0, \"fp\": 10969.0, \"fn\": 171246.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4366185135593053, \"tn_rate\": 0.999991422009994, \"fp_rate\": 8.577990005944863e-06, \"fn_rate\": 0.5633814864406947, \"precision\": 0.9236588625038279, \"recall\": 0.4366185135593053, \"specificity\": 0.999991422009994, \"npv\": 0.9998660987891443, \"accuracy\": 0.9998575378797662, \"f1\": 0.5929475365524021, \"f2\": 0.48809219081916666, \"f0_5\": 0.7551806823057322, \"p4\": 0.744446126136269, \"phi\": 0.6349961998679711}, {\"truth_threshold\": -3.999999910593033, \"match_probability\": 0.05882353284275095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132712.0, \"tn\": 1278727155.0, \"fp\": 10637.0, \"fn\": 171249.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4366086438720757, \"tn_rate\": 0.9999916816410163, \"fp_rate\": 8.31835898379392e-06, \"fn_rate\": 0.5633913561279243, \"precision\": 0.9257964827100293, \"recall\": 0.4366086438720757, \"specificity\": 0.9999916816410163, \"npv\": 0.9998660964784503, \"accuracy\": 0.9998577951035817, \"f1\": 0.5933781940935816, \"f2\": 0.48820145483386096, \"f0_5\": 0.7563169838503596, \"p4\": 0.7447854890177316, \"phi\": 0.6357236690488867}, {\"truth_threshold\": -3.9799999110400677, \"match_probability\": 0.05959574194304676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132701.0, \"tn\": 1278727187.0, \"fp\": 10605.0, \"fn\": 171260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43657245501890046, \"tn_rate\": 0.999991706665693, \"fp_rate\": 8.293334306960094e-06, \"fn_rate\": 0.5634275449810996, \"precision\": 0.9259975158053396, \"recall\": 0.43657245501890046, \"specificity\": 0.999991706665693, \"npv\": 0.9998660878818003, \"accuracy\": 0.9998578115221232, \"f1\": 0.593386053520604, \"f2\": 0.4881764338005371, \"f0_5\": 0.7564025832635077, \"p4\": 0.744791682255655, \"phi\": 0.6357663627292285}, {\"truth_threshold\": -3.9599999114871025, \"match_probability\": 0.06037743794709161, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132697.0, \"tn\": 1278727272.0, \"fp\": 10520.0, \"fn\": 171264.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43655929543592764, \"tn_rate\": 0.9999917731374909, \"fp_rate\": 8.226862509120244e-06, \"fn_rate\": 0.5634407045640724, \"precision\": 0.9265450330617175, \"recall\": 0.43655929543592764, \"specificity\": 0.9999917731374909, \"npv\": 0.999866084763428, \"accuracy\": 0.9998578748507829, \"f1\": 0.5934862627410115, \"f2\": 0.48819368667042906, \"f0_5\": 0.7566868796538435, \"p4\": 0.7448706216317521, \"phi\": 0.6359447801695226}, {\"truth_threshold\": -3.9399999119341373, \"match_probability\": 0.061168720255186666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132696.0, \"tn\": 1278727294.0, \"fp\": 10498.0, \"fn\": 171265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365560055401844, \"tn_rate\": 0.9999917903419562, \"fp_rate\": 8.209658043796988e-06, \"fn_rate\": 0.5634439944598155, \"precision\": 0.9266868723549869, \"recall\": 0.4365560055401844, \"specificity\": 0.9999917903419562, \"npv\": 0.9998660839839135, \"accuracy\": 0.9998578912693243, \"f1\": 0.5935123167581711, \"f2\": 0.4881982696583907, \"f0_5\": 0.7567605792843236, \"p4\": 0.7448911439380893, \"phi\": 0.6359910776558334}, {\"truth_threshold\": -3.919999912381172, \"match_probability\": 0.06196968885565049, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132696.0, \"tn\": 1278727304.0, \"fp\": 10488.0, \"fn\": 171265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365560055401844, \"tn_rate\": 0.9999917981621678, \"fp_rate\": 8.201837832286418e-06, \"fn_rate\": 0.5634439944598155, \"precision\": 0.9267515923566879, \"recall\": 0.4365560055401844, \"specificity\": 0.9999917981621678, \"npv\": 0.9998660839849607, \"accuracy\": 0.9998578990876774, \"f1\": 0.5935255901329546, \"f2\": 0.4882018619189597, \"f0_5\": 0.7567951070894505, \"p4\": 0.7449015988160103, \"phi\": 0.6360132950487148}, {\"truth_threshold\": -3.899999912828207, \"match_probability\": 0.06278044431542429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132691.0, \"tn\": 1278727317.0, \"fp\": 10475.0, \"fn\": 171270.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43653955606146844, \"tn_rate\": 0.9999918083284427, \"fp_rate\": 8.191671557322675e-06, \"fn_rate\": 0.5634604439385316, \"precision\": 0.9268331866504617, \"recall\": 0.43653955606146844, \"specificity\": 0.9999918083284427, \"npv\": 0.9998660800772313, \"accuracy\": 0.9998579053423599, \"f1\": 0.5935271186933466, \"f2\": 0.48818993237724523, \"f0_5\": 0.7568287466134322, \"p4\": 0.7449028035305493, \"phi\": 0.6360293195158301}, {\"truth_threshold\": -3.879999913275242, \"match_probability\": 0.06360108777022676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132690.0, \"tn\": 1278727327.0, \"fp\": 10465.0, \"fn\": 171271.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365362661657252, \"tn_rate\": 0.9999918161486542, \"fp_rate\": 8.183851345812106e-06, \"fn_rate\": 0.5634637338342748, \"precision\": 0.9268974188816318, \"recall\": 0.4365362661657252, \"specificity\": 0.9999918161486542, \"npv\": 0.9998660792964604, \"accuracy\": 0.9998579123788776, \"f1\": 0.5935372476046484, \"f2\": 0.48819020470213736, \"f0_5\": 0.7568610316673531, \"p4\": 0.7449107816632594, \"phi\": 0.6360489702991811}, {\"truth_threshold\": -3.8599999137222767, \"match_probability\": 0.06443172091424951, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132687.0, \"tn\": 1278727371.0, \"fp\": 10421.0, \"fn\": 171274.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365263964784956, \"tn_rate\": 0.9999918505575849, \"fp_rate\": 8.149442415165595e-06, \"fn_rate\": 0.5634736035215044, \"precision\": 0.9271808703915924, \"recall\": 0.4365263964784956, \"specificity\": 0.9999918505575849, \"npv\": 0.9998660769556136, \"accuracy\": 0.9998579444341251, \"f1\": 0.5935862249451427, \"f2\": 0.48819605107465164, \"f0_5\": 0.7570062745822935, \"p4\": 0.7449493574248934, \"phi\": 0.6361390637086768}, {\"truth_threshold\": -3.8399999141693115, \"match_probability\": 0.06527244598938357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132684.0, \"tn\": 1278727426.0, \"fp\": 10366.0, \"fn\": 171277.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43651652679126596, \"tn_rate\": 0.9999918935687482, \"fp_rate\": 8.106431251857457e-06, \"fn_rate\": 0.563483473208734, \"precision\": 0.927535826634044, \"recall\": 0.43651652679126596, \"specificity\": 0.9999918935687482, \"npv\": 0.9998660746159189, \"accuracy\": 0.999857985089561, \"f1\": 0.5936498206979247, \"f2\": 0.488205849757229, \"f0_5\": 0.7571896032806756, \"p4\": 0.7449994433377447, \"phi\": 0.6362536750019564}, {\"truth_threshold\": -3.8199999146163464, \"match_probability\": 0.06612336577396749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132681.0, \"tn\": 1278727430.0, \"fp\": 10362.0, \"fn\": 171280.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43650665710403636, \"tn_rate\": 0.9999918966968327, \"fp_rate\": 8.103303167253229e-06, \"fn_rate\": 0.5634933428959636, \"precision\": 0.9275602441223968, \"recall\": 0.43650665710403636, \"specificity\": 0.9999918966968327, \"npv\": 0.9998660722708838, \"accuracy\": 0.9998579858713963, \"f1\": 0.5936456944456873, \"f2\": 0.4881973261941574, \"f0_5\": 0.7571966813257804, \"p4\": 0.7449961942338098, \"phi\": 0.6362548592054399}, {\"truth_threshold\": -3.799999915063381, \"match_probability\": 0.06698458357104768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132680.0, \"tn\": 1278727438.0, \"fp\": 10354.0, \"fn\": 171281.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365033672082932, \"tn_rate\": 0.999991902953002, \"fp_rate\": 8.097046998044773e-06, \"fn_rate\": 0.5634966327917068, \"precision\": 0.9276116168183789, \"recall\": 0.4365033672082932, \"specificity\": 0.999991902953002, \"npv\": 0.9998660714899035, \"accuracy\": 0.9998579913442435, \"f1\": 0.5936531728542825, \"f2\": 0.4881968800731191, \"f0_5\": 0.7572220884217159, \"p4\": 0.7450020838452469, \"phi\": 0.6362700874052599}, {\"truth_threshold\": -3.779999915510416, \"match_probability\": 0.06785620319614147, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132671.0, \"tn\": 1278727548.0, \"fp\": 10244.0, \"fn\": 171290.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43647375814660433, \"tn_rate\": 0.9999919889753286, \"fp_rate\": 8.011024671428496e-06, \"fn_rate\": 0.5635262418533956, \"precision\": 0.9283210299828569, \"recall\": 0.43647375814660433, \"specificity\": 0.9999919889753286, \"npv\": 0.9998660644650613, \"accuracy\": 0.9998580703096094, \"f1\": 0.5937709789740331, \"f2\": 0.48820651785931135, \"f0_5\": 0.7575823329956682, \"p4\": 0.7450948536133344, \"phi\": 0.6364918488458016}, {\"truth_threshold\": -3.759999915957451, \"match_probability\": 0.06873832896449351, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132661.0, \"tn\": 1278727552.0, \"fp\": 10240.0, \"fn\": 171300.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4364408591891723, \"tn_rate\": 0.9999919921034132, \"fp_rate\": 8.007896586824267e-06, \"fn_rate\": 0.5635591408108277, \"precision\": 0.9283419990063051, \"recall\": 0.4364408591891723, \"specificity\": 0.9999919921034132, \"npv\": 0.9998660566473009, \"accuracy\": 0.9998580656185975, \"f1\": 0.5937448250242804, \"f2\": 0.4881747494930984, \"f0_5\": 0.7575736809945578, \"p4\": 0.7450742609109973, \"phi\": 0.6364750492530324}, {\"truth_threshold\": -3.7399999164044857, \"match_probability\": 0.06963106567781589, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132655.0, \"tn\": 1278727561.0, \"fp\": 10231.0, \"fn\": 171306.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4364211198147131, \"tn_rate\": 0.9999919991416035, \"fp_rate\": 8.000858396464754e-06, \"fn_rate\": 0.5635788801852869, \"precision\": 0.9283974637123301, \"recall\": 0.4364211198147131, \"specificity\": 0.9999919991416035, \"npv\": 0.9998660519573359, \"accuracy\": 0.9998580679641035, \"f1\": 0.5937379013398322, \"f2\": 0.48815805936425927, \"f0_5\": 0.7575913330020959, \"p4\": 0.7450688098297736, \"phi\": 0.636479674527596}, {\"truth_threshold\": -3.7199999168515205, \"match_probability\": 0.07053451861050251, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132654.0, \"tn\": 1278727563.0, \"fp\": 10229.0, \"fn\": 171307.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4364178299189699, \"tn_rate\": 0.9999920007056459, \"fp_rate\": 7.999294354162639e-06, \"fn_rate\": 0.5635821700810302, \"precision\": 0.9284099577976386, \"recall\": 0.4364178299189699, \"specificity\": 0.9999920007056459, \"npv\": 0.9998660511757275, \"accuracy\": 0.9998580687459387, \"f1\": 0.5937374117141553, \"f2\": 0.4881554572772897, \"f0_5\": 0.7575960059075286, \"p4\": 0.7450684244266532, \"phi\": 0.636481559708497}, {\"truth_threshold\": -3.6999999172985554, \"match_probability\": 0.07144879349530835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132654.0, \"tn\": 1278727595.0, \"fp\": 10197.0, \"fn\": 171307.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4364178299189699, \"tn_rate\": 0.9999920257303226, \"fp_rate\": 7.974269677328813e-06, \"fn_rate\": 0.5635821700810302, \"precision\": 0.9286179305710146, \"recall\": 0.4364178299189699, \"specificity\": 0.9999920257303226, \"npv\": 0.999866051179079, \"accuracy\": 0.9998580937646685, \"f1\": 0.593779934290037, \"f2\": 0.48816695432013807, \"f0_5\": 0.757706785169615, \"p4\": 0.7451019075935953, \"phi\": 0.636552873254248}, {\"truth_threshold\": -3.67999991774559, \"match_probability\": 0.07237399650848404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132643.0, \"tn\": 1278727603.0, \"fp\": 10189.0, \"fn\": 171318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43638164106579463, \"tn_rate\": 0.9999920319864919, \"fp_rate\": 7.968013508120357e-06, \"fn_rate\": 0.5636183589342054, \"precision\": 0.9286644449423098, \"recall\": 0.43638164106579463, \"specificity\": 0.9999920319864919, \"npv\": 0.9998660425799202, \"accuracy\": 0.9998580914191626, \"f1\": 0.5937559451468577, \"f2\": 0.4881333003600564, \"f0_5\": 0.7577097392975348, \"p4\": 0.7450830198935089, \"phi\": 0.6365424254369113}, {\"truth_threshold\": -3.659999918192625, \"match_probability\": 0.07331023425435647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132640.0, \"tn\": 1278727634.0, \"fp\": 10158.0, \"fn\": 171321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43637177137856503, \"tn_rate\": 0.9999920562291476, \"fp_rate\": 7.943770852437588e-06, \"fn_rate\": 0.563628228621435, \"precision\": 0.9288645499236684, \"recall\": 0.43637177137856503, \"specificity\": 0.9999920562291476, \"npv\": 0.9998660402377137, \"accuracy\": 0.9998581133105512, \"f1\": 0.5937877020944178, \"f2\": 0.4881344754541667, \"f0_5\": 0.757810348590475, \"p4\": 0.7451080260121306, \"phi\": 0.6366038290327749}, {\"truth_threshold\": -3.63999991863966, \"match_probability\": 0.0742576137493457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132634.0, \"tn\": 1278727658.0, \"fp\": 10134.0, \"fn\": 171327.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43635203200410577, \"tn_rate\": 0.9999920749976552, \"fp_rate\": 7.925002344812219e-06, \"fn_rate\": 0.5636479679958942, \"precision\": 0.9290177070491987, \"recall\": 0.43635203200410577, \"specificity\": 0.9999920749976552, \"npv\": 0.9998660355493205, \"accuracy\": 0.9998581273835867, \"f1\": 0.593800715870248, \"f2\": 0.48812317276750095, \"f0_5\": 0.757879988526147, \"p4\": 0.7451182737661084, \"phi\": 0.6366419301087578}, {\"truth_threshold\": -3.6199999190866947, \"match_probability\": 0.07521624240540926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132634.0, \"tn\": 1278727758.0, \"fp\": 10034.0, \"fn\": 171327.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43635203200410577, \"tn_rate\": 0.9999921531997703, \"fp_rate\": 7.846800229706513e-06, \"fn_rate\": 0.5636479679958942, \"precision\": 0.9296688815992374, \"recall\": 0.43635203200410577, \"specificity\": 0.9999921531997703, \"npv\": 0.9998660355597956, \"accuracy\": 0.9998582055671172, \"f1\": 0.5939336675406209, \"f2\": 0.4881591034897005, \"f0_5\": 0.7582265933254291, \"p4\": 0.7452229484423871, \"phi\": 0.636865100351959}, {\"truth_threshold\": -3.5999999195337296, \"match_probability\": 0.07618622801290433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132632.0, \"tn\": 1278727831.0, \"fp\": 9961.0, \"fn\": 171329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4363454522126194, \"tn_rate\": 0.9999922102873143, \"fp_rate\": 7.789712685679348e-06, \"fn_rate\": 0.5636545477873807, \"precision\": 0.9301438359526765, \"recall\": 0.4363454522126194, \"specificity\": 0.9999922102873143, \"npv\": 0.9998660340038068, \"accuracy\": 0.9998582610774239, \"f1\": 0.5940244628869072, \"f2\": 0.48817869360154353, \"f0_5\": 0.758475317756507, \"p4\": 0.7452944231299247, \"phi\": 0.6370230237273056}, {\"truth_threshold\": -3.5799999199807644, \"match_probability\": 0.07716767872285835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132613.0, \"tn\": 1278727857.0, \"fp\": 9935.0, \"fn\": 171348.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4362829441934985, \"tn_rate\": 0.9999922306198642, \"fp_rate\": 7.769380135751866e-06, \"fn_rate\": 0.5637170558065014, \"precision\": 0.9303041782417151, \"recall\": 0.4362829441934985, \"specificity\": 0.9999922306198642, \"npv\": 0.999866019151994, \"accuracy\": 0.9998582665502711, \"f1\": 0.593999225099606, \"f2\": 0.48812493006437024, \"f0_5\": 0.7585228215198025, \"p4\": 0.745274559500193, \"phi\": 0.6370323111696302}, {\"truth_threshold\": -3.5599999204277992, \"match_probability\": 0.07816070302863944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132606.0, \"tn\": 1278727864.0, \"fp\": 9928.0, \"fn\": 171355.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4362599149232961, \"tn_rate\": 0.9999922360940123, \"fp_rate\": 7.763905987694466e-06, \"fn_rate\": 0.5637400850767039, \"precision\": 0.9303464436555489, \"recall\": 0.4362599149232961, \"specificity\": 0.9999922360940123, \"npv\": 0.9998660136800037, \"accuracy\": 0.9998582665502711, \"f1\": 0.5939864948095723, \"f2\": 0.48810419485592377, \"f0_5\": 0.7585313758084057, \"p4\": 0.7452645393875733, \"phi\": 0.6370299721486666}, {\"truth_threshold\": -3.539999920874834, \"match_probability\": 0.07916540974701694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132602.0, \"tn\": 1278727892.0, \"fp\": 9900.0, \"fn\": 171359.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43624675534032326, \"tn_rate\": 0.9999922579906045, \"fp_rate\": 7.742009395464868e-06, \"fn_rate\": 0.5637532446596767, \"precision\": 0.9305272908450408, \"recall\": 0.43624675534032326, \"specificity\": 0.9999922579906045, \"npv\": 0.9998660105556665, \"accuracy\": 0.9998582853143184, \"f1\": 0.5940111498601228, \"f2\": 0.4881009698559866, \"f0_5\": 0.7586195849051854, \"p4\": 0.7452839480358271, \"phi\": 0.637082299089175}, {\"truth_threshold\": -3.519999921321869, \"match_probability\": 0.08018190799860368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132598.0, \"tn\": 1278727899.0, \"fp\": 9893.0, \"fn\": 171363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43623359575735043, \"tn_rate\": 0.9999922634647526, \"fp_rate\": 7.736535247407469e-06, \"fn_rate\": 0.5637664042426496, \"precision\": 0.9305710536104035, \"recall\": 0.43623359575735043, \"specificity\": 0.9999922634647526, \"npv\": 0.9998660074291293, \"accuracy\": 0.9998582876598243, \"f1\": 0.5940078664671679, \"f2\": 0.48809019866233294, \"f0_5\": 0.7586348942987099, \"p4\": 0.7452813640309235, \"phi\": 0.637087675602078}, {\"truth_threshold\": -3.4999999217689037, \"match_probability\": 0.08121030718767058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132591.0, \"tn\": 1278727931.0, \"fp\": 9861.0, \"fn\": 171370.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.436210566487148, \"tn_rate\": 0.9999922884894294, \"fp_rate\": 7.711510570573643e-06, \"fn_rate\": 0.5637894335128519, \"precision\": 0.9307766826720579, \"recall\": 0.436210566487148, \"specificity\": 0.9999922884894294, \"npv\": 0.9998660019597587, \"accuracy\": 0.999858307205707, \"f1\": 0.5940283997105819, \"f2\": 0.4880784453462279, \"f0_5\": 0.7587302822599565, \"p4\": 0.7452975281134896, \"phi\": 0.637141268479342}, {\"truth_threshold\": -3.4799999222159386, \"match_probability\": 0.08225071698132529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132587.0, \"tn\": 1278727937.0, \"fp\": 9855.0, \"fn\": 171374.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4361974069041752, \"tn_rate\": 0.9999922931815564, \"fp_rate\": 7.7068184436673e-06, \"fn_rate\": 0.5638025930958248, \"precision\": 0.9308139453251147, \"recall\": 0.4361974069041752, \"specificity\": 0.9999922931815564, \"npv\": 0.9998659988331169, \"accuracy\": 0.9998583087693776, \"f1\": 0.5940237856824439, \"f2\": 0.48806731424751487, \"f0_5\": 0.7587421271355306, \"p4\": 0.7452938967438424, \"phi\": 0.6371444151196685}, {\"truth_threshold\": -3.4599999226629734, \"match_probability\": 0.08330324728804604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132585.0, \"tn\": 1278727941.0, \"fp\": 9851.0, \"fn\": 171376.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4361908271126888, \"tn_rate\": 0.9999922963096409, \"fp_rate\": 7.703690359063072e-06, \"fn_rate\": 0.5638091728873112, \"precision\": 0.9308391137072088, \"recall\": 0.4361908271126888, \"specificity\": 0.9999922963096409, \"npv\": 0.9998659972699008, \"accuracy\": 0.9998583103330482, \"f1\": 0.5940228092930732, \"f2\": 0.48806210796006716, \"f0_5\": 0.7587515236836232, \"p4\": 0.7452931284665816, \"phi\": 0.6371482263108967}, {\"truth_threshold\": -3.4399999231100082, \"match_probability\": 0.0843680082355622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132582.0, \"tn\": 1278727945.0, \"fp\": 9847.0, \"fn\": 171379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4361809574254592, \"tn_rate\": 0.9999922994377255, \"fp_rate\": 7.700562274458844e-06, \"fn_rate\": 0.5638190425745409, \"precision\": 0.9308637988050187, \"recall\": 0.4361809574254592, \"specificity\": 0.9999922994377255, \"npv\": 0.9998659949248672, \"accuracy\": 0.9998583111148835, \"f1\": 0.5940186832142297, \"f2\": 0.48805357980317654, \"f0_5\": 0.7587586716830133, \"p4\": 0.7452898810192847, \"phi\": 0.6371494686419855}, {\"truth_threshold\": -3.419999923557043, \"match_probability\": 0.08544511014807338, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132578.0, \"tn\": 1278727974.0, \"fp\": 9818.0, \"fn\": 171383.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4361677978424864, \"tn_rate\": 0.9999923221163389, \"fp_rate\": 7.677883661078188e-06, \"fn_rate\": 0.5638322021575136, \"precision\": 0.9310514340290458, \"recall\": 0.4361677978424864, \"specificity\": 0.9999923221163389, \"npv\": 0.9998659918006355, \"accuracy\": 0.9998583306607661, \"f1\": 0.5940446772426555, \"f2\": 0.4880507126870067, \"f0_5\": 0.7588504312885999, \"p4\": 0.7453103428454367, \"phi\": 0.637204092988765}, {\"truth_threshold\": -3.399999924004078, \"match_probability\": 0.08653466352279893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132571.0, \"tn\": 1278727990.0, \"fp\": 9802.0, \"fn\": 171390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43614476857228396, \"tn_rate\": 0.9999923346286773, \"fp_rate\": 7.665371322661276e-06, \"fn_rate\": 0.5638552314277161, \"precision\": 0.9311526764203887, \"recall\": 0.43614476857228396, \"specificity\": 0.9999923346286773, \"npv\": 0.9998659863295891, \"accuracy\": 0.9998583376972839, \"f1\": 0.5940439222644925, \"f2\": 0.48803320824286545, \"f0_5\": 0.7588902894603373, \"p4\": 0.7453097496121072, \"phi\": 0.6372219257039168}, {\"truth_threshold\": -3.3799999244511127, \"match_probability\": 0.08763677900584982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132564.0, \"tn\": 1278727997.0, \"fp\": 9795.0, \"fn\": 171397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43612173930208153, \"tn_rate\": 0.9999923401028254, \"fp_rate\": 7.659897174603876e-06, \"fn_rate\": 0.5638782606979185, \"precision\": 0.931195077234316, \"recall\": 0.43612173930208153, \"specificity\": 0.9999923401028254, \"npv\": 0.9998659808575998, \"accuracy\": 0.9998583376972839, \"f1\": 0.5940311883850152, \"f2\": 0.48801246941731097, \"f0_5\": 0.7588988741660436, \"p4\": 0.7452997272360273, \"phi\": 0.6372196138063505}, {\"truth_threshold\": -3.3599999248981476, \"match_probability\": 0.0887515673674152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132559.0, \"tn\": 1278728101.0, \"fp\": 9691.0, \"fn\": 171402.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4361052898233655, \"tn_rate\": 0.9999924214330251, \"fp_rate\": 7.578566974893943e-06, \"fn_rate\": 0.5638947101766345, \"precision\": 0.9318734622144113, \"recall\": 0.4361052898233655, \"specificity\": 0.9999924214330251, \"npv\": 0.9998659769594108, \"accuracy\": 0.9998584150989792, \"f1\": 0.5941538868382895, \"f2\": 0.48803322892229845, \"f0_5\": 0.7592492677221548, \"p4\": 0.7453963028467108, \"phi\": 0.6374397515930559}, {\"truth_threshold\": -3.3399999253451824, \"match_probability\": 0.08987913947625616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132558.0, \"tn\": 1278728101.0, \"fp\": 9691.0, \"fn\": 171403.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4361019999276223, \"tn_rate\": 0.9999924214330251, \"fp_rate\": 7.578566974893943e-06, \"fn_rate\": 0.5638980000723777, \"precision\": 0.931872983289865, \"recall\": 0.4361019999276223, \"specificity\": 0.9999924214330251, \"npv\": 0.9998659761775934, \"accuracy\": 0.9998584143171438, \"f1\": 0.5941507362004438, \"f2\": 0.4880299066411505, \"f0_5\": 0.759247019039884, \"p4\": 0.745393823341882, \"phi\": 0.6374371830918973}, {\"truth_threshold\": -3.3199999257922173, \"match_probability\": 0.09101960627349945, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132555.0, \"tn\": 1278728112.0, \"fp\": 9680.0, \"fn\": 171406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4360921302403927, \"tn_rate\": 0.9999924300352577, \"fp_rate\": 7.5699647422323155e-06, \"fn_rate\": 0.5639078697596073, \"precision\": 0.93194361444089, \"recall\": 0.4360921302403927, \"specificity\": 0.9999924300352577, \"npv\": 0.9998659738332938, \"accuracy\": 0.9998584205718263, \"f1\": 0.5941559314740608, \"f2\": 0.4880238925717871, \"f0_5\": 0.7592785436149116, \"p4\": 0.7453979126292817, \"phi\": 0.6374541352624378}, {\"truth_threshold\": -3.299999926239252, \"match_probability\": 0.09217307874572404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132549.0, \"tn\": 1278728132.0, \"fp\": 9660.0, \"fn\": 171412.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43607239086593347, \"tn_rate\": 0.9999924456756808, \"fp_rate\": 7.554324319211174e-06, \"fn_rate\": 0.5639276091340666, \"precision\": 0.9320718098010674, \"recall\": 0.43607239086593347, \"specificity\": 0.9999924456756808, \"npv\": 0.999865969144485, \"accuracy\": 0.9998584315175206, \"f1\": 0.5941636595916355, \"f2\": 0.48801114536766976, \"f0_5\": 0.7593346448257727, \"p4\": 0.7454039957397196, \"phi\": 0.6374835646844924}, {\"truth_threshold\": -3.279999926686287, \"match_probability\": 0.09333966789733368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132547.0, \"tn\": 1278728173.0, \"fp\": 9619.0, \"fn\": 171414.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43606581107444703, \"tn_rate\": 0.9999924777385479, \"fp_rate\": 7.522261452017835e-06, \"fn_rate\": 0.5639341889255529, \"precision\": 0.9323396592715558, \"recall\": 0.43606581107444703, \"specificity\": 0.9999924777385479, \"npv\": 0.9998659675851471, \"accuracy\": 0.9998584620090976, \"f1\": 0.5942119620646139, \"f2\": 0.488019234026259, \"f0_5\": 0.7594728548918493, \"p4\": 0.7454420099425519, \"phi\": 0.6375703807964884}, {\"truth_threshold\": -3.2599999271333218, \"match_probability\": 0.09451948472220921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132543.0, \"tn\": 1278728200.0, \"fp\": 9592.0, \"fn\": 171418.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4360526514914742, \"tn_rate\": 0.999992498853119, \"fp_rate\": 7.501146880939294e-06, \"fn_rate\": 0.5639473485085258, \"precision\": 0.9325148626305977, \"recall\": 0.4360526514914742, \"specificity\": 0.999992498853119, \"npv\": 0.9998659644607072, \"accuracy\": 0.9998584799913095, \"f1\": 0.5942353215451383, \"f2\": 0.4880156467809885, \"f0_5\": 0.7595578687015831, \"p4\": 0.7454603935532725, \"phi\": 0.6376206849902567}, {\"truth_threshold\": -3.2399999275803566, \"match_probability\": 0.09571264017463423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132539.0, \"tn\": 1278728209.0, \"fp\": 9583.0, \"fn\": 171422.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43603949190850144, \"tn_rate\": 0.9999925058913094, \"fp_rate\": 7.4941086905797804e-06, \"fn_rate\": 0.5639605080914986, \"precision\": 0.9325720155922377, \"recall\": 0.43603949190850144, \"specificity\": 0.9999925058913094, \"npv\": 0.9998659613343809, \"accuracy\": 0.999858483900486, \"f1\": 0.5942347052006017, \"f2\": 0.4880055907143478, \"f0_5\": 0.7595802161501704, \"p4\": 0.7454599091142732, \"phi\": 0.6376306092901496}, {\"truth_threshold\": -3.2199999280273914, \"match_probability\": 0.09691924513948837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132533.0, \"tn\": 1278728217.0, \"fp\": 9575.0, \"fn\": 171428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4360197525340422, \"tn_rate\": 0.9999925121474786, \"fp_rate\": 7.487852521371324e-06, \"fn_rate\": 0.5639802474659578, \"precision\": 0.9326216680271343, \"recall\": 0.4360197525340422, \"specificity\": 0.9999925121474786, \"npv\": 0.9998659566443151, \"accuracy\": 0.9998584854641567, \"f1\": 0.5942264537549123, \"f2\": 0.48798852978603074, \"f0_5\": 0.7595945863848059, \"p4\": 0.745453416489348, \"phi\": 0.6376331555216453}, {\"truth_threshold\": -3.1999999284744263, \"match_probability\": 0.09813941040170256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132531.0, \"tn\": 1278728225.0, \"fp\": 9567.0, \"fn\": 171430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4360131727425558, \"tn_rate\": 0.9999925184036479, \"fp_rate\": 7.4815963521628675e-06, \"fn_rate\": 0.5639868272574442, \"precision\": 0.9326732255204155, \"recall\": 0.4360131727425558, \"specificity\": 0.9999925184036479, \"npv\": 0.9998659550815189, \"accuracy\": 0.9998584901551685, \"f1\": 0.5942308080321214, \"f2\": 0.48798475929016116, \"f0_5\": 0.7596179528241435, \"p4\": 0.7454568434142098, \"phi\": 0.6376459754121097}, {\"truth_threshold\": -3.179999928921461, \"match_probability\": 0.09937324661497114, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132514.0, \"tn\": 1278728236.0, \"fp\": 9556.0, \"fn\": 171447.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43595724451492135, \"tn_rate\": 0.9999925270058805, \"fp_rate\": 7.47299411950124e-06, \"fn_rate\": 0.5640427554850787, \"precision\": 0.932737382980221, \"recall\": 0.43595724451492135, \"specificity\": 0.9999925270058805, \"npv\": 0.9998659417917769, \"accuracy\": 0.9998584854641567, \"f1\": 0.5941918835237909, \"f2\": 0.48793222545757686, \"f0_5\": 0.7596180413440781, \"p4\": 0.7454262133669147, \"phi\": 0.6376270119387137}, {\"truth_threshold\": -3.159999929368496, \"match_probability\": 0.10062086426971596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132513.0, \"tn\": 1278728251.0, \"fp\": 9541.0, \"fn\": 171448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43595395461917813, \"tn_rate\": 0.9999925387361978, \"fp_rate\": 7.461263802235384e-06, \"fn_rate\": 0.5640460453808219, \"precision\": 0.9328354006222985, \"recall\": 0.43595395461917813, \"specificity\": 0.9999925387361978, \"npv\": 0.9998659410115319, \"accuracy\": 0.999858496409851, \"f1\": 0.594208714953533, \"f2\": 0.48793429256100235, \"f0_5\": 0.7596680490313319, \"p4\": 0.7454394595939867, \"phi\": 0.6376581209653985}, {\"truth_threshold\": -3.1399999298155308, \"match_probability\": 0.10188237366029808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132512.0, \"tn\": 1278728283.0, \"fp\": 9509.0, \"fn\": 171449.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4359506647234349, \"tn_rate\": 0.9999925637608746, \"fp_rate\": 7.436239125401558e-06, \"fn_rate\": 0.5640493352765651, \"precision\": 0.9330451130466622, \"recall\": 0.4359506647234349, \"specificity\": 0.9999925637608746, \"npv\": 0.9998659402330691, \"accuracy\": 0.9998585206467454, \"f1\": 0.5942481983577813, \"f2\": 0.4879424685075468, \"f0_5\": 0.7597773050702659, \"p4\": 0.745470531482232, \"phi\": 0.6377274154805199}, {\"truth_threshold\": -3.1199999302625656, \"match_probability\": 0.10315788485147312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132489.0, \"tn\": 1278728320.0, \"fp\": 9472.0, \"fn\": 171472.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4358749971213412, \"tn_rate\": 0.9999925926956572, \"fp_rate\": 7.407304342812447e-06, \"fn_rate\": 0.5641250028786587, \"precision\": 0.9332774494403393, \"recall\": 0.4358749971213412, \"specificity\": 0.9999925926956572, \"npv\": 0.9998659222551504, \"accuracy\": 0.9998585315924398, \"f1\": 0.5942249989908549, \"f2\": 0.4878793346614573, \"f0_5\": 0.7598545546309095, \"p4\": 0.7454522781788928, \"phi\": 0.6377514816718347}, {\"truth_threshold\": -3.0999999307096004, \"match_probability\": 0.10444750764408649, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132487.0, \"tn\": 1278728354.0, \"fp\": 9438.0, \"fn\": 171474.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4358684173298548, \"tn_rate\": 0.9999926192843763, \"fp_rate\": 7.380715623676507e-06, \"fn_rate\": 0.5641315826701452, \"precision\": 0.9335000880746873, \"recall\": 0.4358684173298548, \"specificity\": 0.9999926192843763, \"npv\": 0.9998659206950804, \"accuracy\": 0.9998585566111695, \"f1\": 0.5942640047007531, \"f2\": 0.48788490531158096, \"f0_5\": 0.7599686116506302, \"p4\": 0.7454829736725677, \"phi\": 0.6378227623116618}, {\"truth_threshold\": -3.0799999311566353, \"match_probability\": 0.10575135154000553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132480.0, \"tn\": 1278728356.0, \"fp\": 9436.0, \"fn\": 171481.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4358453880596524, \"tn_rate\": 0.9999926208484187, \"fp_rate\": 7.379151581374394e-06, \"fn_rate\": 0.5641546119403477, \"precision\": 0.9335099636404633, \"recall\": 0.4358453880596524, \"specificity\": 0.9999926208484187, \"npv\": 0.9998659152225695, \"accuracy\": 0.999858552701993, \"f1\": 0.5942446010895381, \"f2\": 0.4878623615366486, \"f0_5\": 0.7599598451168794, \"p4\": 0.7454677053996906, \"phi\": 0.6378092854501924}, {\"truth_threshold\": -3.05999993160367, \"match_probability\": 0.10706952570628571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132470.0, \"tn\": 1278728360.0, \"fp\": 9432.0, \"fn\": 171491.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43581248910222037, \"tn_rate\": 0.9999926239765032, \"fp_rate\": 7.3760234967701654e-06, \"fn_rate\": 0.5641875108977796, \"precision\": 0.9335315922256205, \"recall\": 0.43581248910222037, \"specificity\": 0.9999926239765032, \"npv\": 0.9998659074048168, \"accuracy\": 0.9998585480109812, \"f1\": 0.5942184034109133, \"f2\": 0.48783056624729515, \"f0_5\": 0.7599513062075407, \"p4\": 0.7454470905172945, \"phi\": 0.637792601771015}, {\"truth_threshold\": -3.039999932050705, \"match_probability\": 0.10840213893856886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132453.0, \"tn\": 1278728374.0, \"fp\": 9418.0, \"fn\": 171508.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43575656087458586, \"tn_rate\": 0.9999926349247994, \"fp_rate\": 7.365075200655366e-06, \"fn_rate\": 0.5642434391254141, \"precision\": 0.9336157495189291, \"recall\": 0.43575656087458586, \"specificity\": 0.9999926349247994, \"npv\": 0.9998658941153925, \"accuracy\": 0.9998585456654753, \"f1\": 0.594183459240252, \"f2\": 0.48777909944281383, \"f0_5\": 0.7599619023575785, \"p4\": 0.7454195925331232, \"phi\": 0.6377804289151118}, {\"truth_threshold\": -3.01999993249774, \"match_probability\": 0.10974929962371176, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132452.0, \"tn\": 1278728381.0, \"fp\": 9411.0, \"fn\": 171509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4357532709788427, \"tn_rate\": 0.9999926403989474, \"fp_rate\": 7.359601052597967e-06, \"fn_rate\": 0.5642467290211574, \"precision\": 0.9336613493299873, \"recall\": 0.4357532709788427, \"specificity\": 0.9999926403989474, \"npv\": 0.9998658933343094, \"accuracy\": 0.9998585503564871, \"f1\": 0.5941896353718059, \"f2\": 0.4877782908978152, \"f0_5\": 0.7599840718465297, \"p4\": 0.7454244532866724, \"phi\": 0.6377936023124953}, {\"truth_threshold\": -2.9999999329447746, \"match_probability\": 0.11111111570164359, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132449.0, \"tn\": 1278728414.0, \"fp\": 9378.0, \"fn\": 171512.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43574340129161304, \"tn_rate\": 0.9999926662056454, \"fp_rate\": 7.333794354613084e-06, \"fn_rate\": 0.564256598708387, \"precision\": 0.9338771884055928, \"recall\": 0.43574340129161304, \"specificity\": 0.9999926662056454, \"npv\": 0.9998658909923184, \"accuracy\": 0.9998585738115462, \"f1\": 0.594224160363222, \"f2\": 0.4877801764934215, \"f0_5\": 0.7600924628329483, \"p4\": 0.7454516241483692, \"phi\": 0.6378601237494206}, {\"truth_threshold\": -2.9799999333918095, \"match_probability\": 0.1124876946264522, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132445.0, \"tn\": 1278728420.0, \"fp\": 9372.0, \"fn\": 171516.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4357302417086403, \"tn_rate\": 0.9999926708977723, \"fp_rate\": 7.329102227706742e-06, \"fn_rate\": 0.5642697582913597, \"precision\": 0.9339148339056672, \"recall\": 0.4357302417086403, \"specificity\": 0.9999926708977723, \"npv\": 0.999865887865679, \"accuracy\": 0.9998585753752168, \"f1\": 0.5942195442574555, \"f2\": 0.4877690380735692, \"f0_5\": 0.760104404238151, \"p4\": 0.7454479920354555, \"phi\": 0.6378633520009823}, {\"truth_threshold\": -2.9599999338388443, \"match_probability\": 0.11387914332669864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132445.0, \"tn\": 1278728855.0, \"fp\": 8937.0, \"fn\": 171516.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4357302417086403, \"tn_rate\": 0.999993011076973, \"fp_rate\": 6.988923026996922e-06, \"fn_rate\": 0.5642697582913597, \"precision\": 0.9367882757352421, \"recall\": 0.4357302417086403, \"specificity\": 0.999993011076973, \"npv\": 0.9998658879112953, \"accuracy\": 0.9998589154735749, \"f1\": 0.594799963174452, \"f2\": 0.4879253713088314, \"f0_5\": 0.7616255064756426, \"p4\": 0.7459045956198442, \"phi\": 0.6388442681274188}, {\"truth_threshold\": -2.939999934285879, \"match_probability\": 0.11528556816496083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132444.0, \"tn\": 1278728868.0, \"fp\": 8924.0, \"fn\": 171517.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43572695181289706, \"tn_rate\": 0.999993021243248, \"fp_rate\": 6.97875675203318e-06, \"fn_rate\": 0.564273048187103, \"precision\": 0.9368739743081885, \"recall\": 0.43572695181289706, \"specificity\": 0.999993021243248, \"npv\": 0.9998658871308417, \"accuracy\": 0.9998589248555985, \"f1\": 0.5948141710959762, \"f2\": 0.4879267203649835, \"f0_5\": 0.7616688117428255, \"p4\": 0.7459157686799098, \"phi\": 0.6388710880818064}, {\"truth_threshold\": -2.919999934732914, \"match_probability\": 0.11670707489660731, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132431.0, \"tn\": 1278728884.0, \"fp\": 8908.0, \"fn\": 171530.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4356841831682354, \"tn_rate\": 0.9999930337555863, \"fp_rate\": 6.966244413616267e-06, \"fn_rate\": 0.5643158168317646, \"precision\": 0.9369742250900318, \"recall\": 0.4356841831682354, \"specificity\": 0.9999930337555863, \"npv\": 0.9998658769689006, \"accuracy\": 0.9998589272011045, \"f1\": 0.5947945205479452, \"f2\": 0.4878892529599914, \"f0_5\": 0.761695676030723, \"p4\": 0.7459003176367162, \"phi\": 0.6388739221220919}, {\"truth_threshold\": -2.899999935179949, \"match_probability\": 0.11814376862780324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132429.0, \"tn\": 1278728918.0, \"fp\": 8874.0, \"fn\": 171532.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.435677603376749, \"tn_rate\": 0.9999930603443056, \"fp_rate\": 6.939655694480327e-06, \"fn_rate\": 0.564322396623251, \"precision\": 0.9371987855884164, \"recall\": 0.435677603376749, \"specificity\": 0.9999930603443056, \"npv\": 0.9998658754088326, \"accuracy\": 0.9998589522198342, \"f1\": 0.5948336267921952, \"f2\": 0.4878948264263193, \"f0_5\": 0.761810364564937, \"p4\": 0.7459310702692812, \"phi\": 0.6389456806382029}, {\"truth_threshold\": -2.8799999356269836, \"match_probability\": 0.11959575377275039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132420.0, \"tn\": 1278728926.0, \"fp\": 8866.0, \"fn\": 171541.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4356479943150602, \"tn_rate\": 0.9999930666004747, \"fp_rate\": 6.933399525271871e-06, \"fn_rate\": 0.5643520056849398, \"precision\": 0.9372478518749203, \"recall\": 0.4356479943150602, \"specificity\": 0.9999930666004747, \"npv\": 0.9998658683733204, \"accuracy\": 0.999858951437999, \"f1\": 0.5948159111684076, \"f2\": 0.48786777980001916, \"f0_5\": 0.7618181922782633, \"p4\": 0.7459171405926038, \"phi\": 0.6389406977861462}, {\"truth_threshold\": -2.8599999360740185, \"match_probability\": 0.12106313401016536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132418.0, \"tn\": 1278728932.0, \"fp\": 8860.0, \"fn\": 171543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43564141452357374, \"tn_rate\": 0.9999930712926016, \"fp_rate\": 6.928707398365528e-06, \"fn_rate\": 0.5643585854764263, \"precision\": 0.9372867679327284, \"recall\": 0.43564141452357374, \"specificity\": 0.9999930712926016, \"npv\": 0.9998658668103161, \"accuracy\": 0.9998589545653401, \"f1\": 0.594817614809125, \"f2\": 0.4878632871620974, \"f0_5\": 0.7618347365526256, \"p4\": 0.7459184805921304, \"phi\": 0.638949142082185}, {\"truth_threshold\": -2.8399999365210533, \"match_probability\": 0.12254601223899865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132412.0, \"tn\": 1278728955.0, \"fp\": 8837.0, \"fn\": 171549.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43562167514911454, \"tn_rate\": 0.9999930892790881, \"fp_rate\": 6.910720911891216e-06, \"fn_rate\": 0.5643783248508855, \"precision\": 0.9374367252157537, \"recall\": 0.43562167514911454, \"specificity\": 0.9999930892790881, \"npv\": 0.9998658621218277, \"accuracy\": 0.9998589678565404, \"f1\": 0.5948294063475663, \"f2\": 0.48785160633795915, \"f0_5\": 0.761901912292553, \"p4\": 0.7459277539920189, \"phi\": 0.6389857946629216}, {\"truth_threshold\": -2.819999936968088, \"match_probability\": 0.1240444905334001, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132383.0, \"tn\": 1278729005.0, \"fp\": 8787.0, \"fn\": 171578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4355262681725616, \"tn_rate\": 0.9999931283801456, \"fp_rate\": 6.871619854338363e-06, \"fn_rate\": 0.5644737318274384, \"precision\": 0.9377558971452858, \"recall\": 0.4355262681725616, \"specificity\": 0.9999931283801456, \"npv\": 0.999865839454387, \"accuracy\": 0.9998589842750818, \"f1\": 0.594804675477556, \"f2\": 0.48777315488270573, \"f0_5\": 0.7620121546185363, \"p4\": 0.745908310522248, \"phi\": 0.6390246105734826}, {\"truth_threshold\": -2.799999937415123, \"match_probability\": 0.1255586700969354, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132370.0, \"tn\": 1278729010.0, \"fp\": 8782.0, \"fn\": 171591.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43548349952789994, \"tn_rate\": 0.9999931322902514, \"fp_rate\": 6.867709748583078e-06, \"fn_rate\": 0.5645165004721, \"precision\": 0.9377833824529586, \"recall\": 0.43548349952789994, \"specificity\": 0.9999931322902514, \"npv\": 0.9998658292912945, \"accuracy\": 0.9998589780203994, \"f1\": 0.5947703167510273, \"f2\": 0.4877317250750923, \"f0_5\": 0.7620004858566216, \"p4\": 0.7458812925624894, \"phi\": 0.6390025982398914}, {\"truth_threshold\": -2.779999937862158, \"match_probability\": 0.1270886512160602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132363.0, \"tn\": 1278729085.0, \"fp\": 8707.0, \"fn\": 171598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4354604702576975, \"tn_rate\": 0.9999931909418377, \"fp_rate\": 6.809058162253798e-06, \"fn_rate\": 0.5645395297423025, \"precision\": 0.9382788686467711, \"recall\": 0.4354604702576975, \"specificity\": 0.9999931909418377, \"npv\": 0.9998658238264464, \"accuracy\": 0.9998590311852001, \"f1\": 0.5948484487597493, \"f2\": 0.48773540548627253, \"f0_5\": 0.7622480394268412, \"p4\": 0.7459427353446346, \"phi\": 0.6391545517888257}, {\"truth_threshold\": -2.7599999383091927, \"match_probability\": 0.1286345332128581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132344.0, \"tn\": 1278729105.0, \"fp\": 8687.0, \"fn\": 171617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4353979622385767, \"tn_rate\": 0.9999932065822608, \"fp_rate\": 6.793417739232657e-06, \"fn_rate\": 0.5646020377614234, \"precision\": 0.9384036133899639, \"recall\": 0.4353979622385767, \"specificity\": 0.9999932065822608, \"npv\": 0.9998658089740292, \"accuracy\": 0.9998590319670354, \"f1\": 0.5948151876887674, \"f2\": 0.48767941040994933, \"f0_5\": 0.7622755836122038, \"p4\": 0.7459165829301587, \"phi\": 0.6391511718458404}, {\"truth_threshold\": -2.7399999387562275, \"match_probability\": 0.13019641439705099, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132340.0, \"tn\": 1278729127.0, \"fp\": 8665.0, \"fn\": 171621.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43538480265560386, \"tn_rate\": 0.9999932237867261, \"fp_rate\": 6.776213273909402e-06, \"fn_rate\": 0.5646151973443961, \"precision\": 0.9385482784298429, \"recall\": 0.43538480265560386, \"specificity\": 0.9999932237867261, \"npv\": 0.9998658058490713, \"accuracy\": 0.9998590460400709, \"f1\": 0.594831964689437, \"f2\": 0.487674015310473, \"f0_5\": 0.7623438761908383, \"p4\": 0.7459297764493883, \"phi\": 0.639190794676394}, {\"truth_threshold\": -2.7199999392032623, \"match_probability\": 0.13177439201728938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132325.0, \"tn\": 1278729251.0, \"fp\": 8541.0, \"fn\": 171636.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4353354542194558, \"tn_rate\": 0.9999933207573488, \"fp_rate\": 6.679242651178327e-06, \"fn_rate\": 0.5646645457805443, \"precision\": 0.9393679099285847, \"recall\": 0.4353354542194558, \"specificity\": 0.9999933207573488, \"npv\": 0.9998657941348351, \"accuracy\": 0.9998591312601193, \"f1\": 0.5949503964462589, \"f2\": 0.4876686985427984, \"f0_5\": 0.7627460587370666, \"p4\": 0.746022901932624, \"phi\": 0.6394337008688666}, {\"truth_threshold\": -2.699999939650297, \"match_probability\": 0.13336856221173263, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132319.0, \"tn\": 1278729271.0, \"fp\": 8521.0, \"fn\": 171642.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43531571484499654, \"tn_rate\": 0.9999933363977719, \"fp_rate\": 6.663602228157186e-06, \"fn_rate\": 0.5646842851550035, \"precision\": 0.9394987219539903, \"recall\": 0.43531571484499654, \"specificity\": 0.9999933363977719, \"npv\": 0.9998657894460351, \"accuracy\": 0.9998591422058135, \"f1\": 0.5949581947882311, \"f2\": 0.4876559316686863, \"f0_5\": 0.7628029299417401, \"p4\": 0.7460290341971559, \"phi\": 0.6394637395729892}, {\"truth_threshold\": -2.679999940097332, \"match_probability\": 0.13497901995792916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132285.0, \"tn\": 1278729283.0, \"fp\": 8509.0, \"fn\": 171676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43520385838972764, \"tn_rate\": 0.9999933457820257, \"fp_rate\": 6.654217974344501e-06, \"fn_rate\": 0.5647961416102724, \"precision\": 0.9395641859738341, \"recall\": 0.43520385838972764, \"specificity\": 0.9999933457820257, \"npv\": 0.9998657628655355, \"accuracy\": 0.9998591250054368, \"f1\": 0.5948668367977875, \"f2\": 0.4875471570160942, \"f0_5\": 0.7627687435780044, \"p4\": 0.7459572060855786, \"phi\": 0.6394038530147491}, {\"truth_threshold\": -2.659999940544367, \"match_probability\": 0.13660585902200775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132280.0, \"tn\": 1278729308.0, \"fp\": 8484.0, \"fn\": 171681.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4351874089110116, \"tn_rate\": 0.9999933653325545, \"fp_rate\": 6.634667445568075e-06, \"fn_rate\": 0.5648125910889884, \"precision\": 0.9397289079594214, \"recall\": 0.4351874089110116, \"specificity\": 0.9999933653325545, \"npv\": 0.9998657589590776, \"accuracy\": 0.9998591406421429, \"f1\": 0.5948844791725223, \"f2\": 0.4875395103080625, \"f0_5\": 0.7628454805384439, \"p4\": 0.7459710793506944, \"phi\": 0.6394478357338603}, {\"truth_threshold\": -2.6399999409914017, \"match_probability\": 0.13824917190719177, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132268.0, \"tn\": 1278729312.0, \"fp\": 8480.0, \"fn\": 171693.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4351479301620932, \"tn_rate\": 0.999993368460639, \"fp_rate\": 6.631539360963847e-06, \"fn_rate\": 0.5648520698379068, \"precision\": 0.9397504760280786, \"recall\": 0.4351479301620932, \"specificity\": 0.999993368460639, \"npv\": 0.9998657495777009, \"accuracy\": 0.9998591343874604, \"f1\": 0.5948519143979546, \"f2\": 0.48750103199782985, \"f0_5\": 0.7628325872336793, \"p4\": 0.74594547460811, \"phi\": 0.6394261682298348}, {\"truth_threshold\": -2.6199999414384365, \"match_probability\": 0.13990904980164973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132261.0, \"tn\": 1278729350.0, \"fp\": 8442.0, \"fn\": 171700.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4351249008918907, \"tn_rate\": 0.9999933981774428, \"fp_rate\": 6.601822557223678e-06, \"fn_rate\": 0.5648750991081093, \"precision\": 0.9400012792904202, \"recall\": 0.4351249008918907, \"specificity\": 0.9999933981774428, \"npv\": 0.9998657441089754, \"accuracy\": 0.9998591586243549, \"f1\": 0.5948806289692892, \"f2\": 0.48749140280432596, \"f0_5\": 0.7629506225966891, \"p4\": 0.745968054707272, \"phi\": 0.6394945977667853}, {\"truth_threshold\": -2.5999999418854713, \"match_probability\": 0.14158558252569556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132261.0, \"tn\": 1278729369.0, \"fp\": 8423.0, \"fn\": 171700.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4351249008918907, \"tn_rate\": 0.9999934130358447, \"fp_rate\": 6.586964155353594e-06, \"fn_rate\": 0.5648750991081093, \"precision\": 0.9401282306445651, \"recall\": 0.4351249008918907, \"specificity\": 0.9999934130358447, \"npv\": 0.99986574411097, \"accuracy\": 0.9998591734792257, \"f1\": 0.5949060486455487, \"f2\": 0.4874982307773964, \"f0_5\": 0.7630175251558503, \"p4\": 0.7459880422233957, \"phi\": 0.6395377966921569}, {\"truth_threshold\": -2.579999942332506, \"match_probability\": 0.14327885847835395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132249.0, \"tn\": 1278729377.0, \"fp\": 8415.0, \"fn\": 171712.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4350854221429723, \"tn_rate\": 0.9999934192920139, \"fp_rate\": 6.580707986145138e-06, \"fn_rate\": 0.5649145778570277, \"precision\": 0.9401765910254223, \"recall\": 0.4350854221429723, \"specificity\": 0.9999934192920139, \"npv\": 0.9998657347300139, \"accuracy\": 0.9998591703518845, \"f1\": 0.5948788304751195, \"f2\": 0.48746118710689507, \"f0_5\": 0.7630187268424229, \"p4\": 0.7459666423040114, \"phi\": 0.639525234834033}, {\"truth_threshold\": -2.559999942779541, \"match_probability\": 0.14498896458330635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132246.0, \"tn\": 1278729401.0, \"fp\": 8391.0, \"fn\": 171715.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4350755524557427, \"tn_rate\": 0.9999934380605214, \"fp_rate\": 6.561939478519768e-06, \"fn_rate\": 0.5649244475442573, \"precision\": 0.940335758015316, \"recall\": 0.4350755524557427, \"specificity\": 0.9999934380605214, \"npv\": 0.9998657323870848, \"accuracy\": 0.999859186770426, \"f1\": 0.5949014615450362, \"f2\": 0.48745983172635665, \"f0_5\": 0.7630965171740859, \"p4\": 0.7459844376520401, \"phi\": 0.639572133000852}, {\"truth_threshold\": -2.539999943226576, \"match_probability\": 0.14671598623423449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132240.0, \"tn\": 1278729437.0, \"fp\": 8355.0, \"fn\": 171721.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43505581308128344, \"tn_rate\": 0.9999934662132829, \"fp_rate\": 6.533786717081714e-06, \"fn_rate\": 0.5649441869187165, \"precision\": 0.9405739891176784, \"recall\": 0.43505581308128344, \"specificity\": 0.9999934662132829, \"npv\": 0.9998657276999666, \"accuracy\": 0.9998592102254851, \"f1\": 0.5949306724012273, \"f2\": 0.487452808419693, \"f0_5\": 0.763209867707981, \"p4\": 0.7460074064111587, \"phi\": 0.6396386644203917}, {\"truth_threshold\": -2.5199999436736107, \"match_probability\": 0.14846000723957972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132239.0, \"tn\": 1278729449.0, \"fp\": 8343.0, \"fn\": 171722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4350525231855403, \"tn_rate\": 0.9999934755975367, \"fp_rate\": 6.524402463269029e-06, \"fn_rate\": 0.5649474768144598, \"precision\": 0.9406538532671324, \"recall\": 0.4350525231855403, \"specificity\": 0.9999934755975367, \"npv\": 0.9998657269194102, \"accuracy\": 0.9998592188256735, \"f1\": 0.5949435712630724, \"f2\": 0.48745379401456473, \"f0_5\": 0.7632499085178271, \"p4\": 0.7460175483901018, \"phi\": 0.6396634115980799}, {\"truth_threshold\": -2.4999999441206455, \"match_probability\": 0.15022110976673644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132201.0, \"tn\": 1278732255.0, \"fp\": 5537.0, \"fn\": 171760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4349275071472985, \"tn_rate\": 0.9999956699488866, \"fp_rate\": 4.330051113402926e-06, \"fn_rate\": 0.5650724928527014, \"precision\": 0.9598004907868563, \"recall\": 0.4349275071472985, \"specificity\": 0.9999956699488866, \"npv\": 0.9998656975050626, \"accuracy\": 0.9998613829457997, \"f1\": 0.5986022155359193, \"f2\": 0.488337610872485, \"f0_5\": 0.7731839380147454, \"p4\": 0.748887585598751, \"phi\": 0.6460503599284712}, {\"truth_threshold\": -2.4799999445676804, \"match_probability\": 0.1519993742857004, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132186.0, \"tn\": 1278732265.0, \"fp\": 5527.0, \"fn\": 171775.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43487815871115043, \"tn_rate\": 0.9999956777690981, \"fp_rate\": 4.322230901892356e-06, \"fn_rate\": 0.5651218412888496, \"precision\": 0.9598658078757997, \"recall\": 0.43487815871115043, \"specificity\": 0.9999956777690981, \"npv\": 0.9998656857788955, \"accuracy\": 0.9998613790366232, \"f1\": 0.598568174717099, \"f2\": 0.48829122083517723, \"f0_5\": 0.77318665017963, \"p4\": 0.7488609449493078, \"phi\": 0.6460356930050666}, {\"truth_threshold\": -2.459999945014715, \"match_probability\": 0.1537948795121923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132177.0, \"tn\": 1278732293.0, \"fp\": 5499.0, \"fn\": 171784.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4348485496494616, \"tn_rate\": 0.9999956996656904, \"fp_rate\": 4.300334309662758e-06, \"fn_rate\": 0.5651514503505384, \"precision\": 0.9600583979778611, \"recall\": 0.4348485496494616, \"specificity\": 0.9999956996656904, \"npv\": 0.9998656787455061, \"accuracy\": 0.999861393891494, \"f1\": 0.5985775648326567, \"f2\": 0.48827132218216207, \"f0_5\": 0.7732678885879263, \"p4\": 0.7488682957835096, \"phi\": 0.6460785281545215}, {\"truth_threshold\": -2.43999994546175, \"match_probability\": 0.15560770235027924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132172.0, \"tn\": 1278732296.0, \"fp\": 5496.0, \"fn\": 171789.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4348321001707456, \"tn_rate\": 0.9999957020117538, \"fp_rate\": 4.297988246209587e-06, \"fn_rate\": 0.5651678998292544, \"precision\": 0.9600778684952204, \"recall\": 0.4348321001707456, \"specificity\": 0.9999957020117538, \"npv\": 0.999865674836749, \"accuracy\": 0.9998613923278235, \"f1\": 0.5985657644765177, \"f2\": 0.4882557376661603, \"f0_5\": 0.7732675897139474, \"p4\": 0.748859060533568, \"phi\": 0.6460728605709429}, {\"truth_threshold\": -2.419999945908785, \"match_probability\": 0.1574379178345172, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132158.0, \"tn\": 1278732310.0, \"fp\": 5482.0, \"fn\": 171803.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43478604163034074, \"tn_rate\": 0.9999957129600499, \"fp_rate\": 4.287039950094788e-06, \"fn_rate\": 0.5652139583696593, \"precision\": 0.960171461784365, \"recall\": 0.43478604163034074, \"specificity\": 0.9999957129600499, \"npv\": 0.9998656638928176, \"accuracy\": 0.9998613923278235, \"f1\": 0.598540311276469, \"f2\": 0.4882141200043739, \"f0_5\": 0.7732870227882053, \"p4\": 0.7488391402398916, \"phi\": 0.6460701401348315}, {\"truth_threshold\": -2.3999999463558197, \"match_probability\": 0.15928559907163878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132148.0, \"tn\": 1278732332.0, \"fp\": 5460.0, \"fn\": 171813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4347531426729087, \"tn_rate\": 0.9999957301645153, \"fp_rate\": 4.269835484771533e-06, \"fn_rate\": 0.5652468573270913, \"precision\": 0.960322074298006, \"recall\": 0.4347531426729087, \"specificity\": 0.9999957301645153, \"npv\": 0.9998656560769845, \"accuracy\": 0.999861401709847, \"f1\": 0.5985383937731136, \"f2\": 0.48818872039791583, \"f0_5\": 0.7733443509017514, \"p4\": 0.7488376408453107, \"phi\": 0.6460963809625089}, {\"truth_threshold\": -2.3799999468028545, \"match_probability\": 0.16115081718181212, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132147.0, \"tn\": 1278732339.0, \"fp\": 5453.0, \"fn\": 171814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4347498527771655, \"tn_rate\": 0.9999957356386633, \"fp_rate\": 4.264361336714134e-06, \"fn_rate\": 0.5652501472228345, \"precision\": 0.9603706395348838, \"recall\": 0.4347498527771655, \"specificity\": 0.9999957356386633, \"npv\": 0.9998656552959055, \"accuracy\": 0.9998614064008589, \"f1\": 0.5985447084321306, \"f2\": 0.4881879117274154, \"f0_5\": 0.773367464104752, \"p4\": 0.7488425835801056, \"phi\": 0.6461102792979282}, {\"truth_threshold\": -2.3599999472498894, \"match_probability\": 0.16303364123949682, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132141.0, \"tn\": 1278732346.0, \"fp\": 5446.0, \"fn\": 171820.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4347301134027063, \"tn_rate\": 0.9999957411128113, \"fp_rate\": 4.258887188656735e-06, \"fn_rate\": 0.5652698865972937, \"precision\": 0.9604177720278806, \"recall\": 0.4347301134027063, \"specificity\": 0.9999957411128113, \"npv\": 0.9998656506057546, \"accuracy\": 0.9998614071826942, \"f1\": 0.5985351535959851, \"f2\": 0.4881704349907753, \"f0_5\": 0.7733794212632665, \"p4\": 0.7488351057198398, \"phi\": 0.6461114698575571}, {\"truth_threshold\": -2.339999947696924, \"match_probability\": 0.1649341382139255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132136.0, \"tn\": 1278732354.0, \"fp\": 5438.0, \"fn\": 171825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43471366392399025, \"tn_rate\": 0.9999957473689806, \"fp_rate\": 4.252631019448278e-06, \"fn_rate\": 0.5652863360760098, \"precision\": 0.9604721822437379, \"recall\": 0.43471366392399025, \"specificity\": 0.9999957473689806, \"npv\": 0.9998656466975232, \"accuracy\": 0.9998614095282001, \"f1\": 0.5985301278494344, \"f2\": 0.48815665226855265, \"f0_5\": 0.7733972329170261, \"p4\": 0.74883117267687, \"phi\": 0.6461175529742442}, {\"truth_threshold\": -2.319999948143959, \"match_probability\": 0.16685237290923954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132133.0, \"tn\": 1278732366.0, \"fp\": 5426.0, \"fn\": 171828.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43470379423676064, \"tn_rate\": 0.9999957567532344, \"fp_rate\": 4.243246765635594e-06, \"fn_rate\": 0.5652962057632394, \"precision\": 0.9605551072630653, \"recall\": 0.43470379423676064, \"specificity\": 0.9999957567532344, \"npv\": 0.9998656443533408, \"accuracy\": 0.9998614165647178, \"f1\": 0.5985368726218517, \"f2\": 0.48815097942002494, \"f0_5\": 0.773433997075616, \"p4\": 0.7488364524158685, \"phi\": 0.6461381195140287}, {\"truth_threshold\": -2.299999948590994, \"match_probability\": 0.16878840790430902, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132128.0, \"tn\": 1278732381.0, \"fp\": 5411.0, \"fn\": 171833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4346873447580446, \"tn_rate\": 0.9999957684835517, \"fp_rate\": 4.231516448369737e-06, \"fn_rate\": 0.5653126552419554, \"precision\": 0.9606584314267226, \"recall\": 0.4346873447580446, \"specificity\": 0.9999957684835517, \"npv\": 0.999865640445845, \"accuracy\": 0.9998614243830709, \"f1\": 0.5985413363533408, \"f2\": 0.4881397209806832, \"f0_5\": 0.7734771699895916, \"p4\": 0.7488399469982637, \"phi\": 0.6461606564199514}, {\"truth_threshold\": -2.2799999490380287, \"match_probability\": 0.17074230349226796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132125.0, \"tn\": 1278732394.0, \"fp\": 5398.0, \"fn\": 171836.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.434677475070815, \"tn_rate\": 0.9999957786498266, \"fp_rate\": 4.221350173405996e-06, \"fn_rate\": 0.565322524929185, \"precision\": 0.9607483839066919, \"recall\": 0.434677475070815, \"specificity\": 0.9999957786498266, \"npv\": 0.9998656381017678, \"accuracy\": 0.999861432201424, \"f1\": 0.5985494378052205, \"f2\": 0.4881344084790009, \"f0_5\": 0.7735175685818093, \"p4\": 0.7488462885490029, \"phi\": 0.6461835826729809}, {\"truth_threshold\": -2.2599999494850636, \"match_probability\": 0.17271411761979777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132111.0, \"tn\": 1278732401.0, \"fp\": 5391.0, \"fn\": 171850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43463141653041015, \"tn_rate\": 0.9999957841239746, \"fp_rate\": 4.215876025348596e-06, \"fn_rate\": 0.5653685834695898, \"precision\": 0.9607932975520356, \"recall\": 0.43463141653041015, \"specificity\": 0.9999957841239746, \"npv\": 0.9998656271571029, \"accuracy\": 0.9998614267285768, \"f1\": 0.59851448479261, \"f2\": 0.4880902592537311, \"f0_5\": 0.7735116848503868, \"p4\": 0.7488189319815034, \"phi\": 0.6461644521559387}, {\"truth_threshold\": -2.2399999499320984, \"match_probability\": 0.1747039058261921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132104.0, \"tn\": 1278732416.0, \"fp\": 5376.0, \"fn\": 171857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43460838726020773, \"tn_rate\": 0.9999957958542919, \"fp_rate\": 4.20414570808274e-06, \"fn_rate\": 0.5653916127397923, \"precision\": 0.9608961303462322, \"recall\": 0.43460838726020773, \"specificity\": 0.9999957958542919, \"npv\": 0.999865621685979, \"accuracy\": 0.9998614329832594, \"f1\": 0.5985125985125985, \"f2\": 0.4880723315333209, \"f0_5\": 0.7735504127624341, \"p4\": 0.7488174565371141, \"phi\": 0.6461819220696402}, {\"truth_threshold\": -2.2199999503791332, \"match_probability\": 0.17671172118223738, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132103.0, \"tn\": 1278732426.0, \"fp\": 5366.0, \"fn\": 171858.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4346050973644645, \"tn_rate\": 0.9999958036745035, \"fp_rate\": 4.19632549657217e-06, \"fn_rate\": 0.5653949026355355, \"precision\": 0.9609657450043283, \"recall\": 0.4346050973644645, \"specificity\": 0.9999958036745035, \"npv\": 0.9998656209052155, \"accuracy\": 0.9998614400197771, \"f1\": 0.5985229821262714, \"f2\": 0.488072604046514, \"f0_5\": 0.7735844195086415, \"p4\": 0.7488255843512387, \"phi\": 0.6462028918000832}, {\"truth_threshold\": -2.199999950826168, \"match_probability\": 0.17873761422894588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132089.0, \"tn\": 1278732442.0, \"fp\": 5350.0, \"fn\": 171872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43455903882405966, \"tn_rate\": 0.9999958161868419, \"fp_rate\": 4.183813158155257e-06, \"fn_rate\": 0.5654409611759403, \"precision\": 0.9610736399420834, \"recall\": 0.43455903882405966, \"specificity\": 0.9999958161868419, \"npv\": 0.9998656099614971, \"accuracy\": 0.9998614415834477, \"f1\": 0.5985002265518804, \"f2\": 0.4880316977306299, \"f0_5\": 0.7736111615441651, \"p4\": 0.7488077745807434, \"phi\": 0.6462049337602855}, {\"truth_threshold\": -2.179999951273203, \"match_probability\": 0.18078163291617783, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132081.0, \"tn\": 1278732482.0, \"fp\": 5310.0, \"fn\": 171880.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.434532719658114, \"tn_rate\": 0.9999958474676879, \"fp_rate\": 4.152532312112975e-06, \"fn_rate\": 0.565467280341886, \"precision\": 0.9613511802083106, \"recall\": 0.434532719658114, \"specificity\": 0.9999958474676879, \"npv\": 0.9998656037111866, \"accuracy\": 0.9998614666021775, \"f1\": 0.5985290652359114, \"f2\": 0.4880194496890784, \"f0_5\": 0.7737383204944202, \"p4\": 0.7488303490301601, \"phi\": 0.6462786951569816}, {\"truth_threshold\": -2.1599999517202377, \"match_probability\": 0.18284382254119044, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132071.0, \"tn\": 1278732484.0, \"fp\": 5308.0, \"fn\": 171890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.434499820700682, \"tn_rate\": 0.9999958490317302, \"fp_rate\": 4.15096826981086e-06, \"fn_rate\": 0.565500179299318, \"precision\": 0.9613623625153772, \"recall\": 0.434499820700682, \"specificity\": 0.9999958490317302, \"npv\": 0.9998655958932549, \"accuracy\": 0.999861460347495, \"f1\": 0.598500022658268, \"f2\": 0.4879868284828147, \"f0_5\": 0.7737232520618599, \"p4\": 0.7488076176296566, \"phi\": 0.6462579868398362}, {\"truth_threshold\": -2.1399999521672726, \"match_probability\": 0.1849242256871536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132065.0, \"tn\": 1278732524.0, \"fp\": 5268.0, \"fn\": 171896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4344800813262228, \"tn_rate\": 0.9999958803125762, \"fp_rate\": 4.1196874237685786e-06, \"fn_rate\": 0.5655199186737773, \"precision\": 0.9616406835938922, \"recall\": 0.4344800813262228, \"specificity\": 0.9999958803125762, \"npv\": 0.9998655912065735, \"accuracy\": 0.9998614869298954, \"f1\": 0.5985352168848885, \"f2\": 0.48798124709479984, \"f0_5\": 0.7738549361122147, \"p4\": 0.7488351664374341, \"phi\": 0.646336880709798}, {\"truth_threshold\": -2.1199999526143074, \"match_probability\": 0.18702288216167304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132059.0, \"tn\": 1278732529.0, \"fp\": 5263.0, \"fn\": 171902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43446034195176353, \"tn_rate\": 0.999995884222682, \"fp_rate\": 4.115777318013293e-06, \"fn_rate\": 0.5655396580482365, \"precision\": 0.9616740216425628, \"recall\": 0.43446034195176353, \"specificity\": 0.999995884222682, \"npv\": 0.999865586516214, \"accuracy\": 0.9998614861480601, \"f1\": 0.598522943326618, \"f2\": 0.4879630437063893, \"f0_5\": 0.7738596822264076, \"p4\": 0.7488255604541612, \"phi\": 0.6463334042720654}, {\"truth_threshold\": -2.0999999530613422, \"match_probability\": 0.18913982893536135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132040.0, \"tn\": 1278732546.0, \"fp\": 5246.0, \"fn\": 171921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4343978339326427, \"tn_rate\": 0.9999958975170415, \"fp_rate\": 4.102482958445323e-06, \"fn_rate\": 0.5656021660673574, \"precision\": 0.9617878006497385, \"recall\": 0.4343978339326427, \"specificity\": 0.9999958975170415, \"npv\": 0.9998655716635323, \"accuracy\": 0.9998614845843895, \"f1\": 0.5984856554265525, \"f2\": 0.4879058183618721, \"f0_5\": 0.7738789480779037, \"p4\": 0.7487963760363213, \"phi\": 0.6463251478631589}, {\"truth_threshold\": -2.079999953508377, \"match_probability\": 0.19127510008050128, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132029.0, \"tn\": 1278732562.0, \"fp\": 5230.0, \"fn\": 171932.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43436164507946745, \"tn_rate\": 0.9999959100293799, \"fp_rate\": 4.08997062002841e-06, \"fn_rate\": 0.5656383549205326, \"precision\": 0.9618968519368493, \"recall\": 0.43436164507946745, \"specificity\": 0.9999959100293799, \"npv\": 0.9998655630652589, \"accuracy\": 0.999861488493566, \"f1\": 0.598472417388151, \"f2\": 0.48787490678832285, \"f0_5\": 0.7739124522126104, \"p4\": 0.7487860152138892, \"phi\": 0.6463348754135865}, {\"truth_threshold\": -2.059999953955412, \"match_probability\": 0.19342872670984337, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132023.0, \"tn\": 1278732567.0, \"fp\": 5225.0, \"fn\": 171938.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4343419057050082, \"tn_rate\": 0.9999959139394857, \"fp_rate\": 4.086060514273124e-06, \"fn_rate\": 0.5656580942949918, \"precision\": 0.9619302284914899, \"recall\": 0.4343419057050082, \"specificity\": 0.9999959139394857, \"npv\": 0.9998655583748999, \"accuracy\": 0.9998614877117307, \"f1\": 0.5984601402056622, \"f2\": 0.48785670153988053, \"f0_5\": 0.773917202940842, \"p4\": 0.7487764056390677, \"phi\": 0.646331404939299}, {\"truth_threshold\": -2.0399999544024467, \"match_probability\": 0.19560073691558413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132017.0, \"tn\": 1278732620.0, \"fp\": 5172.0, \"fn\": 171944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.434322166330549, \"tn_rate\": 0.9999959553866067, \"fp_rate\": 4.044613393267101e-06, \"fn_rate\": 0.565677833669451, \"precision\": 0.962300184417118, \"recall\": 0.434322166330549, \"specificity\": 0.9999959553866067, \"npv\": 0.9998655536895871, \"accuracy\": 0.99986152445799, \"f1\": 0.5985129774453134, \"f2\": 0.487855802482275, \"f0_5\": 0.7740962124597024, \"p4\": 0.748817765943331, \"phi\": 0.6464410384212198}, {\"truth_threshold\": -2.0199999548494816, \"match_probability\": 0.19779115570857017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132000.0, \"tn\": 1278732825.0, \"fp\": 4967.0, \"fn\": 171961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43426623810291454, \"tn_rate\": 0.9999961157009427, \"fp_rate\": 3.884299057300404e-06, \"fn_rate\": 0.5657337618970855, \"precision\": 0.9637357903728635, \"recall\": 0.43426623810291454, \"specificity\": 0.9999961157009427, \"npv\": 0.9998655404203015, \"accuracy\": 0.9998616714430275, \"f1\": 0.5987372087959939, \"f2\": 0.4878730288266432, \"f0_5\": 0.7748033936388642, \"p4\": 0.7489932596680725, \"phi\": 0.6468815827017872}, {\"truth_threshold\": -1.9999999552965164, \"match_probability\": 0.20000000495777503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131995.0, \"tn\": 1278732847.0, \"fp\": 4945.0, \"fn\": 171966.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4342497886241985, \"tn_rate\": 0.999996132905408, \"fp_rate\": 3.867094591977148e-06, \"fn_rate\": 0.5657502113758015, \"precision\": 0.9638892945815686, \"recall\": 0.4342497886241985, \"specificity\": 0.999996132905408, \"npv\": 0.999865536513545, \"accuracy\": 0.9998616847342278, \"f1\": 0.5987511935786038, \"f2\": 0.48786428579876756, \"f0_5\": 0.7748722879910205, \"p4\": 0.7490042037480519, \"phi\": 0.6469208643702165}, {\"truth_threshold\": -1.9799999557435513, \"match_probability\": 0.20222730333009747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131982.0, \"tn\": 1278732879.0, \"fp\": 4913.0, \"fn\": 171979.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43420701997953687, \"tn_rate\": 0.9999961579300849, \"fp_rate\": 3.8420699151433225e-06, \"fn_rate\": 0.5657929800204632, \"precision\": 0.9641111801015376, \"recall\": 0.43420701997953687, \"specificity\": 0.9999961579300849, \"npv\": 0.9998655263533294, \"accuracy\": 0.9998616995890985, \"f1\": 0.5987533344221242, \"f2\": 0.48783246435565175, \"f0_5\": 0.7749597494424814, \"p4\": 0.7490058808913374, \"phi\": 0.6469634838022574}, {\"truth_threshold\": -1.959999956190586, \"match_probability\": 0.20447306623052947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131979.0, \"tn\": 1278732879.0, \"fp\": 4913.0, \"fn\": 171982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4341971502923072, \"tn_rate\": 0.9999961579300849, \"fp_rate\": 3.8420699151433225e-06, \"fn_rate\": 0.5658028497076928, \"precision\": 0.9641103935949508, \"recall\": 0.4341971502923072, \"specificity\": 0.9999961579300849, \"npv\": 0.9998655240078879, \"accuracy\": 0.9998616972435926, \"f1\": 0.5987437989533926, \"f2\": 0.4878224575970478, \"f0_5\": 0.7749530550339448, \"p4\": 0.7489984196968791, \"phi\": 0.6469558661227925}, {\"truth_threshold\": -1.939999956637621, \"match_probability\": 0.20673730574274402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131971.0, \"tn\": 1278732888.0, \"fp\": 4904.0, \"fn\": 171990.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4341708311263616, \"tn_rate\": 0.9999961649682753, \"fp_rate\": 3.8350317247838096e-06, \"fn_rate\": 0.5658291688736384, \"precision\": 0.9641716894977169, \"recall\": 0.4341708311263616, \"specificity\": 0.9999961649682753, \"npv\": 0.9998655177543235, \"accuracy\": 0.9998616980254279, \"f1\": 0.5987305936901705, \"f2\": 0.4877990181257157, \"f0_5\": 0.7749679668240824, \"p4\": 0.7489880874259844, \"phi\": 0.6469568288503347}, {\"truth_threshold\": -1.9199999570846558, \"match_probability\": 0.20902003057015453, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131962.0, \"tn\": 1278733001.0, \"fp\": 4791.0, \"fn\": 171999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43414122206467276, \"tn_rate\": 0.9999962533366653, \"fp_rate\": 3.746663334714362e-06, \"fn_rate\": 0.5658587779353272, \"precision\": 0.9649660336519126, \"recall\": 0.43414122206467276, \"specificity\": 0.9999962533366653, \"npv\": 0.9998655107298822, \"accuracy\": 0.9998617793362997, \"f1\": 0.5988554935854091, \"f2\": 0.48780974673165767, \"f0_5\": 0.7753595002426634, \"p4\": 0.7490858191995301, \"phi\": 0.6472013062915483}, {\"truth_threshold\": -1.8999999575316906, \"match_probability\": 0.211321245977496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131955.0, \"tn\": 1278733006.0, \"fp\": 4786.0, \"fn\": 172006.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43411819279447034, \"tn_rate\": 0.999996257246771, \"fp_rate\": 3.7427532289590765e-06, \"fn_rate\": 0.5658818072055296, \"precision\": 0.9649995246487886, \"recall\": 0.43411819279447034, \"specificity\": 0.999996257246771, \"npv\": 0.9998655052577118, \"accuracy\": 0.9998617777726291, \"f1\": 0.5988400324936125, \"f2\": 0.4877881981539053, \"f0_5\": 0.775362105943532, \"p4\": 0.7490737232124842, \"phi\": 0.6471953737642802}, {\"truth_threshold\": -1.8799999579787254, \"match_probability\": 0.2136409537329821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131948.0, \"tn\": 1278733021.0, \"fp\": 4771.0, \"fn\": 172013.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4340951635242679, \"tn_rate\": 0.9999962689770883, \"fp_rate\": 3.731022911693221e-06, \"fn_rate\": 0.5659048364757321, \"precision\": 0.9651036066676907, \"recall\": 0.4340951635242679, \"specificity\": 0.9999962689770883, \"npv\": 0.9998654997865932, \"accuracy\": 0.9998617840273116, \"f1\": 0.5988381592084959, \"f2\": 0.48777025543357316, \"f0_5\": 0.7754011637951805, \"p4\": 0.7490722585361599, \"phi\": 0.6472131192584818}, {\"truth_threshold\": -1.8599999584257603, \"match_probability\": 0.21597915205109092, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131937.0, \"tn\": 1278733024.0, \"fp\": 4768.0, \"fn\": 172024.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43405897467109267, \"tn_rate\": 0.9999962713231517, \"fp_rate\": 3.7286768482400494e-06, \"fn_rate\": 0.5659410253289073, \"precision\": 0.9651219779817856, \"recall\": 0.43405897467109267, \"specificity\": 0.9999962713231517, \"npv\": 0.9998654911869579, \"accuracy\": 0.9998617777726291, \"f1\": 0.5988072599202117, \"f2\": 0.48773464029768976, \"f0_5\": 0.7753875556694378, \"p4\": 0.7490480832773605, \"phi\": 0.6471923001020657}, {\"truth_threshold\": -1.839999958872795, \"match_probability\": 0.218335835536034, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131930.0, \"tn\": 1278733033.0, \"fp\": 4759.0, \"fn\": 172031.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43403594540089024, \"tn_rate\": 0.9999962783613421, \"fp_rate\": 3.721638657880536e-06, \"fn_rate\": 0.5659640545991097, \"precision\": 0.9651837382671612, \"recall\": 0.43403594540089024, \"specificity\": 0.9999962783613421, \"npv\": 0.9998654857152086, \"accuracy\": 0.9998617793362997, \"f1\": 0.5987972313627595, \"f2\": 0.4877145326583529, \"f0_5\": 0.7754047468194476, \"p4\": 0.7490402373492486, \"phi\": 0.6471958441809439}, {\"truth_threshold\": -1.81999995931983, \"match_probability\": 0.22071099512596293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131916.0, \"tn\": 1278733823.0, \"fp\": 3969.0, \"fn\": 172045.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4339898868604854, \"tn_rate\": 0.9999968961580514, \"fp_rate\": 3.103841948545461e-06, \"fn_rate\": 0.5660101131395147, \"precision\": 0.9707914780880892, \"recall\": 0.4339898868604854, \"specificity\": 0.9999968961580514, \"npv\": 0.9998654748529154, \"accuracy\": 0.999862386040497, \"f1\": 0.599828121660763, \"f2\": 0.48795283670025574, \"f0_5\": 0.7782645684193883, \"p4\": 0.7498463564284961, \"phi\": 0.6490395122189726}, {\"truth_threshold\": -1.7999999597668648, \"match_probability\": 0.22310461803797055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131909.0, \"tn\": 1278733838.0, \"fp\": 3954.0, \"fn\": 172052.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.433966857590283, \"tn_rate\": 0.9999969078883687, \"fp_rate\": 3.0921116312796047e-06, \"fn_rate\": 0.566033142409717, \"precision\": 0.9708971537504693, \"recall\": 0.433966857590283, \"specificity\": 0.9999969078883687, \"npv\": 0.999865469381801, \"accuracy\": 0.9998623922951795, \"f1\": 0.5998262941540252, \"f2\": 0.48793488529688755, \"f0_5\": 0.7783040854931421, \"p4\": 0.7498449293337656, \"phi\": 0.6490576271182809}, {\"truth_threshold\": -1.7799999602138996, \"match_probability\": 0.22551668771394165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131899.0, \"tn\": 1278733853.0, \"fp\": 3939.0, \"fn\": 172062.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43393395863285095, \"tn_rate\": 0.999996919618686, \"fp_rate\": 3.080381314013749e-06, \"fn_rate\": 0.5660660413671491, \"precision\": 0.9710022232365023, \"recall\": 0.43393395863285095, \"specificity\": 0.999996919618686, \"npv\": 0.9998654615652474, \"accuracy\": 0.999862396204356, \"f1\": 0.5998149154500124, \"f2\": 0.487906918935075, \"f0_5\": 0.7783369309806412, \"p4\": 0.7498360387361642, \"phi\": 0.6490681529177499}, {\"truth_threshold\": -1.7599999606609344, \"match_probability\": 0.22794718376731132, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131894.0, \"tn\": 1278733866.0, \"fp\": 3926.0, \"fn\": 172067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4339175091541349, \"tn_rate\": 0.9999969297849609, \"fp_rate\": 3.070215039050007e-06, \"fn_rate\": 0.5660824908458651, \"precision\": 0.971094095125902, \"recall\": 0.4339175091541349, \"specificity\": 0.9999969297849609, \"npv\": 0.9998654576575492, \"accuracy\": 0.9998624024590385, \"f1\": 0.5998167269618288, \"f2\": 0.4878949206311628, \"f0_5\": 0.7783735678514142, \"p4\": 0.7498374551121951, \"phi\": 0.6490865655508412}, {\"truth_threshold\": -1.7399999611079693, \"match_probability\": 0.23039608193078784, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131891.0, \"tn\": 1278733880.0, \"fp\": 3912.0, \"fn\": 172070.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4339076394669053, \"tn_rate\": 0.9999969407332571, \"fp_rate\": 3.0592667429352086e-06, \"fn_rate\": 0.5660923605330948, \"precision\": 0.9711935671524193, \"recall\": 0.4339076394669053, \"specificity\": 0.9999969407332571, \"npv\": 0.9998654553135827, \"accuracy\": 0.9998624110592268, \"f1\": 0.5998262704541527, \"f2\": 0.4878899594346749, \"f0_5\": 0.7784183395835326, \"p4\": 0.749844913454048, \"phi\": 0.64911243825141}, {\"truth_threshold\": -1.7199999615550041, \"match_probability\": 0.232863354005098, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131881.0, \"tn\": 1278733892.0, \"fp\": 3900.0, \"fn\": 172080.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4338747405094733, \"tn_rate\": 0.9999969501175109, \"fp_rate\": 3.049882489122524e-06, \"fn_rate\": 0.5661252594905267, \"precision\": 0.9712772773804877, \"recall\": 0.4338747405094733, \"specificity\": 0.9999969501175109, \"npv\": 0.999865447496714, \"accuracy\": 0.9998624126228974, \"f1\": 0.5998107981498242, \"f2\": 0.48786090816609634, \"f0_5\": 0.7784401801472107, \"p4\": 0.7498328238177918, \"phi\": 0.6491158108400746}, {\"truth_threshold\": -1.699999962002039, \"match_probability\": 0.23534896780881392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131876.0, \"tn\": 1278734290.0, \"fp\": 3502.0, \"fn\": 172085.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43385829103075724, \"tn_rate\": 0.999997261361929, \"fp_rate\": 2.738638071001815e-06, \"fn_rate\": 0.5661417089692428, \"precision\": 0.9741316905257871, \"recall\": 0.43385829103075724, \"specificity\": 0.999997261361929, \"npv\": 0.9998654436295229, \"accuracy\": 0.9998627198841725, \"f1\": 0.6003382353945359, \"f2\": 0.4879879102027646, \"f0_5\": 0.7798948044467416, \"p4\": 0.7502448677862661, \"phi\": 0.6500569703247904}, {\"truth_threshold\": -1.6799999624490738, \"match_probability\": 0.2378528871293195, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131863.0, \"tn\": 1278734293.0, \"fp\": 3499.0, \"fn\": 172098.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4338155223860956, \"tn_rate\": 0.9999972637079925, \"fp_rate\": 2.736292007548644e-06, \"fn_rate\": 0.5661844776139044, \"precision\": 0.9741507956442724, \"recall\": 0.4338155223860956, \"specificity\": 0.9999972637079925, \"npv\": 0.9998654334662715, \"accuracy\": 0.9998627120658194, \"f1\": 0.6003009175481365, \"f2\": 0.4879455834269534, \"f0_5\": 0.7798769589630581, \"p4\": 0.7502157252624401, \"phi\": 0.6500313023626652}, {\"truth_threshold\": -1.6599999628961086, \"match_probability\": 0.24037507167497607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131855.0, \"tn\": 1278734297.0, \"fp\": 3495.0, \"fn\": 172106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43378920322014997, \"tn_rate\": 0.999997266836077, \"fp_rate\": 2.7331639229444156e-06, \"fn_rate\": 0.5662107967798501, \"precision\": 0.9741780568895456, \"recall\": 0.43378920322014997, \"specificity\": 0.999997266836077, \"npv\": 0.9998654272121899, \"accuracy\": 0.9998627089384783, \"f1\": 0.60028089440055, \"f2\": 0.4879203134412971, \"f0_5\": 0.7798739236846743, \"p4\": 0.7502000882305735, \"phi\": 0.6500206801708392}, {\"truth_threshold\": -1.6399999633431435, \"match_probability\": 0.24291547702854654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131852.0, \"tn\": 1278734434.0, \"fp\": 3358.0, \"fn\": 172109.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43377933353292036, \"tn_rate\": 0.9999973739729747, \"fp_rate\": 2.6260270252495986e-06, \"fn_rate\": 0.5662206664670797, \"precision\": 0.9751645588344058, \"recall\": 0.43377933353292036, \"specificity\": 0.9999973739729747, \"npv\": 0.9998654248811674, \"accuracy\": 0.9998628137044092, \"f1\": 0.6004585913004274, \"f2\": 0.4879597706679378, \"f0_5\": 0.7803731292931708, \"p4\": 0.7503388573974258, \"phi\": 0.650342445220722}, {\"truth_threshold\": -1.6199999637901783, \"match_probability\": 0.24547405460193694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131842.0, \"tn\": 1278734491.0, \"fp\": 3301.0, \"fn\": 172119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4337464345754883, \"tn_rate\": 0.9999974185481804, \"fp_rate\": 2.5814518196393464e-06, \"fn_rate\": 0.5662535654245117, \"precision\": 0.9755740215919434, \"recall\": 0.4337464345754883, \"specificity\": 0.9999974185481804, \"npv\": 0.9998654170690384, \"accuracy\": 0.9998628504506686, \"f1\": 0.6005046640431424, \"f2\": 0.48794696025942513, \"f0_5\": 0.7805615647937972, \"p4\": 0.7503748333904304, \"phi\": 0.6504543493694255}, {\"truth_threshold\": -1.5999999642372131, \"match_probability\": 0.24805075159231657, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131831.0, \"tn\": 1278734496.0, \"fp\": 3296.0, \"fn\": 172130.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43371024572231304, \"tn_rate\": 0.9999974224582862, \"fp_rate\": 2.577541713884061e-06, \"fn_rate\": 0.5662897542776869, \"precision\": 0.9756081316095229, \"recall\": 0.43371024572231304, \"specificity\": 0.9999974224582862, \"npv\": 0.999865408469625, \"accuracy\": 0.9998628457596568, \"f1\": 0.6004764420799475, \"f2\": 0.4879120277193219, \"f0_5\": 0.7805555917387139, \"p4\": 0.7503527989690693, \"phi\": 0.6504385862167169}, {\"truth_threshold\": -1.579999964684248, \"match_probability\": 0.25064551093967435, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131823.0, \"tn\": 1278734498.0, \"fp\": 3294.0, \"fn\": 172138.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43368392655636745, \"tn_rate\": 0.9999974240223284, \"fp_rate\": 2.5759776715819468e-06, \"fn_rate\": 0.5663160734436326, \"precision\": 0.9756211283554252, \"recall\": 0.43368392655636745, \"specificity\": 0.9999974240223284, \"npv\": 0.9998654022153342, \"accuracy\": 0.999862841068645, \"f1\": 0.6004536779342167, \"f2\": 0.487886030758845, \"f0_5\": 0.780545196813468, \"p4\": 0.7503350250686894, \"phi\": 0.650423182281546}, {\"truth_threshold\": -1.5599999651312828, \"match_probability\": 0.2532582712858729, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131809.0, \"tn\": 1278734536.0, \"fp\": 3256.0, \"fn\": 172152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43363786801596255, \"tn_rate\": 0.9999974537391322, \"fp_rate\": 2.546260867841779e-06, \"fn_rate\": 0.5663621319840374, \"precision\": 0.9758930885129382, \"recall\": 0.43363786801596255, \"specificity\": 0.9999974537391322, \"npv\": 0.9998653912739567, \"accuracy\": 0.9998628598326923, \"f1\": 0.6004610205318136, \"f2\": 0.48785299379899016, \"f0_5\": 0.780654591629443, \"p4\": 0.7503407605422623, \"phi\": 0.6504793173788481}, {\"truth_threshold\": -1.5399999655783176, \"match_probability\": 0.2558889669352588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131804.0, \"tn\": 1278734565.0, \"fp\": 3227.0, \"fn\": 172157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43362141853724656, \"tn_rate\": 0.9999974764177455, \"fp_rate\": 2.523582254461124e-06, \"fn_rate\": 0.5663785814627534, \"precision\": 0.9761017840347772, \"recall\": 0.43362141853724656, \"specificity\": 0.9999974764177455, \"npv\": 0.999865387367946, \"accuracy\": 0.9998628785967396, \"f1\": 0.6004847468746584, \"f2\": 0.4878467659850097, \"f0_5\": 0.7807507537747975, \"p4\": 0.7503592874845547, \"phi\": 0.6505365526824747}, {\"truth_threshold\": -1.5199999660253525, \"match_probability\": 0.25853752781688866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131801.0, \"tn\": 1278734606.0, \"fp\": 3186.0, \"fn\": 172160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43361154885001696, \"tn_rate\": 0.9999975084806128, \"fp_rate\": 2.4915193872677847e-06, \"fn_rate\": 0.566388451149983, \"precision\": 0.9763977271885441, \"recall\": 0.43361154885001696, \"specificity\": 0.9999975084806128, \"npv\": 0.9998653850268238, \"accuracy\": 0.9998629083064812, \"f1\": 0.6005312702187958, \"f2\": 0.4878515521186588, \"f0_5\": 0.7808958074863522, \"p4\": 0.7503956130926659, \"phi\": 0.6506277951289603}, {\"truth_threshold\": -1.4999999664723873, \"match_probability\": 0.2612038794484303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131786.0, \"tn\": 1278734623.0, \"fp\": 3169.0, \"fn\": 172175.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4335622004138689, \"tn_rate\": 0.9999975217749723, \"fp_rate\": 2.478225027699815e-06, \"fn_rate\": 0.5664377995861312, \"precision\": 0.9765180986254678, \"recall\": 0.4335622004138689, \"specificity\": 0.9999975217749723, \"npv\": 0.9998653733014249, \"accuracy\": 0.9998629098701518, \"f1\": 0.6005067028770881, \"f2\": 0.4878075864728949, \"f0_5\": 0.7809253822970652, \"p4\": 0.7503764335094149, \"phi\": 0.6506308837108793}, {\"truth_threshold\": -1.4799999669194221, \"match_probability\": 0.2638879429017973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131783.0, \"tn\": 1278734637.0, \"fp\": 3155.0, \"fn\": 172178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4335523307266393, \"tn_rate\": 0.9999975327232684, \"fp_rate\": 2.467276731585016e-06, \"fn_rate\": 0.5664476692733608, \"precision\": 0.9766188916391232, \"recall\": 0.4335523307266393, \"specificity\": 0.9999975327232684, \"npv\": 0.9998653709574611, \"accuracy\": 0.9998629184703401, \"f1\": 0.6005162919031486, \"f2\": 0.4878026210002798, \"f0_5\": 0.7809705433008618, \"p4\": 0.7503839209744945, \"phi\": 0.6506570669021684}, {\"truth_threshold\": -1.459999967366457, \"match_probability\": 0.2665896347705756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131777.0, \"tn\": 1278734638.0, \"fp\": 3154.0, \"fn\": 172184.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43353259135218003, \"tn_rate\": 0.9999975335052895, \"fp_rate\": 2.466494710433959e-06, \"fn_rate\": 0.56646740864782, \"precision\": 0.9766250898607436, \"recall\": 0.43353259135218003, \"specificity\": 0.9999975335052895, \"npv\": 0.9998653662666912, \"accuracy\": 0.9998629145611637, \"f1\": 0.6004985281116995, \"f2\": 0.4877829394236642, \"f0_5\": 0.7809609036548001, \"p4\": 0.7503700519735952, \"phi\": 0.6506443186311968}, {\"truth_threshold\": -1.4399999678134918, \"match_probability\": 0.2693088671393003, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131769.0, \"tn\": 1278734639.0, \"fp\": 3153.0, \"fn\": 172192.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43350627218623444, \"tn_rate\": 0.9999975342873108, \"fp_rate\": 2.465712689282902e-06, \"fn_rate\": 0.5664937278137656, \"precision\": 0.9766309423222306, \"recall\": 0.43350627218623444, \"specificity\": 0.9999975342873108, \"npv\": 0.9998653600122963, \"accuracy\": 0.9998629090883165, \"f1\": 0.6004743861120162, \"f2\": 0.48775657663873684, \"f0_5\": 0.7809468155595515, \"p4\": 0.7503512026990816, \"phi\": 0.650626516574109}, {\"truth_threshold\": -1.4199999682605267, \"match_probability\": 0.27204554755463817, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131761.0, \"tn\": 1278734648.0, \"fp\": 3144.0, \"fn\": 172200.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4334799530202888, \"tn_rate\": 0.9999975413255011, \"fp_rate\": 2.458674498923388e-06, \"fn_rate\": 0.5665200469797113, \"precision\": 0.9766947110929913, \"recall\": 0.4334799530202888, \"specificity\": 0.9999975413255011, \"npv\": 0.9998653537587439, \"accuracy\": 0.9998629098701518, \"f1\": 0.6004611886088237, \"f2\": 0.4877331021529537, \"f0_5\": 0.7809623497921362, \"p4\": 0.750340898816319, \"phi\": 0.650628011993099}, {\"truth_threshold\": -1.3999999687075615, \"match_probability\": 0.27479957899853474, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131755.0, \"tn\": 1278734659.0, \"fp\": 3133.0, \"fn\": 172206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43346021364582954, \"tn_rate\": 0.9999975499277337, \"fp_rate\": 2.4500722662617607e-06, \"fn_rate\": 0.5665397863541705, \"precision\": 0.9767733230531996, \"recall\": 0.43346021364582954, \"specificity\": 0.9999975499277337, \"npv\": 0.999865349069027, \"accuracy\": 0.9998629137793283, \"f1\": 0.600457104835604, \"f2\": 0.48771703046940473, \"f0_5\": 0.7809897417111532, \"p4\": 0.7503377109133637, \"phi\": 0.6506393890916495}, {\"truth_threshold\": -1.3799999691545963, \"match_probability\": 0.2775708598633799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131740.0, \"tn\": 1278734660.0, \"fp\": 3132.0, \"fn\": 172221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43341086520968153, \"tn_rate\": 0.9999975507097549, \"fp_rate\": 2.4492902451107035e-06, \"fn_rate\": 0.5665891347903185, \"precision\": 0.9767779820867193, \"recall\": 0.43341086520968153, \"specificity\": 0.9999975507097549, \"npv\": 0.9998653373419453, \"accuracy\": 0.9998629028336341, \"f1\": 0.6004106345694148, \"f2\": 0.48766728164914014, \"f0_5\": 0.7809600817595374, \"p4\": 0.7503014260250969, \"phi\": 0.6506038994594773}, {\"truth_threshold\": -1.3599999696016312, \"match_probability\": 0.2803592839292471, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131739.0, \"tn\": 1278734661.0, \"fp\": 3131.0, \"fn\": 172222.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4334075753139383, \"tn_rate\": 0.999997551491776, \"fp_rate\": 2.4485082239596466e-06, \"fn_rate\": 0.5665924246860617, \"precision\": 0.9767850522725587, \"recall\": 0.4334075753139383, \"specificity\": 0.999997551491776, \"npv\": 0.999865336560238, \"accuracy\": 0.9998629028336341, \"f1\": 0.6004088134156429, \"f2\": 0.4876643019913912, \"f0_5\": 0.7809615610339076, \"p4\": 0.7503000040502854, \"phi\": 0.6506037854308323}, {\"truth_threshold\": -1.339999970048666, \"match_probability\": 0.2831647403432607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131725.0, \"tn\": 1278734705.0, \"fp\": 3087.0, \"fn\": 172236.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43336151677353346, \"tn_rate\": 0.9999975859007066, \"fp_rate\": 2.414099293313136e-06, \"fn_rate\": 0.5666384832264666, \"precision\": 0.9771014449752248, \"recall\": 0.43336151677353346, \"specificity\": 0.9999975859007066, \"npv\": 0.9998653256194971, \"accuracy\": 0.9998629262886932, \"f1\": 0.6004243652184614, \"f2\": 0.4876334166508719, \"f0_5\": 0.7810934181205371, \"p4\": 0.7503121502496957, \"phi\": 0.6506746061185106}, {\"truth_threshold\": -1.3199999704957008, \"match_probability\": 0.2859871136011437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131724.0, \"tn\": 1278734705.0, \"fp\": 3087.0, \"fn\": 172237.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43335822687779024, \"tn_rate\": 0.9999975859007066, \"fp_rate\": 2.414099293313136e-06, \"fn_rate\": 0.5666417731222098, \"precision\": 0.9771012751184992, \"recall\": 0.43335822687779024, \"specificity\": 0.9999975859007066, \"npv\": 0.9998653248376848, \"accuracy\": 0.999862925506858, \"f1\": 0.6004211754624269, \"f2\": 0.48763007577804846, \"f0_5\": 0.7810911937192023, \"p4\": 0.7503096595872468, \"phi\": 0.6506720794543568}, {\"truth_threshold\": -1.2999999709427357, \"match_probability\": 0.2888262835309975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131712.0, \"tn\": 1278734738.0, \"fp\": 3054.0, \"fn\": 172249.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4333187481288718, \"tn_rate\": 0.9999976117074046, \"fp_rate\": 2.3882925953282532e-06, \"fn_rate\": 0.5666812518711282, \"precision\": 0.9773384978407017, \"recall\": 0.4333187481288718, \"specificity\": 0.9999976117074046, \"npv\": 0.9998653154594112, \"accuracy\": 0.9998629419253994, \"f1\": 0.6004280566274699, \"f2\": 0.48760189840146306, \"f0_5\": 0.7811867975445568, \"p4\": 0.7503150346806815, \"phi\": 0.6507214451647749}, {\"truth_threshold\": -1.2799999713897705, \"match_probability\": 0.2916821252793642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131664.0, \"tn\": 1278734809.0, \"fp\": 2983.0, \"fn\": 172297.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43316083313319803, \"tn_rate\": 0.9999976672309064, \"fp_rate\": 2.332769093603202e-06, \"fn_rate\": 0.566839166866802, \"precision\": 0.977845774506673, \"recall\": 0.43316083313319803, \"specificity\": 0.9999976672309064, \"npv\": 0.9998652779398975, \"accuracy\": 0.9998629599076114, \"f1\": 0.6003720862364571, \"f2\": 0.4874671508362514, \"f0_5\": 0.7813432809249077, \"p4\": 0.7502713344517713, \"phi\": 0.6507717366843514}, {\"truth_threshold\": -1.2599999718368053, \"match_probability\": 0.2945545092996211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131644.0, \"tn\": 1278734849.0, \"fp\": 2943.0, \"fn\": 172317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4330950352183339, \"tn_rate\": 0.9999976985117525, \"fp_rate\": 2.3014882475609198e-06, \"fn_rate\": 0.5669049647816661, \"precision\": 0.978133103494394, \"recall\": 0.4330950352183339, \"specificity\": 0.9999976985117525, \"npv\": 0.9998652623078663, \"accuracy\": 0.9998629755443175, \"f1\": 0.6003630161350639, \"f2\": 0.48741475869555717, \"f0_5\": 0.7814471886208031, \"p4\": 0.7502642542553178, \"phi\": 0.650817936007343}, {\"truth_threshold\": -1.2399999722838402, \"match_probability\": 0.29744330134275365, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131604.0, \"tn\": 1278734908.0, \"fp\": 2884.0, \"fn\": 172357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43296343938860576, \"tn_rate\": 0.9999977446510003, \"fp_rate\": 2.2553489996485534e-06, \"fn_rate\": 0.5670365606113942, \"precision\": 0.9785557075724228, \"recall\": 0.43296343938860576, \"specificity\": 0.9999977446510003, \"npv\": 0.9998652310415955, \"accuracy\": 0.9998629903991884, \"f1\": 0.6003161143029178, \"f2\": 0.4873023819327395, \"f0_5\": 0.7815771938430693, \"p4\": 0.7502276317216493, \"phi\": 0.6508596531292044}, {\"truth_threshold\": -1.219999972730875, \"match_probability\": 0.3003483624505542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131589.0, \"tn\": 1278734923.0, \"fp\": 2869.0, \"fn\": 172372.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4329140909524577, \"tn_rate\": 0.9999977563813176, \"fp_rate\": 2.2436186823826978e-06, \"fn_rate\": 0.5670859090475423, \"precision\": 0.9786624819646284, \"recall\": 0.4329140909524577, \"specificity\": 0.9999977563813176, \"npv\": 0.9998652193159943, \"accuracy\": 0.9998629903991884, \"f1\": 0.6002887648573625, \"f2\": 0.48725766532227605, \"f0_5\": 0.7815995143699223, \"p4\": 0.7502062741408801, \"phi\": 0.6508580757958428}, {\"truth_threshold\": -1.1999999731779099, \"match_probability\": 0.30326954895129116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131582.0, \"tn\": 1278734923.0, \"fp\": 2869.0, \"fn\": 172379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4328910616822553, \"tn_rate\": 0.9999977563813176, \"fp_rate\": 2.2436186823826978e-06, \"fn_rate\": 0.5671089383177447, \"precision\": 0.9786613710571137, \"recall\": 0.4328910616822553, \"specificity\": 0.9999977563813176, \"npv\": 0.9998652138433095, \"accuracy\": 0.9998629849263412, \"f1\": 0.6002664160652537, \"f2\": 0.4872342710296639, \"f0_5\": 0.7815839337582342, \"p4\": 0.750188820330885, \"phi\": 0.6508403927087875}, {\"truth_threshold\": -1.1799999736249447, \"match_probability\": 0.3062067124578904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131567.0, \"tn\": 1278734940.0, \"fp\": 2852.0, \"fn\": 172394.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4328417132461072, \"tn_rate\": 0.9999977696756772, \"fp_rate\": 2.2303243228147275e-06, \"fn_rate\": 0.5671582867538928, \"precision\": 0.9787827613655807, \"recall\": 0.4328417132461072, \"specificity\": 0.9999977696756772, \"npv\": 0.9998652021179198, \"accuracy\": 0.9998629864900118, \"f1\": 0.6002417993521603, \"f2\": 0.48719027330231224, \"f0_5\": 0.7816136885616959, \"p4\": 0.7501695958396019, \"phi\": 0.6508436666947415}, {\"truth_threshold\": -1.1599999740719795, \"match_probability\": 0.30915969986867026, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131555.0, \"tn\": 1278734958.0, \"fp\": 2834.0, \"fn\": 172406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4328022344971888, \"tn_rate\": 0.999997783752058, \"fp_rate\": 2.2162479420957004e-06, \"fn_rate\": 0.5671977655028112, \"precision\": 0.9789119645209057, \"recall\": 0.4328022344971888, \"specificity\": 0.999997783752058, \"npv\": 0.9998651927380723, \"accuracy\": 0.9998629911810236, \"f1\": 0.6002281282080529, \"f2\": 0.4871566611096011, \"f0_5\": 0.7816538465651912, \"p4\": 0.7501589196037496, \"phi\": 0.6508569516596036}, {\"truth_threshold\": -1.1399999745190144, \"match_probability\": 0.31212835337067063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131544.0, \"tn\": 1278734959.0, \"fp\": 2833.0, \"fn\": 172417.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43276604564401355, \"tn_rate\": 0.9999977845340791, \"fp_rate\": 2.2154659209446436e-06, \"fn_rate\": 0.5672339543559864, \"precision\": 0.9789175230880285, \"recall\": 0.43276604564401355, \"specificity\": 0.9999977845340791, \"npv\": 0.9998651841382452, \"accuracy\": 0.9998629833626705, \"f1\": 0.6001943705542299, \"f2\": 0.48712025660984387, \"f0_5\": 0.7816330726384454, \"p4\": 0.7501325536545909, \"phi\": 0.650831585966235}, {\"truth_threshold\": -1.1199999749660492, \"match_probability\": 0.3151125104456104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131538.0, \"tn\": 1278735006.0, \"fp\": 2786.0, \"fn\": 172423.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4327463062695543, \"tn_rate\": 0.9999978212890731, \"fp_rate\": 2.178710926844962e-06, \"fn_rate\": 0.5672536937304457, \"precision\": 0.9792591048509574, \"recall\": 0.4327463062695543, \"specificity\": 0.9999978212890731, \"npv\": 0.9998651794523277, \"accuracy\": 0.9998630154179181, \"f1\": 0.6002395701427153, \"f2\": 0.4871171587535773, \"f0_5\": 0.7817943862577073, \"p4\": 0.7501678589548413, \"phi\": 0.6509303220639601}, {\"truth_threshold\": -1.099999975413084, \"match_probability\": 0.318112003878512, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131523.0, \"tn\": 1278735013.0, \"fp\": 2779.0, \"fn\": 172438.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4326969578334063, \"tn_rate\": 0.9999978267632212, \"fp_rate\": 2.1732367787875623e-06, \"fn_rate\": 0.5673030421665938, \"precision\": 0.9793078286250391, \"recall\": 0.4326969578334063, \"specificity\": 0.9999978267632212, \"npv\": 0.9998651677258857, \"accuracy\": 0.9998630091632357, \"f1\": 0.6002012490217061, \"f2\": 0.4870695465527432, \"f0_5\": 0.7817870130734728, \"p4\": 0.7501379294838817, \"phi\": 0.6509094013293231}, {\"truth_threshold\": -1.0799999758601189, \"match_probability\": 0.3211266617690227, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131518.0, \"tn\": 1278735043.0, \"fp\": 2749.0, \"fn\": 172443.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43268050835469024, \"tn_rate\": 0.9999978502238558, \"fp_rate\": 2.1497761442558505e-06, \"fn_rate\": 0.5673194916453098, \"precision\": 0.9795258700946621, \"recall\": 0.43268050835469024, \"specificity\": 0.9999978502238558, \"npv\": 0.9998651638199888, \"accuracy\": 0.9998630287091183, \"f1\": 0.600226366183813, \"f2\": 0.48706365624752335, \"f0_5\": 0.7818874259983901, \"p4\": 0.7501575487661502, \"phi\": 0.650969511544693}, {\"truth_threshold\": -1.0599999763071537, \"match_probability\": 0.32415630754546576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131500.0, \"tn\": 1278735081.0, \"fp\": 2711.0, \"fn\": 172461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43262129023131257, \"tn_rate\": 0.9999978799406595, \"fp_rate\": 2.1200593405156827e-06, \"fn_rate\": 0.5673787097686874, \"precision\": 0.9798004634493447, \"recall\": 0.43262129023131257, \"specificity\": 0.9999978799406595, \"npv\": 0.9998651497513805, \"accuracy\": 0.9998630443458244, \"f1\": 0.6002209178130963, \"f2\": 0.487017195595735, \"f0_5\": 0.7819886894107433, \"p4\": 0.7501532958357833, \"phi\": 0.6510162245512119}, {\"truth_threshold\": -1.0399999767541885, \"match_probability\": 0.327200759981648, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131468.0, \"tn\": 1278735098.0, \"fp\": 2694.0, \"fn\": 172493.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43251601356753006, \"tn_rate\": 0.9999978932350191, \"fp_rate\": 2.1067649809477125e-06, \"fn_rate\": 0.56748398643247, \"precision\": 0.979919798452617, \"recall\": 0.43251601356753006, \"specificity\": 0.9999978932350191, \"npv\": 0.9998651247351928, \"accuracy\": 0.9998630326182948, \"f1\": 0.600141969264339, \"f2\": 0.4869163544458321, \"f0_5\": 0.7819806830524061, \"p4\": 0.7500916327871202, \"phi\": 0.6509766546921595}, {\"truth_threshold\": -1.0199999772012234, \"match_probability\": 0.3302598332164518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131445.0, \"tn\": 1278735116.0, \"fp\": 2676.0, \"fn\": 172516.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43244034596543635, \"tn_rate\": 0.9999979073113998, \"fp_rate\": 2.0926886002286854e-06, \"fn_rate\": 0.5675596540345637, \"precision\": 0.980047867224372, \"recall\": 0.43244034596543635, \"specificity\": 0.9999979073113998, \"npv\": 0.999865106755419, \"accuracy\": 0.9998630287091183, \"f1\": 0.6000931332490265, \"f2\": 0.4868459552655069, \"f0_5\": 0.7819964423608922, \"p4\": 0.7500534866660473, \"phi\": 0.6509622530002263}, {\"truth_threshold\": -0.9999999776482582, \"match_probability\": 0.3333333367762326, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131429.0, \"tn\": 1278735123.0, \"fp\": 2669.0, \"fn\": 172532.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4323877076335451, \"tn_rate\": 0.9999979127855478, \"fp_rate\": 2.087214452171286e-06, \"fn_rate\": 0.5676122923664549, \"precision\": 0.9800966457367001, \"recall\": 0.4323877076335451, \"specificity\": 0.9999979127855478, \"npv\": 0.9998650942471683, \"accuracy\": 0.9998630216726005, \"f1\": 0.6000515912240132, \"f2\": 0.4867949882291239, \"f0_5\": 0.7819868555238096, \"p4\": 0.750021035572044, \"phi\": 0.6509388334781531}, {\"truth_threshold\": -0.979999978095293, \"match_probability\": 0.3364210756000459, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131422.0, \"tn\": 1278735154.0, \"fp\": 2638.0, \"fn\": 172539.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4323646783633427, \"tn_rate\": 0.9999979370282035, \"fp_rate\": 2.0629717964885175e-06, \"fn_rate\": 0.5676353216366573, \"precision\": 0.9803222437714456, \"recall\": 0.4323646783633427, \"specificity\": 0.9999979370282035, \"npv\": 0.9998650887777559, \"accuracy\": 0.9998630404366479, \"f1\": 0.600071686060714, \"f2\": 0.4867827638113525, \"f0_5\": 0.7820866673569776, \"p4\": 0.750036735287186, \"phi\": 0.6509964352242154}, {\"truth_threshold\": -0.9599999785423279, \"match_probability\": 0.33952285006771876, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131413.0, \"tn\": 1278735172.0, \"fp\": 2620.0, \"fn\": 172548.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43233506930165383, \"tn_rate\": 0.9999979511045842, \"fp_rate\": 2.0488954157694904e-06, \"fn_rate\": 0.5676649306983461, \"precision\": 0.9804525751120993, \"recall\": 0.43233506930165383, \"specificity\": 0.9999979511045842, \"npv\": 0.9998650817433489, \"accuracy\": 0.9998630474731657, \"f1\": 0.6000675808344407, \"f2\": 0.4867591639830888, \"f0_5\": 0.782133644727429, \"p4\": 0.7500335295131626, \"phi\": 0.6510174295254174}, {\"truth_threshold\": -0.9399999789893627, \"match_probability\": 0.34263845603078413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131396.0, \"tn\": 1278735198.0, \"fp\": 2594.0, \"fn\": 172565.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4322791410740194, \"tn_rate\": 0.9999979714371342, \"fp_rate\": 2.028562865842007e-06, \"fn_rate\": 0.5677208589259807, \"precision\": 0.9806403462944996, \"recall\": 0.4322791410740194, \"specificity\": 0.9999979714371342, \"npv\": 0.9998650684552925, \"accuracy\": 0.9998630545096834, \"f1\": 0.6000488639139995, \"f2\": 0.48671169936451447, \"f0_5\": 0.7821926109717462, \"p4\": 0.7500189097245187, \"phi\": 0.65103767132908}, {\"truth_threshold\": -0.9199999794363976, \"match_probability\": 0.34576768484629017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131383.0, \"tn\": 1278735199.0, \"fp\": 2593.0, \"fn\": 172578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4322363724293577, \"tn_rate\": 0.9999979722191553, \"fp_rate\": 2.0277808446909496e-06, \"fn_rate\": 0.5677636275706422, \"precision\": 0.980645787305189, \"recall\": 0.4322363724293577, \"specificity\": 0.9999979722191553, \"npv\": 0.9998650582918459, \"accuracy\": 0.9998630451276598, \"f1\": 0.6000086770471552, \"f2\": 0.48666859284941694, \"f0_5\": 0.7821673721371887, \"p4\": 0.7499875151568958, \"phi\": 0.6510072678299327}, {\"truth_threshold\": -0.8999999798834324, \"match_probability\": 0.3489103234134934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131376.0, \"tn\": 1278735202.0, \"fp\": 2590.0, \"fn\": 172585.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43221334315915527, \"tn_rate\": 0.9999979745652188, \"fp_rate\": 2.0254347812377786e-06, \"fn_rate\": 0.5677866568408447, \"precision\": 0.9806667363360853, \"recall\": 0.43221334315915527, \"specificity\": 0.9999979745652188, \"npv\": 0.9998650528194806, \"accuracy\": 0.9998630420003185, \"f1\": 0.5999904093604642, \"f2\": 0.48664626873411815, \"f0_5\": 0.7821629506147114, \"p4\": 0.7499732438118187, \"phi\": 0.6509968791488675}, {\"truth_threshold\": -0.8799999803304672, \"match_probability\": 0.35206615421344434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131366.0, \"tn\": 1278735212.0, \"fp\": 2580.0, \"fn\": 172595.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43218044420172325, \"tn_rate\": 0.9999979823854303, \"fp_rate\": 2.017614569727208e-06, \"fn_rate\": 0.5678195557982767, \"precision\": 0.9807385065623461, \"recall\": 0.43218044420172325, \"specificity\": 0.9999979823854303, \"npv\": 0.999865045002419, \"accuracy\": 0.9998630420003185, \"f1\": 0.5999721402032852, \"f2\": 0.48661643663088333, \"f0_5\": 0.7821779230599766, \"p4\": 0.7499589714320304, \"phi\": 0.6509959293429067}, {\"truth_threshold\": -0.8599999807775021, \"match_probability\": 0.35523495535147065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131353.0, \"tn\": 1278735222.0, \"fp\": 2570.0, \"fn\": 172608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4321376755570616, \"tn_rate\": 0.9999979902056417, \"fp_rate\": 2.0097943582166374e-06, \"fn_rate\": 0.5678623244429384, \"precision\": 0.9808098683571903, \"recall\": 0.4321376755570616, \"specificity\": 0.9999979902056417, \"npv\": 0.9998650348399227, \"accuracy\": 0.9998630396548126, \"f1\": 0.5999442774798805, \"f2\": 0.4865765721046669, \"f0_5\": 0.7821862126378397, \"p4\": 0.7499372033307, \"phi\": 0.6509874055539471}, {\"truth_threshold\": -0.8399999812245369, \"match_probability\": 0.358416500602555, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131347.0, \"tn\": 1278735226.0, \"fp\": 2566.0, \"fn\": 172614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43211793618260236, \"tn_rate\": 0.9999979933337264, \"fp_rate\": 2.006666273612409e-06, \"fn_rate\": 0.5678820638173976, \"precision\": 0.9808383054669823, \"recall\": 0.43211793618260236, \"specificity\": 0.9999979933337264, \"npv\": 0.999865030149475, \"accuracy\": 0.999863038091142, \"f1\": 0.599930573635338, \"f2\": 0.48655795080151465, \"f0_5\": 0.7821877460210835, \"p4\": 0.7499264966948347, \"phi\": 0.6509819762863405}, {\"truth_threshold\": -0.8199999816715717, \"match_probability\": 0.3616105594596116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131327.0, \"tn\": 1278735246.0, \"fp\": 2546.0, \"fn\": 172634.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4320521382677383, \"tn_rate\": 0.9999980089741494, \"fp_rate\": 1.991025850591268e-06, \"fn_rate\": 0.5679478617322617, \"precision\": 0.9809819754543485, \"recall\": 0.4320521382677383, \"specificity\": 0.9999980089741494, \"npv\": 0.9998650145153535, \"accuracy\": 0.999863038091142, \"f1\": 0.5998940237624305, \"f2\": 0.4864982807507055, \"f0_5\": 0.7822177060538231, \"p4\": 0.7498979404432286, \"phi\": 0.6509800968064785}, {\"truth_threshold\": -0.7999999821186066, \"match_probability\": 0.36481689718465177, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131318.0, \"tn\": 1278735264.0, \"fp\": 2528.0, \"fn\": 172643.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43202252920604944, \"tn_rate\": 0.9999980230505301, \"fp_rate\": 1.976949469872241e-06, \"fn_rate\": 0.5679774707939506, \"precision\": 0.981112621968531, \"recall\": 0.43202252920604944, \"specificity\": 0.9999980230505301, \"npv\": 0.9998650074809491, \"accuracy\": 0.9998630451276598, \"f1\": 0.5998899058260831, \"f2\": 0.48647467196170974, \"f0_5\": 0.782264742150129, \"p4\": 0.7498947240259702, \"phi\": 0.6510011499422368}, {\"truth_threshold\": -0.7799999825656414, \"match_probability\": 0.3680352748628328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131303.0, \"tn\": 1278735271.0, \"fp\": 2521.0, \"fn\": 172658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4319731807699014, \"tn_rate\": 0.9999980285246782, \"fp_rate\": 1.9714753218148417e-06, \"fn_rate\": 0.5680268192300986, \"precision\": 0.981161824485892, \"recall\": 0.4319731807699014, \"specificity\": 0.9999980285246782, \"npv\": 0.9998649957545146, \"accuracy\": 0.9998630388729772, \"f1\": 0.5998515252920954, \"f2\": 0.48642703242575214, \"f0_5\": 0.7822574014872679, \"p4\": 0.7498647350484514, \"phi\": 0.6509802930117504}, {\"truth_threshold\": -0.7599999830126762, \"match_probability\": 0.37126544945937895, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131297.0, \"tn\": 1278735272.0, \"fp\": 2520.0, \"fn\": 172664.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4319534413954422, \"tn_rate\": 0.9999980293066993, \"fp_rate\": 1.9706933006637844e-06, \"fn_rate\": 0.5680465586045578, \"precision\": 0.9811683119484071, \"recall\": 0.4319534413954422, \"specificity\": 0.9999980293066993, \"npv\": 0.9998649910637508, \"accuracy\": 0.9998630349638008, \"f1\": 0.5998337056681697, \"f2\": 0.48640732746963866, \"f0_5\": 0.7822477535928811, \"p4\": 0.7498508108936128, \"phi\": 0.6509675706545459}, {\"truth_threshold\": -0.7399999834597111, \"match_probability\": 0.3745071738793591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131282.0, \"tn\": 1278735275.0, \"fp\": 2517.0, \"fn\": 172679.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4319040929592941, \"tn_rate\": 0.9999980316527628, \"fp_rate\": 1.9683472372106135e-06, \"fn_rate\": 0.5680959070407059, \"precision\": 0.9811882002107639, \"recall\": 0.4319040929592941, \"specificity\": 0.9999980316527628, \"npv\": 0.9998649793368944, \"accuracy\": 0.9998630255817771, \"f1\": 0.5997898391812866, \"f2\": 0.4863582443653618, \"f0_5\": 0.7822254953483079, \"p4\": 0.749816532577602, \"phi\": 0.6509369805165838}, {\"truth_threshold\": -0.7199999839067459, \"match_probability\": 0.3777601970303052, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131248.0, \"tn\": 1278735280.0, \"fp\": 2512.0, \"fn\": 172713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4317922365040252, \"tn_rate\": 0.9999980355628686, \"fp_rate\": 1.964437131455328e-06, \"fn_rate\": 0.5682077634959748, \"precision\": 0.9812200956937799, \"recall\": 0.4317922365040252, \"specificity\": 0.9999980355628686, \"npv\": 0.9998649527558313, \"accuracy\": 0.9998630029085532, \"f1\": 0.5996879290689732, \"f2\": 0.48624633596225264, \"f0_5\": 0.7821683168434841, \"p4\": 0.7497368902129903, \"phi\": 0.6508632575209783}, {\"truth_threshold\": -0.6999999843537807, \"match_probability\": 0.3810242638876482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131241.0, \"tn\": 1278735286.0, \"fp\": 2506.0, \"fn\": 172720.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4317692072338228, \"tn_rate\": 0.9999980402549955, \"fp_rate\": 1.9597450045489856e-06, \"fn_rate\": 0.5682307927661773, \"precision\": 0.9812631311356517, \"recall\": 0.4317692072338228, \"specificity\": 0.9999980402549955, \"npv\": 0.9998649472837845, \"accuracy\": 0.9998630021267179, \"f1\": 0.5996737551061438, \"f2\": 0.4862250859704903, \"f0_5\": 0.782175078580462, \"p4\": 0.7497258128447354, \"phi\": 0.6508601768837554}, {\"truth_threshold\": -0.6799999848008156, \"match_probability\": 0.38429911556295054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131227.0, \"tn\": 1278735290.0, \"fp\": 2502.0, \"fn\": 172734.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4317231486934179, \"tn_rate\": 0.9999980433830801, \"fp_rate\": 1.9566169199447574e-06, \"fn_rate\": 0.5682768513065821, \"precision\": 0.98129052038077, \"recall\": 0.4317231486934179, \"specificity\": 0.9999980433830801, \"npv\": 0.9998649363388465, \"accuracy\": 0.9998629943083649, \"f1\": 0.5996344444698303, \"f2\": 0.486179702765245, \"f0_5\": 0.7821587670182876, \"p4\": 0.7496950886063799, \"phi\": 0.6508345437877078}, {\"truth_threshold\": -0.6599999852478504, \"match_probability\": 0.38758448937490547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131221.0, \"tn\": 1278735296.0, \"fp\": 2496.0, \"fn\": 172740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4317034093189587, \"tn_rate\": 0.999998048075207, \"fp_rate\": 1.951924793038415e-06, \"fn_rate\": 0.5682965906810413, \"precision\": 0.9813337122430207, \"recall\": 0.4317034093189587, \"specificity\": 0.999998048075207, \"npv\": 0.9998649316486116, \"accuracy\": 0.9998629943083649, \"f1\": 0.5996234674806593, \"f2\": 0.48616179631746914, \"f0_5\": 0.7821677600559828, \"p4\": 0.749686509295531, \"phi\": 0.6508339915532967}, {\"truth_threshold\": -0.6399999856948853, \"match_probability\": 0.3908801189230734, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131214.0, \"tn\": 1278735311.0, \"fp\": 2481.0, \"fn\": 172747.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43168038004875625, \"tn_rate\": 0.9999980598055243, \"fp_rate\": 1.9401944757725593e-06, \"fn_rate\": 0.5683196199512437, \"precision\": 0.9814428363065185, \"recall\": 0.43168038004875625, \"specificity\": 0.9999980598055243, \"npv\": 0.9998649261775158, \"accuracy\": 0.9998630005630473, \"f1\": 0.599621620633557, \"f2\": 0.486143786878334, \"f0_5\": 0.7822080952284436, \"p4\": 0.7496850667186391, \"phi\": 0.650852828161638}, {\"truth_threshold\": -0.6199999861419201, \"match_probability\": 0.39418573416432234, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131207.0, \"tn\": 1278735321.0, \"fp\": 2471.0, \"fn\": 172754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4316573507785538, \"tn_rate\": 0.9999980676257357, \"fp_rate\": 1.9323742642619887e-06, \"fn_rate\": 0.5683426492214462, \"precision\": 0.9815152829934619, \"recall\": 0.4316573507785538, \"specificity\": 0.9999980676257357, \"npv\": 0.9998649207058921, \"accuracy\": 0.9998630029085532, \"f1\": 0.599612922979899, \"f2\": 0.4861239757484502, \"f0_5\": 0.7822297844332654, \"p4\": 0.7496782691037096, \"phi\": 0.6508594951612302}, {\"truth_threshold\": -0.5999999865889549, \"match_probability\": 0.39750106149193387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131202.0, \"tn\": 1278735326.0, \"fp\": 2466.0, \"fn\": 172759.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4316409012998378, \"tn_rate\": 0.9999980715358415, \"fp_rate\": 1.9284641585067036e-06, \"fn_rate\": 0.5683590987001622, \"precision\": 0.9815513062213843, \"recall\": 0.4316409012998378, \"specificity\": 0.9999980715358415, \"npv\": 0.9998649167973631, \"accuracy\": 0.9998630029085532, \"f1\": 0.5996037739729314, \"f2\": 0.4861090527538844, \"f0_5\": 0.7822372837701355, \"p4\": 0.7496711183088726, \"phi\": 0.6508590403674854}, {\"truth_threshold\": -0.5799999870359898, \"match_probability\": 0.40082582381733545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131182.0, \"tn\": 1278735336.0, \"fp\": 2456.0, \"fn\": 172779.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43157510338497374, \"tn_rate\": 0.999998079356053, \"fp_rate\": 1.920643946996133e-06, \"fn_rate\": 0.5684248966150263, \"precision\": 0.9816219937442943, \"recall\": 0.43157510338497374, \"specificity\": 0.999998079356053, \"npv\": 0.9998649011621917, \"accuracy\": 0.9998629950902002, \"f1\": 0.5995534724713721, \"f2\": 0.4860457568163192, \"f0_5\": 0.7822299713898294, \"p4\": 0.7496318004744718, \"phi\": 0.6508328687561806}, {\"truth_threshold\": -0.5599999874830246, \"match_probability\": 0.4041597406544148, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131166.0, \"tn\": 1278735350.0, \"fp\": 2442.0, \"fn\": 172795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43152246505308245, \"tn_rate\": 0.9999980903043492, \"fp_rate\": 1.909695650881334e-06, \"fn_rate\": 0.5684775349469176, \"precision\": 0.9817226513382432, \"recall\": 0.43152246505308245, \"specificity\": 0.9999980903043492, \"npv\": 0.9998648886546891, \"accuracy\": 0.9998629935265295, \"f1\": 0.5995214469032313, \"f2\": 0.4859972788954331, \"f0_5\": 0.7822465120772716, \"p4\": 0.7496067670934768, \"phi\": 0.6508265516938329}, {\"truth_threshold\": -0.5399999879300594, \"match_probability\": 0.407502528206371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131158.0, \"tn\": 1278735354.0, \"fp\": 2438.0, \"fn\": 172803.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43149614588713686, \"tn_rate\": 0.9999980934324337, \"fp_rate\": 1.906567566277106e-06, \"fn_rate\": 0.5685038541128632, \"precision\": 0.9817509506272643, \"recall\": 0.43149614588713686, \"specificity\": 0.9999980934324337, \"npv\": 0.9998648824006211, \"accuracy\": 0.9998629903991884, \"f1\": 0.5995013221134617, \"f2\": 0.4859719587384396, \"f0_5\": 0.7822435870673768, \"p4\": 0.7495910353629296, \"phi\": 0.6508160855237168}, {\"truth_threshold\": -0.5199999883770943, \"match_probability\": 0.41085389945505063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131144.0, \"tn\": 1278735357.0, \"fp\": 2435.0, \"fn\": 172817.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43145008734673196, \"tn_rate\": 0.9999980957784972, \"fp_rate\": 1.9042215028239348e-06, \"fn_rate\": 0.568549912653268, \"precision\": 0.9817710867726215, \"recall\": 0.43145008734673196, \"specificity\": 0.9999980957784972, \"npv\": 0.9998648714555796, \"accuracy\": 0.9998629817989999, \"f1\": 0.5994606207432464, \"f2\": 0.48592620697883465, \"f0_5\": 0.7822235370885757, \"p4\": 0.7495592172033623, \"phi\": 0.6507880228368916}, {\"truth_threshold\": -0.4999999888241291, \"match_probability\": 0.4142135642527169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131131.0, \"tn\": 1278735358.0, \"fp\": 2434.0, \"fn\": 172830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43140731870207033, \"tn_rate\": 0.9999980965605183, \"fp_rate\": 1.9034394816728777e-06, \"fn_rate\": 0.5685926812979296, \"precision\": 0.9817766630479542, \"recall\": 0.43140731870207033, \"specificity\": 0.9999980965605183, \"npv\": 0.9998648612921384, \"accuracy\": 0.9998629724169763, \"f1\": 0.5994203773032917, \"f2\": 0.4858830791850358, \"f0_5\": 0.7821982508192947, \"p4\": 0.7495277553138143, \"phi\": 0.6507576119008813}, {\"truth_threshold\": -0.47999998927116394, \"match_probability\": 0.41758122941619635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131099.0, \"tn\": 1278735366.0, \"fp\": 2426.0, \"fn\": 172862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4313020420382878, \"tn_rate\": 0.9999981028166876, \"fp_rate\": 1.8971833124644212e-06, \"fn_rate\": 0.5686979579617122, \"precision\": 0.9818311177682082, \"recall\": 0.4313020420382878, \"specificity\": 0.9999981028166876, \"npv\": 0.9998648362750232, \"accuracy\": 0.999862953652929, \"f1\": 0.5993288928102842, \"f2\": 0.4857789085120527, \"f0_5\": 0.7821566687866396, \"p4\": 0.7494562281889761, \"phi\": 0.6506962480162222}, {\"truth_threshold\": -0.4599999897181988, \"match_probability\": 0.4209565988233432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131077.0, \"tn\": 1278735387.0, \"fp\": 2405.0, \"fn\": 172884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4312296643319373, \"tn_rate\": 0.9999981192391317, \"fp_rate\": 1.880760868292223e-06, \"fn_rate\": 0.5687703356680627, \"precision\": 0.9819825894128047, \"recall\": 0.4312296643319373, \"specificity\": 0.9999981192391317, \"npv\": 0.9998648190773958, \"accuracy\": 0.9998629528710936, \"f1\": 0.599287221420848, \"f2\": 0.48571286701656974, \"f0_5\": 0.7821859458711118, \"p4\": 0.7494236458034861, \"phi\": 0.6506918485490863}, {\"truth_threshold\": -0.4399999901652336, \"match_probability\": 0.4243393735117586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131069.0, \"tn\": 1278735392.0, \"fp\": 2400.0, \"fn\": 172892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4312033451659917, \"tn_rate\": 0.9999981231492374, \"fp_rate\": 1.8768507625369377e-06, \"fn_rate\": 0.5687966548340083, \"precision\": 0.9820182963834299, \"recall\": 0.4312033451659917, \"specificity\": 0.9999981231492374, \"npv\": 0.9998648128234346, \"accuracy\": 0.9998629505255877, \"f1\": 0.5992684543812724, \"f2\": 0.48568790191749434, \"f0_5\": 0.7821867499286854, \"p4\": 0.7494089712341017, \"phi\": 0.6506838236839168}, {\"truth_threshold\": -0.41999999061226845, \"match_probability\": 0.4277292517797018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131057.0, \"tn\": 1278735406.0, \"fp\": 2386.0, \"fn\": 172904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4311638664170732, \"tn_rate\": 0.9999981340975336, \"fp_rate\": 1.8659024664221388e-06, \"fn_rate\": 0.5688361335829267, \"precision\": 0.9821197065413697, \"recall\": 0.4311638664170732, \"specificity\": 0.9999981340975336, \"npv\": 0.9998648034431804, \"accuracy\": 0.9998629520892583, \"f1\": 0.5992492066830665, \"f2\": 0.48565279291951974, \"f0_5\": 0.7822122322983576, \"p4\": 0.7493939210216322, \"phi\": 0.6506876407304004}, {\"truth_threshold\": -0.3999999910593033, \"match_probability\": 0.43112592928912336, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131034.0, \"tn\": 1278735416.0, \"fp\": 2376.0, \"fn\": 172927.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43108819881497956, \"tn_rate\": 0.999998141917745, \"fp_rate\": 1.8580822549115682e-06, \"fn_rate\": 0.5689118011850205, \"precision\": 0.9821902406116483, \"recall\": 0.43108819881497956, \"specificity\": 0.999998141917745, \"npv\": 0.9998647854625811, \"accuracy\": 0.9998629419253994, \"f1\": 0.5991892466578717, \"f2\": 0.48557943871205866, \"f0_5\": 0.7821982065446436, \"p4\": 0.749347032481807, \"phi\": 0.6506539076871205}, {\"truth_threshold\": -0.3799999915063381, \"match_probability\": 0.43452909917075166, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131017.0, \"tn\": 1278735418.0, \"fp\": 2374.0, \"fn\": 172944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4310322705873451, \"tn_rate\": 0.9999981434817874, \"fp_rate\": 1.856518212609454e-06, \"fn_rate\": 0.5689677294126549, \"precision\": 0.9822026973334033, \"recall\": 0.4310322705873451, \"specificity\": 0.9999981434817874, \"npv\": 0.9998647721720033, \"accuracy\": 0.9998629301978698, \"f1\": 0.5991375368124531, \"f2\": 0.4855232780056847, \"f0_5\": 0.7821676964866721, \"p4\": 0.7493065923155694, \"phi\": 0.6506158221444822}, {\"truth_threshold\": -0.35999999195337296, \"match_probability\": 0.4379384521311571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130989.0, \"tn\": 1278735429.0, \"fp\": 2363.0, \"fn\": 172972.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43094015350653536, \"tn_rate\": 0.9999981520840201, \"fp_rate\": 1.8479159799478267e-06, \"fn_rate\": 0.5690598464934646, \"precision\": 0.9822799808026876, \"recall\": 0.43094015350653536, \"specificity\": 0.9999981520840201, \"npv\": 0.9998647502824559, \"accuracy\": 0.9998629169066696, \"f1\": 0.5990629137482764, \"f2\": 0.4854335470902671, \"f0_5\": 0.7821462222747677, \"p4\": 0.7492482285532387, \"phi\": 0.6505718916910901}, {\"truth_threshold\": -0.3399999924004078, \"match_probability\": 0.441353676561721, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130976.0, \"tn\": 1278735440.0, \"fp\": 2352.0, \"fn\": 172985.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43089738486187373, \"tn_rate\": 0.9999981606862527, \"fp_rate\": 1.839313747286199e-06, \"fn_rate\": 0.5691026151381263, \"precision\": 0.9823592943717748, \"recall\": 0.43089738486187373, \"specificity\": 0.9999981606862527, \"npv\": 0.9998647401200754, \"accuracy\": 0.999862915342999, \"f1\": 0.5990363352382521, \"f2\": 0.48539400461912935, \"f0_5\": 0.7821582685695108, \"p4\": 0.7492274402512622, \"phi\": 0.6505658776733126}, {\"truth_threshold\": -0.3199999928474426, \"match_probability\": 0.44477445864942694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130964.0, \"tn\": 1278735444.0, \"fp\": 2348.0, \"fn\": 172997.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43085790611295527, \"tn_rate\": 0.9999981638143374, \"fp_rate\": 1.8361856626819708e-06, \"fn_rate\": 0.5691420938870447, \"precision\": 0.9823871819491119, \"recall\": 0.43085790611295527, \"specificity\": 0.9999981638143374, \"npv\": 0.999864730738766, \"accuracy\": 0.9998629090883165, \"f1\": 0.5990033686049676, \"f2\": 0.48535528878795337, \"f0_5\": 0.7821463935528643, \"p4\": 0.7492016539318037, \"phi\": 0.6505453087827667}, {\"truth_threshold\": -0.29999999329447746, \"match_probability\": 0.44820048248939814, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130952.0, \"tn\": 1278735445.0, \"fp\": 2347.0, \"fn\": 173009.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43081842736403686, \"tn_rate\": 0.9999981645963585, \"fp_rate\": 1.8354036415309137e-06, \"fn_rate\": 0.5691815726359631, \"precision\": 0.9823929661887936, \"recall\": 0.43081842736403686, \"specificity\": 0.9999981645963585, \"npv\": 0.9998647213571394, \"accuracy\": 0.9998629004881282, \"f1\": 0.5989662900791292, \"f2\": 0.4853154928721418, \"f0_5\": 0.7821233054253861, \"p4\": 0.7491726498224573, \"phi\": 0.6505174166580305}, {\"truth_threshold\": -0.2799999937415123, \"match_probability\": 0.45163143019909374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130924.0, \"tn\": 1278735455.0, \"fp\": 2337.0, \"fn\": 173037.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4307263102832271, \"tn_rate\": 0.99999817241657, \"fp_rate\": 1.827583430020343e-06, \"fn_rate\": 0.5692736897167728, \"precision\": 0.9824629861699973, \"recall\": 0.4307263102832271, \"specificity\": 0.99999817241657, \"npv\": 0.9998646994674893, \"accuracy\": 0.9998628864150927, \"f1\": 0.598890266272054, \"f2\": 0.4852253901660731, \"f0_5\": 0.7820980758776829, \"p4\": 0.74911317765655, \"phi\": 0.6504710479628554}, {\"truth_threshold\": -0.25999999418854713, \"match_probability\": 0.45506698203407975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130912.0, \"tn\": 1278735460.0, \"fp\": 2332.0, \"fn\": 173049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4306868315343087, \"tn_rate\": 0.9999981763266758, \"fp_rate\": 1.8236733242650578e-06, \"fn_rate\": 0.5693131684656914, \"precision\": 0.9824982738434751, \"recall\": 0.4306868315343087, \"specificity\": 0.9999981763266758, \"npv\": 0.9998646900862866, \"accuracy\": 0.9998628809422455, \"f1\": 0.5988586589814846, \"f2\": 0.485187030052895, \"f0_5\": 0.7820899303053874, \"p4\": 0.749088450185062, \"phi\": 0.650452919773929}, {\"truth_threshold\": -0.23999999463558197, \"match_probability\": 0.45850681650528874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130873.0, \"tn\": 1278735480.0, \"fp\": 2312.0, \"fn\": 173088.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4305585256003237, \"tn_rate\": 0.9999981919670987, \"fp_rate\": 1.8080329012439166e-06, \"fn_rate\": 0.5694414743996763, \"precision\": 0.9826406877651387, \"recall\": 0.4305585256003237, \"specificity\": 0.9999981919670987, \"npv\": 0.9998646595977767, \"accuracy\": 0.9998628660873747, \"f1\": 0.5987610546590841, \"f2\": 0.4850637013733582, \"f0_5\": 0.7820774685341597, \"p4\": 0.7490120850798849, \"phi\": 0.6504031652390824}, {\"truth_threshold\": -0.2199999950826168, \"match_probability\": 0.4619506104976753, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130855.0, \"tn\": 1278735482.0, \"fp\": 2310.0, \"fn\": 173106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43049930747694604, \"tn_rate\": 0.999998193531141, \"fp_rate\": 1.8064688589418025e-06, \"fn_rate\": 0.5695006925230539, \"precision\": 0.9826530995381669, \"recall\": 0.43049930747694604, \"specificity\": 0.999998193531141, \"npv\": 0.9998646455253923, \"accuracy\": 0.9998628535780099, \"f1\": 0.5987060938951241, \"f2\": 0.48500417714040456, \"f0_5\": 0.7820446773389623, \"p4\": 0.7489690793842912, \"phi\": 0.650362540392636}, {\"truth_threshold\": -0.19999999552965164, \"match_probability\": 0.4653980393901789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130849.0, \"tn\": 1278735485.0, \"fp\": 2307.0, \"fn\": 173112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43047956810248683, \"tn_rate\": 0.9999981958772045, \"fp_rate\": 1.8041227954886313e-06, \"fn_rate\": 0.5695204318975131, \"precision\": 0.9826744570278471, \"recall\": 0.43047956810248683, \"specificity\": 0.9999981958772045, \"npv\": 0.9998646408348446, \"accuracy\": 0.9998628512325038, \"f1\": 0.5986909683219824, \"f2\": 0.48498517420311343, \"f0_5\": 0.7820424702809636, \"p4\": 0.74895724356178, \"phi\": 0.6503546985073259}, {\"truth_threshold\": -0.17999999597668648, \"match_probability\": 0.4688487771768984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130839.0, \"tn\": 1278735486.0, \"fp\": 2306.0, \"fn\": 173122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4304466691450548, \"tn_rate\": 0.9999981966592256, \"fp_rate\": 1.8033407743375742e-06, \"fn_rate\": 0.5695533308549452, \"precision\": 0.9826805362574637, \"recall\": 0.4304466691450548, \"specificity\": 0.9999981966592256, \"npv\": 0.9998646330168418, \"accuracy\": 0.9998628441959861, \"f1\": 0.598660279200011, \"f2\": 0.4849520641013381, \"f0_5\": 0.7820238338587111, \"p4\": 0.7489332281913166, \"phi\": 0.6503318564663141}, {\"truth_threshold\": -0.1599999964237213, \"match_probability\": 0.4723024965893847, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130802.0, \"tn\": 1278735502.0, \"fp\": 2290.0, \"fn\": 173159.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43032494300255625, \"tn_rate\": 0.9999982091715641, \"fp_rate\": 1.7908284359206613e-06, \"fn_rate\": 0.5696750569974437, \"precision\": 0.9827938568809546, \"recall\": 0.43032494300255625, \"specificity\": 0.9999982091715641, \"npv\": 0.9998646040915349, \"accuracy\": 0.9998628277774447, \"f1\": 0.5985635609411215, \"f2\": 0.48483397284971264, \"f0_5\": 0.7820008632966213, \"p4\": 0.7488575373606822, \"phi\": 0.6502773919153667}, {\"truth_threshold\": -0.13999999687075615, \"match_probability\": 0.4757588692199541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130782.0, \"tn\": 1278735514.0, \"fp\": 2278.0, \"fn\": 173179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4302591450876922, \"tn_rate\": 0.9999982185558179, \"fp_rate\": 1.7814441821079768e-06, \"fn_rate\": 0.5697408549123079, \"precision\": 0.9828799038027958, \"recall\": 0.4302591450876922, \"specificity\": 0.9999982185558179, \"npv\": 0.9998645884565897, \"accuracy\": 0.9998628215227623, \"f1\": 0.5985158607938749, \"f2\": 0.4847713402881154, \"f0_5\": 0.7820009782337022, \"p4\": 0.7488202045450247, \"phi\": 0.6502561452033367}, {\"truth_threshold\": -0.11999999731779099, \"match_probability\": 0.47921756564592466, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130768.0, \"tn\": 1278735515.0, \"fp\": 2277.0, \"fn\": 173193.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4302130865472873, \"tn_rate\": 0.9999982193378391, \"fp_rate\": 1.7806621609569197e-06, \"fn_rate\": 0.5697869134527127, \"precision\": 0.9828854898718479, \"recall\": 0.4302130865472873, \"specificity\": 0.9999982193378391, \"npv\": 0.9998645775113449, \"accuracy\": 0.9998628113589033, \"f1\": 0.5984723321876587, \"f2\": 0.4847248365136049, \"f0_5\": 0.781973375303926, \"p4\": 0.7487861340426425, \"phi\": 0.6502231846432572}, {\"truth_threshold\": -0.09999999776482582, \"match_probability\": 0.48267825555467603, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130744.0, \"tn\": 1278735523.0, \"fp\": 2269.0, \"fn\": 173217.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4301341290494504, \"tn_rate\": 0.9999982255940083, \"fp_rate\": 1.7744059917484632e-06, \"fn_rate\": 0.5698658709505495, \"precision\": 0.9829415169945794, \"recall\": 0.4301341290494504, \"specificity\": 0.9999982255940083, \"npv\": 0.9998645587487345, \"accuracy\": 0.9998627988495384, \"f1\": 0.5984063125037188, \"f2\": 0.4846473718118377, \"f0_5\": 0.7819495629852646, \"p4\": 0.7487344562979328, \"phi\": 0.6501820449054011}, {\"truth_threshold\": -0.07999999821186066, \"match_probability\": 0.4861406078694332, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130733.0, \"tn\": 1278735527.0, \"fp\": 2265.0, \"fn\": 173228.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4300979401962752, \"tn_rate\": 0.9999982287220929, \"fp_rate\": 1.771277907144235e-06, \"fn_rate\": 0.5699020598037248, \"precision\": 0.9829696687168228, \"recall\": 0.4300979401962752, \"specificity\": 0.9999982287220929, \"npv\": 0.9998645501492404, \"accuracy\": 0.9998627933766913, \"f1\": 0.5983765067203102, \"f2\": 0.48461198568846464, \"f0_5\": 0.7819398937500075, \"p4\": 0.7487111240689628, \"phi\": 0.6501640040914066}, {\"truth_threshold\": -0.05999999865889549, \"match_probability\": 0.489604290875671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130716.0, \"tn\": 1278735539.0, \"fp\": 2253.0, \"fn\": 173245.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4300420119686407, \"tn_rate\": 0.9999982381063467, \"fp_rate\": 1.7618936533315503e-06, \"fn_rate\": 0.5699579880313593, \"precision\": 0.9830562010694222, \"recall\": 0.4300420119686407, \"specificity\": 0.9999982381063467, \"npv\": 0.9998645368597296, \"accuracy\": 0.9998627894675147, \"f1\": 0.5983384066097545, \"f2\": 0.48455938666071574, \"f0_5\": 0.7819467192766054, \"p4\": 0.7486812981336116, \"phi\": 0.650150351797908}, {\"truth_threshold\": -0.03999999910593033, \"match_probability\": 0.4930689723480393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130707.0, \"tn\": 1278735543.0, \"fp\": 2249.0, \"fn\": 173254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43001240290695186, \"tn_rate\": 0.9999982412344313, \"fp_rate\": 1.758765568727322e-06, \"fn_rate\": 0.5699875970930481, \"precision\": 0.9830846295014892, \"recall\": 0.43001240290695186, \"specificity\": 0.9999982412344313, \"npv\": 0.9998645298238573, \"accuracy\": 0.9998627855583382, \"f1\": 0.5983150117756919, \"f2\": 0.48453069395017795, \"f0_5\": 0.7819415280245517, \"p4\": 0.7486629830236865, \"phi\": 0.6501373709914877}, {\"truth_threshold\": -0.019999999552965164, \"match_probability\": 0.49653431967770384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130675.0, \"tn\": 1278735544.0, \"fp\": 2248.0, \"fn\": 173286.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42990712624316935, \"tn_rate\": 0.9999982420164524, \"fp_rate\": 1.757983547576265e-06, \"fn_rate\": 0.5700928737568306, \"precision\": 0.9830879531758988, \"recall\": 0.42990712624316935, \"specificity\": 0.9999982420164524, \"npv\": 0.9998645048060228, \"accuracy\": 0.9998627613214437, \"f1\": 0.5982137134800084, \"f2\": 0.4844239219969053, \"f0_5\": 0.7818735767118649, \"p4\": 0.7485836724321036, \"phi\": 0.6500588730495249}, {\"truth_threshold\": -0.0, \"match_probability\": 0.5, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130653.0, \"tn\": 1278735553.0, \"fp\": 2239.0, \"fn\": 173308.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42983474853681886, \"tn_rate\": 0.9999982490546427, \"fp_rate\": 1.7509453572167514e-06, \"fn_rate\": 0.5701652514631811, \"precision\": 0.9831517322336936, \"recall\": 0.42983474853681886, \"specificity\": 0.9999982490546427, \"npv\": 0.9998644876071431, \"accuracy\": 0.9998627511575847, \"f1\": 0.5981554435931538, \"f2\": 0.48435349838663755, \"f0_5\": 0.7818579606452918, \"p4\": 0.7485380465220707, \"phi\": 0.6500252367833221}, {\"truth_threshold\": 0.019999999552965164, \"match_probability\": 0.5034656803222961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130599.0, \"tn\": 1278735557.0, \"fp\": 2235.0, \"fn\": 173362.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42965709416668585, \"tn_rate\": 0.9999982521827274, \"fp_rate\": 1.7478172726125232e-06, \"fn_rate\": 0.5703429058333142, \"precision\": 0.98317448845928, \"recall\": 0.42965709416668585, \"specificity\": 0.9999982521827274, \"npv\": 0.9998644453897971, \"accuracy\": 0.9998627120658194, \"f1\": 0.597987614327087, \"f2\": 0.4841741320018566, \"f0_5\": 0.7817518798702737, \"p4\": 0.748406614544202, \"phi\": 0.6498984025198732}, {\"truth_threshold\": 0.03999999910593033, \"match_probability\": 0.5069310276519607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130551.0, \"tn\": 1278735559.0, \"fp\": 2233.0, \"fn\": 173410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42949917917101205, \"tn_rate\": 0.9999982537467696, \"fp_rate\": 1.746253230310409e-06, \"fn_rate\": 0.5705008208289879, \"precision\": 0.983183214845162, \"recall\": 0.42949917917101205, \"specificity\": 0.9999982537467696, \"npv\": 0.9998644078631057, \"accuracy\": 0.9998626761013955, \"f1\": 0.5978362660133487, \"f2\": 0.484014123983782, \"f0_5\": 0.7816517123160543, \"p4\": 0.748288065506757, \"phi\": 0.6497818329171177}, {\"truth_threshold\": 0.05999999865889549, \"match_probability\": 0.5103957091243291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130540.0, \"tn\": 1278735563.0, \"fp\": 2229.0, \"fn\": 173421.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4294629903178368, \"tn_rate\": 0.9999982568748543, \"fp_rate\": 1.7431251457061808e-06, \"fn_rate\": 0.5705370096821631, \"precision\": 0.9832114424300853, \"recall\": 0.4294629903178368, \"specificity\": 0.9999982568748543, \"npv\": 0.9998643992636148, \"accuracy\": 0.9998626706285483, \"f1\": 0.5978064250223251, \"f2\": 0.4839787248083772, \"f0_5\": 0.7816420110725633, \"p4\": 0.7482646890482912, \"phi\": 0.6497637855857935}, {\"truth_threshold\": 0.07999999821186066, \"match_probability\": 0.5138593921305669, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130525.0, \"tn\": 1278735569.0, \"fp\": 2223.0, \"fn\": 173436.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4294136418816888, \"tn_rate\": 0.9999982615669812, \"fp_rate\": 1.7384330187998385e-06, \"fn_rate\": 0.5705863581183113, \"precision\": 0.9832539849941242, \"recall\": 0.4294136418816888, \"specificity\": 0.9999982615669812, \"npv\": 0.9998643875370945, \"accuracy\": 0.9998626635920306, \"f1\": 0.5977664760744569, \"f2\": 0.4839306476680864, \"f0_5\": 0.7816308223337122, \"p4\": 0.7482333930201414, \"phi\": 0.6497405110226614}, {\"truth_threshold\": 0.09999999776482582, \"match_probability\": 0.517321744445324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130503.0, \"tn\": 1278735580.0, \"fp\": 2212.0, \"fn\": 173458.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4293412641753383, \"tn_rate\": 0.9999982701692138, \"fp_rate\": 1.7298307861382108e-06, \"fn_rate\": 0.5706587358246618, \"precision\": 0.9833327054213917, \"recall\": 0.4293412641753383, \"specificity\": 0.9999982701692138, \"npv\": 0.9998643703384321, \"accuracy\": 0.9998626549918421, \"f1\": 0.5977108886222279, \"f2\": 0.48386092117586255, \"f0_5\": 0.7816226472501291, \"p4\": 0.7481898433419496, \"phi\": 0.649711762765342}, {\"truth_threshold\": 0.11999999731779099, \"match_probability\": 0.5207824343540752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130484.0, \"tn\": 1278735589.0, \"fp\": 2203.0, \"fn\": 173477.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4292787561562174, \"tn_rate\": 0.9999982772074042, \"fp_rate\": 1.7227925957786975e-06, \"fn_rate\": 0.5707212438437826, \"precision\": 0.9833970170401019, \"recall\": 0.4292787561562174, \"specificity\": 0.9999982772074042, \"npv\": 0.9998643554849895, \"accuracy\": 0.999862647173489, \"f1\": 0.5976621901394258, \"f2\": 0.4838005207147629, \"f0_5\": 0.7816137120840916, \"p4\": 0.7481516882583418, \"phi\": 0.6496857124938289}, {\"truth_threshold\": 0.13999999687075615, \"match_probability\": 0.5242411307800459, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130453.0, \"tn\": 1278735598.0, \"fp\": 2194.0, \"fn\": 173508.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4291767693881781, \"tn_rate\": 0.9999982842455946, \"fp_rate\": 1.715754405419184e-06, \"fn_rate\": 0.5708232306118219, \"precision\": 0.9834598596274322, \"recall\": 0.4291767693881781, \"specificity\": 0.9999982842455946, \"npv\": 0.9998643312498238, \"accuracy\": 0.9998626299731124, \"f1\": 0.5975749413661683, \"f2\": 0.48369992829021474, \"f0_5\": 0.7815778342553883, \"p4\": 0.7480833228992676, \"phi\": 0.6496292884092685}, {\"truth_threshold\": 0.1599999964237213, \"match_probability\": 0.5276975034106154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130410.0, \"tn\": 1278735598.0, \"fp\": 2194.0, \"fn\": 173551.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4290353038712203, \"tn_rate\": 0.9999982842455946, \"fp_rate\": 1.715754405419184e-06, \"fn_rate\": 0.5709646961287796, \"precision\": 0.9834544960936321, \"recall\": 0.4290353038712203, \"specificity\": 0.9999982842455946, \"npv\": 0.9998642976319814, \"accuracy\": 0.9998625963541943, \"f1\": 0.5974368078063976, \"f2\": 0.4835559102019507, \"f0_5\": 0.7814812728538778, \"p4\": 0.7479750696793712, \"phi\": 0.649520431037237}, {\"truth_threshold\": 0.17999999597668648, \"match_probability\": 0.5311512228231017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130392.0, \"tn\": 1278735607.0, \"fp\": 2185.0, \"fn\": 173569.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42897608574784263, \"tn_rate\": 0.9999982912837849, \"fp_rate\": 1.7087162150596704e-06, \"fn_rate\": 0.5710239142521574, \"precision\": 0.9835190115932628, \"recall\": 0.42897608574784263, \"specificity\": 0.9999982912837849, \"npv\": 0.999864283560352, \"accuracy\": 0.9998625893176765, \"f1\": 0.59739129239608, \"f2\": 0.4834988479117427, \"f0_5\": 0.7814745603636237, \"p4\": 0.7479393963932176, \"phi\": 0.6494969102481019}, {\"truth_threshold\": 0.19999999552965164, \"match_probability\": 0.5346019606098211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130359.0, \"tn\": 1278735609.0, \"fp\": 2183.0, \"fn\": 173602.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42886751918831695, \"tn_rate\": 0.9999982928478273, \"fp_rate\": 1.7071521727575563e-06, \"fn_rate\": 0.5711324808116831, \"precision\": 0.9835297490606751, \"recall\": 0.42886751918831695, \"specificity\": 0.9999982928478273, \"npv\": 0.9998642577608271, \"accuracy\": 0.999862565080782, \"f1\": 0.5972879911478272, \"f2\": 0.4833890295508853, \"f0_5\": 0.7814079117258841, \"p4\": 0.7478584240168827, \"phi\": 0.649418254507048}, {\"truth_threshold\": 0.2199999950826168, \"match_probability\": 0.5380493895023247, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130351.0, \"tn\": 1278735609.0, \"fp\": 2183.0, \"fn\": 173610.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4288412000223713, \"tn_rate\": 0.9999982928478273, \"fp_rate\": 1.7071521727575563e-06, \"fn_rate\": 0.5711587999776288, \"precision\": 0.9835287548855388, \"recall\": 0.4288412000223713, \"specificity\": 0.9999982928478273, \"npv\": 0.9998642515063456, \"accuracy\": 0.9998625588260995, \"f1\": 0.5972622825003723, \"f2\": 0.4833622322523803, \"f0_5\": 0.7813899342642403, \"p4\": 0.7478382707114254, \"phi\": 0.6493979967271193}, {\"truth_threshold\": 0.23999999463558197, \"match_probability\": 0.5414931834947113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130335.0, \"tn\": 1278735609.0, \"fp\": 2183.0, \"fn\": 173626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42878856169048, \"tn_rate\": 0.9999982928478273, \"fp_rate\": 1.7071521727575563e-06, \"fn_rate\": 0.5712114383095199, \"precision\": 0.9835267661751611, \"recall\": 0.42878856169048, \"specificity\": 0.9999982928478273, \"npv\": 0.9998642389973827, \"accuracy\": 0.9998625463167347, \"f1\": 0.5972108623782587, \"f2\": 0.48330863670141994, \"f0_5\": 0.78135397520242, \"p4\": 0.7477979599381132, \"phi\": 0.6493574792740893}, {\"truth_threshold\": 0.25999999418854713, \"match_probability\": 0.5449330179659203, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130319.0, \"tn\": 1278735613.0, \"fp\": 2179.0, \"fn\": 173642.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4287359233585888, \"tn_rate\": 0.9999982959759118, \"fp_rate\": 1.704024088153328e-06, \"fn_rate\": 0.5712640766414112, \"precision\": 0.983554468746698, \"recall\": 0.4287359233585888, \"specificity\": 0.9999982959759118, \"npv\": 0.999864226488845, \"accuracy\": 0.9998625369347109, \"f1\": 0.5971649112516869, \"f2\": 0.48325647350597994, \"f0_5\": 0.7813330007806195, \"p4\": 0.7477619346359655, \"phi\": 0.6493267641032239}, {\"truth_threshold\": 0.2799999937415123, \"match_probability\": 0.5483685698009062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130291.0, \"tn\": 1278735617.0, \"fp\": 2175.0, \"fn\": 173670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42864380627777904, \"tn_rate\": 0.9999982991039964, \"fp_rate\": 1.7008960035490998e-06, \"fn_rate\": 0.5713561937222209, \"precision\": 0.9835806924040886, \"recall\": 0.42864380627777904, \"specificity\": 0.9999982991039964, \"npv\": 0.9998642045985862, \"accuracy\": 0.9998625181706636, \"f1\": 0.5970803822861556, \"f2\": 0.48316410914403957, \"f0_5\": 0.7812850418253231, \"p4\": 0.7476956590039281, \"phi\": 0.6492656553200623}, {\"truth_threshold\": 0.29999999329447746, \"match_probability\": 0.5517995175106017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130271.0, \"tn\": 1278735619.0, \"fp\": 2173.0, \"fn\": 173690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.428578008362915, \"tn_rate\": 0.9999983006680387, \"fp_rate\": 1.6993319612469857e-06, \"fn_rate\": 0.5714219916370851, \"precision\": 0.9835930657485428, \"recall\": 0.428578008362915, \"specificity\": 0.9999983006680387, \"npv\": 0.9998641889625968, \"accuracy\": 0.9998625040976281, \"f1\": 0.5970188242572839, \"f2\": 0.48309782479707597, \"f0_5\": 0.7812475636801534, \"p4\": 0.7476473894525503, \"phi\": 0.6492199013537823}, {\"truth_threshold\": 0.3199999928474426, \"match_probability\": 0.5552255413505731, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130259.0, \"tn\": 1278735624.0, \"fp\": 2168.0, \"fn\": 173702.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4285385296139965, \"tn_rate\": 0.9999983045781445, \"fp_rate\": 1.6954218554917004e-06, \"fn_rate\": 0.5714614703860035, \"precision\": 0.9836287161983583, \"recall\": 0.4285385296139965, \"specificity\": 0.9999983045781445, \"npv\": 0.9998641795814068, \"accuracy\": 0.999862498624781, \"f1\": 0.5969870848877604, \"f2\": 0.48305941461323426, \"f0_5\": 0.7812393168031917, \"p4\": 0.7476225004283051, \"phi\": 0.6492017652532391}, {\"truth_threshold\": 0.3399999924004078, \"match_probability\": 0.558646323438279, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130243.0, \"tn\": 1278735626.0, \"fp\": 2166.0, \"fn\": 173718.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4284858912821053, \"tn_rate\": 0.9999983061421868, \"fp_rate\": 1.6938578131895863e-06, \"fn_rate\": 0.5715141087178948, \"precision\": 0.9836415953598321, \"recall\": 0.4284858912821053, \"specificity\": 0.9999983061421868, \"npv\": 0.9998641670726585, \"accuracy\": 0.9998624876790867, \"f1\": 0.5969383779819878, \"f2\": 0.48300652770659513, \"f0_5\": 0.7812108248950033, \"p4\": 0.7475843037110835, \"phi\": 0.6491661399657658}, {\"truth_threshold\": 0.35999999195337296, \"match_probability\": 0.5620615478688429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130218.0, \"tn\": 1278735631.0, \"fp\": 2161.0, \"fn\": 173743.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4284036438885252, \"tn_rate\": 0.9999983100522926, \"fp_rate\": 1.689947707434301e-06, \"fn_rate\": 0.5715963561114749, \"precision\": 0.9836756585258991, \"recall\": 0.4284036438885252, \"specificity\": 0.9999983100522926, \"npv\": 0.999864147527939, \"accuracy\": 0.9998624720423807, \"f1\": 0.5968648301783013, \"f2\": 0.4829245606995282, \"f0_5\": 0.7811733257186461, \"p4\": 0.7475266220826695, \"phi\": 0.6491150704551829}, {\"truth_threshold\": 0.3799999915063381, \"match_probability\": 0.5654709008292483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130208.0, \"tn\": 1278735654.0, \"fp\": 2138.0, \"fn\": 173753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4283707449310931, \"tn_rate\": 0.9999983280387791, \"fp_rate\": 1.6719612209599886e-06, \"fn_rate\": 0.5716292550689068, \"precision\": 0.983845375001889, \"recall\": 0.4283707449310931, \"specificity\": 0.9999983280387791, \"npv\": 0.9998641397122822, \"accuracy\": 0.9998624822062396, \"f1\": 0.5968641346574775, \"f2\": 0.4828992946098102, \"f0_5\": 0.7812370626811225, \"p4\": 0.747526078019656, \"phi\": 0.6491461568011878}, {\"truth_threshold\": 0.3999999910593033, \"match_probability\": 0.5688740707108767, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130202.0, \"tn\": 1278735661.0, \"fp\": 2131.0, \"fn\": 173759.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4283510055566339, \"tn_rate\": 0.9999983335129271, \"fp_rate\": 1.6664870729025892e-06, \"fn_rate\": 0.5716489944433661, \"precision\": 0.9838966848782994, \"recall\": 0.4283510055566339, \"specificity\": 0.9999983335129271, \"npv\": 0.999864135022166, \"accuracy\": 0.9998624829880749, \"f1\": 0.5968544146836766, \"f2\": 0.4828816987680401, \"f0_5\": 0.7812498124909245, \"p4\": 0.747518454891125, \"phi\": 0.649148131790344}, {\"truth_threshold\": 0.41999999061226845, \"match_probability\": 0.5722707482202983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130179.0, \"tn\": 1278735667.0, \"fp\": 2125.0, \"fn\": 173782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4282753379545402, \"tn_rate\": 0.999998338205054, \"fp_rate\": 1.6617949459962468e-06, \"fn_rate\": 0.5717246620454598, \"precision\": 0.9839385052606119, \"recall\": 0.4282753379545402, \"specificity\": 0.999998338205054, \"npv\": 0.9998641170411745, \"accuracy\": 0.9998624696968748, \"f1\": 0.5967886491008905, \"f2\": 0.4828067838249213, \"f0_5\": 0.7812205569764888, \"p4\": 0.7474668715800926, \"phi\": 0.6491045876194643}, {\"truth_threshold\": 0.4399999901652336, \"match_probability\": 0.5756606264882413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130173.0, \"tn\": 1278735667.0, \"fp\": 2125.0, \"fn\": 173788.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.428255598580081, \"tn_rate\": 0.999998338205054, \"fp_rate\": 1.6617949459962468e-06, \"fn_rate\": 0.571744401419919, \"precision\": 0.9839377768371403, \"recall\": 0.428255598580081, \"specificity\": 0.999998338205054, \"npv\": 0.9998641123503149, \"accuracy\": 0.9998624650058628, \"f1\": 0.5967693503171281, \"f2\": 0.48278667974145156, \"f0_5\": 0.7812070532063139, \"p4\": 0.7474517336398999, \"phi\": 0.6490893868036828}, {\"truth_threshold\": 0.4599999897181988, \"match_probability\": 0.5790434011766568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130164.0, \"tn\": 1278735677.0, \"fp\": 2115.0, \"fn\": 173797.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42822598951839214, \"tn_rate\": 0.9999983460252655, \"fp_rate\": 1.6539747344856764e-06, \"fn_rate\": 0.5717740104816078, \"precision\": 0.9840110675163858, \"recall\": 0.42822598951839214, \"specificity\": 0.9999983460252655, \"npv\": 0.9998641053150882, \"accuracy\": 0.9998624657876982, \"f1\": 0.5967540803227581, \"f2\": 0.4827601042338125, \"f0_5\": 0.7812243045960937, \"p4\": 0.7474397562453489, \"phi\": 0.6490911277653233}, {\"truth_threshold\": 0.47999998927116394, \"match_probability\": 0.5824187705838036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130140.0, \"tn\": 1278735688.0, \"fp\": 2104.0, \"fn\": 173821.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42814703202055526, \"tn_rate\": 0.9999983546274982, \"fp_rate\": 1.6453725018240488e-06, \"fn_rate\": 0.5718529679794447, \"precision\": 0.9840900154260307, \"recall\": 0.42814703202055526, \"specificity\": 0.9999983546274982, \"npv\": 0.9998640865528196, \"accuracy\": 0.9998624556238392, \"f1\": 0.596691922375947, \"f2\": 0.48268362302757684, \"f0_5\": 0.7812115442104265, \"p4\": 0.7473909969063073, \"phi\": 0.6490573236900367}, {\"truth_threshold\": 0.4999999888241291, \"match_probability\": 0.5857864357472833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130126.0, \"tn\": 1278735692.0, \"fp\": 2100.0, \"fn\": 173835.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4281009734801504, \"tn_rate\": 0.9999983577555828, \"fp_rate\": 1.6422444172198205e-06, \"fn_rate\": 0.5718990265198496, \"precision\": 0.9841181008273713, \"recall\": 0.4281009734801504, \"specificity\": 0.9999983577555828, \"npv\": 0.9998640756079066, \"accuracy\": 0.9998624478054862, \"f1\": 0.5966523532338195, \"f2\": 0.4826381419362496, \"f0_5\": 0.7811950316077636, \"p4\": 0.7473599550212828, \"phi\": 0.6490316723241044}, {\"truth_threshold\": 0.5199999883770943, \"match_probability\": 0.5891461005449494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130106.0, \"tn\": 1278735694.0, \"fp\": 2098.0, \"fn\": 173855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42803517556528636, \"tn_rate\": 0.9999983593196251, \"fp_rate\": 1.6406803749177064e-06, \"fn_rate\": 0.5719648244347136, \"precision\": 0.9841305860639618, \"recall\": 0.42803517556528636, \"specificity\": 0.9999983593196251, \"npv\": 0.9998640599719222, \"accuracy\": 0.9998624337324507, \"f1\": 0.5965907397429872, \"f2\": 0.48257183720460994, \"f0_5\": 0.781157500747499, \"p4\": 0.7473116160761396, \"phi\": 0.6489859063574236}, {\"truth_threshold\": 0.5399999879300594, \"match_probability\": 0.592497471793629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130072.0, \"tn\": 1278735940.0, \"fp\": 1852.0, \"fn\": 173889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4279233191100174, \"tn_rate\": 0.9999985516968283, \"fp_rate\": 1.4483031717576703e-06, \"fn_rate\": 0.5720766808899826, \"precision\": 0.9859616142627573, \"recall\": 0.4279233191100174, \"specificity\": 0.9999985516968283, \"npv\": 0.999864033416542, \"accuracy\": 0.9998625994815354, \"f1\": 0.5968179680420295, \"f2\": 0.4825459574644894, \"f0_5\": 0.782005081421788, \"p4\": 0.7474898857599585, \"phi\": 0.6495047000940763}, {\"truth_threshold\": 0.5599999874830246, \"match_probability\": 0.5958402593455852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130047.0, \"tn\": 1278735947.0, \"fp\": 1845.0, \"fn\": 173914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4278410717164373, \"tn_rate\": 0.9999985571709763, \"fp_rate\": 1.4428290237002708e-06, \"fn_rate\": 0.5721589282835627, \"precision\": 0.9860112819579656, \"recall\": 0.4278410717164373, \"specificity\": 0.9999985571709763, \"npv\": 0.9998640138720457, \"accuracy\": 0.9998625854084999, \"f1\": 0.5967470683923249, \"f2\": 0.48246466667062393, \"f0_5\": 0.7819751325570125, \"p4\": 0.7474342728536117, \"phi\": 0.6494586366329892}, {\"truth_threshold\": 0.5799999870359898, \"match_probability\": 0.5991741761826646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130030.0, \"tn\": 1278735957.0, \"fp\": 1835.0, \"fn\": 173931.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42778514348880287, \"tn_rate\": 0.9999985649911878, \"fp_rate\": 1.4350088121897002e-06, \"fn_rate\": 0.5722148565111972, \"precision\": 0.9860842528343382, \"recall\": 0.42778514348880287, \"specificity\": 0.9999985649911878, \"npv\": 0.9998640005823459, \"accuracy\": 0.9998625799356529, \"f1\": 0.5967060248814894, \"f2\": 0.48241126237192156, \"f0_5\": 0.781974475025288, \"p4\": 0.7474020768913707, \"phi\": 0.6494402206638874}, {\"truth_threshold\": 0.5999999865889549, \"match_probability\": 0.6024989385080661, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130021.0, \"tn\": 1278735960.0, \"fp\": 1832.0, \"fn\": 173940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.427755534427114, \"tn_rate\": 0.9999985673372512, \"fp_rate\": 1.432662748736529e-06, \"fn_rate\": 0.572244465572886, \"precision\": 0.9861057389668798, \"recall\": 0.427755534427114, \"specificity\": 0.9999985673372512, \"npv\": 0.9998639935463788, \"accuracy\": 0.999862575244641, \"f1\": 0.5966811529689271, \"f2\": 0.4823821675050104, \"f0_5\": 0.7819654956319245, \"p4\": 0.7473825654977411, \"phi\": 0.6494248203588006}, {\"truth_threshold\": 0.6199999861419201, \"match_probability\": 0.6058142658356777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130008.0, \"tn\": 1278735960.0, \"fp\": 1832.0, \"fn\": 173953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4277127657824524, \"tn_rate\": 0.9999985673372512, \"fp_rate\": 1.432662748736529e-06, \"fn_rate\": 0.5722872342175477, \"precision\": 0.9861043689320388, \"recall\": 0.4277127657824524, \"specificity\": 0.9999985673372512, \"npv\": 0.9998639833828545, \"accuracy\": 0.999862565080782, \"f1\": 0.5966392917868477, \"f2\": 0.48233858975843, \"f0_5\": 0.7819362195830492, \"p4\": 0.7473497247575767, \"phi\": 0.6493918989196282}, {\"truth_threshold\": 0.6399999856948853, \"match_probability\": 0.6091198810769267, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129986.0, \"tn\": 1278736006.0, \"fp\": 1786.0, \"fn\": 173975.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4276403880761019, \"tn_rate\": 0.9999986033102242, \"fp_rate\": 1.3966897757879045e-06, \"fn_rate\": 0.5723596119238982, \"precision\": 0.9864462860091674, \"recall\": 0.4276403880761019, \"specificity\": 0.9999986033102242, \"npv\": 0.9998639661879377, \"accuracy\": 0.9998625838448293, \"f1\": 0.5966314233716519, \"f2\": 0.4822813026856315, \"f0_5\": 0.7820597822751727, \"p4\": 0.7473435545609636, \"phi\": 0.6494495526548332}, {\"truth_threshold\": 0.6599999852478504, \"match_probability\": 0.6124155106250946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129972.0, \"tn\": 1278736095.0, \"fp\": 1697.0, \"fn\": 173989.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42759432953569704, \"tn_rate\": 0.9999986729101067, \"fp_rate\": 1.3270898933438264e-06, \"fn_rate\": 0.572405670464303, \"precision\": 0.9871116208067199, \"recall\": 0.42759432953569704, \"specificity\": 0.9999986729101067, \"npv\": 0.9998639552520723, \"accuracy\": 0.9998626424824772, \"f1\": 0.5967082156876248, \"f2\": 0.4822662193240436, \"f0_5\": 0.7823634150657869, \"p4\": 0.7474038041761929, \"phi\": 0.6496336274452359}, {\"truth_threshold\": 0.6799999848008156, \"match_probability\": 0.6157008844370494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129941.0, \"tn\": 1278736103.0, \"fp\": 1689.0, \"fn\": 174020.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4274923427676577, \"tn_rate\": 0.9999986791662758, \"fp_rate\": 1.32083372413537e-06, \"fn_rate\": 0.5725076572323423, \"precision\": 0.9871685785915065, \"recall\": 0.4274923427676577, \"specificity\": 0.9999986791662758, \"npv\": 0.9998639310168319, \"accuracy\": 0.9998626245002652, \"f1\": 0.5966193057248658, \"f2\": 0.4821651475278929, \"f0_5\": 0.7823237376893631, \"p4\": 0.7473340537561831, \"phi\": 0.649574888842298}, {\"truth_threshold\": 0.6999999843537807, \"match_probability\": 0.6189757361123518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129915.0, \"tn\": 1278736103.0, \"fp\": 1689.0, \"fn\": 174046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4274068054783344, \"tn_rate\": 0.9999986791662758, \"fp_rate\": 1.32083372413537e-06, \"fn_rate\": 0.5725931945216656, \"precision\": 0.9871660435853014, \"recall\": 0.4274068054783344, \"specificity\": 0.9999986791662758, \"npv\": 0.9998639106897884, \"accuracy\": 0.9998626041725472, \"f1\": 0.5965355343060164, \"f2\": 0.4820779725822444, \"f0_5\": 0.7822651638954354, \"p4\": 0.7472683269757664, \"phi\": 0.6495090576471526}, {\"truth_threshold\": 0.7199999839067459, \"match_probability\": 0.6222398029696947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129905.0, \"tn\": 1278736120.0, \"fp\": 1672.0, \"fn\": 174056.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42737390652090235, \"tn_rate\": 0.9999986924606354, \"fp_rate\": 1.3075393645673999e-06, \"fn_rate\": 0.5726260934790977, \"precision\": 0.9872926119306565, \"recall\": 0.42737390652090235, \"specificity\": 0.9999986924606354, \"npv\": 0.999863902873504, \"accuracy\": 0.9998626096453944, \"f1\": 0.596526594694378, \"f2\": 0.48205052466897874, \"f0_5\": 0.7823066981905864, \"p4\": 0.7472613136459019, \"phi\": 0.6495257079849965}, {\"truth_threshold\": 0.7399999834597111, \"match_probability\": 0.6254928261206408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129882.0, \"tn\": 1278736134.0, \"fp\": 1658.0, \"fn\": 174079.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42729823891880864, \"tn_rate\": 0.9999987034089316, \"fp_rate\": 1.296591068452601e-06, \"fn_rate\": 0.5727017610811913, \"precision\": 0.9873954690588415, \"recall\": 0.42729823891880864, \"specificity\": 0.9999987034089316, \"npv\": 0.99986388489338, \"accuracy\": 0.9998626026088767, \"f1\": 0.596471649892882, \"f2\": 0.481978411499617, \"f0_5\": 0.7823076394887011, \"p4\": 0.7472182007860954, \"phi\": 0.6495020425127579}, {\"truth_threshold\": 0.7599999830126762, \"match_probability\": 0.6287345505406211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129855.0, \"tn\": 1278736153.0, \"fp\": 1639.0, \"fn\": 174106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42720941173374216, \"tn_rate\": 0.9999987182673334, \"fp_rate\": 1.2817326665825171e-06, \"fn_rate\": 0.5727905882662578, \"precision\": 0.9875355529529865, \"recall\": 0.42720941173374216, \"specificity\": 0.9999987182673334, \"npv\": 0.999863863786552, \"accuracy\": 0.9998625963541943, \"f1\": 0.5964106509283393, \"f2\": 0.4818946693405812, \"f0_5\": 0.782318416940081, \"p4\": 0.7471703342222513, \"phi\": 0.649480606630753}, {\"truth_threshold\": 0.7799999825656414, \"match_probability\": 0.6319647251371673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129834.0, \"tn\": 1278736161.0, \"fp\": 1631.0, \"fn\": 174127.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4271403239231349, \"tn_rate\": 0.9999987245235026, \"fp_rate\": 1.2754764973740606e-06, \"fn_rate\": 0.5728596760768652, \"precision\": 0.987593656106188, \"recall\": 0.4271403239231349, \"specificity\": 0.9999987245235026, \"npv\": 0.9998638473694098, \"accuracy\": 0.9998625861903353, \"f1\": 0.5963539154758788, \"f2\": 0.48182710870334866, \"f0_5\": 0.7823012432801772, \"p4\": 0.747125809393401, \"phi\": 0.6494471944785497}, {\"truth_threshold\": 0.7999999821186066, \"match_probability\": 0.6351831028153483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129820.0, \"tn\": 1278736163.0, \"fp\": 1629.0, \"fn\": 174141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42709426538273004, \"tn_rate\": 0.9999987260875449, \"fp_rate\": 1.2739124550719465e-06, \"fn_rate\": 0.57290573461727, \"precision\": 0.987607361029753, \"recall\": 0.42709426538273004, \"specificity\": 0.9999987260875449, \"npv\": 0.9998638364242939, \"accuracy\": 0.9998625768083116, \"f1\": 0.5963115224730714, \"f2\": 0.48178087468724323, \"f0_5\": 0.7822772209213059, \"p4\": 0.7470925379119395, \"phi\": 0.6494166826555839}, {\"truth_threshold\": 0.8199999816715717, \"match_probability\": 0.6383894405403884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129804.0, \"tn\": 1278736166.0, \"fp\": 1626.0, \"fn\": 174157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42704162705083876, \"tn_rate\": 0.9999987284336084, \"fp_rate\": 1.2715663916187753e-06, \"fn_rate\": 0.5729583729491612, \"precision\": 0.9876283953435289, \"recall\": 0.42704162705083876, \"specificity\": 0.9999987284336084, \"npv\": 0.9998638239156664, \"accuracy\": 0.9998625666444526, \"f1\": 0.5962640477180282, \"f2\": 0.48172828986531324, \"f0_5\": 0.7822524560644393, \"p4\": 0.7470552760476046, \"phi\": 0.6493835756704757}, {\"truth_threshold\": 0.8399999812245369, \"match_probability\": 0.641583499397445, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129785.0, \"tn\": 1278736691.0, \"fp\": 1101.0, \"fn\": 174176.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42697911903171787, \"tn_rate\": 0.9999991389947127, \"fp_rate\": 8.610052873138202e-07, \"fn_rate\": 0.5730208809682821, \"precision\": 0.9915880995675627, \"recall\": 0.42697911903171787, \"specificity\": 0.9999991389947127, \"npv\": 0.9998638091171994, \"accuracy\": 0.9998629622531173, \"f1\": 0.5969225957635674, \"f2\": 0.4818523386276388, \"f0_5\": 0.784194657434094, \"p4\": 0.7475719933818629, \"phi\": 0.6506369255484962}, {\"truth_threshold\": 0.8599999807775021, \"match_probability\": 0.6447650446485294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129748.0, \"tn\": 1278736695.0, \"fp\": 1097.0, \"fn\": 174213.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42685739288921937, \"tn_rate\": 0.9999991421227973, \"fp_rate\": 8.57877202709592e-07, \"fn_rate\": 0.5731426071107807, \"precision\": 0.991616034238985, \"recall\": 0.42685739288921937, \"specificity\": 0.9999991421227973, \"npv\": 0.9998637801906995, \"accuracy\": 0.9998629364525522, \"f1\": 0.5968086916923869, \"f2\": 0.4817296346818011, \"f0_5\": 0.784126496813285, \"p4\": 0.7474826571227617, \"phi\": 0.650553332265551}, {\"truth_threshold\": 0.8799999803304672, \"match_probability\": 0.6479338457865556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129721.0, \"tn\": 1278736695.0, \"fp\": 1097.0, \"fn\": 174240.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42676856570415284, \"tn_rate\": 0.9999991421227973, \"fp_rate\": 8.57877202709592e-07, \"fn_rate\": 0.5732314342958472, \"precision\": 0.9916143038419789, \"recall\": 0.42676856570415284, \"specificity\": 0.9999991421227973, \"npv\": 0.9998637590818629, \"accuracy\": 0.999862915342999, \"f1\": 0.5967215527888882, \"f2\": 0.4816390452838203, \"f0_5\": 0.784065674362604, \"p4\": 0.7474143042935335, \"phi\": 0.6504850653740735}, {\"truth_threshold\": 0.8999999798834324, \"match_probability\": 0.6510896765865067, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129705.0, \"tn\": 1278736704.0, \"fp\": 1088.0, \"fn\": 174256.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42671592737226155, \"tn_rate\": 0.9999991491609876, \"fp_rate\": 8.508390123500784e-07, \"fn_rate\": 0.5732840726277384, \"precision\": 0.9916815120075233, \"recall\": 0.42671592737226155, \"specificity\": 0.9999991491609876, \"npv\": 0.9998637465738819, \"accuracy\": 0.9998629098701518, \"f1\": 0.5966822616928193, \"f2\": 0.4815885795503911, \"f0_5\": 0.7840637479099491, \"p4\": 0.7473834819989195, \"phi\": 0.6504669944753113}, {\"truth_threshold\": 0.9199999794363976, \"match_probability\": 0.6542323151537098, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129672.0, \"tn\": 1278736706.0, \"fp\": 1086.0, \"fn\": 174289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42660736081273587, \"tn_rate\": 0.99999915072503, \"fp_rate\": 8.492749700479643e-07, \"fn_rate\": 0.5733926391872641, \"precision\": 0.9916945808287064, \"recall\": 0.42660736081273587, \"specificity\": 0.99999915072503, \"npv\": 0.9998637207744078, \"accuracy\": 0.9998628856332573, \"f1\": 0.5965784794315409, \"f2\": 0.48147856604995387, \"f0_5\": 0.7839969624894044, \"p4\": 0.7473020603011709, \"phi\": 0.6503885208344443}, {\"truth_threshold\": 0.9399999789893627, \"match_probability\": 0.6573615439692159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129658.0, \"tn\": 1278736713.0, \"fp\": 1079.0, \"fn\": 174303.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42656130227233097, \"tn_rate\": 0.999999156199178, \"fp_rate\": 8.438008219905649e-07, \"fn_rate\": 0.573438697727669, \"precision\": 0.9917467893557295, \"recall\": 0.42656130227233097, \"specificity\": 0.999999156199178, \"npv\": 0.9998637098298323, \"accuracy\": 0.9998628801604103, \"f1\": 0.596542887245858, \"f2\": 0.4814340912280806, \"f0_5\": 0.7839919507466965, \"p4\": 0.7472741346427269, \"phi\": 0.6503705322028014}, {\"truth_threshold\": 0.9599999785423279, \"match_probability\": 0.6604771499322812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129647.0, \"tn\": 1278736721.0, \"fp\": 1071.0, \"fn\": 174314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4265251134191557, \"tn_rate\": 0.9999991624553473, \"fp_rate\": 8.375446527821084e-07, \"fn_rate\": 0.5734748865808442, \"precision\": 0.9918067901895684, \"recall\": 0.4265251134191557, \"specificity\": 0.9999991624553473, \"npv\": 0.9998637012307897, \"accuracy\": 0.9998628778149043, \"f1\": 0.5965183503228819, \"f2\": 0.4814000395080212, \"f0_5\": 0.783997494052608, \"p4\": 0.7472548824269287, \"phi\": 0.650362620588838}, {\"truth_threshold\": 0.979999978095293, \"match_probability\": 0.663578924399954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129626.0, \"tn\": 1278736724.0, \"fp\": 1068.0, \"fn\": 174335.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42645602560854845, \"tn_rate\": 0.9999991648014107, \"fp_rate\": 8.351985893289372e-07, \"fn_rate\": 0.5735439743914515, \"precision\": 0.9918282400110181, \"recall\": 0.42645602560854845, \"specificity\": 0.9999991648014107, \"npv\": 0.9998636848131282, \"accuracy\": 0.9998628637418688, \"f1\": 0.5964546594425464, \"f2\": 0.4813306419870809, \"f0_5\": 0.7839615258540503, \"p4\": 0.7472049052681603, \"phi\": 0.6503169755041769}, {\"truth_threshold\": 0.9999999776482582, \"match_probability\": 0.6666666632237674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129609.0, \"tn\": 1278736724.0, \"fp\": 1068.0, \"fn\": 174352.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.426400097380914, \"tn_rate\": 0.9999991648014107, \"fp_rate\": 8.351985893289372e-07, \"fn_rate\": 0.573599902619086, \"precision\": 0.9918271769324365, \"recall\": 0.426400097380914, \"specificity\": 0.9999991648014107, \"npv\": 0.9998636715223819, \"accuracy\": 0.9998628504506686, \"f1\": 0.5963997625610278, \"f2\": 0.4812735932079782, \"f0_5\": 0.7839231905393815, \"p4\": 0.7471618252501652, \"phi\": 0.6502739777156227}, {\"truth_threshold\": 1.0199999772012234, \"match_probability\": 0.6697401667835483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129560.0, \"tn\": 1278736741.0, \"fp\": 1051.0, \"fn\": 174401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42623889248949703, \"tn_rate\": 0.9999991780957702, \"fp_rate\": 8.219042297609673e-07, \"fn_rate\": 0.573761107510503, \"precision\": 0.991953204553981, \"recall\": 0.42623889248949703, \"specificity\": 0.9999991780957702, \"npv\": 0.9998636332155749, \"accuracy\": 0.9998628254319388, \"f1\": 0.5962648306839833, \"f2\": 0.4811152247939961, \"f0_5\": 0.7838771546638754, \"p4\": 0.7470559266985797, \"phi\": 0.6501923525425968}, {\"truth_threshold\": 1.0399999767541885, \"match_probability\": 0.672799240018352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129523.0, \"tn\": 1278736760.0, \"fp\": 1032.0, \"fn\": 174438.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4261171663469985, \"tn_rate\": 0.9999991929541721, \"fp_rate\": 8.070458278908832e-07, \"fn_rate\": 0.5738828336530015, \"precision\": 0.9920952855118532, \"recall\": 0.4261171663469985, \"specificity\": 0.9999991929541721, \"npv\": 0.9998636042906867, \"accuracy\": 0.9998628113589033, \"f1\": 0.5961713722854854, \"f2\": 0.4809978319948247, \"f0_5\": 0.7838657630712883, \"p4\": 0.7469825677270849, \"phi\": 0.6501460687407787}, {\"truth_threshold\": 1.0599999763071537, \"match_probability\": 0.6758436924545342, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129501.0, \"tn\": 1278736762.0, \"fp\": 1030.0, \"fn\": 174460.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.426044788640648, \"tn_rate\": 0.9999991945182144, \"fp_rate\": 8.054817855887691e-07, \"fn_rate\": 0.573955211359352, \"precision\": 0.9921091541472907, \"recall\": 0.426044788640648, \"specificity\": 0.9999991945182144, \"npv\": 0.999863587091114, \"accuracy\": 0.9998627957221972, \"f1\": 0.5961030352687736, \"f2\": 0.48092470522699843, \"f0_5\": 0.7838236985298123, \"p4\": 0.7469289212789749, \"phi\": 0.6500953913559343}, {\"truth_threshold\": 1.0799999758601189, \"match_probability\": 0.6788733382309773, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129474.0, \"tn\": 1278736772.0, \"fp\": 1020.0, \"fn\": 174487.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42595596145558146, \"tn_rate\": 0.9999992023384259, \"fp_rate\": 7.976615740781986e-07, \"fn_rate\": 0.5740440385444185, \"precision\": 0.9921835486689043, \"recall\": 0.42595596145558146, \"specificity\": 0.9999992023384259, \"npv\": 0.9998635659833534, \"accuracy\": 0.999862782430997, \"f1\": 0.5960295082344547, \"f2\": 0.48083764998091116, \"f0_5\": 0.7838007015062892, \"p4\": 0.7468711958865837, \"phi\": 0.6500519911615338}, {\"truth_threshold\": 1.099999975413084, \"match_probability\": 0.681887996121488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129452.0, \"tn\": 1278736772.0, \"fp\": 1020.0, \"fn\": 174509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42588358374923097, \"tn_rate\": 0.9999992023384259, \"fp_rate\": 7.976615740781986e-07, \"fn_rate\": 0.574116416250769, \"precision\": 0.9921822306701821, \"recall\": 0.42588358374923097, \"specificity\": 0.9999992023384259, \"npv\": 0.9998635487835689, \"accuracy\": 0.9998627652306202, \"f1\": 0.5959584101576078, \"f2\": 0.48076380285163367, \"f0_5\": 0.7837510247030631, \"p4\": 0.7468153717818308, \"phi\": 0.6499963234359596}, {\"truth_threshold\": 1.1199999749660492, \"match_probability\": 0.6848874895543896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129423.0, \"tn\": 1278736778.0, \"fp\": 1014.0, \"fn\": 174538.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42578817677267805, \"tn_rate\": 0.9999992070305528, \"fp_rate\": 7.929694471718562e-07, \"fn_rate\": 0.5742118232273219, \"precision\": 0.9922261321557534, \"recall\": 0.42578817677267805, \"specificity\": 0.9999992070305528, \"npv\": 0.9998635261117668, \"accuracy\": 0.9998627472484083, \"f1\": 0.5958729091754567, \"f2\": 0.4806685974176268, \"f0_5\": 0.783708304015095, \"p4\": 0.74674823273261, \"phi\": 0.6499378894109565}, {\"truth_threshold\": 1.1399999745190144, \"match_probability\": 0.6878716466293294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129380.0, \"tn\": 1278736778.0, \"fp\": 1014.0, \"fn\": 174581.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4256467112557203, \"tn_rate\": 0.9999992070305528, \"fp_rate\": 7.929694471718562e-07, \"fn_rate\": 0.5743532887442797, \"precision\": 0.992223568569106, \"recall\": 0.4256467112557203, \"specificity\": 0.9999992070305528, \"npv\": 0.9998634924940095, \"accuracy\": 0.9998627136294901, \"f1\": 0.595733904294874, \"f2\": 0.48052424608427335, \"f0_5\": 0.7836111524983133, \"p4\": 0.7466390641544776, \"phi\": 0.6498290606968419}, {\"truth_threshold\": 1.1599999740719795, \"match_probability\": 0.6908403001313297, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129368.0, \"tn\": 1278736780.0, \"fp\": 1012.0, \"fn\": 174593.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4256072325068019, \"tn_rate\": 0.9999992085945951, \"fp_rate\": 7.914054048697421e-07, \"fn_rate\": 0.5743927674931981, \"precision\": 0.9922380733241295, \"recall\": 0.4256072325068019, \"specificity\": 0.9999992085945951, \"npv\": 0.9998634831125237, \"accuracy\": 0.999862705811137, \"f1\": 0.5956978503065564, \"f2\": 0.48048467417012325, \"f0_5\": 0.7835916271846354, \"p4\": 0.7466107458904495, \"phi\": 0.6498036723858682}, {\"truth_threshold\": 1.1799999736249447, \"match_probability\": 0.6937932875421096, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129338.0, \"tn\": 1278736783.0, \"fp\": 1009.0, \"fn\": 174623.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42550853563450575, \"tn_rate\": 0.9999992109406586, \"fp_rate\": 7.890593414165709e-07, \"fn_rate\": 0.5744914643654943, \"precision\": 0.9922591237235994, \"recall\": 0.42550853563450575, \"specificity\": 0.9999992109406586, \"npv\": 0.9998634596585966, \"accuracy\": 0.9998626847015838, \"f1\": 0.5956049623769306, \"f2\": 0.4803850270875381, \"f0_5\": 0.7835352075303902, \"p4\": 0.7465377819151113, \"phi\": 0.6497352112832494}, {\"truth_threshold\": 1.1999999731779099, \"match_probability\": 0.6967304510487088, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129323.0, \"tn\": 1278736783.0, \"fp\": 1009.0, \"fn\": 174638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4254591871983577, \"tn_rate\": 0.9999992109406586, \"fp_rate\": 7.890593414165709e-07, \"fn_rate\": 0.5745408128016423, \"precision\": 0.9922582328207962, \"recall\": 0.4254591871983577, \"specificity\": 0.9999992109406586, \"npv\": 0.9998634479314733, \"accuracy\": 0.9998626729740542, \"f1\": 0.5955564561252427, \"f2\": 0.48033466649234574, \"f0_5\": 0.7835012946979786, \"p4\": 0.7464996765156693, \"phi\": 0.6496972379900111}, {\"truth_threshold\": 1.219999972730875, \"match_probability\": 0.6996516375494458, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129296.0, \"tn\": 1278736795.0, \"fp\": 997.0, \"fn\": 174665.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4253703600132912, \"tn_rate\": 0.9999992203249124, \"fp_rate\": 7.796750876038862e-07, \"fn_rate\": 0.5746296399867088, \"precision\": 0.9923480156263191, \"recall\": 0.4253703600132912, \"specificity\": 0.9999992203249124, \"npv\": 0.9998634268239336, \"accuracy\": 0.9998626612465246, \"f1\": 0.5954855913820022, \"f2\": 0.4802482956786716, \"f0_5\": 0.7834858138021386, \"p4\": 0.7464440033866232, \"phi\": 0.649658806514487}, {\"truth_threshold\": 1.2399999722838402, \"match_probability\": 0.7025566986572463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129243.0, \"tn\": 1278736797.0, \"fp\": 995.0, \"fn\": 174718.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42519599553890136, \"tn_rate\": 0.9999992218889547, \"fp_rate\": 7.781110453017721e-07, \"fn_rate\": 0.5748040044610986, \"precision\": 0.9923601406655508, \"recall\": 0.42519599553890136, \"specificity\": 0.9999992218889547, \"npv\": 0.999863385388316, \"accuracy\": 0.999862621372924, \"f1\": 0.5953168938666372, \"f2\": 0.4800710506492175, \"f0_5\": 0.7833735193893174, \"p4\": 0.7463114487992731, \"phi\": 0.6495295973991546}, {\"truth_threshold\": 1.2599999718368053, \"match_probability\": 0.7054454907003789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129207.0, \"tn\": 1278736803.0, \"fp\": 989.0, \"fn\": 174754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.425077559292146, \"tn_rate\": 0.9999992265810816, \"fp_rate\": 7.734189183954297e-07, \"fn_rate\": 0.5749224407078539, \"precision\": 0.9924037604841931, \"recall\": 0.425077559292146, \"specificity\": 0.9999992265810816, \"npv\": 0.9998633572438661, \"accuracy\": 0.9998625979178648, \"f1\": 0.595208645720327, \"f2\": 0.47995230453775517, \"f0_5\": 0.7833148427695833, \"p4\": 0.7462263780201833, \"phi\": 0.6494533987373805}, {\"truth_threshold\": 1.2799999713897705, \"match_probability\": 0.7083178747206358, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129177.0, \"tn\": 1278736806.0, \"fp\": 986.0, \"fn\": 174784.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4249788624198499, \"tn_rate\": 0.9999992289271451, \"fp_rate\": 7.710728549422585e-07, \"fn_rate\": 0.57502113758015, \"precision\": 0.9924248826471425, \"recall\": 0.4249788624198499, \"specificity\": 0.9999992289271451, \"npv\": 0.9998633337899455, \"accuracy\": 0.9998625768083116, \"f1\": 0.5951156812339332, \"f2\": 0.4798526307812664, \"f0_5\": 0.7832583284522557, \"p4\": 0.7461533091168939, \"phi\": 0.6493849030332839}, {\"truth_threshold\": 1.2999999709427357, \"match_probability\": 0.7111737164690025, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129144.0, \"tn\": 1278736822.0, \"fp\": 970.0, \"fn\": 174817.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4248702958603242, \"tn_rate\": 0.9999992414394835, \"fp_rate\": 7.585605165253457e-07, \"fn_rate\": 0.5751297041396758, \"precision\": 0.9925449990008761, \"recall\": 0.4248702958603242, \"specificity\": 0.9999992414394835, \"npv\": 0.9998633079919917, \"accuracy\": 0.9998625635171114, \"f1\": 0.595030812647584, \"f2\": 0.47974751069498456, \"f0_5\": 0.7832444018015154, \"p4\": 0.7460865968844422, \"phi\": 0.6493412494247884}, {\"truth_threshold\": 1.3199999704957008, \"match_probability\": 0.7140128863988563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129122.0, \"tn\": 1278736823.0, \"fp\": 969.0, \"fn\": 174839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4247979181539737, \"tn_rate\": 0.9999992422215046, \"fp_rate\": 7.577784953742886e-07, \"fn_rate\": 0.5752020818460263, \"precision\": 0.9925513678886319, \"recall\": 0.4247979181539737, \"specificity\": 0.9999992422215046, \"npv\": 0.9998632907923237, \"accuracy\": 0.9998625470985699, \"f1\": 0.5949609724180513, \"f2\": 0.47967398128438593, \"f0_5\": 0.7831983744275619, \"p4\": 0.7460316918308667, \"phi\": 0.6492880169252082}, {\"truth_threshold\": 1.339999970048666, \"match_probability\": 0.7168352596567393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129088.0, \"tn\": 1278736834.0, \"fp\": 958.0, \"fn\": 174873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42468606169870476, \"tn_rate\": 0.9999992508237373, \"fp_rate\": 7.491762627126609e-07, \"fn_rate\": 0.5753139383012952, \"precision\": 0.9926333758823801, \"recall\": 0.42468606169870476, \"specificity\": 0.9999992508237373, \"npv\": 0.9998632642120305, \"accuracy\": 0.999862529116358, \"f1\": 0.5948659814242627, \"f2\": 0.4795637087726337, \"f0_5\": 0.7831631569687373, \"p4\": 0.7459570073357458, \"phi\": 0.6492293475929507}, {\"truth_threshold\": 1.3599999696016312, \"match_probability\": 0.7196407160707529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129080.0, \"tn\": 1278736837.0, \"fp\": 955.0, \"fn\": 174881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4246597425327591, \"tn_rate\": 0.9999992531698008, \"fp_rate\": 7.468301992594898e-07, \"fn_rate\": 0.5753402574672408, \"precision\": 0.9926558234321529, \"recall\": 0.4246597425327591, \"specificity\": 0.9999992531698008, \"npv\": 0.9998632579578882, \"accuracy\": 0.9998625252071814, \"f1\": 0.5948441921123697, \"f2\": 0.47953790793971823, \"f0_5\": 0.783156433495409, \"p4\": 0.7459398747636101, \"phi\": 0.6492165711984886}, {\"truth_threshold\": 1.3799999691545963, \"match_probability\": 0.7224291401366201, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129019.0, \"tn\": 1278736839.0, \"fp\": 953.0, \"fn\": 174942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4244590588924237, \"tn_rate\": 0.999999254733843, \"fp_rate\": 7.452661569573756e-07, \"fn_rate\": 0.5755409411075763, \"precision\": 0.992667651494168, \"recall\": 0.4244590588924237, \"specificity\": 0.999999254733843, \"npv\": 0.9998632102678238, \"accuracy\": 0.9998624790788984, \"f1\": 0.5946494044011402, \"f2\": 0.4793337276418173, \"f0_5\": 0.7830257729268348, \"p4\": 0.7457866940837948, \"phi\": 0.6490670040955097}, {\"truth_threshold\": 1.3999999687075615, \"match_probability\": 0.7252004210014652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129001.0, \"tn\": 1278736840.0, \"fp\": 952.0, \"fn\": 174960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.424399840769046, \"tn_rate\": 0.9999992555158642, \"fp_rate\": 7.444841358063186e-07, \"fn_rate\": 0.575600159230954, \"precision\": 0.9926742745454126, \"recall\": 0.424399840769046, \"specificity\": 0.9999992555158642, \"npv\": 0.9998631961953904, \"accuracy\": 0.9998624657876982, \"f1\": 0.5945924768502514, \"f2\": 0.47927362001847235, \"f0_5\": 0.782988760253128, \"p4\": 0.7457419193283318, \"phi\": 0.6490238867802227}, {\"truth_threshold\": 1.4199999682605267, \"match_probability\": 0.7279544524453618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128961.0, \"tn\": 1278736852.0, \"fp\": 940.0, \"fn\": 175000.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42426824493931786, \"tn_rate\": 0.999999264900118, \"fp_rate\": 7.35099881993634e-07, \"fn_rate\": 0.5757317550606821, \"precision\": 0.9927637200637408, \"recall\": 0.42426824493931786, \"specificity\": 0.999999264900118, \"npv\": 0.9998631649243641, \"accuracy\": 0.9998624438963096, \"f1\": 0.5944793505769116, \"f2\": 0.4791435227327614, \"f0_5\": 0.7829436656487344, \"p4\": 0.7456529341973361, \"phi\": 0.6489524918617536}, {\"truth_threshold\": 1.4399999678134918, \"match_probability\": 0.7306911328606996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128910.0, \"tn\": 1278736896.0, \"fp\": 896.0, \"fn\": 175051.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42410046025641446, \"tn_rate\": 0.9999992993090486, \"fp_rate\": 7.006909513471234e-07, \"fn_rate\": 0.5758995397435855, \"precision\": 0.9930973914919187, \"recall\": 0.42410046025641446, \"specificity\": 0.9999992993090486, \"npv\": 0.9998631250568809, \"accuracy\": 0.9998624384234625, \"f1\": 0.5943743991589955, \"f2\": 0.4789878497380448, \"f0_5\": 0.7829953169700614, \"p4\": 0.7455703701801392, \"phi\": 0.6489332140724067}, {\"truth_threshold\": 1.459999967366457, \"match_probability\": 0.7334103652294244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128888.0, \"tn\": 1278736899.0, \"fp\": 893.0, \"fn\": 175073.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42402808255006397, \"tn_rate\": 0.9999993016551121, \"fp_rate\": 6.983448878939523e-07, \"fn_rate\": 0.575971917449936, \"precision\": 0.9931191776916498, \"recall\": 0.42402808255006397, \"specificity\": 0.9999993016551121, \"npv\": 0.9998631078574343, \"accuracy\": 0.9998624235685917, \"f1\": 0.5943072148881132, \"f2\": 0.4789150023223409, \"f0_5\": 0.7829568027603467, \"p4\": 0.7455175098383867, \"phi\": 0.6488849521320829}, {\"truth_threshold\": 1.4799999669194221, \"match_probability\": 0.7361120570982027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128877.0, \"tn\": 1278736908.0, \"fp\": 884.0, \"fn\": 175084.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4239918936968887, \"tn_rate\": 0.9999993086933024, \"fp_rate\": 6.913066975344387e-07, \"fn_rate\": 0.5760081063031113, \"precision\": 0.9931874754356086, \"recall\": 0.4239918936968887, \"specificity\": 0.9999993086933024, \"npv\": 0.9998630992585141, \"accuracy\": 0.999862422004921, \"f1\": 0.5942838961362348, \"f2\": 0.4788812467254506, \"f0_5\": 0.782966081615543, \"p4\": 0.7454991621865766, \"phi\": 0.648879578349351}, {\"truth_threshold\": 1.4999999664723873, \"match_probability\": 0.7387961205515697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128847.0, \"tn\": 1278736947.0, \"fp\": 845.0, \"fn\": 175114.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42389319682459264, \"tn_rate\": 0.9999993391921274, \"fp_rate\": 6.608078726432135e-07, \"fn_rate\": 0.5761068031754074, \"precision\": 0.9934845634271967, \"recall\": 0.42389319682459264, \"specificity\": 0.9999993391921274, \"npv\": 0.9998630758084625, \"accuracy\": 0.9998624290414388, \"f1\": 0.5942400951913166, \"f2\": 0.4787943243436073, \"f0_5\": 0.783046422333478, \"p4\": 0.745464698678491, \"phi\": 0.6489011095242676}, {\"truth_threshold\": 1.5199999660253525, \"match_probability\": 0.7414624721831113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128801.0, \"tn\": 1278736950.0, \"fp\": 842.0, \"fn\": 175160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4237418616204052, \"tn_rate\": 0.9999993415381908, \"fp_rate\": 6.584618091900423e-07, \"fn_rate\": 0.5762581383795947, \"precision\": 0.9935052413165385, \"recall\": 0.4237418616204052, \"specificity\": 0.9999993415381908, \"npv\": 0.9998630398456388, \"accuracy\": 0.9998623954225206, \"f1\": 0.5940950729236815, \"f2\": 0.4786408192721297, \"f0_5\": 0.7829533891041454, \"p4\": 0.7453505706698584, \"phi\": 0.6487920087664826}, {\"truth_threshold\": 1.5399999655783176, \"match_probability\": 0.7441110330647412, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128740.0, \"tn\": 1278736951.0, \"fp\": 841.0, \"fn\": 175221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4235411779800698, \"tn_rate\": 0.9999993423202119, \"fp_rate\": 6.576797880389852e-07, \"fn_rate\": 0.5764588220199302, \"precision\": 0.9935098509812396, \"recall\": 0.4235411779800698, \"specificity\": 0.9999993423202119, \"npv\": 0.9998629921554926, \"accuracy\": 0.9998623485124023, \"f1\": 0.593898630351846, \"f2\": 0.4784361818756155, \"f0_5\": 0.7828186091197091, \"p4\": 0.7451959431780173, \"phi\": 0.6486398467827132}, {\"truth_threshold\": 1.5599999651312828, \"match_probability\": 0.7467417287141271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128728.0, \"tn\": 1278736951.0, \"fp\": 841.0, \"fn\": 175233.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4235016992311514, \"tn_rate\": 0.9999993423202119, \"fp_rate\": 6.576797880389852e-07, \"fn_rate\": 0.5764983007688487, \"precision\": 0.9935092498977379, \"recall\": 0.4235016992311514, \"specificity\": 0.9999993423202119, \"npv\": 0.9998629827738039, \"accuracy\": 0.9998623391303787, \"f1\": 0.5938597098240029, \"f2\": 0.4783958531692499, \"f0_5\": 0.7827913363178743, \"p4\": 0.7451653028004527, \"phi\": 0.6486094165093513}, {\"truth_threshold\": 1.579999964684248, \"match_probability\": 0.7493544890603256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128712.0, \"tn\": 1278736953.0, \"fp\": 839.0, \"fn\": 175249.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4234490608992601, \"tn_rate\": 0.9999993438842543, \"fp_rate\": 6.561157457368711e-07, \"fn_rate\": 0.5765509391007398, \"precision\": 0.9935237859993362, \"recall\": 0.4234490608992601, \"specificity\": 0.9999993438842543, \"npv\": 0.9998629702651003, \"accuracy\": 0.9998623281846843, \"f1\": 0.5938105519570392, \"f2\": 0.4783427915221924, \"f0_5\": 0.7827625841528161, \"p4\": 0.7451266010143577, \"phi\": 0.6485738487429519}, {\"truth_threshold\": 1.5999999642372131, \"match_probability\": 0.7519492484076834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128684.0, \"tn\": 1278736964.0, \"fp\": 828.0, \"fn\": 175277.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4233569438184504, \"tn_rate\": 0.999999352486487, \"fp_rate\": 6.475135130752435e-07, \"fn_rate\": 0.5766430561815497, \"precision\": 0.9936067700290321, \"recall\": 0.4233569438184504, \"specificity\": 0.999999352486487, \"npv\": 0.9998629483756736, \"accuracy\": 0.9998623148934842, \"f1\": 0.5937347885566113, \"f2\": 0.4782525963388129, \"f0_5\": 0.7827408215725132, \"p4\": 0.7450669486234889, \"phi\": 0.6485303851593425}, {\"truth_threshold\": 1.6199999637901783, \"match_probability\": 0.754525945398063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128644.0, \"tn\": 1278736973.0, \"fp\": 819.0, \"fn\": 175317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42322534798872224, \"tn_rate\": 0.9999993595246773, \"fp_rate\": 6.4047532271573e-07, \"fn_rate\": 0.5767746520112778, \"precision\": 0.9936738682094498, \"recall\": 0.42322534798872224, \"specificity\": 0.9999993595246773, \"npv\": 0.9998629171043465, \"accuracy\": 0.9998622906565897, \"f1\": 0.5936173354498135, \"f2\": 0.47812135074001694, \"f0_5\": 0.7826841386057413, \"p4\": 0.7449744600842376, \"phi\": 0.6484514749526248}, {\"truth_threshold\": 1.6399999633431435, \"match_probability\": 0.7570845229714535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128615.0, \"tn\": 1278736978.0, \"fp\": 814.0, \"fn\": 175346.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42312994101216933, \"tn_rate\": 0.999999363434783, \"fp_rate\": 6.365652169604447e-07, \"fn_rate\": 0.5768700589878307, \"precision\": 0.993710837602083, \"recall\": 0.42312994101216933, \"specificity\": 0.999999363434783, \"npv\": 0.9998628944324724, \"accuracy\": 0.9998622718925424, \"f1\": 0.593530076836106, \"f2\": 0.4780256498123429, \"f0_5\": 0.7826372163270969, \"p4\": 0.744905739290598, \"phi\": 0.6483904395906406}, {\"truth_threshold\": 1.6599999628961086, \"match_probability\": 0.7596249283250239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128591.0, \"tn\": 1278736980.0, \"fp\": 812.0, \"fn\": 175370.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42305098351433246, \"tn_rate\": 0.9999993649988254, \"fp_rate\": 6.350011746583306e-07, \"fn_rate\": 0.5769490164856675, \"precision\": 0.9937250295588201, \"recall\": 0.42305098351433246, \"specificity\": 0.9999993649988254, \"npv\": 0.9998628756693139, \"accuracy\": 0.9998622546921656, \"f1\": 0.5934549247284039, \"f2\": 0.4779456858108585, \"f0_5\": 0.782590226309774, \"p4\": 0.7448465468375406, \"phi\": 0.6483345660885438}, {\"truth_threshold\": 1.6799999624490738, \"match_probability\": 0.7621471128706805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128542.0, \"tn\": 1278736980.0, \"fp\": 812.0, \"fn\": 175419.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42288977862291544, \"tn_rate\": 0.9999993649988254, \"fp_rate\": 6.350011746583306e-07, \"fn_rate\": 0.5771102213770846, \"precision\": 0.9937226525658271, \"recall\": 0.42288977862291544, \"specificity\": 0.9999993649988254, \"npv\": 0.9998628373607629, \"accuracy\": 0.9998622163822356, \"f1\": 0.5932958702098935, \"f2\": 0.4777809660733959, \"f0_5\": 0.7824786912708781, \"p4\": 0.744721251206688, \"phi\": 0.6482102413183884}, {\"truth_threshold\": 1.699999962002039, \"match_probability\": 0.764651032191186, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128529.0, \"tn\": 1278736991.0, \"fp\": 801.0, \"fn\": 175432.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4228470099782538, \"tn_rate\": 0.999999373601058, \"fp_rate\": 6.26398941996703e-07, \"fn_rate\": 0.5771529900217462, \"precision\": 0.9938065414057063, \"recall\": 0.4228470099782538, \"specificity\": 0.999999373601058, \"npv\": 0.99986282719845, \"accuracy\": 0.9998622148185651, \"f1\": 0.5932687270217937, \"f2\": 0.4777411695438657, \"f0_5\": 0.7824910109938011, \"p4\": 0.7446998672776982, \"phi\": 0.6482048279578035}, {\"truth_threshold\": 1.7199999615550041, \"match_probability\": 0.767136645994902, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128501.0, \"tn\": 1278736992.0, \"fp\": 800.0, \"fn\": 175460.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42275489289744406, \"tn_rate\": 0.9999993743830792, \"fp_rate\": 6.256169208456459e-07, \"fn_rate\": 0.5772451071025559, \"precision\": 0.9938128862112435, \"recall\": 0.42275489289744406, \"specificity\": 0.9999993743830792, \"npv\": 0.9998628053079587, \"accuracy\": 0.9998621937090117, \"f1\": 0.5931791848812035, \"f2\": 0.4776473911734423, \"f0_5\": 0.7824310583134937, \"p4\": 0.744629316867309, \"phi\": 0.6481362811034941}, {\"truth_threshold\": 1.7399999611079693, \"match_probability\": 0.7696039180692122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128490.0, \"tn\": 1278737005.0, \"fp\": 787.0, \"fn\": 175471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4227187040442688, \"tn_rate\": 0.9999993845493541, \"fp_rate\": 6.154506458819041e-07, \"fn_rate\": 0.5772812959557312, \"precision\": 0.993912296850948, \"recall\": 0.4227187040442688, \"specificity\": 0.9999993845493541, \"npv\": 0.9998627967094755, \"accuracy\": 0.9998621952726824, \"f1\": 0.5931612647090052, \"f2\": 0.47761502496801406, \"f0_5\": 0.7824555548924633, \"p4\": 0.7446151973825229, \"phi\": 0.6481409630950747}, {\"truth_threshold\": 1.7599999606609344, \"match_probability\": 0.7720528162326886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128466.0, \"tn\": 1278737010.0, \"fp\": 782.0, \"fn\": 175495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42263974654643194, \"tn_rate\": 0.9999993884594599, \"fp_rate\": 6.115405401266188e-07, \"fn_rate\": 0.577360253453568, \"precision\": 0.993949616241644, \"recall\": 0.42263974654643194, \"specificity\": 0.9999993884594599, \"npv\": 0.999862777946643, \"accuracy\": 0.9998621804178116, \"f1\": 0.5930901712568298, \"f2\": 0.4775361090542506, \"f0_5\": 0.7824199436508545, \"p4\": 0.7445591760829502, \"phi\": 0.6480925941853309}, {\"truth_threshold\": 1.7799999602138996, \"match_probability\": 0.7744833122860583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128426.0, \"tn\": 1278737012.0, \"fp\": 780.0, \"fn\": 175535.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4225081507167038, \"tn_rate\": 0.9999993900235021, \"fp_rate\": 6.099764978245048e-07, \"fn_rate\": 0.5774918492832962, \"precision\": 0.9939631286472764, \"recall\": 0.4225081507167038, \"specificity\": 0.9999993900235021, \"npv\": 0.9998627466745778, \"accuracy\": 0.9998621507080699, \"f1\": 0.5929629911789217, \"f2\": 0.477402327051039, \"f0_5\": 0.7823364218400677, \"p4\": 0.7444589458840294, \"phi\": 0.6479960852553193}, {\"truth_threshold\": 1.7999999597668648, \"match_probability\": 0.7768953819620296, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128391.0, \"tn\": 1278737013.0, \"fp\": 779.0, \"fn\": 175570.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42239300436569166, \"tn_rate\": 0.9999993908055234, \"fp_rate\": 6.091944766734477e-07, \"fn_rate\": 0.5776069956343084, \"precision\": 0.9939691878919253, \"recall\": 0.42239300436569166, \"specificity\": 0.9999993908055234, \"npv\": 0.9998627193114418, \"accuracy\": 0.9998621241256695, \"f1\": 0.5928506618090139, \"f2\": 0.47728499480302805, \"f0_5\": 0.782260452499936, \"p4\": 0.7443704061221263, \"phi\": 0.6479097465551872}, {\"truth_threshold\": 1.81999995931983, \"match_probability\": 0.7792890048740371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128375.0, \"tn\": 1278737018.0, \"fp\": 774.0, \"fn\": 175586.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4223403660338004, \"tn_rate\": 0.999999394715629, \"fp_rate\": 6.052843709181624e-07, \"fn_rate\": 0.5776596339661996, \"precision\": 0.994006922237106, \"recall\": 0.4223403660338004, \"specificity\": 0.999999394715629, \"npv\": 0.9998627068030679, \"accuracy\": 0.9998621155254812, \"f1\": 0.5928055228463901, \"f2\": 0.47723296701172424, \"f0_5\": 0.7822430373514576, \"p4\": 0.744334823659067, \"phi\": 0.6478816723329587}, {\"truth_threshold\": 1.839999958872795, \"match_probability\": 0.781664164463966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128355.0, \"tn\": 1278737018.0, \"fp\": 774.0, \"fn\": 175606.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4222745681189363, \"tn_rate\": 0.999999394715629, \"fp_rate\": 6.052843709181624e-07, \"fn_rate\": 0.5777254318810637, \"precision\": 0.994005994005994, \"recall\": 0.4222745681189363, \"specificity\": 0.999999394715629, \"npv\": 0.9998626911669299, \"accuracy\": 0.9998620998887751, \"f1\": 0.5927405389180078, \"f2\": 0.47716571262025337, \"f0_5\": 0.7821974290565122, \"p4\": 0.744283593672514, \"phi\": 0.6478308947751331}, {\"truth_threshold\": 1.8599999584257603, \"match_probability\": 0.784020847948909, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128294.0, \"tn\": 1278737021.0, \"fp\": 771.0, \"fn\": 175667.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4220738844786009, \"tn_rate\": 0.9999993970616925, \"fp_rate\": 6.029383074649913e-07, \"fn_rate\": 0.5779261155213992, \"precision\": 0.9940262658350444, \"recall\": 0.4220738844786009, \"specificity\": 0.9999993970616925, \"npv\": 0.9998626434770346, \"accuracy\": 0.9998620545423273, \"f1\": 0.5925464059894787, \"f2\": 0.47696163829671745, \"f0_5\": 0.782069710480468, \"p4\": 0.7441305245488513, \"phi\": 0.6476835287699173}, {\"truth_threshold\": 1.8799999579787254, \"match_probability\": 0.7863590462670179, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128272.0, \"tn\": 1278737023.0, \"fp\": 769.0, \"fn\": 175689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4220015067722504, \"tn_rate\": 0.9999993986257348, \"fp_rate\": 6.013742651628771e-07, \"fn_rate\": 0.5779984932277497, \"precision\": 0.9940406537457087, \"recall\": 0.4220015067722504, \"specificity\": 0.9999993986257348, \"npv\": 0.9998626262775, \"accuracy\": 0.9998620389056212, \"f1\": 0.5924776328977696, \"f2\": 0.47688835848418265, \"f0_5\": 0.7820271300106691, \"p4\": 0.7440762897358241, \"phi\": 0.6476326767912667}, {\"truth_threshold\": 1.8999999575316906, \"match_probability\": 0.7886787540225041, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128249.0, \"tn\": 1278737023.0, \"fp\": 769.0, \"fn\": 175712.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4219258391701567, \"tn_rate\": 0.9999993986257348, \"fp_rate\": 6.013742651628771e-07, \"fn_rate\": 0.5780741608298433, \"precision\": 0.9940395913748469, \"recall\": 0.4219258391701567, \"specificity\": 0.9999993986257348, \"npv\": 0.9998626082959444, \"accuracy\": 0.9998620209234093, \"f1\": 0.5924028648040667, \"f2\": 0.4768110036568808, \"f0_5\": 0.7819746278503427, \"p4\": 0.7440173217831805, \"phi\": 0.6475742597895305}, {\"truth_threshold\": 1.9199999570846558, \"match_probability\": 0.7909799694298455, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128208.0, \"tn\": 1278737024.0, \"fp\": 768.0, \"fn\": 175753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4217909534446853, \"tn_rate\": 0.999999399407756, \"fp_rate\": 6.005922440118201e-07, \"fn_rate\": 0.5782090465553147, \"precision\": 0.9940454037960551, \"recall\": 0.4217909534446853, \"specificity\": 0.999999399407756, \"npv\": 0.9998625762419762, \"accuracy\": 0.999861989649997, \"f1\": 0.592270930874469, \"f2\": 0.4766734581579691, \"f0_5\": 0.7818848225012655, \"p4\": 0.7439132549493191, \"phi\": 0.6474726230529739}, {\"truth_threshold\": 1.939999956637621, \"match_probability\": 0.7932626942572559, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128160.0, \"tn\": 1278737024.0, \"fp\": 768.0, \"fn\": 175801.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42163303844901157, \"tn_rate\": 0.999999399407756, \"fp_rate\": 6.005922440118201e-07, \"fn_rate\": 0.5783669615509884, \"precision\": 0.9940431868950111, \"recall\": 0.42163303844901157, \"specificity\": 0.999999399407756, \"npv\": 0.9998625387152561, \"accuracy\": 0.9998619521219023, \"f1\": 0.5921148377528651, \"f2\": 0.4765120035217866, \"f0_5\": 0.7817751713183184, \"p4\": 0.7437901094860346, \"phi\": 0.647350673197191}, {\"truth_threshold\": 1.959999956190586, \"match_probability\": 0.7955269337694706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128105.0, \"tn\": 1278737027.0, \"fp\": 765.0, \"fn\": 175856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42145209418313534, \"tn_rate\": 0.9999994017538194, \"fp_rate\": 5.982461805586489e-07, \"fn_rate\": 0.5785479058168647, \"precision\": 0.9940637852099015, \"recall\": 0.42145209418313534, \"specificity\": 0.9999994017538194, \"npv\": 0.9998624957162152, \"accuracy\": 0.9998619114664664, \"f1\": 0.5919400412632182, \"f2\": 0.47632805191289745, \"f0_5\": 0.7816609127441756, \"p4\": 0.743652180034698, \"phi\": 0.6472184468534298}, {\"truth_threshold\": 1.9799999557435513, \"match_probability\": 0.7977726966699026, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128093.0, \"tn\": 1278737035.0, \"fp\": 757.0, \"fn\": 175868.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4214126154342169, \"tn_rate\": 0.9999994080099887, \"fp_rate\": 5.919900113501924e-07, \"fn_rate\": 0.5785873845657831, \"precision\": 0.9941249514939853, \"recall\": 0.4214126154342169, \"specificity\": 0.9999994080099887, \"npv\": 0.9998624863353966, \"accuracy\": 0.9998619083391251, \"f1\": 0.5919119430883226, \"f2\": 0.4762905166528593, \"f0_5\": 0.7816640040226469, \"p4\": 0.7436300058059693, \"phi\": 0.6472080480446772}, {\"truth_threshold\": 1.9999999552965164, \"match_probability\": 0.7999999950422251, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128077.0, \"tn\": 1278737036.0, \"fp\": 756.0, \"fn\": 175884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42135997710232564, \"tn_rate\": 0.9999994087920098, \"fp_rate\": 5.912079901991354e-07, \"fn_rate\": 0.5786400228976744, \"precision\": 0.9941319382456358, \"recall\": 0.42135997710232564, \"specificity\": 0.9999994087920098, \"npv\": 0.9998624738265995, \"accuracy\": 0.9998618966115956, \"f1\": 0.5918612550081563, \"f2\": 0.4762370442864718, \"f0_5\": 0.7816312357117661, \"p4\": 0.7435900014867076, \"phi\": 0.6471698965906542}, {\"truth_threshold\": 2.0199999548494816, \"match_probability\": 0.8022088442914298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128051.0, \"tn\": 1278737036.0, \"fp\": 756.0, \"fn\": 175910.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42127443981300233, \"tn_rate\": 0.9999994087920098, \"fp_rate\": 5.912079901991354e-07, \"fn_rate\": 0.5787255601869977, \"precision\": 0.9941307537633824, \"recall\": 0.42127443981300233, \"specificity\": 0.9999994087920098, \"npv\": 0.9998624534996301, \"accuracy\": 0.9998618762838777, \"f1\": 0.5917766563146998, \"f2\": 0.4761495733837256, \"f0_5\": 0.7815717740350517, \"p4\": 0.7435232282726449, \"phi\": 0.6471038123137034}, {\"truth_threshold\": 2.0399999544024467, \"match_probability\": 0.8043992630844159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128032.0, \"tn\": 1278737036.0, \"fp\": 756.0, \"fn\": 175929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42121193179388144, \"tn_rate\": 0.9999994087920098, \"fp_rate\": 5.912079901991354e-07, \"fn_rate\": 0.5787880682061185, \"precision\": 0.9941298878777526, \"recall\": 0.42121193179388144, \"specificity\": 0.9999994087920098, \"npv\": 0.9998624386453069, \"accuracy\": 0.9998618614290068, \"f1\": 0.5917148277639, \"f2\": 0.4760856502002035, \"f0_5\": 0.7815283117225584, \"p4\": 0.7434744228997563, \"phi\": 0.6470555156915571}, {\"truth_threshold\": 2.059999953955412, \"match_probability\": 0.8065712732901567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128022.0, \"tn\": 1278737036.0, \"fp\": 756.0, \"fn\": 175939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4211790328364494, \"tn_rate\": 0.9999994087920098, \"fp_rate\": 5.912079901991354e-07, \"fn_rate\": 0.5788209671635506, \"precision\": 0.9941294320458464, \"recall\": 0.4211790328364494, \"specificity\": 0.9999994087920098, \"npv\": 0.9998624308272421, \"accuracy\": 0.9998618536106538, \"f1\": 0.5916822842406162, \"f2\": 0.4760520056937935, \"f0_5\": 0.7815054335816222, \"p4\": 0.7434487326171577, \"phi\": 0.6470300949695127}, {\"truth_threshold\": 2.079999953508377, \"match_probability\": 0.8087248999194987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127965.0, \"tn\": 1278737037.0, \"fp\": 755.0, \"fn\": 175996.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4209915087790868, \"tn_rate\": 0.999999409574031, \"fp_rate\": 5.904259690480783e-07, \"fn_rate\": 0.5790084912209132, \"precision\": 0.9941345556246115, \"recall\": 0.4209915087790868, \"specificity\": 0.999999409574031, \"npv\": 0.9998623862643833, \"accuracy\": 0.9998618098278766, \"f1\": 0.5914981244843198, \"f2\": 0.4758605763652753, \"f0_5\": 0.7813788024781367, \"p4\": 0.7433033347699808, \"phi\": 0.6468876914936924}, {\"truth_threshold\": 2.0999999530613422, \"match_probability\": 0.8108601710646386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127915.0, \"tn\": 1278737038.0, \"fp\": 754.0, \"fn\": 176046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42082701399192657, \"tn_rate\": 0.9999994103560521, \"fp_rate\": 5.896439478970212e-07, \"fn_rate\": 0.5791729860080734, \"precision\": 0.9941400026424392, \"recall\": 0.42082701399192657, \"specificity\": 0.9999994103560521, \"npv\": 0.9998623471741728, \"accuracy\": 0.9998617715179466, \"f1\": 0.5913367080415135, \"f2\": 0.47569268575313145, \"f0_5\": 0.781268132273523, \"p4\": 0.7431758655657654, \"phi\": 0.6467630591389814}, {\"truth_threshold\": 2.1199999526143074, \"match_probability\": 0.8129771178383269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127875.0, \"tn\": 1278737039.0, \"fp\": 753.0, \"fn\": 176086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42069541816219846, \"tn_rate\": 0.9999994111380732, \"fp_rate\": 5.888619267459642e-07, \"fn_rate\": 0.5793045818378015, \"precision\": 0.9941459091333147, \"recall\": 0.42069541816219846, \"specificity\": 0.9999994111380732, \"npv\": 0.9998623159020281, \"accuracy\": 0.9998617410263697, \"f1\": 0.591207820818375, \"f2\": 0.4755584348353852, \"f0_5\": 0.781180319937249, \"p4\": 0.7430740658590288, \"phi\": 0.6466638389103798}, {\"truth_threshold\": 2.1399999521672726, \"match_probability\": 0.8150757743128464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127860.0, \"tn\": 1278737040.0, \"fp\": 752.0, \"fn\": 176101.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4206460697260504, \"tn_rate\": 0.9999994119200944, \"fp_rate\": 5.880799055949071e-07, \"fn_rate\": 0.5793539302739497, \"precision\": 0.9941529561782726, \"recall\": 0.4206460697260504, \"specificity\": 0.9999994119200944, \"npv\": 0.9998623041750417, \"accuracy\": 0.9998617300806755, \"f1\": 0.5911603359432974, \"f2\": 0.47550830968064406, \"f0_5\": 0.7811497674145812, \"p4\": 0.7430365565011795, \"phi\": 0.6466281991646652}, {\"truth_threshold\": 2.1599999517202377, \"match_probability\": 0.8171561774588095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127838.0, \"tn\": 1278737042.0, \"fp\": 750.0, \"fn\": 176123.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4205736920196999, \"tn_rate\": 0.9999994134841367, \"fp_rate\": 5.86515863292793e-07, \"fn_rate\": 0.5794263079803001, \"precision\": 0.9941674184216257, \"recall\": 0.4205736920196999, \"specificity\": 0.9999994134841367, \"npv\": 0.9998622869755196, \"accuracy\": 0.9998617144439693, \"f1\": 0.5910914139207349, \"f2\": 0.47543497923286565, \"f0_5\": 0.7811069847356696, \"p4\": 0.7429821095162046, \"phi\": 0.6465772654230437}, {\"truth_threshold\": 2.179999951273203, \"match_probability\": 0.8192183670838221, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127796.0, \"tn\": 1278737042.0, \"fp\": 750.0, \"fn\": 176165.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4204355163984853, \"tn_rate\": 0.9999994134841367, \"fp_rate\": 5.86515863292793e-07, \"fn_rate\": 0.5795644836015147, \"precision\": 0.9941655127347409, \"recall\": 0.4204355163984853, \"specificity\": 0.9999994134841367, \"npv\": 0.9998622541396588, \"accuracy\": 0.9998616816068865, \"f1\": 0.5909545972666338, \"f2\": 0.4752936275931835, \"f0_5\": 0.7810107010371022, \"p4\": 0.7428740129409477, \"phi\": 0.6464704126773456}, {\"truth_threshold\": 2.199999950826168, \"match_probability\": 0.8212623857710541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127768.0, \"tn\": 1278737044.0, \"fp\": 748.0, \"fn\": 176193.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4203433993176756, \"tn_rate\": 0.999999415048179, \"fp_rate\": 5.849518209906789e-07, \"fn_rate\": 0.5796566006823244, \"precision\": 0.9941797130318404, \"recall\": 0.4203433993176756, \"specificity\": 0.999999415048179, \"npv\": 0.9998622322493015, \"accuracy\": 0.9998616612791685, \"f1\": 0.5908661038621708, \"f2\": 0.4752000952125919, \"f0_5\": 0.7809541273188472, \"p4\": 0.7428040859908797, \"phi\": 0.6464041993034886}, {\"truth_threshold\": 2.2199999503791332, \"match_probability\": 0.8232882788177627, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127756.0, \"tn\": 1278737044.0, \"fp\": 748.0, \"fn\": 176205.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42030392056875715, \"tn_rate\": 0.999999415048179, \"fp_rate\": 5.849518209906789e-07, \"fn_rate\": 0.5796960794312428, \"precision\": 0.994179169520015, \"recall\": 0.42030392056875715, \"specificity\": 0.999999415048179, \"npv\": 0.9998622228676278, \"accuracy\": 0.9998616518971449, \"f1\": 0.5908270033413109, \"f2\": 0.47515970567144816, \"f0_5\": 0.7809266030707465, \"p4\": 0.7427731864640365, \"phi\": 0.6463736635738109}, {\"truth_threshold\": 2.2399999499320984, \"match_probability\": 0.8252960941738079, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127729.0, \"tn\": 1278737046.0, \"fp\": 746.0, \"fn\": 176232.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4202150933836907, \"tn_rate\": 0.9999994166122214, \"fp_rate\": 5.833877786885648e-07, \"fn_rate\": 0.5797849066163093, \"precision\": 0.9941934228449114, \"recall\": 0.4202150933836907, \"specificity\": 0.9999994166122214, \"npv\": 0.9998622017590781, \"accuracy\": 0.9998616323512622, \"f1\": 0.5907417513805511, \"f2\": 0.4750695333473677, \"f0_5\": 0.780872299816228, \"p4\": 0.7427058102199385, \"phi\": 0.6463099853798066}, {\"truth_threshold\": 2.2599999494850636, \"match_probability\": 0.8272858823802022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127706.0, \"tn\": 1278737046.0, \"fp\": 746.0, \"fn\": 176255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42013942578159696, \"tn_rate\": 0.9999994166122214, \"fp_rate\": 5.833877786885648e-07, \"fn_rate\": 0.579860574218403, \"precision\": 0.9941923831470121, \"recall\": 0.42013942578159696, \"specificity\": 0.9999994166122214, \"npv\": 0.9998621837775382, \"accuracy\": 0.9998616143690502, \"f1\": 0.5906667930890145, \"f2\": 0.4749921148318525, \"f0_5\": 0.7808195223834604, \"p4\": 0.7426465631824174, \"phi\": 0.6462514487596673}, {\"truth_threshold\": 2.2799999490380287, \"match_probability\": 0.8292576965077321, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127685.0, \"tn\": 1278737046.0, \"fp\": 746.0, \"fn\": 176276.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4200703379709897, \"tn_rate\": 0.9999994166122214, \"fp_rate\": 5.833877786885648e-07, \"fn_rate\": 0.5799296620290103, \"precision\": 0.9941914335324026, \"recall\": 0.4200703379709897, \"specificity\": 0.9999994166122214, \"npv\": 0.999862167359611, \"accuracy\": 0.9998615979505088, \"f1\": 0.5905983459453459, \"f2\": 0.4749214260474977, \"f0_5\": 0.7807713239205807, \"p4\": 0.7425924576798094, \"phi\": 0.6461979976518538}, {\"truth_threshold\": 2.299999948590994, \"match_probability\": 0.831211592095691, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127655.0, \"tn\": 1278737046.0, \"fp\": 746.0, \"fn\": 176306.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41997164109869356, \"tn_rate\": 0.9999994166122214, \"fp_rate\": 5.833877786885648e-07, \"fn_rate\": 0.5800283589013064, \"precision\": 0.9941900764012741, \"recall\": 0.41997164109869356, \"specificity\": 0.9999994166122214, \"npv\": 0.9998621439054302, \"accuracy\": 0.9998615744954497, \"f1\": 0.5905005527775337, \"f2\": 0.4748204382385651, \"f0_5\": 0.7807024517928238, \"p4\": 0.7425151469091366, \"phi\": 0.6461216312600051}, {\"truth_threshold\": 2.319999948143959, \"match_probability\": 0.8331476270907604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127608.0, \"tn\": 1278737055.0, \"fp\": 737.0, \"fn\": 176353.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.419817015998763, \"tn_rate\": 0.9999994236504117, \"fp_rate\": 5.763495883290513e-07, \"fn_rate\": 0.580182984001237, \"precision\": 0.9942576648876076, \"recall\": 0.419817015998763, \"specificity\": 0.9999994236504117, \"npv\": 0.9998621071615195, \"accuracy\": 0.999861544785708, \"f1\": 0.5903596063899182, \"f2\": 0.4746653930362471, \"f0_5\": 0.7806288929589975, \"p4\": 0.7424037050320929, \"phi\": 0.6460246305571589}, {\"truth_threshold\": 2.339999947696924, \"match_probability\": 0.8350658617860744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127587.0, \"tn\": 1278737055.0, \"fp\": 737.0, \"fn\": 176374.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4197479281881557, \"tn_rate\": 0.9999994236504117, \"fp_rate\": 5.763495883290513e-07, \"fn_rate\": 0.5802520718118442, \"precision\": 0.9942567251644275, \"recall\": 0.4197479281881557, \"specificity\": 0.9999994236504117, \"npv\": 0.9998620907435948, \"accuracy\": 0.9998615283671666, \"f1\": 0.5902911273812416, \"f2\": 0.4745946935204528, \"f0_5\": 0.7805806496610002, \"p4\": 0.7423495534301735, \"phi\": 0.645971160649053}, {\"truth_threshold\": 2.3599999472498894, \"match_probability\": 0.8369663587605032, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127561.0, \"tn\": 1278737057.0, \"fp\": 735.0, \"fn\": 176400.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4196623908988324, \"tn_rate\": 0.999999425214454, \"fp_rate\": 5.747855460269372e-07, \"fn_rate\": 0.5803376091011676, \"precision\": 0.9942710606721955, \"recall\": 0.4196623908988324, \"specificity\": 0.999999425214454, \"npv\": 0.999862070416857, \"accuracy\": 0.9998615096031193, \"f1\": 0.5902090654402358, \"f2\": 0.47450786376419124, \"f0_5\": 0.7805285475649977, \"p4\": 0.742284654745568, \"phi\": 0.6459099900537377}, {\"truth_threshold\": 2.3799999468028545, \"match_probability\": 0.8388491828181879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127528.0, \"tn\": 1278737059.0, \"fp\": 733.0, \"fn\": 176433.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4195538243393067, \"tn_rate\": 0.9999994267784963, \"fp_rate\": 5.732215037248231e-07, \"fn_rate\": 0.5804461756606933, \"precision\": 0.994285090557535, \"recall\": 0.4195538243393067, \"specificity\": 0.9999994267784963, \"npv\": 0.9998620446174791, \"accuracy\": 0.9998614853662248, \"f1\": 0.5901041594365858, \"f2\": 0.4743974615078435, \"f0_5\": 0.7804603399000006, \"p4\": 0.7422016800461434, \"phi\": 0.6458309861350159}, {\"truth_threshold\": 2.3999999463558197, \"match_probability\": 0.8407144009283612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127507.0, \"tn\": 1278737059.0, \"fp\": 733.0, \"fn\": 176454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4194847365286994, \"tn_rate\": 0.9999994267784963, \"fp_rate\": 5.732215037248231e-07, \"fn_rate\": 0.5805152634713006, \"precision\": 0.9942841547099189, \"recall\": 0.4194847365286994, \"specificity\": 0.9999994267784963, \"npv\": 0.9998620281995566, \"accuracy\": 0.9998614689476834, \"f1\": 0.5900356547069535, \"f2\": 0.4743267533874371, \"f0_5\": 0.780412059428023, \"p4\": 0.7421474907000675, \"phi\": 0.6457775001831697}, {\"truth_threshold\": 2.419999945908785, \"match_probability\": 0.8425620821654828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127496.0, \"tn\": 1278737063.0, \"fp\": 729.0, \"fn\": 176465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41944854767552414, \"tn_rate\": 0.9999994299065809, \"fp_rate\": 5.700934191205948e-07, \"fn_rate\": 0.5805514523244758, \"precision\": 0.9943146812244102, \"recall\": 0.41944854767552414, \"specificity\": 0.9999994299065809, \"npv\": 0.9998620196001242, \"accuracy\": 0.9998614634748362, \"f1\": 0.5900052292300074, \"f2\": 0.474291126422825, \"f0_5\": 0.7804020512669843, \"p4\": 0.7421234219662556, \"phi\": 0.6457595578232663}, {\"truth_threshold\": 2.43999994546175, \"match_probability\": 0.8443922976497208, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127441.0, \"tn\": 1278737075.0, \"fp\": 717.0, \"fn\": 176520.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41926760340964797, \"tn_rate\": 0.9999994392908347, \"fp_rate\": 5.607091653079101e-07, \"fn_rate\": 0.580732396590352, \"precision\": 0.9944053434042354, \"recall\": 0.41926760340964797, \"specificity\": 0.9999994392908347, \"npv\": 0.9998619766021019, \"accuracy\": 0.9998614298559181, \"f1\": 0.5898421499633203, \"f2\": 0.4741101575741703, \"f0_5\": 0.7803214085842028, \"p4\": 0.7419943982828562, \"phi\": 0.6456496874565893}, {\"truth_threshold\": 2.459999945014715, \"match_probability\": 0.8462051204878077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127413.0, \"tn\": 1278737078.0, \"fp\": 714.0, \"fn\": 176548.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4191754863288382, \"tn_rate\": 0.9999994416368981, \"fp_rate\": 5.583631018547389e-07, \"fn_rate\": 0.5808245136711617, \"precision\": 0.9944274040600342, \"recall\": 0.4191754863288382, \"specificity\": 0.9999994416368981, \"npv\": 0.9998619547118658, \"accuracy\": 0.9998614103100354, \"f1\": 0.5897548647497732, \"f2\": 0.4740169244723286, \"f0_5\": 0.7802684486489996, \"p4\": 0.7419253296132557, \"phi\": 0.6455859124394749}, {\"truth_threshold\": 2.4799999445676804, \"match_probability\": 0.8480006257142996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127392.0, \"tn\": 1278737078.0, \"fp\": 714.0, \"fn\": 176569.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41910639851823095, \"tn_rate\": 0.9999994416368981, \"fp_rate\": 5.583631018547389e-07, \"fn_rate\": 0.580893601481769, \"precision\": 0.9944264905625029, \"recall\": 0.41910639851823095, \"specificity\": 0.9999994416368981, \"npv\": 0.9998619382939464, \"accuracy\": 0.999861393891494, \"f1\": 0.5896863217973138, \"f2\": 0.4739462033557796, \"f0_5\": 0.7802201167341389, \"p4\": 0.7418710862058999, \"phi\": 0.6455324061055382}, {\"truth_threshold\": 2.4999999441206455, \"match_probability\": 0.8497788902332636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127363.0, \"tn\": 1278737085.0, \"fp\": 707.0, \"fn\": 176598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41901099154167804, \"tn_rate\": 0.9999994471110462, \"fp_rate\": 5.528889537973395e-07, \"fn_rate\": 0.5809890084583219, \"precision\": 0.9944795814788787, \"recall\": 0.41901099154167804, \"specificity\": 0.9999994471110462, \"npv\": 0.9998619156223384, \"accuracy\": 0.9998613766911173, \"f1\": 0.5896012091724899, \"f2\": 0.47385100534706837, \"f0_5\": 0.7801801183719024, \"p4\": 0.7418037238475895, \"phi\": 0.6454761551529131}, {\"truth_threshold\": 2.5199999436736107, \"match_probability\": 0.8515399927604203, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127350.0, \"tn\": 1278737087.0, \"fp\": 705.0, \"fn\": 176611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4189682228970164, \"tn_rate\": 0.9999994486750885, \"fp_rate\": 5.513249114952254e-07, \"fn_rate\": 0.5810317771029836, \"precision\": 0.9944945531217055, \"recall\": 0.4189682228970164, \"specificity\": 0.9999994486750885, \"npv\": 0.9998619054590813, \"accuracy\": 0.999861368090929, \"f1\": 0.5895614977223066, \"f2\": 0.4738079275302683, \"f0_5\": 0.7801578326376135, \"p4\": 0.7417722916867561, \"phi\": 0.6454480693009131}, {\"truth_threshold\": 2.539999943226576, \"match_probability\": 0.8532840137657655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127318.0, \"tn\": 1278737115.0, \"fp\": 677.0, \"fn\": 176643.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4188629462332339, \"tn_rate\": 0.9999994705716807, \"fp_rate\": 5.294283192656278e-07, \"fn_rate\": 0.5811370537667662, \"precision\": 0.9947107308879253, \"recall\": 0.4188629462332339, \"specificity\": 0.9999994705716807, \"npv\": 0.9998618804443262, \"accuracy\": 0.9998613649635877, \"f1\": 0.5894952263656483, \"f2\": 0.4737100203223749, \"f0_5\": 0.7801912148059725, \"p4\": 0.7417198350408956, \"phi\": 0.6454371291385412}, {\"truth_threshold\": 2.559999942779541, \"match_probability\": 0.8550110354166937, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127292.0, \"tn\": 1278737116.0, \"fp\": 676.0, \"fn\": 176669.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4187774089439106, \"tn_rate\": 0.9999994713537019, \"fp_rate\": 5.286462981145708e-07, \"fn_rate\": 0.5812225910560894, \"precision\": 0.9947174293573393, \"recall\": 0.4187774089439106, \"specificity\": 0.9999994713537019, \"npv\": 0.9998618601174902, \"accuracy\": 0.9998613454177051, \"f1\": 0.5894116857168655, \"f2\": 0.47362279842716093, \"f0_5\": 0.7801351502084373, \"p4\": 0.7416537006236504, \"phi\": 0.6453733896395831}, {\"truth_threshold\": 2.579999942332506, \"match_probability\": 0.856721141521646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127257.0, \"tn\": 1278737117.0, \"fp\": 675.0, \"fn\": 176704.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4186622625928984, \"tn_rate\": 0.999999472135723, \"fp_rate\": 5.278642769635137e-07, \"fn_rate\": 0.5813377374071016, \"precision\": 0.9947237594972329, \"recall\": 0.4186622625928984, \"specificity\": 0.999999472135723, \"npv\": 0.9998618327544058, \"accuracy\": 0.9998613188353047, \"f1\": 0.5892987383449141, \"f2\": 0.473505256828519, \"f0_5\": 0.7800583310550957, \"p4\": 0.7415642754887313, \"phi\": 0.6452867032476064}, {\"truth_threshold\": 2.5999999418854713, \"match_probability\": 0.8584144174743045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127246.0, \"tn\": 1278737130.0, \"fp\": 662.0, \"fn\": 176715.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4186260737397232, \"tn_rate\": 0.999999482301998, \"fp_rate\": 5.176980019997719e-07, \"fn_rate\": 0.5813739262602768, \"precision\": 0.9948244050411233, \"recall\": 0.4186260737397232, \"specificity\": 0.999999482301998, \"npv\": 0.99986182415595, \"accuracy\": 0.9998613203989752, \"f1\": 0.5892805457210404, \"f2\": 0.473472783668415, \"f0_5\": 0.7800827128236756, \"p4\": 0.7415498712468742, \"phi\": 0.6452914657615331}, {\"truth_threshold\": 2.6199999414384365, \"match_probability\": 0.8600909501983502, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127213.0, \"tn\": 1278737159.0, \"fp\": 633.0, \"fn\": 176748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4185175071801975, \"tn_rate\": 0.9999995049806114, \"fp_rate\": 4.950193886191173e-07, \"fn_rate\": 0.5814824928198026, \"precision\": 0.9950487305038875, \"recall\": 0.4185175071801975, \"specificity\": 0.9999995049806114, \"npv\": 0.9998617983595044, \"accuracy\": 0.9998613172716341, \"f1\": 0.5892123101292939, \"f2\": 0.47337183427725144, \"f0_5\": 0.7801176189220514, \"p4\": 0.7414958406721772, \"phi\": 0.6452805451175767}, {\"truth_threshold\": 2.6399999409914017, \"match_probability\": 0.8617508280928082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127190.0, \"tn\": 1278737162.0, \"fp\": 630.0, \"fn\": 176771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41844183957810377, \"tn_rate\": 0.9999995073266749, \"fp_rate\": 4.926733251659461e-07, \"fn_rate\": 0.5815581604218962, \"precision\": 0.9950711938663745, \"recall\": 0.41844183957810377, \"specificity\": 0.9999995073266749, \"npv\": 0.9998617803783048, \"accuracy\": 0.9998613016349279, \"f1\": 0.5891412544785435, \"f2\": 0.47329540718512964, \"f0_5\": 0.7800760756635154, \"p4\": 0.7414395704733652, \"phi\": 0.6452294892694544}, {\"truth_threshold\": 2.659999940544367, \"match_probability\": 0.8633941409779923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127147.0, \"tn\": 1278737163.0, \"fp\": 629.0, \"fn\": 176814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.418300374061146, \"tn_rate\": 0.999999508108696, \"fp_rate\": 4.91891304014889e-07, \"fn_rate\": 0.581699625938854, \"precision\": 0.9950773228149261, \"recall\": 0.418300374061146, \"specificity\": 0.999999508108696, \"npv\": 0.9998617467607831, \"accuracy\": 0.9998612687978451, \"f1\": 0.589002100816006, \"f2\": 0.47315089087688483, \"f0_5\": 0.7799807377325735, \"p4\": 0.7413293574004626, \"phi\": 0.6451223880549266}, {\"truth_threshold\": 2.679999940097332, \"match_probability\": 0.8650209800420708, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127134.0, \"tn\": 1278737163.0, \"fp\": 629.0, \"fn\": 176827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4182576054164844, \"tn_rate\": 0.999999508108696, \"fp_rate\": 4.91891304014889e-07, \"fn_rate\": 0.5817423945835156, \"precision\": 0.9950768219281012, \"recall\": 0.4182576054164844, \"specificity\": 0.999999508108696, \"npv\": 0.9998617365973141, \"accuracy\": 0.9998612586339861, \"f1\": 0.5889596130861383, \"f2\": 0.4731070915825833, \"f0_5\": 0.7799507492518524, \"p4\": 0.7412957022235392, \"phi\": 0.6450892415966523}, {\"truth_threshold\": 2.699999939650297, \"match_probability\": 0.8666314377882673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127103.0, \"tn\": 1278737165.0, \"fp\": 627.0, \"fn\": 176858.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.418155618648445, \"tn_rate\": 0.9999995096727383, \"fp_rate\": 4.903272617127749e-07, \"fn_rate\": 0.5818443813515549, \"precision\": 0.9950912080169106, \"recall\": 0.418155618648445, \"specificity\": 0.9999995096727383, \"npv\": 0.9998617123615666, \"accuracy\": 0.9998612359607623, \"f1\": 0.5888610140123375, \"f2\": 0.4730033477873195, \"f0_5\": 0.779886879188495, \"p4\": 0.7412175935890735, \"phi\": 0.6450152448542579}, {\"truth_threshold\": 2.7199999392032623, \"match_probability\": 0.8682256079827106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127046.0, \"tn\": 1278737165.0, \"fp\": 627.0, \"fn\": 176915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4179680945910824, \"tn_rate\": 0.9999995096727383, \"fp_rate\": 4.903272617127749e-07, \"fn_rate\": 0.5820319054089176, \"precision\": 0.9950890164717677, \"recall\": 0.4179680945910824, \"specificity\": 0.9999995096727383, \"npv\": 0.9998616677986687, \"accuracy\": 0.9998611913961498, \"f1\": 0.588674664183081, \"f2\": 0.47281128560338276, \"f0_5\": 0.7797553068607125, \"p4\": 0.7410699434772895, \"phi\": 0.6448698735909155}, {\"truth_threshold\": 2.7399999387562275, \"match_probability\": 0.869803585602949, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127027.0, \"tn\": 1278737180.0, \"fp\": 612.0, \"fn\": 176934.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41790558657196153, \"tn_rate\": 0.9999995214030556, \"fp_rate\": 4.785969444469191e-07, \"fn_rate\": 0.5820944134280385, \"precision\": 0.9952052272424572, \"recall\": 0.41790558657196153, \"specificity\": 0.9999995214030556, \"npv\": 0.9998616529459929, \"accuracy\": 0.9998611882688087, \"f1\": 0.5886329935125116, \"f2\": 0.4727525394813332, \"f0_5\": 0.7797688691580409, \"p4\": 0.7410369228560152, \"phi\": 0.644859311794067}, {\"truth_threshold\": 2.7599999383091927, \"match_probability\": 0.8713654667871419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126980.0, \"tn\": 1278737200.0, \"fp\": 592.0, \"fn\": 176981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41775096147203095, \"tn_rate\": 0.9999995370434785, \"fp_rate\": 4.6295652142577794e-07, \"fn_rate\": 0.582249038527969, \"precision\": 0.9953594832721914, \"recall\": 0.41775096147203095, \"specificity\": 0.9999995370434785, \"npv\": 0.9998616162033158, \"accuracy\": 0.9998611671592553, \"f1\": 0.5885065568566019, \"f2\": 0.4726011898027119, \"f0_5\": 0.779736910944932, \"p4\": 0.7409367198789684, \"phi\": 0.6447899738977387}, {\"truth_threshold\": 2.779999937862158, \"match_probability\": 0.8729113487839398, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126963.0, \"tn\": 1278737203.0, \"fp\": 589.0, \"fn\": 176998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4176950332443965, \"tn_rate\": 0.999999539389542, \"fp_rate\": 4.606104579726068e-07, \"fn_rate\": 0.5823049667556035, \"precision\": 0.9953822754641244, \"recall\": 0.4176950332443965, \"specificity\": 0.999999539389542, \"npv\": 0.9998616029129541, \"accuracy\": 0.9998611562135611, \"f1\": 0.5884550407519588, \"f2\": 0.47254495323791346, \"f0_5\": 0.7797091267292171, \"p4\": 0.7408958876854211, \"phi\": 0.644754190715545}, {\"truth_threshold\": 2.799999937415123, \"match_probability\": 0.8744413299030646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126928.0, \"tn\": 1278737211.0, \"fp\": 581.0, \"fn\": 177033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4175798868933843, \"tn_rate\": 0.9999995456457113, \"fp_rate\": 4.5435428876415033e-07, \"fn_rate\": 0.5824201131066157, \"precision\": 0.9954434588930977, \"recall\": 0.4175798868933843, \"specificity\": 0.9999995456457113, \"npv\": 0.9998615755506434, \"accuracy\": 0.9998611351040079, \"f1\": 0.5883514496952279, \"f2\": 0.4724298080995837, \"f0_5\": 0.7796588930917436, \"p4\": 0.7408137724566481, \"phi\": 0.6446851258454179}, {\"truth_threshold\": 2.819999936968088, \"match_probability\": 0.8759555094666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126900.0, \"tn\": 1278737211.0, \"fp\": 581.0, \"fn\": 177061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4174877698125746, \"tn_rate\": 0.9999995456457113, \"fp_rate\": 4.5435428876415033e-07, \"fn_rate\": 0.5825122301874254, \"precision\": 0.9954424580917941, \"recall\": 0.4174877698125746, \"specificity\": 0.9999995456457113, \"npv\": 0.9998615536601033, \"accuracy\": 0.9998611132126193, \"f1\": 0.5882598356210105, \"f2\": 0.4723354363240467, \"f0_5\": 0.7795941687093385, \"p4\": 0.7407411418530562, \"phi\": 0.6446136827055114}, {\"truth_threshold\": 2.8399999365210533, \"match_probability\": 0.8774539877610013, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126875.0, \"tn\": 1278737223.0, \"fp\": 569.0, \"fn\": 177086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41740552241899453, \"tn_rate\": 0.9999995550299651, \"fp_rate\": 4.4497003495146566e-07, \"fn_rate\": 0.5825944775810055, \"precision\": 0.9955352939330215, \"recall\": 0.41740552241899453, \"specificity\": 0.9999995550299651, \"npv\": 0.9998615341162783, \"accuracy\": 0.9998611030487603, \"f1\": 0.5881943881039858, \"f2\": 0.47225539124893545, \"f0_5\": 0.7795823466304224, \"p4\": 0.7406892514213615, \"phi\": 0.6445802433400878}, {\"truth_threshold\": 2.8599999360740185, \"match_probability\": 0.8789368659898347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126827.0, \"tn\": 1278737225.0, \"fp\": 567.0, \"fn\": 177134.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41724760742332073, \"tn_rate\": 0.9999995565940073, \"fp_rate\": 4.4340599264935154e-07, \"fn_rate\": 0.5827523925766792, \"precision\": 0.9955492409375638, \"recall\": 0.41724760742332073, \"specificity\": 0.9999995565940073, \"npv\": 0.9998614965898588, \"accuracy\": 0.9998610670843362, \"f1\": 0.5880400134460015, \"f2\": 0.47209429751094, \"f0_5\": 0.7794789911214856, \"p4\": 0.7405668360200538, \"phi\": 0.644462805184065}, {\"truth_threshold\": 2.8799999356269836, \"match_probability\": 0.8804042462272496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126821.0, \"tn\": 1278737227.0, \"fp\": 565.0, \"fn\": 177140.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4172278680488615, \"tn_rate\": 0.9999995581580496, \"fp_rate\": 4.418419503472374e-07, \"fn_rate\": 0.5827721319511384, \"precision\": 0.9955646617367686, \"recall\": 0.4172278680488615, \"specificity\": 0.9999995581580496, \"npv\": 0.9998614918992461, \"accuracy\": 0.999861063956995, \"f1\": 0.5880230997317705, \"f2\": 0.47207477498269096, \"f0_5\": 0.7794727752134283, \"p4\": 0.7405534225153652, \"phi\": 0.6444525522182372}, {\"truth_threshold\": 2.899999935179949, \"match_probability\": 0.8818562313721967, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126777.0, \"tn\": 1278737227.0, \"fp\": 565.0, \"fn\": 177184.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41708311263616055, \"tn_rate\": 0.9999995581580496, \"fp_rate\": 4.418419503472374e-07, \"fn_rate\": 0.5829168873638394, \"precision\": 0.9955631292111008, \"recall\": 0.41708311263616055, \"specificity\": 0.9999995581580496, \"npv\": 0.9998614574998327, \"accuracy\": 0.9998610295562416, \"f1\": 0.587879054863982, \"f2\": 0.47192644950140933, \"f0_5\": 0.7793709556649278, \"p4\": 0.740439174377191, \"phi\": 0.6443402402454925}, {\"truth_threshold\": 2.919999934732914, \"match_probability\": 0.8832929251033927, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126724.0, \"tn\": 1278737235.0, \"fp\": 557.0, \"fn\": 177237.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41690874816177076, \"tn_rate\": 0.9999995644142189, \"fp_rate\": 4.3558578113878094e-07, \"fn_rate\": 0.5830912518382293, \"precision\": 0.9956238558779393, \"recall\": 0.41690874816177076, \"specificity\": 0.9999995644142189, \"npv\": 0.9998614160650455, \"accuracy\": 0.9998609943736528, \"f1\": 0.5877164098116603, \"f2\": 0.4717505816658911, \"f0_5\": 0.7792789191781917, \"p4\": 0.7403101492249367, \"phi\": 0.6442251818424982}, {\"truth_threshold\": 2.939999934285879, \"match_probability\": 0.8847144318350393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126712.0, \"tn\": 1278737251.0, \"fp\": 541.0, \"fn\": 177249.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4168692694128523, \"tn_rate\": 0.9999995769265573, \"fp_rate\": 4.2307344272186803e-07, \"fn_rate\": 0.5831307305871477, \"precision\": 0.9957486267514322, \"recall\": 0.4168692694128523, \"specificity\": 0.9999995769265573, \"npv\": 0.9998614066851225, \"accuracy\": 0.999860997500994, \"f1\": 0.587698915155816, \"f2\": 0.4717157435389998, \"f0_5\": 0.7793124740920055, \"p4\": 0.7402962702130373, \"phi\": 0.6442350549625793}, {\"truth_threshold\": 2.9599999338388443, \"match_probability\": 0.8861208566733013, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126669.0, \"tn\": 1278737255.0, \"fp\": 537.0, \"fn\": 177292.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41672780389589453, \"tn_rate\": 0.9999995800546418, \"fp_rate\": 4.199453581176398e-07, \"fn_rate\": 0.5832721961041054, \"precision\": 0.9957785010141031, \"recall\": 0.41672780389589453, \"specificity\": 0.9999995800546418, \"npv\": 0.9998613730679536, \"accuracy\": 0.9998609670094171, \"f1\": 0.5875635194715737, \"f2\": 0.47157216782696104, \"f0_5\": 0.77922820918201, \"p4\": 0.7401888390947057, \"phi\": 0.6441353895595684}, {\"truth_threshold\": 2.9799999333918095, \"match_probability\": 0.8875123053735477, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126652.0, \"tn\": 1278737255.0, \"fp\": 537.0, \"fn\": 177309.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4166718756682601, \"tn_rate\": 0.9999995800546418, \"fp_rate\": 4.199453581176398e-07, \"fn_rate\": 0.58332812433174, \"precision\": 0.9957779367712617, \"recall\": 0.4166718756682601, \"specificity\": 0.9999995800546418, \"npv\": 0.9998613597772744, \"accuracy\": 0.9998609537182169, \"f1\": 0.5875078279021222, \"f2\": 0.47151484736413773, \"f0_5\": 0.7791888197244551, \"p4\": 0.7401446446168659, \"phi\": 0.6440919771801265}, {\"truth_threshold\": 2.9999999329447746, \"match_probability\": 0.8888888842983563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126637.0, \"tn\": 1278737257.0, \"fp\": 535.0, \"fn\": 177324.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.416622527232112, \"tn_rate\": 0.9999995816186842, \"fp_rate\": 4.183813158155257e-07, \"fn_rate\": 0.583377472767888, \"precision\": 0.9957930991098669, \"recall\": 0.416622527232112, \"specificity\": 0.9999995816186842, \"npv\": 0.9998613480504215, \"accuracy\": 0.999860943554358, \"f1\": 0.5874614098201715, \"f2\": 0.47146497137785404, \"f0_5\": 0.7791617291106, \"p4\": 0.7401078069433363, \"phi\": 0.6440587360346827}, {\"truth_threshold\": 3.01999993249774, \"match_probability\": 0.8902507003762883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126607.0, \"tn\": 1278737258.0, \"fp\": 534.0, \"fn\": 177354.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4165238303598159, \"tn_rate\": 0.9999995824007053, \"fp_rate\": 4.175992946644686e-07, \"fn_rate\": 0.5834761696401841, \"precision\": 0.9957999386507893, \"recall\": 0.4165238303598159, \"specificity\": 0.9999995824007053, \"npv\": 0.9998613245963914, \"accuracy\": 0.9998609208811341, \"f1\": 0.5873644752286002, \"f2\": 0.4713641626674907, \"f0_5\": 0.7790960278145288, \"p4\": 0.740030871914276, \"phi\": 0.6439846483583032}, {\"truth_threshold\": 3.039999932050705, \"match_probability\": 0.8915978610614311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126570.0, \"tn\": 1278737259.0, \"fp\": 533.0, \"fn\": 177391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4164021042173173, \"tn_rate\": 0.9999995831827265, \"fp_rate\": 4.1681727351341155e-07, \"fn_rate\": 0.5835978957826826, \"precision\": 0.9958065505928263, \"recall\": 0.4164021042173173, \"specificity\": 0.9999995831827265, \"npv\": 0.9998612956697306, \"accuracy\": 0.9998608927350631, \"f1\": 0.5872445854907856, \"f2\": 0.471239743638431, \"f0_5\": 0.7790140735844249, \"p4\": 0.7399357048380156, \"phi\": 0.6438926706165369}, {\"truth_threshold\": 3.05999993160367, \"match_probability\": 0.8929304742937143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126551.0, \"tn\": 1278737263.0, \"fp\": 529.0, \"fn\": 177410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4163395961981965, \"tn_rate\": 0.9999995863108111, \"fp_rate\": 4.1368918890918337e-07, \"fn_rate\": 0.5836604038018035, \"precision\": 0.9958372678627636, \"recall\": 0.4163395961981965, \"specificity\": 0.9999995863108111, \"npv\": 0.9998612808158782, \"accuracy\": 0.9998608810075335, \"f1\": 0.5871877617210428, \"f2\": 0.47117707331166914, \"f0_5\": 0.7789853511284888, \"p4\": 0.7398905939915287, \"phi\": 0.6438542690564931}, {\"truth_threshold\": 3.0799999311566353, \"match_probability\": 0.8942486484599944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126526.0, \"tn\": 1278737264.0, \"fp\": 528.0, \"fn\": 177435.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4162573488046164, \"tn_rate\": 0.9999995870928322, \"fp_rate\": 4.129071677581263e-07, \"fn_rate\": 0.5837426511953836, \"precision\": 0.9958442866812537, \"recall\": 0.4162573488046164, \"specificity\": 0.9999995870928322, \"npv\": 0.9998612612708738, \"accuracy\": 0.9998608622434861, \"f1\": 0.5871071772444114, \"f2\": 0.4710931135499494, \"f0_5\": 0.7789311935698745, \"p4\": 0.7398266143355388, \"phi\": 0.6437929328958517}, {\"truth_threshold\": 3.0999999307096004, \"match_probability\": 0.8955524923559135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126492.0, \"tn\": 1278737265.0, \"fp\": 527.0, \"fn\": 177469.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41614549234934745, \"tn_rate\": 0.9999995878748534, \"fp_rate\": 4.1212514660706925e-07, \"fn_rate\": 0.5838545076506525, \"precision\": 0.9958510144151662, \"recall\": 0.41614549234934745, \"specificity\": 0.9999995878748534, \"npv\": 0.9998612346896302, \"accuracy\": 0.999860836442921, \"f1\": 0.5869970764304608, \"f2\": 0.47097879679460974, \"f0_5\": 0.7788561358657302, \"p4\": 0.7397391898018877, \"phi\": 0.643708593840361}, {\"truth_threshold\": 3.1199999302625656, \"match_probability\": 0.8968421151485269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126442.0, \"tn\": 1278737270.0, \"fp\": 522.0, \"fn\": 177519.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41598099756218726, \"tn_rate\": 0.9999995917849591, \"fp_rate\": 4.0821504085178395e-07, \"fn_rate\": 0.5840190024378128, \"precision\": 0.9958885983428374, \"recall\": 0.41598099756218726, \"specificity\": 0.9999995917849591, \"npv\": 0.9998611955999517, \"accuracy\": 0.9998608012603323, \"f1\": 0.5868399373440853, \"f2\": 0.4708119105635355, \"f0_5\": 0.7787592523930886, \"p4\": 0.7396143941767556, \"phi\": 0.643593494471954}, {\"truth_threshold\": 3.1399999298155308, \"match_probability\": 0.8981176263397019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126422.0, \"tn\": 1278737270.0, \"fp\": 522.0, \"fn\": 177539.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41591519964732315, \"tn_rate\": 0.9999995917849591, \"fp_rate\": 4.0821504085178395e-07, \"fn_rate\": 0.5840848003526768, \"precision\": 0.9958879505923872, \"recall\": 0.41591519964732315, \"specificity\": 0.9999995917849591, \"npv\": 0.9998611799638641, \"accuracy\": 0.9998607856236261, \"f1\": 0.586774347013843, \"f2\": 0.47074445109726926, \"f0_5\": 0.7787128096908235, \"p4\": 0.7395622966642112, \"phi\": 0.6435423777453819}, {\"truth_threshold\": 3.159999929368496, \"match_probability\": 0.899379135730284, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126396.0, \"tn\": 1278737278.0, \"fp\": 514.0, \"fn\": 177565.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4158296623579999, \"tn_rate\": 0.9999995980411284, \"fp_rate\": 4.0195887164332747e-07, \"fn_rate\": 0.5841703376420001, \"precision\": 0.9959498857458041, \"recall\": 0.4158296623579999, \"specificity\": 0.9999995980411284, \"npv\": 0.9998611596378196, \"accuracy\": 0.9998607715505906, \"f1\": 0.5866999635621799, \"f2\": 0.4706595549147498, \"f0_5\": 0.7786831213860013, \"p4\": 0.739503210183519, \"phi\": 0.6434962086128829}, {\"truth_threshold\": 3.179999928921461, \"match_probability\": 0.9006267533850288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126365.0, \"tn\": 1278737278.0, \"fp\": 514.0, \"fn\": 177596.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41572767558996054, \"tn_rate\": 0.9999995980411284, \"fp_rate\": 4.0195887164332747e-07, \"fn_rate\": 0.5842723244100394, \"precision\": 0.9959488961924353, \"recall\": 0.41572767558996054, \"specificity\": 0.9999995980411284, \"npv\": 0.999861135401886, \"accuracy\": 0.9998607473136962, \"f1\": 0.5865982731408411, \"f2\": 0.4705549841627797, \"f0_5\": 0.7786111004994596, \"p4\": 0.7394224227697632, \"phi\": 0.6434169639426643}, {\"truth_threshold\": 3.1999999284744263, \"match_probability\": 0.9018605895982974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126328.0, \"tn\": 1278737407.0, \"fp\": 385.0, \"fn\": 177633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.415605949447462, \"tn_rate\": 0.9999996989218568, \"fp_rate\": 3.010781431569671e-07, \"fn_rate\": 0.584394050552538, \"precision\": 0.99696163771673, \"recall\": 0.415605949447462, \"specificity\": 0.9999996989218568, \"npv\": 0.9998611064891378, \"accuracy\": 0.9998608192425443, \"f1\": 0.5866525492599971, \"f2\": 0.47047536901598963, \"f0_5\": 0.7790205633111458, \"p4\": 0.7394655515002654, \"phi\": 0.6436498760311877}, {\"truth_threshold\": 3.2199999280273914, \"match_probability\": 0.9030807548605116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126311.0, \"tn\": 1278737409.0, \"fp\": 383.0, \"fn\": 177650.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41555002121982754, \"tn_rate\": 0.9999997004858991, \"fp_rate\": 2.99514100854853e-07, \"fn_rate\": 0.5844499787801725, \"precision\": 0.9969769681279302, \"recall\": 0.41555002121982754, \"specificity\": 0.9999997004858991, \"npv\": 0.9998610931986844, \"accuracy\": 0.9998608075150147, \"f1\": 0.5865994821841148, \"f2\": 0.47041871440510435, \"f0_5\": 0.778988747275627, \"p4\": 0.7394233915418098, \"phi\": 0.643611512459147}, {\"truth_threshold\": 3.2399999275803566, \"match_probability\": 0.9042873598253658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126279.0, \"tn\": 1278737417.0, \"fp\": 375.0, \"fn\": 177682.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.415444744556045, \"tn_rate\": 0.9999997067420684, \"fp_rate\": 2.932579316463965e-07, \"fn_rate\": 0.584555255443955, \"precision\": 0.9970391776019707, \"recall\": 0.415444744556045, \"specificity\": 0.9999997067420684, \"npv\": 0.9998610681818215, \"accuracy\": 0.9998607887509674, \"f1\": 0.586505347003704, \"f2\": 0.47031354981534423, \"f0_5\": 0.7789451218082921, \"p4\": 0.7393485977337381, \"phi\": 0.6435500568010245}, {\"truth_threshold\": 3.2599999271333218, \"match_probability\": 0.9054805152777908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126251.0, \"tn\": 1278737417.0, \"fp\": 375.0, \"fn\": 177710.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4153526274752353, \"tn_rate\": 0.9999997067420684, \"fp_rate\": 2.932579316463965e-07, \"fn_rate\": 0.5846473725247647, \"precision\": 0.9970385228941924, \"recall\": 0.4153526274752353, \"specificity\": 0.9999997067420684, \"npv\": 0.9998610462913072, \"accuracy\": 0.9998607668595788, \"f1\": 0.5864134309674932, \"f2\": 0.4702190737968074, \"f0_5\": 0.7788800256642792, \"p4\": 0.7392755580641326, \"phi\": 0.6434784868520638}, {\"truth_threshold\": 3.279999926686287, \"match_probability\": 0.9066603321026663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126228.0, \"tn\": 1278737419.0, \"fp\": 373.0, \"fn\": 177733.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4152769598731416, \"tn_rate\": 0.9999997083061106, \"fp_rate\": 2.916938893442824e-07, \"fn_rate\": 0.5847230401268584, \"precision\": 0.9970537357524822, \"recall\": 0.4152769598731416, \"specificity\": 0.9999997083061106, \"npv\": 0.9998610283100313, \"accuracy\": 0.9998607504410374, \"f1\": 0.5863406431594056, \"f2\": 0.4701421659732801, \"f0_5\": 0.7788342290202563, \"p4\": 0.7392177124687624, \"phi\": 0.6434247754622028}, {\"truth_threshold\": 3.299999926239252, \"match_probability\": 0.907826921254276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126206.0, \"tn\": 1278737422.0, \"fp\": 370.0, \"fn\": 177755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4152045821667911, \"tn_rate\": 0.9999997106521741, \"fp_rate\": 2.8934782589111125e-07, \"fn_rate\": 0.5847954178332089, \"precision\": 0.9970768550120086, \"recall\": 0.4152045821667911, \"specificity\": 0.9999997106521741, \"npv\": 0.9998610111106688, \"accuracy\": 0.9998607355861666, \"f1\": 0.5862724922596664, \"f2\": 0.4700689799019681, \"f0_5\": 0.7787945918927758, \"p4\": 0.73916354715533, \"phi\": 0.6433761587810932}, {\"truth_threshold\": 3.3199999257922173, \"match_probability\": 0.9089803937265005, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126174.0, \"tn\": 1278737429.0, \"fp\": 363.0, \"fn\": 177787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4150993055030086, \"tn_rate\": 0.9999997161263222, \"fp_rate\": 2.8387367783371183e-07, \"fn_rate\": 0.5849006944969913, \"precision\": 0.9971312738566586, \"recall\": 0.4150993055030086, \"specificity\": 0.9999997161263222, \"npv\": 0.9998609860937021, \"accuracy\": 0.9998607160402839, \"f1\": 0.5861769392656876, \"f2\": 0.4699634455493634, \"f0_5\": 0.7787470574947322, \"p4\": 0.7390875954063482, \"phi\": 0.643312141714588}, {\"truth_threshold\": 3.3399999253451824, \"match_probability\": 0.9101208605237439, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126146.0, \"tn\": 1278737430.0, \"fp\": 362.0, \"fn\": 177815.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4150071884221989, \"tn_rate\": 0.9999997169083433, \"fp_rate\": 2.8309165668265477e-07, \"fn_rate\": 0.5849928115778011, \"precision\": 0.9971385208840547, \"recall\": 0.4150071884221989, \"specificity\": 0.9999997169083433, \"npv\": 0.9998609642033003, \"accuracy\": 0.9998606949307307, \"f1\": 0.5860863383890593, \"f2\": 0.4698693040275576, \"f0_5\": 0.7786857417286323, \"p4\": 0.7390155711198185, \"phi\": 0.6432430885149465}, {\"truth_threshold\": 3.3599999248981476, \"match_probability\": 0.9112484326325848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126094.0, \"tn\": 1278737430.0, \"fp\": 362.0, \"fn\": 177867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4148361138435523, \"tn_rate\": 0.9999997169083433, \"fp_rate\": 2.8309165668265477e-07, \"fn_rate\": 0.5851638861564477, \"precision\": 0.9971373442145884, \"recall\": 0.4148361138435523, \"specificity\": 0.9999997169083433, \"npv\": 0.9998609235494976, \"accuracy\": 0.9998606542752948, \"f1\": 0.5859155191360936, \"f2\": 0.4696938091335767, \"f0_5\": 0.7785646807485938, \"p4\": 0.7388797537455972, \"phi\": 0.6431101030664309}, {\"truth_threshold\": 3.3799999244511127, \"match_probability\": 0.9123632209941501, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126069.0, \"tn\": 1278737430.0, \"fp\": 362.0, \"fn\": 177892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4147538664499722, \"tn_rate\": 0.9999997169083433, \"fp_rate\": 2.8309165668265477e-07, \"fn_rate\": 0.5852461335500277, \"precision\": 0.9971367781635833, \"recall\": 0.4147538664499722, \"specificity\": 0.9999997169083433, \"npv\": 0.9998609040044013, \"accuracy\": 0.9998606347294121, \"f1\": 0.5858333798025985, \"f2\": 0.4696094317483377, \"f0_5\": 0.7785064562144538, \"p4\": 0.7388144348334773, \"phi\": 0.6430461579693223}, {\"truth_threshold\": 3.399999924004078, \"match_probability\": 0.9134653364772011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126050.0, \"tn\": 1278737430.0, \"fp\": 362.0, \"fn\": 177911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4146913584308513, \"tn_rate\": 0.9999997169083433, \"fp_rate\": 2.8309165668265477e-07, \"fn_rate\": 0.5853086415691486, \"precision\": 0.9971363478150809, \"recall\": 0.4146913584308513, \"specificity\": 0.9999997169083433, \"npv\": 0.9998608891501287, \"accuracy\": 0.9998606198745413, \"f1\": 0.5857709475269127, \"f2\": 0.46954530283343865, \"f0_5\": 0.7784621959489086, \"p4\": 0.7387647828595484, \"phi\": 0.6429975554442712}, {\"truth_threshold\": 3.419999923557043, \"match_probability\": 0.9145548898519266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126031.0, \"tn\": 1278737430.0, \"fp\": 362.0, \"fn\": 177930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4146288504117305, \"tn_rate\": 0.9999997169083433, \"fp_rate\": 2.8309165668265477e-07, \"fn_rate\": 0.5853711495882695, \"precision\": 0.9971359173371943, \"recall\": 0.4146288504117305, \"specificity\": 0.9999997169083433, \"npv\": 0.9998608742958565, \"accuracy\": 0.9998606050196706, \"f1\": 0.5857085097384943, \"f2\": 0.4694811721029893, \"f0_5\": 0.7784179273729421, \"p4\": 0.738715122591794, \"phi\": 0.6429489492467672}, {\"truth_threshold\": 3.4399999231100082, \"match_probability\": 0.9156319917644378, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125998.0, \"tn\": 1278737444.0, \"fp\": 348.0, \"fn\": 177963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41452028385220474, \"tn_rate\": 0.9999997278566395, \"fp_rate\": 2.72143360567856e-07, \"fn_rate\": 0.5854797161477953, \"precision\": 0.9972456587466164, \"recall\": 0.41452028385220474, \"specificity\": 0.9999997278566395, \"npv\": 0.9998608484978554, \"accuracy\": 0.9998605901647998, \"f1\": 0.5856191044998106, \"f2\": 0.4693746786967568, \"f0_5\": 0.7783948748679488, \"p4\": 0.7386440076683726, \"phi\": 0.6429001485906993}, {\"truth_threshold\": 3.4599999226629734, \"match_probability\": 0.9166967527119539, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125979.0, \"tn\": 1278737446.0, \"fp\": 346.0, \"fn\": 177982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41445777583308385, \"tn_rate\": 0.9999997294206817, \"fp_rate\": 2.7057931826574186e-07, \"fn_rate\": 0.5855422241669161, \"precision\": 0.9972610330496735, \"recall\": 0.41445777583308385, \"specificity\": 0.9999997294206817, \"npv\": 0.9998608336438022, \"accuracy\": 0.9998605768735995, \"f1\": 0.5855593721385312, \"f2\": 0.4693112417288732, \"f0_5\": 0.7783582799615946, \"p4\": 0.738596490286281, \"phi\": 0.642856625775729}, {\"truth_threshold\": 3.4799999222159386, \"match_probability\": 0.9177492830186748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125948.0, \"tn\": 1278737447.0, \"fp\": 345.0, \"fn\": 178013.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41435578906504456, \"tn_rate\": 0.9999997302027028, \"fp_rate\": 2.697972971146848e-07, \"fn_rate\": 0.5856442109349554, \"precision\": 0.9972682571480604, \"recall\": 0.41435578906504456, \"specificity\": 0.9999997302027028, \"npv\": 0.9998608094079964, \"accuracy\": 0.9998605534185404, \"f1\": 0.5854588219981686, \"f2\": 0.4692069438514846, \"f0_5\": 0.7782898485168693, \"p4\": 0.7385164939307121, \"phi\": 0.642779847342618}, {\"truth_threshold\": 3.4999999217689037, \"match_probability\": 0.9187896928123295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125930.0, \"tn\": 1278737451.0, \"fp\": 341.0, \"fn\": 178031.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4142965709416669, \"tn_rate\": 0.9999997333307875, \"fp_rate\": 2.6666921251045656e-07, \"fn_rate\": 0.5857034290583332, \"precision\": 0.9972994590998725, \"recall\": 0.4142965709416669, \"specificity\": 0.9999997333307875, \"npv\": 0.9998607953359657, \"accuracy\": 0.9998605424728461, \"f1\": 0.5854050837687573, \"f2\": 0.46914757677248226, \"f0_5\": 0.7782632610052593, \"p4\": 0.7384737365661722, \"phi\": 0.6427439678286744}, {\"truth_threshold\": 3.519999921321869, \"match_probability\": 0.9198180920013963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125897.0, \"tn\": 1278737451.0, \"fp\": 341.0, \"fn\": 178064.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41418800438214115, \"tn_rate\": 0.9999997333307875, \"fp_rate\": 2.6666921251045656e-07, \"fn_rate\": 0.5858119956178589, \"precision\": 0.9972987531488141, \"recall\": 0.41418800438214115, \"specificity\": 0.9999997333307875, \"npv\": 0.9998607695364459, \"accuracy\": 0.999860516672281, \"f1\": 0.585296572051539, \"f2\": 0.469036169175952, \"f0_5\": 0.7781862820847236, \"p4\": 0.7383873887834825, \"phi\": 0.6426595108141726}, {\"truth_threshold\": 3.539999920874834, \"match_probability\": 0.9208345902529831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125843.0, \"tn\": 1278737451.0, \"fp\": 341.0, \"fn\": 178118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41401035001200814, \"tn_rate\": 0.9999997333307875, \"fp_rate\": 2.6666921251045656e-07, \"fn_rate\": 0.5859896499879919, \"precision\": 0.9972975971597033, \"recall\": 0.41401035001200814, \"specificity\": 0.9999997333307875, \"npv\": 0.9998607273190526, \"accuracy\": 0.9998604744531745, \"f1\": 0.5851189715096072, \"f2\": 0.46885385401794893, \"f0_5\": 0.778060262372681, \"p4\": 0.7382460383292053, \"phi\": 0.6425212844905701}, {\"truth_threshold\": 3.5599999204277992, \"match_probability\": 0.9218392969713606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125829.0, \"tn\": 1278737462.0, \"fp\": 330.0, \"fn\": 178132.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41396429147160324, \"tn_rate\": 0.9999997419330201, \"fp_rate\": 2.5806697984882896e-07, \"fn_rate\": 0.5860357085283967, \"precision\": 0.9973842532042898, \"recall\": 0.41396429147160324, \"specificity\": 0.9999997419330201, \"npv\": 0.9998607163750011, \"accuracy\": 0.9998604721076686, \"f1\": 0.5850878824514089, \"f2\": 0.4688104273984484, \"f0_5\": 0.7780699161634288, \"p4\": 0.7382212922962933, \"phi\": 0.6425134628157718}, {\"truth_threshold\": 3.5799999199807644, \"match_probability\": 0.9228323212771417, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125781.0, \"tn\": 1278737462.0, \"fp\": 330.0, \"fn\": 178180.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4138063764759295, \"tn_rate\": 0.9999997419330201, \"fp_rate\": 2.5806697984882896e-07, \"fn_rate\": 0.5861936235240706, \"precision\": 0.9973832576063943, \"recall\": 0.4138063764759295, \"specificity\": 0.9999997419330201, \"npv\": 0.9998606788484334, \"accuracy\": 0.9998604345795739, \"f1\": 0.5849299652151267, \"f2\": 0.4686483525900645, \"f0_5\": 0.777957830542859, \"p4\": 0.7380955760517218, \"phi\": 0.6423905684637917}, {\"truth_threshold\": 3.5999999195337296, \"match_probability\": 0.9238137719870957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125749.0, \"tn\": 1278737471.0, \"fp\": 321.0, \"fn\": 178212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.413701099812147, \"tn_rate\": 0.9999997489712105, \"fp_rate\": 2.510287894893154e-07, \"fn_rate\": 0.586298900187853, \"precision\": 0.9974537955104307, \"recall\": 0.413701099812147, \"specificity\": 0.9999997489712105, \"npv\": 0.9998606538317037, \"accuracy\": 0.9998604165973618, \"f1\": 0.584836907106697, \"f2\": 0.46854343870024456, \"f0_5\": 0.7779177250349834, \"p4\": 0.7380214823069078, \"phi\": 0.6423315609533349}, {\"truth_threshold\": 3.6199999190866947, \"match_probability\": 0.9247837575945907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125727.0, \"tn\": 1278737472.0, \"fp\": 320.0, \"fn\": 178234.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4136287221057965, \"tn_rate\": 0.9999997497532317, \"fp_rate\": 2.5024676833825836e-07, \"fn_rate\": 0.5863712778942035, \"precision\": 0.9974612644489754, \"recall\": 0.4136287221057965, \"specificity\": 0.9999997497532317, \"npv\": 0.9998606366321379, \"accuracy\": 0.9998604001788204, \"f1\": 0.5847658648211196, \"f2\": 0.46846949565948354, \"f0_5\": 0.7778701699810308, \"p4\": 0.7379649115450985, \"phi\": 0.6422777700463574}, {\"truth_threshold\": 3.63999991863966, \"match_probability\": 0.9257423862506543, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125708.0, \"tn\": 1278737474.0, \"fp\": 318.0, \"fn\": 178253.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4135662140866756, \"tn_rate\": 0.9999997513172739, \"fp_rate\": 2.4868272603614424e-07, \"fn_rate\": 0.5864337859133244, \"precision\": 0.997476711154841, \"recall\": 0.4135662140866756, \"specificity\": 0.9999997513172739, \"npv\": 0.9998606217780915, \"accuracy\": 0.9998603868876202, \"f1\": 0.5847060492526518, \"f2\": 0.4684060303904253, \"f0_5\": 0.7778334663671858, \"p4\": 0.737917276724828, \"phi\": 0.6422342072233529}, {\"truth_threshold\": 3.659999918192625, \"match_probability\": 0.9266897657456435, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125691.0, \"tn\": 1278737474.0, \"fp\": 318.0, \"fn\": 178270.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41351028585904115, \"tn_rate\": 0.9999997513172739, \"fp_rate\": 2.4868272603614424e-07, \"fn_rate\": 0.5864897141409589, \"precision\": 0.9974763707354236, \"recall\": 0.41351028585904115, \"specificity\": 0.9999997513172739, \"npv\": 0.9998606084874345, \"accuracy\": 0.99986037359642, \"f1\": 0.5846500918668744, \"f2\": 0.46834861940913053, \"f0_5\": 0.7777937294321637, \"p4\": 0.7378727110409778, \"phi\": 0.6421906658896234}, {\"truth_threshold\": 3.67999991774559, \"match_probability\": 0.9276260034915159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125678.0, \"tn\": 1278737474.0, \"fp\": 318.0, \"fn\": 178283.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41346751721437947, \"tn_rate\": 0.9999997513172739, \"fp_rate\": 2.4868272603614424e-07, \"fn_rate\": 0.5865324827856205, \"precision\": 0.9974761103527096, \"recall\": 0.41346751721437947, \"specificity\": 0.9999997513172739, \"npv\": 0.9998605983239911, \"accuracy\": 0.999860363432561, \"f1\": 0.5846072979390963, \"f2\": 0.4683047159124784, \"f0_5\": 0.7777633378509676, \"p4\": 0.7378386268989227, \"phi\": 0.6421573675843834}, {\"truth_threshold\": 3.6999999172985554, \"match_probability\": 0.9285512065046917, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125639.0, \"tn\": 1278737475.0, \"fp\": 317.0, \"fn\": 178322.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4133392112803945, \"tn_rate\": 0.9999997520992951, \"fp_rate\": 2.479007048850872e-07, \"fn_rate\": 0.5866607887196055, \"precision\": 0.9974832481183905, \"recall\": 0.4133392112803945, \"specificity\": 0.9999997520992951, \"npv\": 0.9998605678337712, \"accuracy\": 0.9998603337228195, \"f1\": 0.584480260143237, \"f2\": 0.4681733492323744, \"f0_5\": 0.7776759905172788, \"p4\": 0.7377374341397268, \"phi\": 0.6420600120072971}, {\"truth_threshold\": 3.7199999168515205, \"match_probability\": 0.9294654813894975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125604.0, \"tn\": 1278737479.0, \"fp\": 313.0, \"fn\": 178357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4132240649293824, \"tn_rate\": 0.9999997552273797, \"fp_rate\": 2.4477262028085894e-07, \"fn_rate\": 0.5867759350706176, \"precision\": 0.9975142355678741, \"recall\": 0.4132240649293824, \"specificity\": 0.9999997552273797, \"npv\": 0.9998605404710932, \"accuracy\": 0.999860309485925, \"f1\": 0.5843704492902637, \"f2\": 0.4680565316774001, \"f0_5\": 0.7776095212034239, \"p4\": 0.7376499507329995, \"phi\": 0.6419805410468584}, {\"truth_threshold\": 3.7399999164044857, \"match_probability\": 0.9303689343221841, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125578.0, \"tn\": 1278737480.0, \"fp\": 312.0, \"fn\": 178383.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4131385276400591, \"tn_rate\": 0.9999997560094008, \"fp_rate\": 2.439905991298019e-07, \"fn_rate\": 0.5868614723599409, \"precision\": 0.997521645881325, \"recall\": 0.4131385276400591, \"specificity\": 0.9999997560094008, \"npv\": 0.9998605201443185, \"accuracy\": 0.9998602899400423, \"f1\": 0.5842861828866281, \"f2\": 0.46796906093160046, \"f0_5\": 0.7775525342374997, \"p4\": 0.7375828095627739, \"phi\": 0.6419164713686782}, {\"truth_threshold\": 3.759999915957451, \"match_probability\": 0.9312616710355065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125550.0, \"tn\": 1278737480.0, \"fp\": 312.0, \"fn\": 178411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4130464105592494, \"tn_rate\": 0.9999997560094008, \"fp_rate\": 2.439905991298019e-07, \"fn_rate\": 0.5869535894407506, \"precision\": 0.9975210945321066, \"recall\": 0.4130464105592494, \"specificity\": 0.9999997560094008, \"npv\": 0.9998604982538293, \"accuracy\": 0.9998602680486538, \"f1\": 0.5841939589086671, \"f2\": 0.4678744821890936, \"f0_5\": 0.7774869985348194, \"p4\": 0.7375093197612667, \"phi\": 0.6418447191543803}, {\"truth_threshold\": 3.779999915510416, \"match_probability\": 0.9321437968038585, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125516.0, \"tn\": 1278737480.0, \"fp\": 312.0, \"fn\": 178445.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41293455410398044, \"tn_rate\": 0.9999997560094008, \"fp_rate\": 2.439905991298019e-07, \"fn_rate\": 0.5870654458960195, \"precision\": 0.9975204247067425, \"recall\": 0.41293455410398044, \"specificity\": 0.9999997560094008, \"npv\": 0.9998604716725222, \"accuracy\": 0.9998602414662534, \"f1\": 0.5840819564949312, \"f2\": 0.46775963126606207, \"f0_5\": 0.7774073950200242, \"p4\": 0.737420057767549, \"phi\": 0.6417575806849791}, {\"truth_threshold\": 3.799999915063381, \"match_probability\": 0.9330154164289524, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125481.0, \"tn\": 1278737484.0, \"fp\": 308.0, \"fn\": 178480.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4128194077529683, \"tn_rate\": 0.9999997591374855, \"fp_rate\": 2.408625145255737e-07, \"fn_rate\": 0.5871805922470317, \"precision\": 0.9975514552146849, \"recall\": 0.4128194077529683, \"specificity\": 0.9999997591374855, \"npv\": 0.9998604443098499, \"accuracy\": 0.9998602172293589, \"f1\": 0.5839720767888307, \"f2\": 0.4676427905395887, \"f0_5\": 0.7773408316266415, \"p4\": 0.7373324754826187, \"phi\": 0.6416780730306619}, {\"truth_threshold\": 3.8199999146163464, \"match_probability\": 0.9338766342260325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125453.0, \"tn\": 1278737485.0, \"fp\": 307.0, \"fn\": 178508.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4127272906721586, \"tn_rate\": 0.9999997599195066, \"fp_rate\": 2.4008049337451663e-07, \"fn_rate\": 0.5872727093278414, \"precision\": 0.9975588422391858, \"recall\": 0.4127272906721586, \"specificity\": 0.9999997599195066, \"npv\": 0.9998604224194731, \"accuracy\": 0.9998601961198056, \"f1\": 0.5838811694099194, \"f2\": 0.4675485463668862, \"f0_5\": 0.7772790863951842, \"p4\": 0.7372600062229339, \"phi\": 0.6416088460315021}, {\"truth_threshold\": 3.8399999141693115, \"match_probability\": 0.9347275540106165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125439.0, \"tn\": 1278737487.0, \"fp\": 305.0, \"fn\": 178522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41268123213175373, \"tn_rate\": 0.999999761483549, \"fp_rate\": 2.385164510724025e-07, \"fn_rate\": 0.5873187678682462, \"precision\": 0.997574436951266, \"recall\": 0.41268123213175373, \"specificity\": 0.999999761483549, \"npv\": 0.9998604114744489, \"accuracy\": 0.999860186737782, \"f1\": 0.5838377491534891, \"f2\": 0.46750194545568385, \"f0_5\": 0.7772539863706832, \"p4\": 0.737225389758851, \"phi\": 0.6415780578502143}, {\"truth_threshold\": 3.8599999137222767, \"match_probability\": 0.9355682790857505, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125400.0, \"tn\": 1278737493.0, \"fp\": 299.0, \"fn\": 178561.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4125529261977688, \"tn_rate\": 0.9999997661756759, \"fp_rate\": 2.3382432416606015e-07, \"fn_rate\": 0.5874470738022312, \"precision\": 0.9976213016809998, \"recall\": 0.4125529261977688, \"specificity\": 0.9999997661756759, \"npv\": 0.9998603809847867, \"accuracy\": 0.9998601609372169, \"f1\": 0.5837173579109063, \"f2\": 0.4673722720777493, \"f0_5\": 0.7771856953208959, \"p4\": 0.7371293988728893, \"phi\": 0.6414933778122454}, {\"truth_threshold\": 3.879999913275242, \"match_probability\": 0.9363989122297732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125359.0, \"tn\": 1278737529.0, \"fp\": 263.0, \"fn\": 178602.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4124180404722974, \"tn_rate\": 0.9999997943284372, \"fp_rate\": 2.056715627280061e-07, \"fn_rate\": 0.5875819595277025, \"precision\": 0.9979064176656955, \"recall\": 0.4124180404722974, \"specificity\": 0.9999997943284372, \"npv\": 0.9998603489347966, \"accuracy\": 0.9998601570280403, \"f1\": 0.5836311027205453, \"f2\": 0.46724628130716694, \"f0_5\": 0.777228318219751, \"p4\": 0.7370606185047565, \"phi\": 0.6414801707905747}, {\"truth_threshold\": 3.899999912828207, \"match_probability\": 0.9372195556845757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125330.0, \"tn\": 1278737529.0, \"fp\": 263.0, \"fn\": 178631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4123226334957445, \"tn_rate\": 0.9999997943284372, \"fp_rate\": 2.056715627280061e-07, \"fn_rate\": 0.5876773665042555, \"precision\": 0.9979059342479278, \"recall\": 0.4123226334957445, \"specificity\": 0.9999997943284372, \"npv\": 0.9998603262625128, \"accuracy\": 0.9998601343548165, \"f1\": 0.5835354809872566, \"f2\": 0.4671482894835911, \"f0_5\": 0.7771603047376208, \"p4\": 0.7369843579540942, \"phi\": 0.641405805192563}, {\"truth_threshold\": 3.919999912381172, \"match_probability\": 0.9380303111443494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125227.0, \"tn\": 1278737529.0, \"fp\": 263.0, \"fn\": 178734.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4119837742341945, \"tn_rate\": 0.9999997943284372, \"fp_rate\": 2.056715627280061e-07, \"fn_rate\": 0.5880162257658055, \"precision\": 0.9979042154753367, \"recall\": 0.4119837742341945, \"specificity\": 0.9999997943284372, \"npv\": 0.9998602457368235, \"accuracy\": 0.99986005382578, \"f1\": 0.5831957545796843, \"f2\": 0.4668002153080441, \"f0_5\": 0.7769185813497849, \"p4\": 0.7367133437728385, \"phi\": 0.6411416094086839}, {\"truth_threshold\": 3.9399999119341373, \"match_probability\": 0.9388312797448133, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125212.0, \"tn\": 1278737529.0, \"fp\": 263.0, \"fn\": 178749.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41193442579804646, \"tn_rate\": 0.9999997943284372, \"fp_rate\": 2.056715627280061e-07, \"fn_rate\": 0.5880655742019535, \"precision\": 0.9979039649332536, \"recall\": 0.41193442579804646, \"specificity\": 0.9999997943284372, \"npv\": 0.9998602340097824, \"accuracy\": 0.9998600420982504, \"f1\": 0.5831462662655204, \"f2\": 0.4667495204347363, \"f0_5\": 0.7768833582962819, \"p4\": 0.7366738551390801, \"phi\": 0.6411031252160024}, {\"truth_threshold\": 3.9599999114871025, \"match_probability\": 0.9396225620529085, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125177.0, \"tn\": 1278737531.0, \"fp\": 261.0, \"fn\": 178784.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41181927944703434, \"tn_rate\": 0.9999997958924796, \"fp_rate\": 2.0410752042589197e-07, \"fn_rate\": 0.5881807205529657, \"precision\": 0.9979192908050192, \"recall\": 0.41181927944703434, \"specificity\": 0.9999997958924796, \"npv\": 0.9998602066469063, \"accuracy\": 0.9998600162976853, \"f1\": 0.5830334956532269, \"f2\": 0.4666319237863477, \"f0_5\": 0.7768088637020875, \"p4\": 0.7365838620232583, \"phi\": 0.6410184318983166}, {\"truth_threshold\": 3.9799999110400677, \"match_probability\": 0.9404042580569533, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125121.0, \"tn\": 1278737531.0, \"fp\": 261.0, \"fn\": 178840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4116350452854149, \"tn_rate\": 0.9999997958924796, \"fp_rate\": 2.0410752042589197e-07, \"fn_rate\": 0.588364954714585, \"precision\": 0.9979183614872948, \"recall\": 0.4116350452854149, \"specificity\": 0.9999997958924796, \"npv\": 0.999860162865958, \"accuracy\": 0.9998599725149082, \"f1\": 0.5828486780965335, \"f2\": 0.46644264277608694, \"f0_5\": 0.7766772730602156, \"p4\": 0.7364363461325528, \"phi\": 0.6408747181804453}, {\"truth_threshold\": 3.999999910593033, \"match_probability\": 0.941176467157249, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125060.0, \"tn\": 1278737534.0, \"fp\": 258.0, \"fn\": 178901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41143436164507946, \"tn_rate\": 0.999999798238543, \"fp_rate\": 2.017614569727208e-07, \"fn_rate\": 0.5885656383549205, \"precision\": 0.9979412374918208, \"recall\": 0.41143436164507946, \"specificity\": 0.999999798238543, \"npv\": 0.9998601151763289, \"accuracy\": 0.9998599271684605, \"f1\": 0.5826513759117031, \"f2\": 0.46623748659744313, \"f0_5\": 0.7765454222566636, \"p4\": 0.736278827553565, \"phi\": 0.6407258081783208}, {\"truth_threshold\": 4.019999910145998, \"match_probability\": 0.9419392881571256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125030.0, \"tn\": 1278737537.0, \"fp\": 255.0, \"fn\": 178931.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4113356647727833, \"tn_rate\": 0.9999998005846065, \"fp_rate\": 1.9941539351954964e-07, \"fn_rate\": 0.5886643352272166, \"precision\": 0.9979646406193878, \"recall\": 0.4113356647727833, \"specificity\": 0.9999998005846065, \"npv\": 0.9998600917225815, \"accuracy\": 0.9998599060589072, \"f1\": 0.5825563895761405, \"f2\": 0.4661371128355289, \"f0_5\": 0.7764864284108454, \"p4\": 0.7362029801605201, \"phi\": 0.640656460689344}, {\"truth_threshold\": 4.039999909698963, \"match_probability\": 0.942692819254419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125004.0, \"tn\": 1278737537.0, \"fp\": 255.0, \"fn\": 178957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41125012748346007, \"tn_rate\": 0.9999998005846065, \"fp_rate\": 1.9941539351954964e-07, \"fn_rate\": 0.58874987251654, \"precision\": 0.9979642181400139, \"recall\": 0.41125012748346007, \"specificity\": 0.9999998005846065, \"npv\": 0.999860071395717, \"accuracy\": 0.9998598857311892, \"f1\": 0.5824705279343926, \"f2\": 0.4660492147135604, \"f0_5\": 0.7764252537587096, \"p4\": 0.7361344109094913, \"phi\": 0.6405897027709225}, {\"truth_threshold\": 4.059999909251928, \"match_probability\": 0.9434371580333715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124959.0, \"tn\": 1278737538.0, \"fp\": 254.0, \"fn\": 179002.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41110208217501587, \"tn_rate\": 0.9999998013666276, \"fp_rate\": 1.9863337236849258e-07, \"fn_rate\": 0.5888979178249841, \"precision\": 0.997971456637889, \"recall\": 0.41110208217501587, \"specificity\": 0.9999998013666276, \"npv\": 0.9998600362147165, \"accuracy\": 0.9998598513304358, \"f1\": 0.5823232535055711, \"f2\": 0.46589742270462775, \"f0_5\": 0.7763231955746241, \"p4\": 0.7360167800403433, \"phi\": 0.6404767022842253}, {\"truth_threshold\": 4.0799999088048935, \"match_probability\": 0.9441724014569458, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124916.0, \"tn\": 1278737540.0, \"fp\": 252.0, \"fn\": 179045.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4109606166580581, \"tn_rate\": 0.9999998029306699, \"fp_rate\": 1.9706933006637846e-07, \"fn_rate\": 0.589039383341942, \"precision\": 0.9979867058673143, \"recall\": 0.4109606166580581, \"specificity\": 0.9999998029306699, \"npv\": 0.9998600025974329, \"accuracy\": 0.9998598192751883, \"f1\": 0.5821839120637384, \"f2\": 0.46575273002777007, \"f0_5\": 0.7762296599816314, \"p4\": 0.7359054653059081, \"phi\": 0.6403713781829289}, {\"truth_threshold\": 4.099999908357859, \"match_probability\": 0.944898645859542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124891.0, \"tn\": 1278737540.0, \"fp\": 252.0, \"fn\": 179070.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.410878369264478, \"tn_rate\": 0.9999998029306699, \"fp_rate\": 1.9706933006637846e-07, \"fn_rate\": 0.589121630735522, \"precision\": 0.9979863036686031, \"recall\": 0.410878369264478, \"specificity\": 0.9999998029306699, \"npv\": 0.9998599830523743, \"accuracy\": 0.9998597997293056, \"f1\": 0.5821013087736306, \"f2\": 0.4656681981257089, \"f0_5\": 0.7761707723611089, \"p4\": 0.7358394672569575, \"phi\": 0.640307159431808}, {\"truth_threshold\": 4.119999907910824, \"match_probability\": 0.9456159869401111, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124849.0, \"tn\": 1278737540.0, \"fp\": 252.0, \"fn\": 179112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4107401936432634, \"tn_rate\": 0.9999998029306699, \"fp_rate\": 1.9706933006637846e-07, \"fn_rate\": 0.5892598063567366, \"precision\": 0.9979856276128888, \"recall\": 0.4107401936432634, \"specificity\": 0.9999998029306699, \"npv\": 0.9998599502166776, \"accuracy\": 0.9998597668922228, \"f1\": 0.5819625135761265, \"f2\": 0.4655261774345704, \"f0_5\": 0.7760718081965277, \"p4\": 0.7357285577037593, \"phi\": 0.6401992574339889}, {\"truth_threshold\": 4.139999907463789, \"match_probability\": 0.9463245197556541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124806.0, \"tn\": 1278737542.0, \"fp\": 250.0, \"fn\": 179155.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41059872812630566, \"tn_rate\": 0.9999998044947123, \"fp_rate\": 1.9550528776426434e-07, \"fn_rate\": 0.5894012718736943, \"precision\": 0.9980008955987717, \"recall\": 0.41059872812630566, \"specificity\": 0.9999998044947123, \"npv\": 0.9998599165993999, \"accuracy\": 0.9998597348369752, \"f1\": 0.5818230979191967, \"f2\": 0.4653814602132896, \"f0_5\": 0.7759781642283803, \"p4\": 0.7356171328833271, \"phi\": 0.640093887838797}, {\"truth_threshold\": 4.159999907016754, \"match_probability\": 0.9470243387150994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124787.0, \"tn\": 1278737543.0, \"fp\": 249.0, \"fn\": 179174.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4105362201071848, \"tn_rate\": 0.9999998052767334, \"fp_rate\": 1.9472326661320728e-07, \"fn_rate\": 0.5894637798928152, \"precision\": 0.9980085735308232, \"recall\": 0.4105362201071848, \"specificity\": 0.9999998052767334, \"npv\": 0.9998599017452674, \"accuracy\": 0.9998597207639398, \"f1\": 0.5817616440208206, \"f2\": 0.46531755265198976, \"f0_5\": 0.7759372221289508, \"p4\": 0.735568011011876, \"phi\": 0.640047621428091}, {\"truth_threshold\": 4.179999906569719, \"match_probability\": 0.9477155375735482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124762.0, \"tn\": 1278737543.0, \"fp\": 249.0, \"fn\": 179199.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41045397271360473, \"tn_rate\": 0.9999998052767334, \"fp_rate\": 1.9472326661320728e-07, \"fn_rate\": 0.5895460272863953, \"precision\": 0.9980081752805753, \"recall\": 0.41045397271360473, \"specificity\": 0.9999998052767334, \"npv\": 0.9998598822002128, \"accuracy\": 0.9998597012180571, \"f1\": 0.5816789907033559, \"f2\": 0.46523300431441134, \"f0_5\": 0.7758782594635606, \"p4\": 0.7355019377317251, \"phi\": 0.6399833701971243}, {\"truth_threshold\": 4.1999999061226845, \"match_probability\": 0.9483982094268801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124685.0, \"tn\": 1278737543.0, \"fp\": 249.0, \"fn\": 179276.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.410200650741378, \"tn_rate\": 0.9999998052767334, \"fp_rate\": 1.9472326661320728e-07, \"fn_rate\": 0.589799349258622, \"precision\": 0.998006947668369, \"recall\": 0.410200650741378, \"specificity\": 0.9999998052767334, \"npv\": 0.9998598220014495, \"accuracy\": 0.9998596410167385, \"f1\": 0.5814243579430863, \"f2\": 0.4649725756240034, \"f0_5\": 0.7756965622616484, \"p4\": 0.7352983402247589, \"phi\": 0.6397854358797794}, {\"truth_threshold\": 4.21999990567565, \"match_probability\": 0.9490724467067111, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124665.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179296.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4101348528265139, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.589865147173486, \"precision\": 0.9980226079159729, \"recall\": 0.4101348528265139, \"specificity\": 0.9999998068407757, \"npv\": 0.9998598063656274, \"accuracy\": 0.9998596269437031, \"f1\": 0.5813609157023175, \"f2\": 0.464905620411171, \"f0_5\": 0.7756570670562425, \"p4\": 0.7352476034386926, \"phi\": 0.6397391377501906}, {\"truth_threshold\": 4.239999905228615, \"match_probability\": 0.9497383411756931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124647.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41007563470313624, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.5899243652968638, \"precision\": 0.9980223229298445, \"recall\": 0.41007563470313624, \"specificity\": 0.9999998068407757, \"npv\": 0.9998597922931908, \"accuracy\": 0.9998596128706676, \"f1\": 0.5813013722586888, \"f2\": 0.4648447347654799, \"f0_5\": 0.7756145641084355, \"p4\": 0.7351999808251921, \"phi\": 0.6396928552116704}, {\"truth_threshold\": 4.25999990478158, \"match_probability\": 0.95039598392315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124613.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179348.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40996377824786734, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.5900362217521327, \"precision\": 0.9980217843985264, \"recall\": 0.40996377824786734, \"specificity\": 0.9999998068407757, \"npv\": 0.9998597657119226, \"accuracy\": 0.9998595862882672, \"f1\": 0.5811888876710796, \"f2\": 0.4647297240852567, \"f0_5\": 0.7755342599772717, \"p4\": 0.7351100063055226, \"phi\": 0.6396054235050638}, {\"truth_threshold\": 4.279999904334545, \"match_probability\": 0.9510454653610375, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124577.0, \"tn\": 1278737549.0, \"fp\": 243.0, \"fn\": 179384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.409845342001112, \"tn_rate\": 0.9999998099688603, \"fp_rate\": 1.9003113970686495e-07, \"fn_rate\": 0.590154657998888, \"precision\": 0.9980531966031084, \"recall\": 0.409845342001112, \"specificity\": 0.9999998099688603, \"npv\": 0.9998597375674906, \"accuracy\": 0.9998595612695373, \"f1\": 0.5810751875666132, \"f2\": 0.46460932791512266, \"f0_5\": 0.7754646488413813, \"p4\": 0.7350190467556891, \"phi\": 0.639523086493326}, {\"truth_threshold\": 4.29999990388751, \"match_probability\": 0.9516868752202245, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124545.0, \"tn\": 1278737554.0, \"fp\": 238.0, \"fn\": 179416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4097400653373295, \"tn_rate\": 0.9999998138789661, \"fp_rate\": 1.8612103395157965e-07, \"fn_rate\": 0.5902599346626706, \"precision\": 0.9980926889079442, \"recall\": 0.4097400653373295, \"specificity\": 0.9999998138789661, \"npv\": 0.9998597125503776, \"accuracy\": 0.9998595401599841, \"f1\": 0.5809760603063833, \"f2\": 0.46450280353894113, \"f0_5\": 0.7754083275535959, \"p4\": 0.7349397348336718, \"phi\": 0.6394535920902664}, {\"truth_threshold\": 4.3199999034404755, \"match_probability\": 0.9523203025470809, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124506.0, \"tn\": 1278737554.0, \"fp\": 238.0, \"fn\": 179455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4096117594033445, \"tn_rate\": 0.9999998138789661, \"fp_rate\": 1.8612103395157965e-07, \"fn_rate\": 0.5903882405966555, \"precision\": 0.9980920926056563, \"recall\": 0.4096117594033445, \"specificity\": 0.9999998138789661, \"npv\": 0.9998596820601047, \"accuracy\": 0.9998595096684072, \"f1\": 0.5808469693612157, \"f2\": 0.46437085816074736, \"f0_5\": 0.7753161206919098, \"p4\": 0.7348364335921075, \"phi\": 0.6393532642293431}, {\"truth_threshold\": 4.339999902993441, \"match_probability\": 0.9529458357003701, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124485.0, \"tn\": 1278737554.0, \"fp\": 238.0, \"fn\": 179476.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4095426715927372, \"tn_rate\": 0.9999998138789661, \"fp_rate\": 1.8612103395157965e-07, \"fn_rate\": 0.5904573284072627, \"precision\": 0.9980917713653457, \"recall\": 0.4095426715927372, \"specificity\": 0.9999998138789661, \"npv\": 0.9998596656422661, \"accuracy\": 0.9998594932498658, \"f1\": 0.5807774491233636, \"f2\": 0.4642998074695259, \"f0_5\": 0.7752664560012854, \"p4\": 0.7347807950729812, \"phi\": 0.6392992350160879}, {\"truth_threshold\": 4.359999902546406, \"match_probability\": 0.9535635623484342, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124387.0, \"tn\": 1278737557.0, \"fp\": 235.0, \"fn\": 179574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40922026180990323, \"tn_rate\": 0.9999998162250295, \"fp_rate\": 1.837749704984085e-07, \"fn_rate\": 0.5907797381900968, \"precision\": 0.9981142976360514, \"recall\": 0.40922026180990323, \"specificity\": 0.9999998162250295, \"npv\": 0.9998595890260227, \"accuracy\": 0.9998594189755118, \"f1\": 0.5804569943278198, \"f2\": 0.46396924651576393, \"f0_5\": 0.775046140003913, \"p4\": 0.734524265226887, \"phi\": 0.6390547330054595}, {\"truth_threshold\": 4.379999902099371, \"match_probability\": 0.9541735694666671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124345.0, \"tn\": 1278737557.0, \"fp\": 235.0, \"fn\": 179616.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4090820861886887, \"tn_rate\": 0.9999998162250295, \"fp_rate\": 1.837749704984085e-07, \"fn_rate\": 0.5909179138113113, \"precision\": 0.9981136619039974, \"recall\": 0.4090820861886887, \"specificity\": 0.9999998162250295, \"npv\": 0.9998595561903523, \"accuracy\": 0.999859386138429, \"f1\": 0.5803178692353824, \"f2\": 0.4638271173897215, \"f0_5\": 0.7749466832693284, \"p4\": 0.7344128606158165, \"phi\": 0.6389466195356048}, {\"truth_threshold\": 4.399999901652336, \"match_probability\": 0.9547759433352639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124335.0, \"tn\": 1278737560.0, \"fp\": 232.0, \"fn\": 179626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40904918723125666, \"tn_rate\": 0.999999818571093, \"fp_rate\": 1.814289070452373e-07, \"fn_rate\": 0.5909508127687434, \"precision\": 0.9981375484678928, \"recall\": 0.40904918723125666, \"specificity\": 0.999999818571093, \"npv\": 0.9998595483726653, \"accuracy\": 0.9998593806655818, \"f1\": 0.5802888025986633, \"f2\": 0.4637943138335928, \"f0_5\": 0.7749345885027841, \"p4\": 0.7343895831763934, \"phi\": 0.63892857210823}, {\"truth_threshold\": 4.419999901205301, \"match_probability\": 0.955370769537244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124299.0, \"tn\": 1278737565.0, \"fp\": 227.0, \"fn\": 179662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4089307509845013, \"tn_rate\": 0.9999998224811987, \"fp_rate\": 1.77518801289952e-07, \"fn_rate\": 0.5910692490154987, \"precision\": 0.9981770875158601, \"recall\": 0.4089307509845013, \"specificity\": 0.9999998224811987, \"npv\": 0.9998595202283564, \"accuracy\": 0.9998593564286873, \"f1\": 0.5801762947300618, \"f2\": 0.46367420936010206, \"f0_5\": 0.7748686203736604, \"p4\": 0.7342994749982465, \"phi\": 0.6388487163206985}, {\"truth_threshold\": 4.4399999007582664, \"match_probability\": 0.9559581329567363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124207.0, \"tn\": 1278737565.0, \"fp\": 227.0, \"fn\": 179754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40862808057612654, \"tn_rate\": 0.9999998224811987, \"fp_rate\": 1.77518801289952e-07, \"fn_rate\": 0.5913719194238735, \"precision\": 0.9981757397495862, \"recall\": 0.40862808057612654, \"specificity\": 0.9999998224811987, \"npv\": 0.9998594483026154, \"accuracy\": 0.9998592844998392, \"f1\": 0.5798713803849251, \"f2\": 0.4633628247274073, \"f0_5\": 0.7746505225789794, \"p4\": 0.7340552020455443, \"phi\": 0.6386117960633004}, {\"truth_threshold\": 4.459999900311232, \"match_probability\": 0.9565381177775213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124190.0, \"tn\": 1278737565.0, \"fp\": 227.0, \"fn\": 179771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4085721523484921, \"tn_rate\": 0.9999998224811987, \"fp_rate\": 1.77518801289952e-07, \"fn_rate\": 0.5914278476515079, \"precision\": 0.9981754904876343, \"recall\": 0.4085721523484921, \"specificity\": 0.9999998224811987, \"npv\": 0.9998594350119905, \"accuracy\": 0.9998592712086389, \"f1\": 0.5798150231804621, \"f2\": 0.463305281583214, \"f0_5\": 0.7746101999802901, \"p4\": 0.7340100428441715, \"phi\": 0.6385680077019088}, {\"truth_threshold\": 4.479999899864197, \"match_probability\": 0.9571108074818223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124166.0, \"tn\": 1278737565.0, \"fp\": 227.0, \"fn\": 179795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40849319485065516, \"tn_rate\": 0.9999998224811987, \"fp_rate\": 1.77518801289952e-07, \"fn_rate\": 0.5915068051493448, \"precision\": 0.9981751384724221, \"recall\": 0.40849319485065516, \"specificity\": 0.9999998224811987, \"npv\": 0.9998594162487559, \"accuracy\": 0.9998592524445916, \"f1\": 0.5797354524528777, \"f2\": 0.46322404171799464, \"f0_5\": 0.7745532623110963, \"p4\": 0.7339462770900124, \"phi\": 0.6385061837284799}, {\"truth_threshold\": 4.499999899417162, \"match_probability\": 0.9576762848493385, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124121.0, \"tn\": 1278737566.0, \"fp\": 226.0, \"fn\": 179840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.408345149542211, \"tn_rate\": 0.9999998232632199, \"fp_rate\": 1.7673678013889495e-07, \"fn_rate\": 0.591654850457789, \"precision\": 0.9981825054082527, \"recall\": 0.408345149542211, \"specificity\": 0.9999998232632199, \"npv\": 0.9998593810678029, \"accuracy\": 0.9998592180438381, \"f1\": 0.5795875865031707, \"f2\": 0.4630720546548962, \"f0_5\": 0.7744503331257667, \"p4\": 0.7338277644599676, \"phi\": 0.6383928155859415}, {\"truth_threshold\": 4.519999898970127, \"match_probability\": 0.9582346319565136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124087.0, \"tn\": 1278737566.0, \"fp\": 226.0, \"fn\": 179874.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40823329308694206, \"tn_rate\": 0.9999998232632199, \"fp_rate\": 1.7673678013889495e-07, \"fn_rate\": 0.5917667069130579, \"precision\": 0.9981820083177142, \"recall\": 0.40823329308694206, \"specificity\": 0.9999998232632199, \"npv\": 0.999859354486557, \"accuracy\": 0.9998591914614378, \"f1\": 0.5794748221932688, \"f2\": 0.4629569520586021, \"f0_5\": 0.7743696120756902, \"p4\": 0.7337373703779373, \"phi\": 0.6383052058255128}, {\"truth_threshold\": 4.539999898523092, \"match_probability\": 0.9587859301760313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124024.0, \"tn\": 1278737567.0, \"fp\": 225.0, \"fn\": 179937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40802602965512025, \"tn_rate\": 0.999999824045241, \"fp_rate\": 1.7595475898783792e-07, \"fn_rate\": 0.5919739703448798, \"precision\": 0.9981891202343681, \"recall\": 0.40802602965512025, \"specificity\": 0.999999824045241, \"npv\": 0.9998593052331857, \"accuracy\": 0.9998591429876488, \"f1\": 0.579267181990145, \"f2\": 0.4627440035878107, \"f0_5\": 0.7742238347376951, \"p4\": 0.7335708882183637, \"phi\": 0.6381454072824626}, {\"truth_threshold\": 4.559999898076057, \"match_probability\": 0.959330260176534, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124012.0, \"tn\": 1278737572.0, \"fp\": 220.0, \"fn\": 179949.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4079865509062018, \"tn_rate\": 0.9999998279553468, \"fp_rate\": 1.7204465323255262e-07, \"fn_rate\": 0.5920134490937983, \"precision\": 0.9982291197115075, \"recall\": 0.4079865509062018, \"specificity\": 0.9999998279553468, \"npv\": 0.9998592958521209, \"accuracy\": 0.9998591375148017, \"f1\": 0.5792341304038132, \"f2\": 0.46270510030774376, \"f0_5\": 0.7742146539657805, \"p4\": 0.7335443843177082, \"phi\": 0.6381273215036833}, {\"truth_threshold\": 4.579999897629023, \"match_probability\": 0.9598677019225548, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123974.0, \"tn\": 1278737576.0, \"fp\": 216.0, \"fn\": 179987.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40786153486796, \"tn_rate\": 0.9999998310834314, \"fp_rate\": 1.6891656862832438e-07, \"fn_rate\": 0.5921384651320399, \"precision\": 0.9982607295273371, \"recall\": 0.40786153486796, \"specificity\": 0.9999998310834314, \"npv\": 0.999859266144115, \"accuracy\": 0.9998591109324013, \"f1\": 0.5791134436215261, \"f2\": 0.4625778151897638, \"f0_5\": 0.7741398064993924, \"p4\": 0.7334475958855353, \"phi\": 0.6380396420426833}, {\"truth_threshold\": 4.599999897181988, \"match_probability\": 0.9603983346746578, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123943.0, \"tn\": 1278737577.0, \"fp\": 215.0, \"fn\": 180018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4077595480999207, \"tn_rate\": 0.9999998318654525, \"fp_rate\": 1.6813454747726735e-07, \"fn_rate\": 0.5922404519000792, \"precision\": 0.9982683355079818, \"recall\": 0.4077595480999207, \"specificity\": 0.9999998318654525, \"npv\": 0.9998592419083889, \"accuracy\": 0.9998590874773421, \"f1\": 0.5790119102399099, \"f2\": 0.46247319033852186, \"f0_5\": 0.7740699706342673, \"p4\": 0.7333661564999447, \"phi\": 0.6379622889275192}, {\"truth_threshold\": 4.619999896734953, \"match_probability\": 0.9609222369897813, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123895.0, \"tn\": 1278737577.0, \"fp\": 215.0, \"fn\": 180066.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4076016331042469, \"tn_rate\": 0.9999998318654525, \"fp_rate\": 1.6813454747726735e-07, \"fn_rate\": 0.5923983668957531, \"precision\": 0.9982676657803561, \"recall\": 0.4076016331042469, \"specificity\": 0.9999998318654525, \"npv\": 0.9998592043819353, \"accuracy\": 0.9998590499492475, \"f1\": 0.5788525735216822, \"f2\": 0.46231064648487935, \"f0_5\": 0.7739558046529177, \"p4\": 0.7332383321546404, \"phi\": 0.6378385175761738}, {\"truth_threshold\": 4.639999896287918, \"match_probability\": 0.9614394867217748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123802.0, \"tn\": 1278737577.0, \"fp\": 215.0, \"fn\": 180159.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40729567280012896, \"tn_rate\": 0.9999998318654525, \"fp_rate\": 1.6813454747726735e-07, \"fn_rate\": 0.592704327199871, \"precision\": 0.99826636670779, \"recall\": 0.40729567280012896, \"specificity\": 0.9999998318654525, \"npv\": 0.9998591316744394, \"accuracy\": 0.999858977238564, \"f1\": 0.5785437569220848, \"f2\": 0.4619956846269874, \"f0_5\": 0.7737344521261105, \"p4\": 0.7329905174321124, \"phi\": 0.6375986422375562}, {\"truth_threshold\": 4.659999895840883, \"match_probability\": 0.9619501610221266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123780.0, \"tn\": 1278737578.0, \"fp\": 214.0, \"fn\": 180181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40722329509377847, \"tn_rate\": 0.9999998326474737, \"fp_rate\": 1.6735252632621029e-07, \"fn_rate\": 0.5927767049062215, \"precision\": 0.9982741100375825, \"recall\": 0.40722329509377847, \"specificity\": 0.9999998326474737, \"npv\": 0.9998591144749285, \"accuracy\": 0.9998589608200226, \"f1\": 0.5784720356112208, \"f2\": 0.4619215158847562, \"f0_5\": 0.7736859277668117, \"p4\": 0.7329329497312727, \"phi\": 0.6375444561663494}, {\"truth_threshold\": 4.679999895393848, \"match_probability\": 0.9624543363408739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123736.0, \"tn\": 1278737578.0, \"fp\": 214.0, \"fn\": 180225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4070785396810775, \"tn_rate\": 0.9999998326474737, \"fp_rate\": 1.6735252632621029e-07, \"fn_rate\": 0.5929214603189225, \"precision\": 0.998273497377975, \"recall\": 0.4070785396810775, \"specificity\": 0.9999998326474737, \"npv\": 0.999859080075688, \"accuracy\": 0.9998589264192691, \"f1\": 0.5783258668274478, \"f2\": 0.4617724814411768, \"f0_5\": 0.7735811073558225, \"p4\": 0.7328156098323286, \"phi\": 0.6374309256679807}, {\"truth_threshold\": 4.699999894946814, \"match_probability\": 0.9629520884276901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123711.0, \"tn\": 1278737578.0, \"fp\": 214.0, \"fn\": 180250.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4069962922874974, \"tn_rate\": 0.9999998326474737, \"fp_rate\": 1.6735252632621029e-07, \"fn_rate\": 0.5930037077125025, \"precision\": 0.9982731490821061, \"recall\": 0.4069962922874974, \"specificity\": 0.9999998326474737, \"npv\": 0.9998590605306661, \"accuracy\": 0.9998589068733865, \"f1\": 0.5782428029895813, \"f2\": 0.46168779841898117, \"f0_5\": 0.7735215297482309, \"p4\": 0.732748919000628, \"phi\": 0.6373664106973151}, {\"truth_threshold\": 4.719999894499779, \"match_probability\": 0.9634434923331444, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123677.0, \"tn\": 1278737578.0, \"fp\": 214.0, \"fn\": 180284.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4068844358322285, \"tn_rate\": 0.9999998326474737, \"fp_rate\": 1.6735252632621029e-07, \"fn_rate\": 0.5931155641677716, \"precision\": 0.998272675174145, \"recall\": 0.4068844358322285, \"specificity\": 0.9999998326474737, \"npv\": 0.9998590339494375, \"accuracy\": 0.9998588802909861, \"f1\": 0.5781298205921673, \"f2\": 0.4615726244369222, \"f0_5\": 0.7734404802851693, \"p4\": 0.7326581956953041, \"phi\": 0.637278659860146}, {\"truth_threshold\": 4.739999894052744, \"match_probability\": 0.9639286224101253, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123595.0, \"tn\": 1278737578.0, \"fp\": 214.0, \"fn\": 180366.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40661466438128574, \"tn_rate\": 0.9999998326474737, \"fp_rate\": 1.6735252632621029e-07, \"fn_rate\": 0.5933853356187142, \"precision\": 0.9982715311487856, \"recall\": 0.40661466438128574, \"specificity\": 0.9999998326474737, \"npv\": 0.9998589698417744, \"accuracy\": 0.999858816180491, \"f1\": 0.5778572597423849, \"f2\": 0.46129482783974657, \"f0_5\": 0.7732448945629176, \"p4\": 0.7324392796269175, \"phi\": 0.6370669757798941}, {\"truth_threshold\": 4.759999893605709, \"match_probability\": 0.9644075523154256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123558.0, \"tn\": 1278737580.0, \"fp\": 212.0, \"fn\": 180403.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40649293823878724, \"tn_rate\": 0.999999834211516, \"fp_rate\": 1.6578848402409617e-07, \"fn_rate\": 0.5935070617612128, \"precision\": 0.9982871455118365, \"recall\": 0.40649293823878724, \"specificity\": 0.999999834211516, \"npv\": 0.9998589409153691, \"accuracy\": 0.9998587888162553, \"f1\": 0.5777369421435435, \"f2\": 0.4611701579708782, \"f0_5\": 0.7731643307414764, \"p4\": 0.7323426187179205, \"phi\": 0.6369765851129967}, {\"truth_threshold\": 4.779999893158674, \"match_probability\": 0.9648803550114816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123515.0, \"tn\": 1278737580.0, \"fp\": 212.0, \"fn\": 180446.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4063514727218294, \"tn_rate\": 0.999999834211516, \"fp_rate\": 1.6578848402409617e-07, \"fn_rate\": 0.5936485272781705, \"precision\": 0.998286550227517, \"recall\": 0.4063514727218294, \"specificity\": 0.999999834211516, \"npv\": 0.9998589072979412, \"accuracy\": 0.9998587551973371, \"f1\": 0.5775939469893941, \"f2\": 0.46102446230920197, \"f0_5\": 0.7730616659302089, \"p4\": 0.7322277197660181, \"phi\": 0.6368655361809524}, {\"truth_threshold\": 4.799999892711639, \"match_probability\": 0.9653471027682606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123488.0, \"tn\": 1278737583.0, \"fp\": 209.0, \"fn\": 180473.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40626264553676295, \"tn_rate\": 0.9999998365575794, \"fp_rate\": 1.6344242057092499e-07, \"fn_rate\": 0.593737354463237, \"precision\": 0.998310387479082, \"recall\": 0.40626264553676295, \"specificity\": 0.9999998365575794, \"npv\": 0.9998588861896559, \"accuracy\": 0.9998587364332898, \"f1\": 0.5775081958013178, \"f2\": 0.46093400649924116, \"f0_5\": 0.7730087924992707, \"p4\": 0.7321588074771738, \"phi\": 0.636803522816079}, {\"truth_threshold\": 4.819999892264605, \"match_probability\": 0.9658078671652934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123418.0, \"tn\": 1278737585.0, \"fp\": 207.0, \"fn\": 180543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40603235283473865, \"tn_rate\": 0.9999998381216217, \"fp_rate\": 1.6187837826881087e-07, \"fn_rate\": 0.5939676471652613, \"precision\": 0.9983255813953489, \"recall\": 0.40603235283473865, \"specificity\": 0.9999998381216217, \"npv\": 0.9998588314638386, \"accuracy\": 0.999858683268489, \"f1\": 0.5772780212635586, \"f2\": 0.4606974853468053, \"f0_5\": 0.7728492687808171, \"p4\": 0.7319737947273303, \"phi\": 0.6366278380118985}, {\"truth_threshold\": 4.83999989181757, \"match_probability\": 0.9662627190938445, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123382.0, \"tn\": 1278737591.0, \"fp\": 201.0, \"fn\": 180579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4059139165879833, \"tn_rate\": 0.9999998428137487, \"fp_rate\": 1.5718625136246853e-07, \"fn_rate\": 0.5940860834120166, \"precision\": 0.9983735627068447, \"recall\": 0.4059139165879833, \"specificity\": 0.9999998428137487, \"npv\": 0.9998588033196839, \"accuracy\": 0.9998586598134299, \"f1\": 0.5771663267406396, \"f2\": 0.46057754547280294, \"f0_5\": 0.7727864330515237, \"p4\": 0.7318839962746296, \"phi\": 0.636550274880401}, {\"truth_threshold\": 4.859999891370535, \"match_probability\": 0.9667117287592163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123330.0, \"tn\": 1278737591.0, \"fp\": 201.0, \"fn\": 180631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40574284200933675, \"tn_rate\": 0.9999998428137487, \"fp_rate\": 1.5718625136246853e-07, \"fn_rate\": 0.5942571579906633, \"precision\": 0.9983728780629963, \"recall\": 0.40574284200933675, \"specificity\": 0.9999998428137487, \"npv\": 0.999858762666062, \"accuracy\": 0.999858619157994, \"f1\": 0.5769932536749226, \"f2\": 0.46040130657956135, \"f0_5\": 0.7726620598056598, \"p4\": 0.7317448259398601, \"phi\": 0.6364158907387226}, {\"truth_threshold\": 4.8799998909235, \"match_probability\": 0.9671549656831816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123288.0, \"tn\": 1278737591.0, \"fp\": 201.0, \"fn\": 180673.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40560466638812215, \"tn_rate\": 0.9999998428137487, \"fp_rate\": 1.5718625136246853e-07, \"fn_rate\": 0.5943953336118778, \"precision\": 0.9983723246604961, \"recall\": 0.40560466638812215, \"specificity\": 0.9999998428137487, \"npv\": 0.9998587298304468, \"accuracy\": 0.9998585863209112, \"f1\": 0.576853433150076, \"f2\": 0.4602589497906794, \"f0_5\": 0.7725615571544409, \"p4\": 0.7316323721059437, \"phi\": 0.6363073289903746}, {\"truth_threshold\": 4.899999890476465, \"match_probability\": 0.9675924987065404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123263.0, \"tn\": 1278737591.0, \"fp\": 201.0, \"fn\": 180698.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40552241899454206, \"tn_rate\": 0.9999998428137487, \"fp_rate\": 1.5718625136246853e-07, \"fn_rate\": 0.5944775810054579, \"precision\": 0.9983719950754876, \"recall\": 0.40552241899454206, \"specificity\": 0.9999998428137487, \"npv\": 0.9998587102854387, \"accuracy\": 0.9998585667750285, \"f1\": 0.5767701936012166, \"f2\": 0.4601742093678228, \"f0_5\": 0.77250171405222, \"p4\": 0.7315654153383621, \"phi\": 0.6362427001109312}, {\"truth_threshold\": 4.91999989002943, \"match_probability\": 0.968024395991795, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123208.0, \"tn\": 1278737592.0, \"fp\": 200.0, \"fn\": 180753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40534147472866583, \"tn_rate\": 0.9999998435957698, \"fp_rate\": 1.5640423021141147e-07, \"fn_rate\": 0.5946585252713341, \"precision\": 0.9983793595228835, \"recall\": 0.40534147472866583, \"specificity\": 0.9999998435957698, \"npv\": 0.9998586672865343, \"accuracy\": 0.999858524555922, \"f1\": 0.5765883814689413, \"f2\": 0.4599881127674254, \"f0_5\": 0.7723738799111828, \"p4\": 0.7314191435973382, \"phi\": 0.6361030716703958}, {\"truth_threshold\": 4.9399998895823956, \"match_probability\": 0.9684507250259401, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123141.0, \"tn\": 1278737593.0, \"fp\": 199.0, \"fn\": 180820.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4051210517138712, \"tn_rate\": 0.999999844377791, \"fp_rate\": 1.556222090603544e-07, \"fn_rate\": 0.5948789482861289, \"precision\": 0.998386573698719, \"recall\": 0.4051210517138712, \"specificity\": 0.999999844377791, \"npv\": 0.9998586149060316, \"accuracy\": 0.9998584729547918, \"f1\": 0.5763665425543119, \"f2\": 0.4597613173395142, \"f0_5\": 0.772217212389991, \"p4\": 0.731240623748896, \"phi\": 0.6359323748062736}, {\"truth_threshold\": 4.959999889135361, \"match_probability\": 0.9688715526233621, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123106.0, \"tn\": 1278737594.0, \"fp\": 198.0, \"fn\": 180855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4050059053628591, \"tn_rate\": 0.9999998451598121, \"fp_rate\": 1.5484018790929735e-07, \"fn_rate\": 0.5949940946371409, \"precision\": 0.9983942126776099, \"recall\": 0.4050059053628591, \"specificity\": 0.9999998451598121, \"npv\": 0.9998585875431374, \"accuracy\": 0.9998584463723914, \"f1\": 0.5762512726293986, \"f2\": 0.45964299689056026, \"f0_5\": 0.7721371790706455, \"p4\": 0.7311478430790593, \"phi\": 0.6358444185213564}, {\"truth_threshold\": 4.979999888688326, \"match_probability\": 0.9692869449288442, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123024.0, \"tn\": 1278737595.0, \"fp\": 197.0, \"fn\": 180937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4047361339119163, \"tn_rate\": 0.9999998459418332, \"fp_rate\": 1.540581667582403e-07, \"fn_rate\": 0.5952638660880837, \"precision\": 0.9984012465407682, \"recall\": 0.4047361339119163, \"specificity\": 0.9999998459418332, \"npv\": 0.9998585234356429, \"accuracy\": 0.9998583830437316, \"f1\": 0.5759793249715578, \"f2\": 0.45936530340200066, \"f0_5\": 0.771944355552209, \"p4\": 0.7309288987713524, \"phi\": 0.6356348371116717}, {\"truth_threshold\": 4.999999888241291, \"match_probability\": 0.9696969674206727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123014.0, \"tn\": 1278737595.0, \"fp\": 197.0, \"fn\": 180947.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4047032349544843, \"tn_rate\": 0.9999998459418332, \"fp_rate\": 1.540581667582403e-07, \"fn_rate\": 0.5952967650455157, \"precision\": 0.998401116783404, \"recall\": 0.4047032349544843, \"specificity\": 0.9999998459418332, \"npv\": 0.9998585156176428, \"accuracy\": 0.9998583752253786, \"f1\": 0.5759459889693145, \"f2\": 0.4593313941548331, \"f0_5\": 0.7719203569254711, \"p4\": 0.7309020548422969, \"phi\": 0.6356089590047713}, {\"truth_threshold\": 5.019999887794256, \"match_probability\": 0.970101684913839, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122984.0, \"tn\": 1278737595.0, \"fp\": 197.0, \"fn\": 180977.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40460453808218816, \"tn_rate\": 0.9999998459418332, \"fp_rate\": 1.540581667582403e-07, \"fn_rate\": 0.5953954619178118, \"precision\": 0.9984007273849052, \"recall\": 0.40460453808218816, \"specificity\": 0.9999998459418332, \"npv\": 0.9998584921636434, \"accuracy\": 0.9998583517703195, \"f1\": 0.5758459715972675, \"f2\": 0.45922966337447024, \"f0_5\": 0.7718483465861664, \"p4\": 0.7308215086993415, \"phi\": 0.6355313183642022}, {\"truth_threshold\": 5.039999887347221, \"match_probability\": 0.9705011615633362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122926.0, \"tn\": 1278737596.0, \"fp\": 196.0, \"fn\": 181035.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40441372412908233, \"tn_rate\": 0.9999998467238544, \"fp_rate\": 1.5327614560718323e-07, \"fn_rate\": 0.5955862758709176, \"precision\": 0.9984080830395867, \"recall\": 0.40441372412908233, \"specificity\": 0.9999998467238544, \"npv\": 0.9998584468193583, \"accuracy\": 0.999858307205707, \"f1\": 0.5756539127054928, \"f2\": 0.45903331376599554, \"f0_5\": 0.7717129408160472, \"p4\": 0.7306668109353948, \"phi\": 0.6353837675005758}, {\"truth_threshold\": 5.0599998869001865, \"match_probability\": 0.9708954608675425, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122893.0, \"tn\": 1278737596.0, \"fp\": 196.0, \"fn\": 181068.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4043051575695566, \"tn_rate\": 0.9999998467238544, \"fp_rate\": 1.5327614560718323e-07, \"fn_rate\": 0.5956948424304433, \"precision\": 0.9984076562487306, \"recall\": 0.4043051575695566, \"specificity\": 0.9999998467238544, \"npv\": 0.9998584210199626, \"accuracy\": 0.9998582814051419, \"f1\": 0.5755438473246692, \"f2\": 0.45892139487188677, \"f0_5\": 0.7716336584551127, \"p4\": 0.7305781394894537, \"phi\": 0.6352983320110998}, {\"truth_threshold\": 5.079999886453152, \"match_probability\": 0.9712846456716904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122869.0, \"tn\": 1278737597.0, \"fp\": 195.0, \"fn\": 181092.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4042262000717197, \"tn_rate\": 0.9999998475058756, \"fp_rate\": 1.524941244561262e-07, \"fn_rate\": 0.5957737999282803, \"precision\": 0.9984154586231554, \"recall\": 0.4042262000717197, \"specificity\": 0.9999998475058756, \"npv\": 0.9998584022568772, \"accuracy\": 0.9998582634229298, \"f1\": 0.5754651367015983, \"f2\": 0.45884033854454526, \"f0_5\": 0.771579858254722, \"p4\": 0.7305147206923416, \"phi\": 0.6352387717886573}, {\"truth_threshold\": 5.099999886006117, \"match_probability\": 0.9716687781714157, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122823.0, \"tn\": 1278737599.0, \"fp\": 193.0, \"fn\": 181138.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40407486486753236, \"tn_rate\": 0.9999998490699179, \"fp_rate\": 1.5093008215401208e-07, \"fn_rate\": 0.5959251351324677, \"precision\": 0.9984310983937049, \"recall\": 0.40407486486753236, \"specificity\": 0.9999998490699179, \"npv\": 0.9998583662943082, \"accuracy\": 0.9998582290221765, \"f1\": 0.5753143611950995, \"f2\": 0.4586850006722137, \"f0_5\": 0.7714770264752991, \"p4\": 0.7303932200207538, \"phi\": 0.6351248144031055}, {\"truth_threshold\": 5.119999885559082, \"match_probability\": 0.9720479199163852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122747.0, \"tn\": 1278737599.0, \"fp\": 193.0, \"fn\": 181214.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40382483279104886, \"tn_rate\": 0.9999998490699179, \"fp_rate\": 1.5093008215401208e-07, \"fn_rate\": 0.5961751672089511, \"precision\": 0.9984301285179763, \"recall\": 0.40382483279104886, \"specificity\": 0.9999998490699179, \"npv\": 0.9998583068775296, \"accuracy\": 0.9998581696026931, \"f1\": 0.575060728365593, \"f2\": 0.4584271996080025, \"f0_5\": 0.7712942099052306, \"p4\": 0.7301887803049332, \"phi\": 0.6349279564084986}, {\"truth_threshold\": 5.139999885112047, \"match_probability\": 0.972422131813996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122710.0, \"tn\": 1278737599.0, \"fp\": 193.0, \"fn\": 181251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4037031066485503, \"tn_rate\": 0.9999998490699179, \"fp_rate\": 1.5093008215401208e-07, \"fn_rate\": 0.5962968933514496, \"precision\": 0.9984296559075043, \"recall\": 0.4037031066485503, \"specificity\": 0.9999998490699179, \"npv\": 0.9998582779509427, \"accuracy\": 0.9998581406747868, \"f1\": 0.5749372165373515, \"f2\": 0.4583016806013384, \"f0_5\": 0.7712051565349755, \"p4\": 0.7300892002593176, \"phi\": 0.6348320955628644}, {\"truth_threshold\": 5.159999884665012, \"match_probability\": 0.9727914741331464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122663.0, \"tn\": 1278737605.0, \"fp\": 187.0, \"fn\": 181298.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4035484815486197, \"tn_rate\": 0.9999998537620447, \"fp_rate\": 1.4623795524766972e-07, \"fn_rate\": 0.5964515184513802, \"precision\": 0.9984778184778185, \"recall\": 0.4035484815486197, \"specificity\": 0.9999998537620447, \"npv\": 0.9998582412070267, \"accuracy\": 0.9998581086195394, \"f1\": 0.5747883723709089, \"f2\": 0.4581442809185669, \"f0_5\": 0.7711152545825103, \"p4\": 0.7299691759183792, \"phi\": 0.6347258108557012}, {\"truth_threshold\": 5.1799998842179775, \"match_probability\": 0.9731560065080713, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122622.0, \"tn\": 1278737605.0, \"fp\": 187.0, \"fn\": 181339.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40341359582314834, \"tn_rate\": 0.9999998537620447, \"fp_rate\": 1.4623795524766972e-07, \"fn_rate\": 0.5965864041768516, \"precision\": 0.9984773102948481, \"recall\": 0.40341359582314834, \"specificity\": 0.9999998537620447, \"npv\": 0.9998582091532456, \"accuracy\": 0.9998580765642918, \"f1\": 0.5746514516015653, \"f2\": 0.45800517385760164, \"f0_5\": 0.7710164902533586, \"p4\": 0.7298587459401108, \"phi\": 0.6346195519710853}, {\"truth_threshold\": 5.199999883770943, \"match_probability\": 0.973515787942243, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122597.0, \"tn\": 1278737605.0, \"fp\": 187.0, \"fn\": 181364.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40333134842956825, \"tn_rate\": 0.9999998537620447, \"fp_rate\": 1.4623795524766972e-07, \"fn_rate\": 0.5966686515704317, \"precision\": 0.9984770002606203, \"recall\": 0.40333134842956825, \"specificity\": 0.9999998537620447, \"npv\": 0.9998581896082581, \"accuracy\": 0.9998580570184091, \"f1\": 0.5745679504153535, \"f2\": 0.45792034829691297, \"f0_5\": 0.7709562481055771, \"p4\": 0.7297913907474373, \"phi\": 0.634554751239014}, {\"truth_threshold\": 5.219999883323908, \"match_probability\": 0.9738708768123288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122570.0, \"tn\": 1278737605.0, \"fp\": 187.0, \"fn\": 181391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4032425212445018, \"tn_rate\": 0.9999998537620447, \"fp_rate\": 1.4623795524766972e-07, \"fn_rate\": 0.5967574787554982, \"precision\": 0.9984766652818169, \"recall\": 0.4032425212445018, \"specificity\": 0.9999998537620447, \"npv\": 0.9998581684996725, \"accuracy\": 0.9998580359088559, \"f1\": 0.5744777581447232, \"f2\": 0.4578287331325765, \"f0_5\": 0.7708911695633525, \"p4\": 0.7297186302502423, \"phi\": 0.634484759017751}, {\"truth_threshold\": 5.239999882876873, \"match_probability\": 0.9742213308722075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122536.0, \"tn\": 1278737605.0, \"fp\": 187.0, \"fn\": 181425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4031306647892328, \"tn_rate\": 0.9999998537620447, \"fp_rate\": 1.4623795524766972e-07, \"fn_rate\": 0.5968693352107671, \"precision\": 0.9984762432469871, \"recall\": 0.4031306647892328, \"specificity\": 0.9999998537620447, \"npv\": 0.9998581419184919, \"accuracy\": 0.9998580093264555, \"f1\": 0.5743641664557377, \"f2\": 0.45771336063118245, \"f0_5\": 0.7708091936496434, \"p4\": 0.7296269809621343, \"phi\": 0.6343966096846124}, {\"truth_threshold\": 5.259999882429838, \"match_probability\": 0.9745672072570385, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122497.0, \"tn\": 1278737605.0, \"fp\": 187.0, \"fn\": 181464.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4030023588552479, \"tn_rate\": 0.9999998537620447, \"fp_rate\": 1.4623795524766972e-07, \"fn_rate\": 0.5969976411447522, \"precision\": 0.998475758860161, \"recall\": 0.4030023588552479, \"specificity\": 0.9999998537620447, \"npv\": 0.9998581114283158, \"accuracy\": 0.9998579788348786, \"f1\": 0.5742338478125842, \"f2\": 0.4575810143680222, \"f0_5\": 0.7707151279040942, \"p4\": 0.7295218195617251, \"phi\": 0.6342954821351334}, {\"truth_threshold\": 5.279999881982803, \"match_probability\": 0.9749085624873802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122416.0, \"tn\": 1278737605.0, \"fp\": 187.0, \"fn\": 181545.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40273587730004834, \"tn_rate\": 0.9999998537620447, \"fp_rate\": 1.4623795524766972e-07, \"fn_rate\": 0.5972641226999517, \"precision\": 0.998474751841309, \"recall\": 0.40273587730004834, \"specificity\": 0.9999998537620447, \"npv\": 0.9998580481025716, \"accuracy\": 0.9998579155062188, \"f1\": 0.5739631098733132, \"f2\": 0.45730611671586546, \"f0_5\": 0.7705196425356854, \"p4\": 0.7293032903201359, \"phi\": 0.6340853964795792}, {\"truth_threshold\": 5.2999998815357685, \"match_probability\": 0.9752454524733574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122390.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181571.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4026503400107251, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5973496599892749, \"precision\": 0.9985395981039251, \"recall\": 0.4026503400107251, \"specificity\": 0.999999860018214, \"npv\": 0.9998580277766793, \"accuracy\": 0.9998579014331833, \"f1\": 0.5738869481630835, \"f2\": 0.45722060380465523, \"f0_5\": 0.7704879022256581, \"p4\": 0.7292418024695818, \"phi\": 0.6340386453279037}, {\"truth_threshold\": 5.319999881088734, \"match_probability\": 0.9755779325188714, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122320.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181641.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4024200473087008, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5975799526912993, \"precision\": 0.9985387635817435, \"recall\": 0.4024200473087008, \"specificity\": 0.999999860018214, \"npv\": 0.9998579730507364, \"accuracy\": 0.9998578467047119, \"f1\": 0.5736528631055667, \"f2\": 0.45698300062091707, \"f0_5\": 0.7703187956022808, \"p4\": 0.7290527791325335, \"phi\": 0.6338570203375022}, {\"truth_threshold\": 5.339999880641699, \"match_probability\": 0.9759060573258537, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122275.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181686.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4022720020002566, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5977279979997434, \"precision\": 0.9985382265993761, \"recall\": 0.4022720020002566, \"specificity\": 0.999999860018214, \"npv\": 0.9998579378697764, \"accuracy\": 0.9998578115221232, \"f1\": 0.573502339270429, \"f2\": 0.4568302425917098, \"f0_5\": 0.7702100212024284, \"p4\": 0.7289312016540268, \"phi\": 0.6337402339390369}, {\"truth_threshold\": 5.359999880194664, \"match_probability\": 0.9762298809985563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122221.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4020943476301236, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5979056523698764, \"precision\": 0.9985375816993464, \"recall\": 0.4020943476301236, \"specificity\": 0.999999860018214, \"npv\": 0.9998578956526276, \"accuracy\": 0.9998577693030166, \"f1\": 0.5733216687267363, \"f2\": 0.45664691939586505, \"f0_5\": 0.7700794267863466, \"p4\": 0.7287852440904892, \"phi\": 0.6336000618572616}, {\"truth_threshold\": 5.379999879747629, \"match_probability\": 0.9765494570478808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122196.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181765.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4020121002365435, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5979878997634565, \"precision\": 0.9985372829417773, \"recall\": 0.4020121002365435, \"specificity\": 0.999999860018214, \"npv\": 0.9998578761076525, \"accuracy\": 0.999857749757134, \"f1\": 0.5732380094573294, \"f2\": 0.4565620425356388, \"f0_5\": 0.7700189423298688, \"p4\": 0.7287176472696073, \"phi\": 0.6335351568763343}, {\"truth_threshold\": 5.399999879300594, \"match_probability\": 0.9768648383957381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122165.0, \"tn\": 1278737619.0, \"fp\": 173.0, \"fn\": 181796.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4019101134685042, \"tn_rate\": 0.9999998647103409, \"fp_rate\": 1.3528965913287093e-07, \"fn_rate\": 0.5980898865314959, \"precision\": 0.9985858850071114, \"recall\": 0.4019101134685042, \"specificity\": 0.9999998647103409, \"npv\": 0.9998578518725514, \"accuracy\": 0.9998577302112513, \"f1\": 0.5731423249878607, \"f2\": 0.45645883743765797, \"f0_5\": 0.7699672134453867, \"p4\": 0.7286403256284449, \"phi\": 0.6334702049047846}, {\"truth_threshold\": 5.4199998788535595, \"match_probability\": 0.9771760773794429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122116.0, \"tn\": 1278737619.0, \"fp\": 173.0, \"fn\": 181845.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40174890857708717, \"tn_rate\": 0.9999998647103409, \"fp_rate\": 1.3528965913287093e-07, \"fn_rate\": 0.5982510914229128, \"precision\": 0.9985853183851369, \"recall\": 0.40174890857708717, \"specificity\": 0.9999998647103409, \"npv\": 0.9998578135644044, \"accuracy\": 0.9998576919013213, \"f1\": 0.5729782991202346, \"f2\": 0.4562924612127494, \"f0_5\": 0.7698485847611386, \"p4\": 0.728507755482454, \"phi\": 0.6333429587971954}, {\"truth_threshold\": 5.439999878406525, \"match_probability\": 0.9774832257561331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122086.0, \"tn\": 1278737621.0, \"fp\": 171.0, \"fn\": 181875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4016502117047911, \"tn_rate\": 0.9999998662743832, \"fp_rate\": 1.337256168307568e-07, \"fn_rate\": 0.5983497882952089, \"precision\": 0.9986013070826211, \"recall\": 0.4016502117047911, \"specificity\": 0.9999998662743832, \"npv\": 0.9998577901106607, \"accuracy\": 0.9998576700099329, \"f1\": 0.5728805446977837, \"f2\": 0.45619127405180926, \"f0_5\": 0.7697836918292688, \"p4\": 0.7284287346891478, \"phi\": 0.6332702221379887}, {\"truth_threshold\": 5.45999987795949, \"match_probability\": 0.9777863347072188, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122049.0, \"tn\": 1278737621.0, \"fp\": 171.0, \"fn\": 181912.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40152848556229254, \"tn_rate\": 0.9999998662743832, \"fp_rate\": 1.337256168307568e-07, \"fn_rate\": 0.5984715144377075, \"precision\": 0.99860088365243, \"recall\": 0.40152848556229254, \"specificity\": 0.9999998662743832, \"npv\": 0.9998577611841042, \"accuracy\": 0.9998576410820265, \"f1\": 0.572756645650557, \"f2\": 0.45606562914778365, \"f0_5\": 0.769694049626596, \"p4\": 0.7283285653491202, \"phi\": 0.6331741103664097}, {\"truth_threshold\": 5.479999877512455, \"match_probability\": 0.9780854548428534, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122005.0, \"tn\": 1278737621.0, \"fp\": 171.0, \"fn\": 181956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40138373014959156, \"tn_rate\": 0.9999998662743832, \"fp_rate\": 1.337256168307568e-07, \"fn_rate\": 0.5986162698504084, \"precision\": 0.9986003797799895, \"recall\": 0.40138373014959156, \"specificity\": 0.9999998662743832, \"npv\": 0.999857726784958, \"accuracy\": 0.9998576066812731, \"f1\": 0.5726092782368112, \"f2\": 0.45591620454103826, \"f0_5\": 0.7695874045151483, \"p4\": 0.7282094018624896, \"phi\": 0.6330597963002476}, {\"truth_threshold\": 5.49999987706542, \"match_probability\": 0.9783806362064269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121949.0, \"tn\": 1278737621.0, \"fp\": 171.0, \"fn\": 182012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40119949598797217, \"tn_rate\": 0.9999998662743832, \"fp_rate\": 1.337256168307568e-07, \"fn_rate\": 0.5988005040120279, \"precision\": 0.9985997379626597, \"recall\": 0.40119949598797217, \"specificity\": 0.9999998662743832, \"npv\": 0.9998576830042298, \"accuracy\": 0.9998575628984959, \"f1\": 0.5724216756907724, \"f2\": 0.45572601355492376, \"f0_5\": 0.769451605860878, \"p4\": 0.7280576713378338, \"phi\": 0.6329142758210089}, {\"truth_threshold\": 5.519999876618385, \"match_probability\": 0.9786719282790798, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121908.0, \"tn\": 1278737621.0, \"fp\": 171.0, \"fn\": 182053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4010646102625008, \"tn_rate\": 0.9999998662743832, \"fp_rate\": 1.337256168307568e-07, \"fn_rate\": 0.5989353897374993, \"precision\": 0.9985992676873172, \"recall\": 0.4010646102625008, \"specificity\": 0.9999998662743832, \"npv\": 0.999857650950485, \"accuracy\": 0.9998575308432484, \"f1\": 0.5722842925546897, \"f2\": 0.455586756487481, \"f0_5\": 0.7693521331554494, \"p4\": 0.7279465346626478, \"phi\": 0.6328077128307621}, {\"truth_threshold\": 5.5399998761713505, \"match_probability\": 0.9789593799842328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121895.0, \"tn\": 1278737622.0, \"fp\": 170.0, \"fn\": 182066.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4010218416178391, \"tn_rate\": 0.9999998670564043, \"fp_rate\": 1.3294359567969975e-07, \"fn_rate\": 0.5989781583821608, \"precision\": 0.9986072993896694, \"recall\": 0.4010218416178391, \"specificity\": 0.9999998670564043, \"npv\": 0.9998576407872142, \"accuracy\": 0.9998575214612248, \"f1\": 0.5722420697328332, \"f2\": 0.45554294051389144, \"f0_5\": 0.7693244688035283, \"p4\": 0.727912374491299, \"phi\": 0.6327765137558916}, {\"truth_threshold\": 5.559999875724316, \"match_probability\": 0.9792430396921339, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121847.0, \"tn\": 1278737623.0, \"fp\": 169.0, \"fn\": 182114.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40086392662216536, \"tn_rate\": 0.9999998678384254, \"fp_rate\": 1.321615745286427e-07, \"fn_rate\": 0.5991360733778347, \"precision\": 0.9986149357461317, \"recall\": 0.40086392662216536, \"specificity\": 0.9999998678384254, \"npv\": 0.9998576032609934, \"accuracy\": 0.9998574847149654, \"f1\": 0.5720825302774563, \"f2\": 0.4553802341052128, \"f0_5\": 0.7692118304346454, \"p4\": 0.7277832831254383, \"phi\": 0.6326543216094365}, {\"truth_threshold\": 5.579999875277281, \"match_probability\": 0.9795229552244182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121822.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182139.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40078167922858526, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5992183207714148, \"precision\": 0.9986473968537631, \"recall\": 0.40078167922858526, \"specificity\": 0.9999998709665101, \"npv\": 0.9998575837164753, \"accuracy\": 0.999857468296424, \"f1\": 0.5720040943964991, \"f2\": 0.4552966705062149, \"f0_5\": 0.7691666593005004, \"p4\": 0.7277198073363588, \"phi\": 0.6325996949022847}, {\"truth_threshold\": 5.599999874830246, \"match_probability\": 0.9797991738586788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121789.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182172.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40067311266905953, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5993268873309405, \"precision\": 0.9986470308476967, \"recall\": 0.40067311266905953, \"specificity\": 0.9999998709665101, \"npv\": 0.9998575579171247, \"accuracy\": 0.9998574424958588, \"f1\": 0.5718934529190096, \"f2\": 0.45518456448581923, \"f0_5\": 0.7690864978396695, \"p4\": 0.7276302574120589, \"phi\": 0.6325138834477931}, {\"truth_threshold\": 5.619999874383211, \"match_probability\": 0.9800717423330486, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121759.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182202.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4005744157967634, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5994255842032365, \"precision\": 0.9986466979429809, \"recall\": 0.4005744157967634, \"specificity\": 0.9999998709665101, \"npv\": 0.9998575344631708, \"accuracy\": 0.9998574190407997, \"f1\": 0.5717928548786644, \"f2\": 0.45508264512232316, \"f0_5\": 0.769013600587123, \"p4\": 0.7275488254066927, \"phi\": 0.6324358629348941}, {\"truth_threshold\": 5.639999873936176, \"match_probability\": 0.9803407068507896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121707.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40040334121811677, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5995966587818832, \"precision\": 0.9986461205198898, \"recall\": 0.40040334121811677, \"specificity\": 0.9999998709665101, \"npv\": 0.9998574938096533, \"accuracy\": 0.9998573783853638, \"f1\": 0.5716184513647369, \"f2\": 0.45490597406325406, \"f0_5\": 0.7688871929840078, \"p4\": 0.7274076247184453, \"phi\": 0.63230060458259}, {\"truth_threshold\": 5.6599998734891415, \"match_probability\": 0.9806061130848882, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121660.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182301.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4002487161181862, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5997512838818138, \"precision\": 0.9986455981941309, \"recall\": 0.4002487161181862, \"specificity\": 0.9999998709665101, \"npv\": 0.9998574570651306, \"accuracy\": 0.9998573416391044, \"f1\": 0.5714607807678036, \"f2\": 0.45474627878795126, \"f0_5\": 0.7687728827782488, \"p4\": 0.7272799443749024, \"phi\": 0.6321783269515587}, {\"truth_threshold\": 5.679999873042107, \"match_probability\": 0.9808680061826558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121640.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40018291820332214, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5998170817966778, \"precision\": 0.9986453758055909, \"recall\": 0.40018291820332214, \"specificity\": 0.9999998709665101, \"npv\": 0.9998574414291644, \"accuracy\": 0.9998573260023983, \"f1\": 0.5713936763386461, \"f2\": 0.4546783199479086, \"f0_5\": 0.7687242236605784, \"p4\": 0.7272255959922642, \"phi\": 0.6321262867457258}, {\"truth_threshold\": 5.699999872595072, \"match_probability\": 0.9811264307703318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121581.0, \"tn\": 1278737629.0, \"fp\": 163.0, \"fn\": 182380.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3999888143544731, \"tn_rate\": 0.9999998725305523, \"fp_rate\": 1.2746944762230036e-07, \"fn_rate\": 0.6000111856455269, \"precision\": 0.9986611249835721, \"recall\": 0.3999888143544731, \"specificity\": 0.9999998725305523, \"npv\": 0.9998573953032899, \"accuracy\": 0.9998572814377858, \"f1\": 0.5711983650650098, \"f2\": 0.45447850907753357, \"f0_5\": 0.7685883957887922, \"p4\": 0.7270673856297747, \"phi\": 0.6319779361337866}, {\"truth_threshold\": 5.719999872148037, \"match_probability\": 0.9813814309576883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121566.0, \"tn\": 1278737633.0, \"fp\": 159.0, \"fn\": 182395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.399939465918325, \"tn_rate\": 0.999999875658637, \"fp_rate\": 1.2434136301807212e-07, \"fn_rate\": 0.6000605340816749, \"precision\": 0.9986937769562538, \"recall\": 0.399939465918325, \"specificity\": 0.999999875658637, \"npv\": 0.9998573835767627, \"accuracy\": 0.9998572728375975, \"f1\": 0.5711533853591615, \"f2\": 0.45442889301411743, \"f0_5\": 0.7685674220880787, \"p4\": 0.7270309448206148, \"phi\": 0.6319492809351759}, {\"truth_threshold\": 5.739999871701002, \"match_probability\": 0.9816330503426346, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121540.0, \"tn\": 1278737633.0, \"fp\": 159.0, \"fn\": 182421.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39985392862900176, \"tn_rate\": 0.999999875658637, \"fp_rate\": 1.2434136301807212e-07, \"fn_rate\": 0.6001460713709983, \"precision\": 0.998693497892341, \"recall\": 0.39985392862900176, \"specificity\": 0.999999875658637, \"npv\": 0.9998573632500097, \"accuracy\": 0.9998572525098796, \"f1\": 0.5710661091011605, \"f2\": 0.4543405333510773, \"f0_5\": 0.7685041042949984, \"p4\": 0.7269602305561474, \"phi\": 0.6318816033106729}, {\"truth_threshold\": 5.759999871253967, \"match_probability\": 0.9818813320158202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121509.0, \"tn\": 1278737633.0, \"fp\": 159.0, \"fn\": 182452.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3997519418609624, \"tn_rate\": 0.999999875658637, \"fp_rate\": 1.2434136301807212e-07, \"fn_rate\": 0.6002480581390376, \"precision\": 0.9986931650064109, \"recall\": 0.3997519418609624, \"specificity\": 0.999999875658637, \"npv\": 0.9998573390142669, \"accuracy\": 0.9998572282729851, \"f1\": 0.570962035011712, \"f2\": 0.4542351769554217, \"f0_5\": 0.7684285882324668, \"p4\": 0.7268758958341106, \"phi\": 0.6318009012872472}, {\"truth_threshold\": 5.7799998708069324, \"match_probability\": 0.9821263185652349, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121460.0, \"tn\": 1278737634.0, \"fp\": 158.0, \"fn\": 182501.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39959073696954545, \"tn_rate\": 0.9999998764406581, \"fp_rate\": 1.2355934186701506e-07, \"fn_rate\": 0.6004092630304546, \"precision\": 0.998700850203095, \"recall\": 0.39959073696954545, \"specificity\": 0.9999998764406581, \"npv\": 0.9998573007062712, \"accuracy\": 0.9998571907448904, \"f1\": 0.5707988411082314, \"f2\": 0.45406897541761937, \"f0_5\": 0.7683130638523442, \"p4\": 0.726743631910948, \"phi\": 0.6316759169444663}, {\"truth_threshold\": 5.799999870359898, \"match_probability\": 0.9823680520808044, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121428.0, \"tn\": 1278737635.0, \"fp\": 157.0, \"fn\": 182533.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39948546030576293, \"tn_rate\": 0.9999998772226792, \"fp_rate\": 1.22777320715958e-07, \"fn_rate\": 0.6005145396942371, \"precision\": 0.998708722293046, \"recall\": 0.39948546030576293, \"specificity\": 0.9999998772226792, \"npv\": 0.9998572756888451, \"accuracy\": 0.9998571665079959, \"f1\": 0.5706927100712966, \"f2\": 0.45396054669070285, \"f0_5\": 0.7682389368101521, \"p4\": 0.7266576010603045, \"phi\": 0.631595182651215}, {\"truth_threshold\": 5.819999869912863, \"match_probability\": 0.9826065741589802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121416.0, \"tn\": 1278737635.0, \"fp\": 157.0, \"fn\": 182545.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39944598155684446, \"tn_rate\": 0.9999998772226792, \"fp_rate\": 1.22777320715958e-07, \"fn_rate\": 0.6005540184431556, \"precision\": 0.9987085948360245, \"recall\": 0.39944598155684446, \"specificity\": 0.9999998772226792, \"npv\": 0.9998572663072687, \"accuracy\": 0.9998571571259722, \"f1\": 0.5706524038032214, \"f2\": 0.4539197572634414, \"f0_5\": 0.7682096746231903, \"p4\": 0.7266249253381962, \"phi\": 0.6315639302179133}, {\"truth_threshold\": 5.839999869465828, \"match_probability\": 0.9828419259073232, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121404.0, \"tn\": 1278737635.0, \"fp\": 157.0, \"fn\": 182557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.399406502807926, \"tn_rate\": 0.9999998772226792, \"fp_rate\": 1.22777320715958e-07, \"fn_rate\": 0.600593497192074, \"precision\": 0.9987084673538388, \"recall\": 0.399406502807926, \"specificity\": 0.9999998772226792, \"npv\": 0.9998572569256925, \"accuracy\": 0.9998571477439486, \"f1\": 0.5706120952618196, \"f2\": 0.45387896710420556, \"f0_5\": 0.7681804088812397, \"p4\": 0.7265922460961729, \"phi\": 0.6315326762386306}, {\"truth_threshold\": 5.859999869018793, \"match_probability\": 0.9830741479490782, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121344.0, \"tn\": 1278737635.0, \"fp\": 157.0, \"fn\": 182617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3992091090633338, \"tn_rate\": 0.9999998772226792, \"fp_rate\": 1.22777320715958e-07, \"fn_rate\": 0.6007908909366663, \"precision\": 0.9987078295651888, \"recall\": 0.3992091090633338, \"specificity\": 0.9999998772226792, \"npv\": 0.9998572100178144, \"accuracy\": 0.9998571008338303, \"f1\": 0.570410518448181, \"f2\": 0.4536750053277202, \"f0_5\": 0.7680340268239733, \"p4\": 0.7264287970674149, \"phi\": 0.6313763831444625}, {\"truth_threshold\": 5.879999868571758, \"match_probability\": 0.9833032804277396, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121299.0, \"tn\": 1278737637.0, \"fp\": 155.0, \"fn\": 182662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3990610637548896, \"tn_rate\": 0.9999998787867216, \"fp_rate\": 1.212132784138439e-07, \"fn_rate\": 0.6009389362451104, \"precision\": 0.9987237966637574, \"recall\": 0.3990610637548896, \"specificity\": 0.9999998787867216, \"npv\": 0.9998571748371319, \"accuracy\": 0.9998570672149121, \"f1\": 0.5702619794788618, \"f2\": 0.4535227002508042, \"f0_5\": 0.7679319605407603, \"p4\": 0.7263083271719484, \"phi\": 0.6312643374144169}, {\"truth_threshold\": 5.899999868124723, \"match_probability\": 0.9835293630116069, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121266.0, \"tn\": 1278737637.0, \"fp\": 155.0, \"fn\": 182695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39895249719536385, \"tn_rate\": 0.9999998787867216, \"fp_rate\": 1.212132784138439e-07, \"fn_rate\": 0.6010475028046361, \"precision\": 0.9987234498151061, \"recall\": 0.39895249719536385, \"specificity\": 0.9999998787867216, \"npv\": 0.9998571490378027, \"accuracy\": 0.9998570414143471, \"f1\": 0.5701510642199247, \"f2\": 0.4534105057711074, \"f0_5\": 0.7678513762513535, \"p4\": 0.7262183563646063, \"phi\": 0.6311783444653196}, {\"truth_threshold\": 5.919999867677689, \"match_probability\": 0.983752434898328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121234.0, \"tn\": 1278737638.0, \"fp\": 154.0, \"fn\": 182727.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39884722053158134, \"tn_rate\": 0.9999998795687427, \"fp_rate\": 1.2043125726278684e-07, \"fn_rate\": 0.6011527794684186, \"precision\": 0.9987313408244637, \"recall\": 0.39884722053158134, \"specificity\": 0.9999998795687427, \"npv\": 0.9998571240203842, \"accuracy\": 0.9998570171774526, \"f1\": 0.5700448337717968, \"f2\": 0.45330204482094355, \"f0_5\": 0.7677770980338513, \"p4\": 0.7261321738677168, \"phi\": 0.6310975466574101}, {\"truth_threshold\": 5.939999867230654, \"match_probability\": 0.9839725348194305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121203.0, \"tn\": 1278737638.0, \"fp\": 154.0, \"fn\": 182758.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39874523376354204, \"tn_rate\": 0.9999998795687427, \"fp_rate\": 1.2043125726278684e-07, \"fn_rate\": 0.601254766236458, \"precision\": 0.9987310167522269, \"recall\": 0.39874523376354204, \"specificity\": 0.9999998795687427, \"npv\": 0.9998570997846531, \"accuracy\": 0.9998569929405581, \"f1\": 0.5699406091442168, \"f2\": 0.4531966398469639, \"f0_5\": 0.7677013487646774, \"p4\": 0.7260476072564261, \"phi\": 0.6310167443901714}, {\"truth_threshold\": 5.959999866783619, \"match_probability\": 0.9841897010448389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121167.0, \"tn\": 1278737638.0, \"fp\": 154.0, \"fn\": 182794.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3986267975167867, \"tn_rate\": 0.9999998795687427, \"fp_rate\": 1.2043125726278684e-07, \"fn_rate\": 0.6013732024832134, \"precision\": 0.9987306402024382, \"recall\": 0.3986267975167867, \"specificity\": 0.9999998795687427, \"npv\": 0.9998570716399345, \"accuracy\": 0.999856964794487, \"f1\": 0.569819555024666, \"f2\": 0.4530742279374647, \"f0_5\": 0.7676133520009629, \"p4\": 0.725949371304342, \"phi\": 0.6309228965176071}, {\"truth_threshold\": 5.979999866336584, \"match_probability\": 0.9844039713873779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121135.0, \"tn\": 1278737638.0, \"fp\": 154.0, \"fn\": 182826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3985215208530042, \"tn_rate\": 0.9999998795687427, \"fp_rate\": 1.2043125726278684e-07, \"fn_rate\": 0.6014784791469958, \"precision\": 0.998730305303861, \"recall\": 0.3985215208530042, \"specificity\": 0.9999998795687427, \"npv\": 0.9998570466224083, \"accuracy\": 0.9998569397757573, \"f1\": 0.5697119341563786, \"f2\": 0.4529654118176726, \"f0_5\": 0.7675351056940859, \"p4\": 0.7258620237741379, \"phi\": 0.6308394644702412}, {\"truth_threshold\": 5.999999865889549, \"match_probability\": 0.9846153832072593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121092.0, \"tn\": 1278737646.0, \"fp\": 146.0, \"fn\": 182869.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3983800553360464, \"tn_rate\": 0.999999885824912, \"fp_rate\": 1.1417508805433038e-07, \"fn_rate\": 0.6016199446639536, \"precision\": 0.9987957571058579, \"recall\": 0.3983800553360464, \"specificity\": 0.999999885824912, \"npv\": 0.9998570130060037, \"accuracy\": 0.9998569124115215, \"f1\": 0.5695780093556194, \"f2\": 0.4528218912527429, \"f0_5\": 0.7674610508383054, \"p4\": 0.7257533111487153, \"phi\": 0.6307481524328007}, {\"truth_threshold\": 6.019999865442514, \"match_probability\": 0.9848239734165524, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121050.0, \"tn\": 1278737646.0, \"fp\": 146.0, \"fn\": 182911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3982418797148318, \"tn_rate\": 0.999999885824912, \"fp_rate\": 1.1417508805433038e-07, \"fn_rate\": 0.6017581202851682, \"precision\": 0.9987953397801907, \"recall\": 0.3982418797148318, \"specificity\": 0.999999885824912, \"npv\": 0.9998569801705048, \"accuracy\": 0.9998568795744387, \"f1\": 0.569436702206479, \"f2\": 0.45267905223478727, \"f0_5\": 0.767358271684765, \"p4\": 0.7256385853119671, \"phi\": 0.6306386152603772}, {\"truth_threshold\": 6.03999986499548, \"match_probability\": 0.9850297784836395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121008.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 182953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3981037040936173, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.6018962959063827, \"precision\": 0.9988443886816126, \"recall\": 0.3981037040936173, \"specificity\": 0.9999998905170389, \"npv\": 0.9998569473356792, \"accuracy\": 0.9998568514283677, \"f1\": 0.5693034021862629, \"f2\": 0.45253823508293245, \"f0_5\": 0.7672788005371864, \"p4\": 0.7255303418188075, \"phi\": 0.6305446786794324}, {\"truth_threshold\": 6.059999864548445, \"match_probability\": 0.9852328344376492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120958.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183003.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3979392093064571, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.6020607906935429, \"precision\": 0.9988439115427175, \"recall\": 0.3979392093064571, \"specificity\": 0.9999998905170389, \"npv\": 0.9998569082458051, \"accuracy\": 0.9998568123366024, \"f1\": 0.5691351083026122, \"f2\": 0.4523681655599121, \"f0_5\": 0.7671563373260456, \"p4\": 0.7253936555590649, \"phi\": 0.630414233040175}, {\"truth_threshold\": 6.07999986410141, \"match_probability\": 0.9854331768728747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120934.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183027.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39786025180862017, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.6021397481913798, \"precision\": 0.9988436823760676, \"recall\": 0.39786025180862017, \"specificity\": 0.9999998905170389, \"npv\": 0.9998568894826667, \"accuracy\": 0.9998567935725551, \"f1\": 0.5690543131742092, \"f2\": 0.45228652767035826, \"f0_5\": 0.7670975329112206, \"p4\": 0.725328024315923, \"phi\": 0.6303516095485384}, {\"truth_threshold\": 6.099999863654375, \"match_probability\": 0.98563084095317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120884.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183077.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39769575702146, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.60230424297854, \"precision\": 0.9988432046536224, \"recall\": 0.39769575702146, \"specificity\": 0.9999998905170389, \"npv\": 0.9998568503927971, \"accuracy\": 0.9998567544807898, \"f1\": 0.5688859606809652, \"f2\": 0.45211643931936435, \"f0_5\": 0.7669749776983137, \"p4\": 0.7251912470371896, \"phi\": 0.6302211239623916}, {\"truth_threshold\": 6.11999986320734, \"match_probability\": 0.9858258614163268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120835.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183126.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.397534552130043, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.602465447869957, \"precision\": 0.9988427361025005, \"recall\": 0.397534552130043, \"specificity\": 0.9999998905170389, \"npv\": 0.9998568120847279, \"accuracy\": 0.9998567161708598, \"f1\": 0.5687209367998945, \"f2\": 0.45194974039118235, \"f0_5\": 0.7668548132221293, \"p4\": 0.7250571455877121, \"phi\": 0.6300932218810977}, {\"truth_threshold\": 6.139999862760305, \"match_probability\": 0.98601827257843, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120813.0, \"tn\": 1278737654.0, \"fp\": 138.0, \"fn\": 183148.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3974621744236925, \"tn_rate\": 0.9999998920810812, \"fp_rate\": 1.0791891884587391e-07, \"fn_rate\": 0.6025378255763075, \"precision\": 0.9988590420914255, \"recall\": 0.3974621744236925, \"specificity\": 0.9999998920810812, \"npv\": 0.9998567948854116, \"accuracy\": 0.9998567005341538, \"f1\": 0.5686495086041345, \"f2\": 0.4518755680564335, \"f0_5\": 0.7668086294770649, \"p4\": 0.7249990930944495, \"phi\": 0.6300409989959845}, {\"truth_threshold\": 6.159999862313271, \"match_probability\": 0.9862081083381921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120786.0, \"tn\": 1278737654.0, \"fp\": 138.0, \"fn\": 183175.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.397373347238626, \"tn_rate\": 0.9999998920810812, \"fp_rate\": 1.0791891884587391e-07, \"fn_rate\": 0.602626652761374, \"precision\": 0.9988587873375012, \"recall\": 0.397373347238626, \"specificity\": 0.9999998920810812, \"npv\": 0.9998567737768856, \"accuracy\": 0.9998566794246004, \"f1\": 0.5685585511373665, \"f2\": 0.451783705175468, \"f0_5\": 0.7667423764405065, \"p4\": 0.7249251605878547, \"phi\": 0.6299705054040411}, {\"truth_threshold\": 6.179999861866236, \"match_probability\": 0.9863954021812639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120744.0, \"tn\": 1278737654.0, \"fp\": 138.0, \"fn\": 183217.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39723517161741145, \"tn_rate\": 0.9999998920810812, \"fp_rate\": 1.0791891884587391e-07, \"fn_rate\": 0.6027648283825886, \"precision\": 0.9988583908274185, \"recall\": 0.39723517161741145, \"specificity\": 0.9999998920810812, \"npv\": 0.9998567409414026, \"accuracy\": 0.9998566465875176, \"f1\": 0.5684170387649085, \"f2\": 0.45164079998443957, \"f0_5\": 0.7666392800407371, \"p4\": 0.7248101187419069, \"phi\": 0.629860833029675}, {\"truth_threshold\": 6.199999861419201, \"match_probability\": 0.9865801871845239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120686.0, \"tn\": 1278737654.0, \"fp\": 138.0, \"fn\": 183275.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3970443576643056, \"tn_rate\": 0.9999998920810812, \"fp_rate\": 1.0791891884587391e-07, \"fn_rate\": 0.6029556423356944, \"precision\": 0.9988578428126862, \"recall\": 0.3970443576643056, \"specificity\": 0.9999998920810812, \"npv\": 0.9998566955971677, \"accuracy\": 0.9998566012410699, \"f1\": 0.5682215709123439, \"f2\": 0.45144343995666836, \"f0_5\": 0.7664968364841469, \"p4\": 0.7246511798914761, \"phi\": 0.6297093493134358}, {\"truth_threshold\": 6.219999860972166, \"match_probability\": 0.986762496020343, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120644.0, \"tn\": 1278737654.0, \"fp\": 138.0, \"fn\": 183317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.396906182043091, \"tn_rate\": 0.9999998920810812, \"fp_rate\": 1.0791891884587391e-07, \"fn_rate\": 0.603093817956909, \"precision\": 0.9988574456458744, \"recall\": 0.396906182043091, \"specificity\": 0.9999998920810812, \"npv\": 0.9998566627616899, \"accuracy\": 0.9998565684039871, \"f1\": 0.5680799919009848, \"f2\": 0.4513005133822027, \"f0_5\": 0.7663936352813977, \"p4\": 0.7245360344036639, \"phi\": 0.6295996314646867}, {\"truth_threshold\": 6.239999860525131, \"match_probability\": 0.9869423609608258, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120594.0, \"tn\": 1278737654.0, \"fp\": 138.0, \"fn\": 183367.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39674168725593084, \"tn_rate\": 0.9999998920810812, \"fp_rate\": 1.0791891884587391e-07, \"fn_rate\": 0.6032583127440692, \"precision\": 0.9988569724679456, \"recall\": 0.39674168725593084, \"specificity\": 0.9999998920810812, \"npv\": 0.9998566236718381, \"accuracy\": 0.9998565293122218, \"f1\": 0.5679114089471688, \"f2\": 0.4511303509864011, \"f0_5\": 0.7662707192501103, \"p4\": 0.7243988996292076, \"phi\": 0.6294689900526034}, {\"truth_threshold\": 6.259999860078096, \"match_probability\": 0.9871198138820265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120570.0, \"tn\": 1278737655.0, \"fp\": 137.0, \"fn\": 183391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39666272975809397, \"tn_rate\": 0.9999998928631023, \"fp_rate\": 1.0713689769481686e-07, \"fn_rate\": 0.6033372702419061, \"precision\": 0.9988650202556604, \"recall\": 0.39666272975809397, \"specificity\": 0.9999998928631023, \"npv\": 0.9998566049088224, \"accuracy\": 0.9998565113300097, \"f1\": 0.5678318121450168, \"f2\": 0.45104900598630354, \"f0_5\": 0.7662155927446875, \"p4\": 0.7243341409664419, \"phi\": 0.6294088807017637}, {\"truth_threshold\": 6.2799998596310616, \"match_probability\": 0.9872948862681414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120528.0, \"tn\": 1278737655.0, \"fp\": 137.0, \"fn\": 183433.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3965245541368794, \"tn_rate\": 0.9999998928631023, \"fp_rate\": 1.0713689769481686e-07, \"fn_rate\": 0.6034754458631206, \"precision\": 0.9988646252020056, \"recall\": 0.3965245541368794, \"specificity\": 0.9999998928631023, \"npv\": 0.9998565720733507, \"accuracy\": 0.9998564784929269, \"f1\": 0.5676901555721976, \"f2\": 0.45090605450468346, \"f0_5\": 0.7661122700766951, \"p4\": 0.7242188751112121, \"phi\": 0.6292991104846488}, {\"truth_threshold\": 6.299999859184027, \"match_probability\": 0.9874676092156737, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120499.0, \"tn\": 1278737659.0, \"fp\": 133.0, \"fn\": 183462.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3964291471603265, \"tn_rate\": 0.9999998959911869, \"fp_rate\": 1.0400881309058862e-07, \"fn_rate\": 0.6035708528396735, \"precision\": 0.9988974733072485, \"recall\": 0.3964291471603265, \"specificity\": 0.9999998959911869, \"npv\": 0.999856549401689, \"accuracy\": 0.9998564589470442, \"f1\": 0.5675976758919719, \"f2\": 0.4508086939084578, \"f0_5\": 0.7660564864861429, \"p4\": 0.7241436134694942, \"phi\": 0.6292337415986439}, {\"truth_threshold\": 6.319999858736992, \"match_probability\": 0.9876380134375741, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120443.0, \"tn\": 1278737666.0, \"fp\": 126.0, \"fn\": 183518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39624491299870707, \"tn_rate\": 0.999999901465335, \"fp_rate\": 9.853466503318923e-08, \"fn_rate\": 0.6037550870012929, \"precision\": 0.998954955253838, \"recall\": 0.39624491299870707, \"specificity\": 0.999999901465335, \"npv\": 0.9998565056218507, \"accuracy\": 0.9998564206371142, \"f1\": 0.5674180858832121, \"f2\": 0.4506204294630477, \"f0_5\": 0.7659458916331844, \"p4\": 0.7239974344492655, \"phi\": 0.6291056048067336}, {\"truth_threshold\": 6.339999858289957, \"match_probability\": 0.9878061292673542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120400.0, \"tn\": 1278737666.0, \"fp\": 126.0, \"fn\": 183561.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3961034474817493, \"tn_rate\": 0.999999901465335, \"fp_rate\": 9.853466503318923e-08, \"fn_rate\": 0.6038965525182507, \"precision\": 0.998954582413753, \"recall\": 0.3961034474817493, \"specificity\": 0.999999901465335, \"npv\": 0.9998564720045889, \"accuracy\": 0.9998563870181961, \"f1\": 0.567272967134447, \"f2\": 0.4504740453616888, \"f0_5\": 0.7658399750656752, \"p4\": 0.7238792888250638, \"phi\": 0.6289931665928284}, {\"truth_threshold\": 6.359999857842922, \"match_probability\": 0.9879719866631735, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120351.0, \"tn\": 1278737671.0, \"fp\": 121.0, \"fn\": 183610.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39594224259033234, \"tn_rate\": 0.9999999053754407, \"fp_rate\": 9.462455927790394e-08, \"fn_rate\": 0.6040577574096677, \"precision\": 0.9989956172388604, \"recall\": 0.39594224259033234, \"specificity\": 0.9999999053754407, \"npv\": 0.9998564336971104, \"accuracy\": 0.9998563526174427, \"f1\": 0.5671142441798823, \"f2\": 0.4503089089706327, \"f0_5\": 0.7657387106174341, \"p4\": 0.7237500428590318, \"phi\": 0.6288780696984162}, {\"truth_threshold\": 6.379999857395887, \"match_probability\": 0.9881356152118985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120315.0, \"tn\": 1278737671.0, \"fp\": 121.0, \"fn\": 183646.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39582380634357694, \"tn_rate\": 0.9999999053754407, \"fp_rate\": 9.462455927790394e-08, \"fn_rate\": 0.604176193656423, \"precision\": 0.998995317014846, \"recall\": 0.39582380634357694, \"specificity\": 0.9999999053754407, \"npv\": 0.99985640555243, \"accuracy\": 0.9998563244713716, \"f1\": 0.5669926978748672, \"f2\": 0.45018633819259435, \"f0_5\": 0.765649957681318, \"p4\": 0.7236510514020994, \"phi\": 0.6287839026911501}, {\"truth_threshold\": 6.3999998569488525, \"match_probability\": 0.9882970441331357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120289.0, \"tn\": 1278737671.0, \"fp\": 121.0, \"fn\": 183672.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3957382690542537, \"tn_rate\": 0.9999999053754407, \"fp_rate\": 9.462455927790394e-08, \"fn_rate\": 0.6042617309457463, \"precision\": 0.9989951000747446, \"recall\": 0.3957382690542537, \"specificity\": 0.9999999053754407, \"npv\": 0.9998563852257175, \"accuracy\": 0.9998563041436537, \"f1\": 0.56690490160732, \"f2\": 0.4500978107455618, \"f0_5\": 0.7655858381035666, \"p4\": 0.7235795375753495, \"phi\": 0.6287158844177501}, {\"truth_threshold\": 6.419999856501818, \"match_probability\": 0.9884563022832351, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120242.0, \"tn\": 1278737671.0, \"fp\": 121.0, \"fn\": 183719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3955836439543231, \"tn_rate\": 0.9999999053754407, \"fp_rate\": 9.462455927790394e-08, \"fn_rate\": 0.6044163560456769, \"precision\": 0.9989947076759469, \"recall\": 0.3955836439543231, \"specificity\": 0.9999999053754407, \"npv\": 0.9998563484812777, \"accuracy\": 0.9998562673973943, \"f1\": 0.5667461656658591, \"f2\": 0.4499377716177209, \"f0_5\": 0.7654698865437675, \"p4\": 0.7234502199985984, \"phi\": 0.6285929096374363}, {\"truth_threshold\": 6.439999856054783, \"match_probability\": 0.9886134181592674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120181.0, \"tn\": 1278737671.0, \"fp\": 121.0, \"fn\": 183780.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3953829603139877, \"tn_rate\": 0.9999999053754407, \"fp_rate\": 9.462455927790394e-08, \"fn_rate\": 0.6046170396860123, \"precision\": 0.9989941979351964, \"recall\": 0.3953829603139877, \"specificity\": 0.9999999053754407, \"npv\": 0.9998563007916895, \"accuracy\": 0.9998562197054407, \"f1\": 0.5665400942340011, \"f2\": 0.44973004447118803, \"f0_5\": 0.7653193134216965, \"p4\": 0.723282300479283, \"phi\": 0.628433268201128}, {\"truth_threshold\": 6.459999855607748, \"match_probability\": 0.9887684199029713, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120152.0, \"tn\": 1278737671.0, \"fp\": 121.0, \"fn\": 183809.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39528755333743476, \"tn_rate\": 0.9999999053754407, \"fp_rate\": 9.462455927790394e-08, \"fn_rate\": 0.6047124466625653, \"precision\": 0.9989939554180906, \"recall\": 0.39528755333743476, \"specificity\": 0.9999999053754407, \"npv\": 0.9998562781195919, \"accuracy\": 0.9998561970322168, \"f1\": 0.5664421050646578, \"f2\": 0.4496312822903982, \"f0_5\": 0.765247696652328, \"p4\": 0.7232024374557052, \"phi\": 0.6283573588730164}, {\"truth_threshold\": 6.479999855160713, \"match_probability\": 0.9889213353046725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120120.0, \"tn\": 1278737679.0, \"fp\": 113.0, \"fn\": 183841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3951822766736522, \"tn_rate\": 0.99999991163161, \"fp_rate\": 8.836839006944748e-08, \"fn_rate\": 0.6048177233263478, \"precision\": 0.9990601581928422, \"recall\": 0.3951822766736522, \"specificity\": 0.99999991163161, \"npv\": 0.9998562531030051, \"accuracy\": 0.9998561782681695, \"f1\": 0.5663446441958161, \"f2\": 0.4495249899519264, \"f0_5\": 0.7651998425263061, \"p4\": 0.7231229955918553, \"phi\": 0.6282944957183153}, {\"truth_threshold\": 6.499999854713678, \"match_probability\": 0.9890721918071752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120070.0, \"tn\": 1278737680.0, \"fp\": 112.0, \"fn\": 183891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.395017781886492, \"tn_rate\": 0.9999999124136311, \"fp_rate\": 8.758636891839043e-08, \"fn_rate\": 0.6049822181135079, \"precision\": 0.9990680800785475, \"recall\": 0.395017781886492, \"specificity\": 0.9999999124136311, \"npv\": 0.9998562140132986, \"accuracy\": 0.9998561399582395, \"f1\": 0.5661769733321074, \"f2\": 0.44935502752191947, \"f0_5\": 0.7650801782617063, \"p4\": 0.7229863005511696, \"phi\": 0.6281661973017484}, {\"truth_threshold\": 6.5199998542666435, \"match_probability\": 0.9892210165096217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120043.0, \"tn\": 1278737680.0, \"fp\": 112.0, \"fn\": 183918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3949289547014255, \"tn_rate\": 0.9999999124136311, \"fp_rate\": 8.758636891839043e-08, \"fn_rate\": 0.6050710452985745, \"precision\": 0.999067870667055, \"recall\": 0.3949289547014255, \"specificity\": 0.9999999124136311, \"npv\": 0.9998561929047975, \"accuracy\": 0.9998561188486862, \"f1\": 0.5660856935366739, \"f2\": 0.4492630608256443, \"f0_5\": 0.765013427549227, \"p4\": 0.7229118716162457, \"phi\": 0.6280954933450809}, {\"truth_threshold\": 6.539999853819609, \"match_probability\": 0.9893678361713254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119955.0, \"tn\": 1278737683.0, \"fp\": 109.0, \"fn\": 184006.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39463944387602357, \"tn_rate\": 0.9999999147596945, \"fp_rate\": 8.524030546521925e-08, \"fn_rate\": 0.6053605561239764, \"precision\": 0.9990921508528785, \"recall\": 0.39463944387602357, \"specificity\": 0.9999999147596945, \"npv\": 0.999856124107064, \"accuracy\": 0.9998560523926853, \"f1\": 0.5657921113141914, \"f2\": 0.448964299936822, \"f0_5\": 0.7648074448781396, \"p4\": 0.7226724279905747, \"phi\": 0.6278728426524345}, {\"truth_threshold\": 6.559999853372574, \"match_probability\": 0.9895126772155729, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119880.0, \"tn\": 1278737683.0, \"fp\": 109.0, \"fn\": 184081.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3943927016952833, \"tn_rate\": 0.9999999147596945, \"fp_rate\": 8.524030546521925e-08, \"fn_rate\": 0.6056072983047167, \"precision\": 0.9990915833951446, \"recall\": 0.3943927016952833, \"specificity\": 0.9999999147596945, \"npv\": 0.9998560654723521, \"accuracy\": 0.9998559937550373, \"f1\": 0.5655383889609624, \"f2\": 0.4487087832086795, \"f0_5\": 0.7646217648041821, \"p4\": 0.722465421306117, \"phi\": 0.6276763313511196}, {\"truth_threshold\": 6.579999852925539, \"match_probability\": 0.9896555657333964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119836.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3942479462825823, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6057520537174177, \"precision\": 0.9991079095903888, \"recall\": 0.3942479462825823, \"specificity\": 0.9999999163237369, \"npv\": 0.9998560310735494, \"accuracy\": 0.9998559609179545, \"f1\": 0.5653921642636068, \"f2\": 0.4485595383096257, \"f0_5\": 0.7645205701431482, \"p4\": 0.7223460893260055, \"phi\": 0.627566250229841}, {\"truth_threshold\": 6.599999852478504, \"match_probability\": 0.9897965274873167, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119800.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39412951003582697, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.605870489964173, \"precision\": 0.999107641755694, \"recall\": 0.39412951003582697, \"specificity\": 0.9999999163237369, \"npv\": 0.999856002928892, \"accuracy\": 0.9998559327718834, \"f1\": 0.5652703200052847, \"f2\": 0.44843687184213227, \"f0_5\": 0.7644313536815857, \"p4\": 0.7222466367598291, \"phi\": 0.627471886408941}, {\"truth_threshold\": 6.619999852031469, \"match_probability\": 0.9899355879150558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119769.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184192.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39402752326778767, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6059724767322123, \"precision\": 0.9991074109913577, \"recall\": 0.39402752326778767, \"specificity\": 0.9999999163237369, \"npv\": 0.9998559786932162, \"accuracy\": 0.999855908534989, \"f1\": 0.5651653819746743, \"f2\": 0.44833123708561673, \"f0_5\": 0.7643545021156019, \"p4\": 0.7221609711035805, \"phi\": 0.627390617305585}, {\"truth_threshold\": 6.6399998515844345, \"match_probability\": 0.9900727721332194, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119716.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184245.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39385315879339783, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6061468412066021, \"precision\": 0.9991070161822021, \"recall\": 0.39385315879339783, \"specificity\": 0.9999999163237369, \"npv\": 0.999855937258031, \"accuracy\": 0.9998558670977178, \"f1\": 0.5649859362316652, \"f2\": 0.44815062436969694, \"f0_5\": 0.7642230543642986, \"p4\": 0.7220144548196142, \"phi\": 0.6272516489739431}, {\"truth_threshold\": 6.6599998511374, \"match_probability\": 0.99020810494095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119637.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184324.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39359325702968473, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6064067429703153, \"precision\": 0.9991064270443613, \"recall\": 0.39359325702968473, \"specificity\": 0.9999999163237369, \"npv\": 0.9998558754961578, \"accuracy\": 0.9998558053327287, \"f1\": 0.5647183771727972, \"f2\": 0.44788138258205373, \"f0_5\": 0.7640269906774109, \"p4\": 0.7217959321863061, \"phi\": 0.6270444503520972}, {\"truth_threshold\": 6.679999850690365, \"match_probability\": 0.9903416108235482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119610.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184351.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3935044298446182, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6064955701553818, \"precision\": 0.9991062255151733, \"recall\": 0.3935044298446182, \"specificity\": 0.9999999163237369, \"npv\": 0.9998558543876712, \"accuracy\": 0.9998557842231754, \"f1\": 0.5646269100590543, \"f2\": 0.447789355933574, \"f0_5\": 0.763959945275405, \"p4\": 0.7217212114111936, \"phi\": 0.6269736199387889}, {\"truth_threshold\": 6.69999985024333, \"match_probability\": 0.9904733139560644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119557.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184404.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3933300653702284, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6066699346297716, \"precision\": 0.9991058296563712, \"recall\": 0.3933300653702284, \"specificity\": 0.9999999163237369, \"npv\": 0.9998558129524965, \"accuracy\": 0.9998557427859042, \"f1\": 0.564447329595751, \"f2\": 0.4476087002099576, \"f0_5\": 0.7638282838220994, \"p4\": 0.7215744841855675, \"phi\": 0.6268345591943056}, {\"truth_threshold\": 6.719999849796295, \"match_probability\": 0.9906032382068604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119505.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184456.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39315899079158184, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6068410092084182, \"precision\": 0.9991054409256597, \"recall\": 0.39315899079158184, \"specificity\": 0.9999999163237369, \"npv\": 0.9998557722991207, \"accuracy\": 0.9998557021304683, \"f1\": 0.5642710937665999, \"f2\": 0.447431439148875, \"f0_5\": 0.7636990372043266, \"p4\": 0.7214304569636786, \"phi\": 0.6266980922597798}, {\"truth_threshold\": 6.73999984934926, \"match_probability\": 0.9907314071411394, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119473.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184488.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39305371412779927, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6069462858722007, \"precision\": 0.9991052015387188, \"recall\": 0.39305371412779927, \"specificity\": 0.9999999163237369, \"npv\": 0.9998557472816604, \"accuracy\": 0.9998556771117385, \"f1\": 0.5641626194394403, \"f2\": 0.4473223485574619, \"f0_5\": 0.7636194666622352, \"p4\": 0.7213417911154072, \"phi\": 0.6266140978410566}, {\"truth_threshold\": 6.7599998489022255, \"match_probability\": 0.9908578440244462, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119439.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39294185767253037, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6070581423274697, \"precision\": 0.9991049470496712, \"recall\": 0.39294185767253037, \"specificity\": 0.9999999163237369, \"npv\": 0.9998557207006102, \"accuracy\": 0.9998556505293381, \"f1\": 0.5640473475054721, \"f2\": 0.44720643407543864, \"f0_5\": 0.7635348944249468, \"p4\": 0.7212475554933075, \"phi\": 0.6265248414375054}, {\"truth_threshold\": 6.779999848455191, \"match_probability\": 0.9909825718261368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119391.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184570.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39278394267685657, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6072160573231434, \"precision\": 0.9991045875244774, \"recall\": 0.39278394267685657, \"specificity\": 0.9999999163237369, \"npv\": 0.9998556831744241, \"accuracy\": 0.9998556130012435, \"f1\": 0.5638845791446161, \"f2\": 0.4470427800518519, \"f0_5\": 0.763415448243053, \"p4\": 0.7211144675525035, \"phi\": 0.6263988107534944}, {\"truth_threshold\": 6.799999848008156, \"match_probability\": 0.9911056132228164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119363.0, \"tn\": 1278737686.0, \"fp\": 106.0, \"fn\": 184598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3926918255960469, \"tn_rate\": 0.999999917105758, \"fp_rate\": 8.289424201204808e-08, \"fn_rate\": 0.6073081744039531, \"precision\": 0.999112740543572, \"recall\": 0.3926918255960469, \"specificity\": 0.999999917105758, \"npv\": 0.999855661284263, \"accuracy\": 0.9998555918916902, \"f1\": 0.5637909453746782, \"f2\": 0.44694764448485114, \"f0_5\": 0.763349649607271, \"p4\": 0.7210378951867152, \"phi\": 0.6263279034322272}, {\"truth_threshold\": 6.819999847561121, \"match_probability\": 0.991226990601748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119328.0, \"tn\": 1278737689.0, \"fp\": 103.0, \"fn\": 184633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3925766792450347, \"tn_rate\": 0.9999999194518214, \"fp_rate\": 8.05481785588769e-08, \"fn_rate\": 0.6074233207549653, \"precision\": 0.9991375773459152, \"recall\": 0.3925766792450347, \"specificity\": 0.9999999194518214, \"npv\": 0.9998556339217606, \"accuracy\": 0.9998555668729604, \"f1\": 0.5636762149497393, \"f2\": 0.44682930482484884, \"f0_5\": 0.763274208920473, \"p4\": 0.7209440578855604, \"phi\": 0.6262438478745431}, {\"truth_threshold\": 6.839999847114086, \"match_probability\": 0.9913467260642292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119308.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39251088133017065, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6074891186698294, \"precision\": 0.9991541676088067, \"recall\": 0.39251088133017065, \"specificity\": 0.9999999210158638, \"npv\": 0.9998556182860779, \"accuracy\": 0.9998555527999249, \"f1\": 0.5636110258166616, \"f2\": 0.44676177473482553, \"f0_5\": 0.7632322027848111, \"p4\": 0.7208907339830657, \"phi\": 0.6261965606845356}, {\"truth_threshold\": 6.859999846667051, \"match_probability\": 0.9914648414289392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119280.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184681.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39241876424936095, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.607581235750639, \"precision\": 0.9991539692245834, \"recall\": 0.39241876424936095, \"specificity\": 0.9999999210158638, \"npv\": 0.9998555963958069, \"accuracy\": 0.9998555309085363, \"f1\": 0.5635160225066258, \"f2\": 0.4466662921979442, \"f0_5\": 0.763162440737826, \"p4\": 0.720813014312737, \"phi\": 0.6261230073301386}, {\"truth_threshold\": 6.8799998462200165, \"match_probability\": 0.9915813582352545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119249.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184712.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3923167774813216, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6076832225186783, \"precision\": 0.9991537494763301, \"recall\": 0.3923167774813216, \"specificity\": 0.9999999210158638, \"npv\": 0.9998555721601509, \"accuracy\": 0.9998555066716419, \"f1\": 0.5634108256104849, \"f2\": 0.44656057471798105, \"f0_5\": 0.7630851808575038, \"p4\": 0.7207269445235328, \"phi\": 0.6260415631827786}, {\"truth_threshold\": 6.899999845772982, \"match_probability\": 0.9916962977465344, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119206.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39217531196436384, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6078246880356362, \"precision\": 0.9991534444751775, \"recall\": 0.39217531196436384, \"specificity\": 0.9999999210158638, \"npv\": 0.9998555385429524, \"accuracy\": 0.9998554730527237, \"f1\": 0.5632648818242816, \"f2\": 0.4464139262150873, \"f0_5\": 0.7629779733201568, \"p4\": 0.7206075173441122, \"phi\": 0.6259285747307558}, {\"truth_threshold\": 6.919999845325947, \"match_probability\": 0.991809680953376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119144.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184817.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3919713384282852, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6080286615717148, \"precision\": 0.9991530043188394, \"recall\": 0.3919713384282852, \"specificity\": 0.9999999210158638, \"npv\": 0.9998554900716471, \"accuracy\": 0.9998554245789347, \"f1\": 0.5630543990397111, \"f2\": 0.44620246290696725, \"f0_5\": 0.7628233118763134, \"p4\": 0.7204352380224517, \"phi\": 0.6257656252476976}, {\"truth_threshold\": 6.939999844878912, \"match_probability\": 0.9919215285768376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119094.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.391806843641125, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6081931563588749, \"precision\": 0.9991526490205126, \"recall\": 0.391806843641125, \"specificity\": 0.9999999210158638, \"npv\": 0.9998554509818881, \"accuracy\": 0.9998553854871695, \"f1\": 0.5628846099310892, \"f2\": 0.44603191367443196, \"f0_5\": 0.7626985133354083, \"p4\": 0.7202962325042548, \"phi\": 0.6256341834715125}, {\"truth_threshold\": 6.959999844431877, \"match_probability\": 0.9920318610716337, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119076.0, \"tn\": 1278737692.0, \"fp\": 100.0, \"fn\": 184885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39174762551774733, \"tn_rate\": 0.9999999217978849, \"fp_rate\": 7.820211510570574e-08, \"fn_rate\": 0.6082523744822527, \"precision\": 0.9991609048801772, \"recall\": 0.39174762551774733, \"specificity\": 0.9999999217978849, \"npv\": 0.9998554369096887, \"accuracy\": 0.9998553721959693, \"f1\": 0.562824806150254, \"f2\": 0.4459708468786984, \"f0_5\": 0.7626574779194661, \"p4\": 0.720247264309528, \"phi\": 0.6255894833070768}, {\"truth_threshold\": 6.979999843984842, \"match_probability\": 0.9921406986292971, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119040.0, \"tn\": 1278737694.0, \"fp\": 98.0, \"fn\": 184921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.391629189270992, \"tn_rate\": 0.9999999233619272, \"fp_rate\": 7.663807280359162e-08, \"fn_rate\": 0.608370810729008, \"precision\": 0.9991774244993201, \"recall\": 0.391629189270992, \"specificity\": 0.9999999233619272, \"npv\": 0.9998554087652911, \"accuracy\": 0.9998553456135689, \"f1\": 0.5627051824750235, \"f2\": 0.4458487080724684, \"f0_5\": 0.7625753831134139, \"p4\": 0.7201493034813836, \"phi\": 0.6255000735272306}, {\"truth_threshold\": 6.9999998435378075, \"match_probability\": 0.992248061181313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119007.0, \"tn\": 1278737694.0, \"fp\": 98.0, \"fn\": 184954.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39152062271146626, \"tn_rate\": 0.9999999233619272, \"fp_rate\": 7.663807280359162e-08, \"fn_rate\": 0.6084793772885337, \"precision\": 0.999177196591243, \"recall\": 0.39152062271146626, \"specificity\": 0.9999999233619272, \"npv\": 0.9998553829660541, \"accuracy\": 0.9998553198130038, \"f1\": 0.5625930705847315, \"f2\": 0.4457361292453869, \"f0_5\": 0.7624929361427303, \"p4\": 0.7200574803877159, \"phi\": 0.6254132882289789}, {\"truth_threshold\": 7.019999843090773, \"match_probability\": 0.9923539684022208, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118966.0, \"tn\": 1278737694.0, \"fp\": 98.0, \"fn\": 184995.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39138573698599494, \"tn_rate\": 0.9999999233619272, \"fp_rate\": 7.663807280359162e-08, \"fn_rate\": 0.6086142630140051, \"precision\": 0.9991769132567359, \"recall\": 0.39138573698599494, \"specificity\": 0.9999999233619272, \"npv\": 0.9998553509124585, \"accuracy\": 0.9998552877577562, \"f1\": 0.5624537556881981, \"f2\": 0.4455962508277724, \"f0_5\": 0.7623904631660167, \"p4\": 0.7199433588351604, \"phi\": 0.6253054472981504}, {\"truth_threshold\": 7.039999842643738, \"match_probability\": 0.9924584397126871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118924.0, \"tn\": 1278737694.0, \"fp\": 98.0, \"fn\": 185037.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39124756136478034, \"tn_rate\": 0.9999999233619272, \"fp_rate\": 7.663807280359162e-08, \"fn_rate\": 0.6087524386352197, \"precision\": 0.9991766228092286, \"recall\": 0.39124756136478034, \"specificity\": 0.9999999233619272, \"npv\": 0.99985531807707, \"accuracy\": 0.9998552549206734, \"f1\": 0.5623110148634816, \"f2\": 0.4454529518318693, \"f0_5\": 0.7622854461706893, \"p4\": 0.7198264097838541, \"phi\": 0.6251949568201947}, {\"truth_threshold\": 7.059999842196703, \"match_probability\": 0.9925614942825483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118902.0, \"tn\": 1278737695.0, \"fp\": 97.0, \"fn\": 185059.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39117518365842985, \"tn_rate\": 0.9999999241439483, \"fp_rate\": 7.585605165253457e-08, \"fn_rate\": 0.6088248163415702, \"precision\": 0.9991848670997235, \"recall\": 0.39117518365842985, \"specificity\": 0.9999999241439483, \"npv\": 0.9998553008776948, \"accuracy\": 0.999855238502132, \"f1\": 0.5622375638358237, \"f2\": 0.4453782205098277, \"f0_5\": 0.7622343283027141, \"p4\": 0.7197662223233705, \"phi\": 0.6251397007129468}, {\"truth_threshold\": 7.079999841749668, \"match_probability\": 0.9926631510338226, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118879.0, \"tn\": 1278737695.0, \"fp\": 97.0, \"fn\": 185082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3910995160563362, \"tn_rate\": 0.9999999241439483, \"fp_rate\": 7.585605165253457e-08, \"fn_rate\": 0.6089004839436638, \"precision\": 0.9991847095212479, \"recall\": 0.3910995160563362, \"specificity\": 0.9999999241439483, \"npv\": 0.9998552828964121, \"accuracy\": 0.9998552205199199, \"f1\": 0.5621593759827114, \"f2\": 0.44529974078902024, \"f0_5\": 0.7621767870080078, \"p4\": 0.719702147115359, \"phi\": 0.6250791804021658}, {\"truth_threshold\": 7.099999841302633, \"match_probability\": 0.9927634286436933, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118867.0, \"tn\": 1278737695.0, \"fp\": 97.0, \"fn\": 185094.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39106003730741773, \"tn_rate\": 0.9999999241439483, \"fp_rate\": 7.585605165253457e-08, \"fn_rate\": 0.6089399626925823, \"precision\": 0.999184627282203, \"recall\": 0.39106003730741773, \"specificity\": 0.9999999241439483, \"npv\": 0.9998552735148736, \"accuracy\": 0.9998552111378963, \"f1\": 0.5621185789442572, \"f2\": 0.44525879377408584, \"f0_5\": 0.7621467600731967, \"p4\": 0.7196687112592626, \"phi\": 0.6250476022624848}, {\"truth_threshold\": 7.1199998408555984, \"match_probability\": 0.9928623455474604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118808.0, \"tn\": 1278737698.0, \"fp\": 94.0, \"fn\": 185153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3908659334585687, \"tn_rate\": 0.9999999264900118, \"fp_rate\": 7.350998819936339e-08, \"fn_rate\": 0.6091340665414313, \"precision\": 0.9992094329784192, \"recall\": 0.3908659334585687, \"specificity\": 0.9999999264900118, \"npv\": 0.9998552273893181, \"accuracy\": 0.9998551673551191, \"f1\": 0.5619219463514188, \"f2\": 0.4450584605610356, \"f0_5\": 0.7620108034054714, \"p4\": 0.7195075336093806, \"phi\": 0.6249002061280442}, {\"truth_threshold\": 7.139999840408564, \"match_probability\": 0.9929599199414655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118757.0, \"tn\": 1278737698.0, \"fp\": 94.0, \"fn\": 185204.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3906981487756653, \"tn_rate\": 0.9999999264900118, \"fp_rate\": 7.350998819936339e-08, \"fn_rate\": 0.6093018512243347, \"precision\": 0.9992090937392197, \"recall\": 0.3906981487756653, \"specificity\": 0.9999999264900118, \"npv\": 0.9998551875177851, \"accuracy\": 0.9998551274815186, \"f1\": 0.5617484839597741, \"f2\": 0.4448844117944549, \"f0_5\": 0.7618830714748546, \"p4\": 0.719365314475286, \"phi\": 0.6247659495793596}, {\"truth_threshold\": 7.159999839961529, \"match_probability\": 0.9930561697859839, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118736.0, \"tn\": 1278737698.0, \"fp\": 94.0, \"fn\": 185225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.390629060965058, \"tn_rate\": 0.9999999264900118, \"fp_rate\": 7.350998819936339e-08, \"fn_rate\": 0.609370939034942, \"precision\": 0.9992089539678533, \"recall\": 0.390629060965058, \"specificity\": 0.9999999264900118, \"npv\": 0.999855171100096, \"accuracy\": 0.9998551110629772, \"f1\": 0.5616770461055226, \"f2\": 0.4448127407891365, \"f0_5\": 0.7618304565362174, \"p4\": 0.7193067344990949, \"phi\": 0.624710659087852}, {\"truth_threshold\": 7.179999839514494, \"match_probability\": 0.9931511128080894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118691.0, \"tn\": 1278737698.0, \"fp\": 94.0, \"fn\": 185270.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39048101565661386, \"tn_rate\": 0.9999999264900118, \"fp_rate\": 7.350998819936339e-08, \"fn_rate\": 0.6095189843433861, \"precision\": 0.9992086542913667, \"recall\": 0.39048101565661386, \"specificity\": 0.9999999264900118, \"npv\": 0.9998551359193355, \"accuracy\": 0.9998550758803884, \"f1\": 0.5615239410899217, \"f2\": 0.44465915246858867, \"f0_5\": 0.7617176720348197, \"p4\": 0.7191811683302896, \"phi\": 0.6245921629880203}, {\"truth_threshold\": 7.199999839067459, \"match_probability\": 0.99324476650449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118672.0, \"tn\": 1278737699.0, \"fp\": 93.0, \"fn\": 185289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.390418507637493, \"tn_rate\": 0.9999999272720329, \"fp_rate\": 7.272796704830633e-08, \"fn_rate\": 0.609581492362507, \"precision\": 0.9992169410179766, \"recall\": 0.390418507637493, \"specificity\": 0.9999999272720329, \"npv\": 0.9998551210653507, \"accuracy\": 0.999855061807353, \"f1\": 0.5614606151502392, \"f2\": 0.4445946340838403, \"f0_5\": 0.7616739471721559, \"p4\": 0.7191292256284716, \"phi\": 0.6245447548738243}, {\"truth_threshold\": 7.219999838620424, \"match_probability\": 0.9933371481443325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118640.0, \"tn\": 1278737699.0, \"fp\": 93.0, \"fn\": 185321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39031323097371046, \"tn_rate\": 0.9999999272720329, \"fp_rate\": 7.272796704830633e-08, \"fn_rate\": 0.6096867690262896, \"precision\": 0.9992167299739753, \"recall\": 0.39031323097371046, \"specificity\": 0.9999999272720329, \"npv\": 0.9998550960479232, \"accuracy\": 0.9998550367886231, \"f1\": 0.561351710693788, \"f2\": 0.4444854062373321, \"f0_5\": 0.7615936977222802, \"p4\": 0.7190398874781652, \"phi\": 0.6244604709098479}, {\"truth_threshold\": 7.239999838173389, \"match_probability\": 0.9934282747719803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118604.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3901947947269551, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6098052052730449, \"precision\": 0.9992333291208559, \"recall\": 0.3901947947269551, \"specificity\": 0.9999999288360752, \"npv\": 0.9998550679035455, \"accuracy\": 0.9998550102062227, \"f1\": 0.5612318291944276, \"f2\": 0.4443631845903342, \"f0_5\": 0.7615112084762456, \"p4\": 0.7189415301882504, \"phi\": 0.6243709001002269}, {\"truth_threshold\": 7.259999837726355, \"match_probability\": 0.993518163209761, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118569.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185392.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39007964837594294, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.609920351624057, \"precision\": 0.9992331029833137, \"recall\": 0.39007964837594294, \"specificity\": 0.9999999288360752, \"npv\": 0.9998550405407371, \"accuracy\": 0.999854982841987, \"f1\": 0.5611126754231333, \"f2\": 0.44424370402786356, \"f0_5\": 0.7614233734608612, \"p4\": 0.7188437548768313, \"phi\": 0.6242786882662277}, {\"truth_threshold\": 7.27999983727932, \"match_probability\": 0.9936068300606864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118517.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185444.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3899085737972964, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6100914262027036, \"precision\": 0.9992327667610954, \"recall\": 0.3899085737972964, \"specificity\": 0.9999999288360752, \"npv\": 0.9998549998874249, \"accuracy\": 0.9998549421865511, \"f1\": 0.5609356105156791, \"f2\": 0.4440661784762584, \"f0_5\": 0.7612928173814513, \"p4\": 0.7186984312234714, \"phi\": 0.6241416626802315}, {\"truth_threshold\": 7.299999836832285, \"match_probability\": 0.9936942917111425, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118470.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185491.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3897539486973658, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6102460513026342, \"precision\": 0.9992324626141817, \"recall\": 0.3897539486973658, \"specificity\": 0.9999999288360752, \"npv\": 0.9998549631430876, \"accuracy\": 0.9998549054402918, \"f1\": 0.5607755335816833, \"f2\": 0.4439057107849566, \"f0_5\": 0.7611747547240123, \"p4\": 0.7185670218469714, \"phi\": 0.6240177867527492}, {\"truth_threshold\": 7.31999983638525, \"match_probability\": 0.993780564333553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118405.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185556.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38954010547405754, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6104598945259425, \"precision\": 0.9992320415879017, \"recall\": 0.38954010547405754, \"specificity\": 0.9999999288360752, \"npv\": 0.9998549123264555, \"accuracy\": 0.9998548546209969, \"f1\": 0.5605540918957432, \"f2\": 0.44368376875459026, \"f0_5\": 0.7610113825527511, \"p4\": 0.7183851928590128, \"phi\": 0.6238464284634518}, {\"truth_threshold\": 7.339999835938215, \"match_probability\": 0.9938656638890125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118368.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185593.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.389418379331559, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.610581620668441, \"precision\": 0.9992318017204265, \"recall\": 0.389418379331559, \"specificity\": 0.9999999288360752, \"npv\": 0.9998548834000673, \"accuracy\": 0.9998548256930906, \"f1\": 0.5604280100374035, \"f2\": 0.443557422864222, \"f0_5\": 0.7609183373039495, \"p4\": 0.7182816421589172, \"phi\": 0.6237488650349855}, {\"truth_threshold\": 7.35999983549118, \"match_probability\": 0.9939496061298939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118285.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38914531798487306, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6108546820151269, \"precision\": 0.9992312630938703, \"recall\": 0.38914531798487306, \"specificity\": 0.9999999288360752, \"npv\": 0.9998548185111484, \"accuracy\": 0.9998547608007602, \"f1\": 0.560145097398523, \"f2\": 0.4432739728080826, \"f0_5\": 0.7607094853144515, \"p4\": 0.7180492258466763, \"phi\": 0.6235299510220492}, {\"truth_threshold\": 7.379999835044146, \"match_probability\": 0.9940324066024261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118225.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38894792424028085, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6110520757597192, \"precision\": 0.999230873254674, \"recall\": 0.38894792424028085, \"specificity\": 0.9999999288360752, \"npv\": 0.9998547716035013, \"accuracy\": 0.9998547138906418, \"f1\": 0.5599405129808159, \"f2\": 0.44306904719074175, \"f0_5\": 0.760558396860626, \"p4\": 0.7178811046442282, \"phi\": 0.6233716520720156}, {\"truth_threshold\": 7.399999834597111, \"match_probability\": 0.9941140806492453, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118183.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185778.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38880974861906625, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6111902513809337, \"precision\": 0.9992306001318971, \"recall\": 0.38880974861906625, \"specificity\": 0.9999999288360752, \"npv\": 0.9998547387681511, \"accuracy\": 0.999854681053559, \"f1\": 0.5597972692931661, \"f2\": 0.4429255882912906, \"f0_5\": 0.7604525794118063, \"p4\": 0.7177633651277542, \"phi\": 0.623260818893574}, {\"truth_threshold\": 7.419999834150076, \"match_probability\": 0.9941946434119178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118137.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3886584134148789, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6113415865851212, \"precision\": 0.9992303007747741, \"recall\": 0.3886584134148789, \"specificity\": 0.9999999288360752, \"npv\": 0.999854702805627, \"accuracy\": 0.9998546450891349, \"f1\": 0.5596403506486431, \"f2\": 0.44276845627522354, \"f0_5\": 0.7603366315987298, \"p4\": 0.7176343606263607, \"phi\": 0.6231394075641079}, {\"truth_threshold\": 7.439999833703041, \"match_probability\": 0.994274109833436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118079.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 185882.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38846759946177306, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.611532400538227, \"precision\": 0.9992891175748754, \"recall\": 0.38846759946177306, \"specificity\": 0.9999999343102233, \"npv\": 0.9998546574623742, \"accuracy\": 0.9998546052155344, \"f1\": 0.5594517250855199, \"f2\": 0.4425726401735523, \"f0_5\": 0.7602177661203199, \"p4\": 0.717479255602601, \"phi\": 0.6230047497189428}, {\"truth_threshold\": 7.459999833256006, \"match_probability\": 0.9943524946606879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118038.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 185923.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3883327137363017, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6116672862636983, \"precision\": 0.9992888708284655, \"recall\": 0.3883327137363017, \"specificity\": 0.9999999343102233, \"npv\": 0.9998546254088255, \"accuracy\": 0.9998545731602868, \"f1\": 0.5593117941257999, \"f2\": 0.4424325657475528, \"f0_5\": 0.7601143152995239, \"p4\": 0.7173641671318076, \"phi\": 0.6228964919409086}, {\"truth_threshold\": 7.479999832808971, \"match_probability\": 0.9944298124468978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117949.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38803991301515656, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6119600869848435, \"precision\": 0.9992883346182847, \"recall\": 0.38803991301515656, \"specificity\": 0.9999999343102233, \"npv\": 0.999854555829178, \"accuracy\": 0.9998545035769446, \"f1\": 0.5590079479803031, \"f2\": 0.4421284721154949, \"f0_5\": 0.7598896008596908, \"p4\": 0.7171141928526306, \"phi\": 0.6226614285994212}, {\"truth_threshold\": 7.499999832361937, \"match_probability\": 0.9945060775540423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117908.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3879050272896852, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6120949727103148, \"precision\": 0.9992880873279545, \"recall\": 0.3879050272896852, \"specificity\": 0.9999999343102233, \"npv\": 0.9998545237756358, \"accuracy\": 0.999854471521697, \"f1\": 0.5588679307885002, \"f2\": 0.4419883703843651, \"f0_5\": 0.7597860113489765, \"p4\": 0.7169989678894014, \"phi\": 0.6225531111423108}, {\"truth_threshold\": 7.519999831914902, \"match_probability\": 0.9945813041552386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117842.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3876878941706337, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6123121058293662, \"precision\": 0.9992876888896427, \"recall\": 0.3876878941706337, \"specificity\": 0.9999999343102233, \"npv\": 0.999854472177255, \"accuracy\": 0.9998544199205669, \"f1\": 0.558642480095381, \"f2\": 0.44176282267557376, \"f0_5\": 0.7596191654902568, \"p4\": 0.7168133932630738, \"phi\": 0.6223787068720268}, {\"truth_threshold\": 7.539999831467867, \"match_probability\": 0.9946555062371064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117818.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186143.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38760893667279683, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6123910633272032, \"precision\": 0.9992875438923852, \"recall\": 0.38760893667279683, \"specificity\": 0.9999999343102233, \"npv\": 0.9998544534142088, \"accuracy\": 0.9998544011565196, \"f1\": 0.5585604805351501, \"f2\": 0.4416807997924642, \"f0_5\": 0.7595584661068197, \"p4\": 0.7167458838716928, \"phi\": 0.6223152750236239}, {\"truth_threshold\": 7.559999831020832, \"match_probability\": 0.9947286976021039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117776.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186185.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3874707610515823, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6125292389484177, \"precision\": 0.9992872900050908, \"recall\": 0.3874707610515823, \"specificity\": 0.9999999343102233, \"npv\": 0.9998544205788796, \"accuracy\": 0.9998543683194367, \"f1\": 0.5584169588522145, \"f2\": 0.44153725264376503, \"f0_5\": 0.759452206019853, \"p4\": 0.7166277068553676, \"phi\": 0.6222042537342178}, {\"truth_threshold\": 7.579999830573797, \"match_probability\": 0.9948008918708379, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117750.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186211.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.387385223762259, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6126147762377411, \"precision\": 0.9992871327460665, \"recall\": 0.387385223762259, \"specificity\": 0.9999999343102233, \"npv\": 0.9998544002522484, \"accuracy\": 0.9998543479917188, \"f1\": 0.5583280977726146, \"f2\": 0.4414483855923244, \"f0_5\": 0.7593864028881835, \"p4\": 0.716554526951197, \"phi\": 0.6221355163445779}, {\"truth_threshold\": 7.599999830126762, \"match_probability\": 0.9948721024843478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117723.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186238.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38729639657719245, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6127036034228075, \"precision\": 0.999286969365148, \"recall\": 0.38729639657719245, \"specificity\": 0.9999999343102233, \"npv\": 0.9998543791438244, \"accuracy\": 0.9998543268821655, \"f1\": 0.5582358073632898, \"f2\": 0.44135609690991123, \"f0_5\": 0.7593180501787306, \"p4\": 0.7164785140513208, \"phi\": 0.6220641271729385}, {\"truth_threshold\": 7.6199998296797276, \"match_probability\": 0.9949423427063642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117681.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186280.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3871582209559779, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6128417790440222, \"precision\": 0.9992867150681441, \"recall\": 0.3871582209559779, \"specificity\": 0.9999999343102233, \"npv\": 0.9998543463085001, \"accuracy\": 0.9998542940450826, \"f1\": 0.5580922210155409, \"f2\": 0.4412125293095652, \"f0_5\": 0.7592116858768988, \"p4\": 0.7163602345159711, \"phi\": 0.6219530610691582}, {\"truth_threshold\": 7.639999829232693, \"match_probability\": 0.9950116256255418, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117598.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.386885159609292, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6131148403907081, \"precision\": 0.9992862119950374, \"recall\": 0.386885159609292, \"specificity\": 0.9999999343102233, \"npv\": 0.9998542814196513, \"accuracy\": 0.9998542291527523, \"f1\": 0.5578083829210968, \"f2\": 0.4409287857904533, \"f0_5\": 0.759001354091771, \"p4\": 0.7161263581870319, \"phi\": 0.6217335149672508}, {\"truth_threshold\": 7.659999828785658, \"match_probability\": 0.9950799641576676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117567.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186394.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3867831728412527, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6132168271587474, \"precision\": 0.9992860239181988, \"recall\": 0.3867831728412527, \"specificity\": 0.9999999343102233, \"npv\": 0.9998542571840592, \"accuracy\": 0.9998542049158579, \"f1\": 0.557702342438071, \"f2\": 0.44082280023547143, \"f0_5\": 0.7589227501888156, \"p4\": 0.7160389613022741, \"phi\": 0.6216514959403946}, {\"truth_threshold\": 7.679999828338623, \"match_probability\": 0.9951473710478438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117524.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186437.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38664170732429487, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6133582926757051, \"precision\": 0.999285762873274, \"recall\": 0.38664170732429487, \"specificity\": 0.9999999343102233, \"npv\": 0.9998542235669498, \"accuracy\": 0.9998541712969397, \"f1\": 0.5575552282070076, \"f2\": 0.44067577985559286, \"f0_5\": 0.758813677293054, \"p4\": 0.7159176923816413, \"phi\": 0.6215377097006571}, {\"truth_threshold\": 7.699999827891588, \"match_probability\": 0.9952138588726456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117465.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186496.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3864476034754459, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6135523965245542, \"precision\": 0.9992854043845545, \"recall\": 0.3864476034754459, \"specificity\": 0.9999999343102233, \"npv\": 0.9998541774411519, \"accuracy\": 0.9998541251686567, \"f1\": 0.5573533249507723, \"f2\": 0.4404740387867643, \"f0_5\": 0.7586639402601798, \"p4\": 0.7157512225835976, \"phi\": 0.6213815504991659}, {\"truth_threshold\": 7.719999827444553, \"match_probability\": 0.995279440042255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117389.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186572.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3861975713989624, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6138024286010376, \"precision\": 0.9992849420717952, \"recall\": 0.3861975713989624, \"specificity\": 0.9999999343102233, \"npv\": 0.9998541180248763, \"accuracy\": 0.9998540657491733, \"f1\": 0.5570931628677326, \"f2\": 0.44021414262324715, \"f0_5\": 0.7584709240643895, \"p4\": 0.7155366545762568, \"phi\": 0.6211803384412249}, {\"truth_threshold\": 7.7399998269975185, \"match_probability\": 0.9953441268025699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117345.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186616.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3860528159862614, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6139471840137386, \"precision\": 0.9992846741435251, \"recall\": 0.3860528159862614, \"specificity\": 0.9999999343102233, \"npv\": 0.9998540836259832, \"accuracy\": 0.99985403134842, \"f1\": 0.5569424998220176, \"f2\": 0.44006366288074533, \"f0_5\": 0.7583591085168617, \"p4\": 0.7154123628349464, \"phi\": 0.6210638174654292}, {\"truth_threshold\": 7.759999826550484, \"match_probability\": 0.9954079312372888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117294.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186667.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.385885031303358, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.614114968696642, \"precision\": 0.9992843633389562, \"recall\": 0.385885031303358, \"specificity\": 0.9999999343102233, \"npv\": 0.9998540437545418, \"accuracy\": 0.9998539914748193, \"f1\": 0.5567678282807905, \"f2\": 0.4398892307507677, \"f0_5\": 0.7582294404588137, \"p4\": 0.7152682348157874, \"phi\": 0.6209287317112028}, {\"truth_threshold\": 7.779999826103449, \"match_probability\": 0.9954708652699722, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117256.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186705.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3857600152651163, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6142399847348837, \"precision\": 0.9992841315834328, \"recall\": 0.3857600152651163, \"specificity\": 0.9999999343102233, \"npv\": 0.999854014046411, \"accuracy\": 0.9998539617650777, \"f1\": 0.5566376533642218, \"f2\": 0.43975925303634006, \"f0_5\": 0.758132780565897, \"p4\": 0.7151608015932497, \"phi\": 0.6208280604780738}, {\"truth_threshold\": 7.799999825656414, \"match_probability\": 0.9955329406660792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117174.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3854902438141735, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6145097561858265, \"precision\": 0.9992836309676099, \"recall\": 0.3854902438141735, \"specificity\": 0.9999999343102233, \"npv\": 0.9998539499393981, \"accuracy\": 0.9998538976545827, \"f1\": 0.5563566695709358, \"f2\": 0.43947874956304916, \"f0_5\": 0.757924069170096, \"p4\": 0.7149288447096005, \"phi\": 0.6206107669341723}, {\"truth_threshold\": 7.819999825209379, \"match_probability\": 0.9955941690349815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117140.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 186821.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3853783873589046, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6146216126410954, \"precision\": 0.9992919478259386, \"recall\": 0.3853783873589046, \"specificity\": 0.9999999350922445, \"npv\": 0.9998539233585582, \"accuracy\": 0.9998538718540175, \"f1\": 0.5562414526667679, \"f2\": 0.4393627627118517, \"f0_5\": 0.7578414006285801, \"p4\": 0.7148337070528068, \"phi\": 0.6205232950672144}, {\"truth_threshold\": 7.839999824762344, \"match_probability\": 0.9956545618319536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117089.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 186872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3852106026760012, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6147893973239988, \"precision\": 0.9992916396408699, \"recall\": 0.3852106026760012, \"specificity\": 0.9999999350922445, \"npv\": 0.9998538834871296, \"accuracy\": 0.999853831980417, \"f1\": 0.5560666107856663, \"f2\": 0.43918827680988076, \"f0_5\": 0.7577114575958812, \"p4\": 0.7146893084687911, \"phi\": 0.6203880916594643}, {\"truth_threshold\": 7.8599998243153095, \"match_probability\": 0.9957141303601397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117051.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 186910.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38508558663775944, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6149144133622405, \"precision\": 0.9992914098383049, \"recall\": 0.38508558663775944, \"specificity\": 0.9999999350922445, \"npv\": 0.9998538537790084, \"accuracy\": 0.9998538022706753, \"f1\": 0.555936308908916, \"f2\": 0.43905825902603046, \"f0_5\": 0.7576145926780298, \"p4\": 0.7145816735256473, \"phi\": 0.6202873327129415}, {\"truth_threshold\": 7.879999823868275, \"match_probability\": 0.9957728857724977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117018.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 186943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3849770200782337, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6150229799217662, \"precision\": 0.9992912101519201, \"recall\": 0.3849770200782337, \"specificity\": 0.9999999350922445, \"npv\": 0.9998538279798519, \"accuracy\": 0.9998537764701103, \"f1\": 0.5558231329352922, \"f2\": 0.43894534283109954, \"f0_5\": 0.7575304422132023, \"p4\": 0.7144881706854235, \"phi\": 0.6201998182470396}, {\"truth_threshold\": 7.89999982342124, \"match_probability\": 0.9958308390737213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116962.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 186999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3847927859166143, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6152072140833857, \"precision\": 0.9992908710325089, \"recall\": 0.3847927859166143, \"specificity\": 0.9999999350922445, \"npv\": 0.9998537841994682, \"accuracy\": 0.9998537326873331, \"f1\": 0.5556310361372522, \"f2\": 0.4387537146754156, \"f0_5\": 0.7573875755852881, \"p4\": 0.7143294345170038, \"phi\": 0.6200512805955413}, {\"truth_threshold\": 7.919999822974205, \"match_probability\": 0.9958880011221378, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116918.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38464803050391333, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6153519694960866, \"precision\": 0.9992906043538089, \"recall\": 0.38464803050391333, \"specificity\": 0.9999999350922445, \"npv\": 0.9998537498005982, \"accuracy\": 0.9998536982865797, \"f1\": 0.55548006708444, \"f2\": 0.4386031383994388, \"f0_5\": 0.7572752650703076, \"p4\": 0.7142046561041487, \"phi\": 0.6199345474825384}, {\"truth_threshold\": 7.93999982252717, \"match_probability\": 0.9959443826315856, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116859.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3844539266550643, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6155460733449357, \"precision\": 0.9992902464469566, \"recall\": 0.3844539266550643, \"specificity\": 0.9999999350922445, \"npv\": 0.999853703674844, \"accuracy\": 0.9998536521582967, \"f1\": 0.5552775817706217, \"f2\": 0.4384012136982231, \"f0_5\": 0.7571245864804873, \"p4\": 0.7140372606235855, \"phi\": 0.6197779844958893}, {\"truth_threshold\": 7.959999822080135, \"match_probability\": 0.9959999941732675, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116798.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187163.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38425324301472885, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6157467569852711, \"precision\": 0.9992898760277548, \"recall\": 0.38425324301472885, \"specificity\": 0.9999999350922445, \"npv\": 0.9998536559855097, \"accuracy\": 0.999853604466343, \"f1\": 0.55506817285347, \"f2\": 0.4381924252940404, \"f0_5\": 0.7569687032152278, \"p4\": 0.7138640955228643, \"phi\": 0.6196160727104513}, {\"truth_threshold\": 7.9799998216331005, \"match_probability\": 0.9960548461775844, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116726.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187235.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3840163705212182, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6159836294787818, \"precision\": 0.9992894383138285, \"recall\": 0.3840163705212182, \"specificity\": 0.9999999350922445, \"npv\": 0.999853599696465, \"accuracy\": 0.999853548174201, \"f1\": 0.5548209235449295, \"f2\": 0.4379459619270733, \"f0_5\": 0.7567845829275788, \"p4\": 0.7136595792824001, \"phi\": 0.6194249092796675}, {\"truth_threshold\": 7.999999821186066, \"match_probability\": 0.9961089489359451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116661.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187300.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3838025272979099, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.61619747270209, \"precision\": 0.9992890426917015, \"recall\": 0.3838025272979099, \"specificity\": 0.9999999350922445, \"npv\": 0.9998535488799719, \"accuracy\": 0.9998534973549061, \"f1\": 0.5545976396762577, \"f2\": 0.43772343740150743, \"f0_5\": 0.7566182450706089, \"p4\": 0.7134748305479484, \"phi\": 0.6192522805158561}, {\"truth_threshold\": 8.01999982073903, \"match_probability\": 0.9961623126025559, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116602.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187359.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3836084234490609, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6163915765509391, \"precision\": 0.9992886832069247, \"recall\": 0.3836084234490609, \"specificity\": 0.9999999350922445, \"npv\": 0.9998535027542365, \"accuracy\": 0.9998534512266231, \"f1\": 0.5543949068813206, \"f2\": 0.43752143480554645, \"f0_5\": 0.7564671643088565, \"p4\": 0.7133070401417766, \"phi\": 0.6190955450541804}, {\"truth_threshold\": 8.039999820291996, \"match_probability\": 0.9962149471961885, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116544.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187417.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38341760949595505, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.616582390504045, \"precision\": 0.999288329460588, \"recall\": 0.38341760949595505, \"specificity\": 0.9999999350922445, \"npv\": 0.9998534574102972, \"accuracy\": 0.9998534058801753, \"f1\": 0.5541955547947159, \"f2\": 0.43732283854582954, \"f0_5\": 0.7563185540235883, \"p4\": 0.7131420050770528, \"phi\": 0.6189414274529546}, {\"truth_threshold\": 8.059999819844961, \"match_probability\": 0.9962668626019269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116494.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187467.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38325311470879486, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6167468852912051, \"precision\": 0.9992880242243324, \"recall\": 0.38325311470879486, \"specificity\": 0.9999999350922445, \"npv\": 0.9998534183206977, \"accuracy\": 0.9998533667884101, \"f1\": 0.5540236554128283, \"f2\": 0.437151620996667, \"f0_5\": 0.756190369857803, \"p4\": 0.712999662940377, \"phi\": 0.6188085366557193}, {\"truth_threshold\": 8.079999819397926, \"match_probability\": 0.9963180685728933, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116449.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187512.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3831050694003507, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6168949305996493, \"precision\": 0.9993049000257445, \"recall\": 0.3831050694003507, \"specificity\": 0.9999999366562867, \"npv\": 0.9998533831402902, \"accuracy\": 0.9998533331694919, \"f1\": 0.5538715454076306, \"f2\": 0.436998170183447, \"f0_5\": 0.7560828016793039, \"p4\": 0.712873681358017, \"phi\": 0.618694221828411}, {\"truth_threshold\": 8.099999818950891, \"match_probability\": 0.9963685747319533, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116377.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187584.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38286819690684004, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.61713180309316, \"precision\": 0.9993044702811313, \"recall\": 0.38286819690684004, \"specificity\": 0.9999999366562867, \"npv\": 0.9998533268512764, \"accuracy\": 0.9998532768773499, \"f1\": 0.5536238847435535, \"f2\": 0.4367515773450764, \"f0_5\": 0.755898014141464, \"p4\": 0.7126685091875218, \"phi\": 0.6185027735775566}, {\"truth_threshold\": 8.119999818503857, \"match_probability\": 0.9964183905734008, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116336.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187625.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38273331118136866, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6172666888186313, \"precision\": 0.9993128092358439, \"recall\": 0.38273331118136866, \"specificity\": 0.999999937438308, \"npv\": 0.9998532947979277, \"accuracy\": 0.9998532456039377, \"f1\": 0.5534841344792888, \"f2\": 0.4366114722351493, \"f0_5\": 0.755796654214715, \"p4\": 0.7125527055762021, \"phi\": 0.618396384940526}, {\"truth_threshold\": 8.139999818056822, \"match_probability\": 0.9964675254646224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116277.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187684.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3825392073325196, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6174607926674803, \"precision\": 0.9993124607887793, \"recall\": 0.3825392073325196, \"specificity\": 0.999999937438308, \"npv\": 0.9998532486722157, \"accuracy\": 0.9998531994756547, \"f1\": 0.5532810871768518, \"f2\": 0.4364093706580313, \"f0_5\": 0.7556450638103742, \"p4\": 0.712384413859821, \"phi\": 0.6182394325676309}, {\"truth_threshold\": 8.159999817609787, \"match_probability\": 0.9965159886477419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116236.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3824043216070483, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6175956783929517, \"precision\": 0.9993122184394236, \"recall\": 0.3824043216070483, \"specificity\": 0.999999937438308, \"npv\": 0.9998532166187575, \"accuracy\": 0.9998531674204071, \"f1\": 0.5531399529358019, \"f2\": 0.4362689166466491, \"f0_5\": 0.7555396665474992, \"p4\": 0.712267411633944, \"phi\": 0.6181303405085005}, {\"truth_threshold\": 8.179999817162752, \"match_probability\": 0.9965637892412448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116166.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.382174028905024, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.617825971094976, \"precision\": 0.9993118042771364, \"recall\": 0.382174028905024, \"specificity\": 0.999999937438308, \"npv\": 0.9998531618933455, \"accuracy\": 0.9998531126919357, \"f1\": 0.5528989283852959, \"f2\": 0.4360290971330766, \"f0_5\": 0.7553596160973802, \"p4\": 0.7120675498031636, \"phi\": 0.6179440412793654}, {\"truth_threshold\": 8.199999816715717, \"match_probability\": 0.9966109362415831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116070.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38185819891367645, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6181418010863236, \"precision\": 0.9993112354713732, \"recall\": 0.38185819891367645, \"specificity\": 0.999999937438308, \"npv\": 0.9998530868413618, \"accuracy\": 0.9998530376357464, \"f1\": 0.5525682498196905, \"f2\": 0.4357001608115352, \"f0_5\": 0.7551124764332304, \"p4\": 0.711793244318118, \"phi\": 0.6176884538565817}, {\"truth_threshold\": 8.219999816268682, \"match_probability\": 0.9966574385247609, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116016.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3816805445435434, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6183194554564566, \"precision\": 0.9993109151047409, \"recall\": 0.3816805445435434, \"specificity\": 0.999999937438308, \"npv\": 0.9998530446246259, \"accuracy\": 0.9998529954166399, \"f1\": 0.5523821767045901, \"f2\": 0.4355151132933916, \"f0_5\": 0.7549733518146146, \"p4\": 0.711638841011805, \"phi\": 0.61754463946212}, {\"truth_threshold\": 8.239999815821648, \"match_probability\": 0.9967033048478998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115961.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188000.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3814996002776672, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6185003997223328, \"precision\": 0.9993105884988926, \"recall\": 0.3814996002776672, \"specificity\": 0.999999937438308, \"npv\": 0.9998530016261022, \"accuracy\": 0.999852952415698, \"f1\": 0.5521926086066257, \"f2\": 0.43532662354482554, \"f0_5\": 0.7548315703824248, \"p4\": 0.7114814995089968, \"phi\": 0.6173981274148146}, {\"truth_threshold\": 8.259999815374613, \"match_probability\": 0.9967485438507871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115923.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188038.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38137458423942544, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6186254157605745, \"precision\": 0.9993103626630345, \"recall\": 0.38137458423942544, \"specificity\": 0.999999937438308, \"npv\": 0.9998529719180336, \"accuracy\": 0.9998529227059564, \"f1\": 0.5520616052804526, \"f2\": 0.4351963851703687, \"f0_5\": 0.7547335648518894, \"p4\": 0.7113727443061532, \"phi\": 0.6172968806042874}, {\"truth_threshold\": 8.279999814927578, \"match_probability\": 0.9967931640574029, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115871.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188090.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38120350966077887, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6187964903392211, \"precision\": 0.9993100533846193, \"recall\": 0.38120350966077887, \"specificity\": 0.999999937438308, \"npv\": 0.9998529312648897, \"accuracy\": 0.9998528820505205, \"f1\": 0.551882299148393, \"f2\": 0.43501815219309276, \"f0_5\": 0.7545993891359987, \"p4\": 0.7112238597396052, \"phi\": 0.6171583054307904}, {\"truth_threshold\": 8.299999814480543, \"match_probability\": 0.9968371738774299, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115815.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188146.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3810192754991594, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6189807245008405, \"precision\": 0.9993097200051771, \"recall\": 0.3810192754991594, \"specificity\": 0.999999937438308, \"npv\": 0.9998528874845848, \"accuracy\": 0.9998528382677434, \"f1\": 0.5516891505659083, \"f2\": 0.4348261934207829, \"f0_5\": 0.7544548108830669, \"p4\": 0.7110634427801961, \"phi\": 0.6170090358352109}, {\"truth_threshold\": 8.319999814033508, \"match_probability\": 0.9968805816077441, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115772.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38087780998220166, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6191221900177983, \"precision\": 0.9993094637986396, \"recall\": 0.38087780998220166, \"specificity\": 0.999999937438308, \"npv\": 0.9998528538675674, \"accuracy\": 0.9998528046488252, \"f1\": 0.5515408050727347, \"f2\": 0.43467878554865375, \"f0_5\": 0.7543437381494431, \"p4\": 0.7109402093108235, \"phi\": 0.6168943936040922}, {\"truth_threshold\": 8.339999813586473, \"match_probability\": 0.9969233954338881, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115701.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3806442273844342, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6193557726155658, \"precision\": 0.999309040343407, \"recall\": 0.3806442273844342, \"specificity\": 0.999999937438308, \"npv\": 0.9998527983604042, \"accuracy\": 0.9998527491385185, \"f1\": 0.5512957959889646, \"f2\": 0.4344353703182202, \"f0_5\": 0.7541602299614776, \"p4\": 0.7107366239264049, \"phi\": 0.6167050539894802}, {\"truth_threshold\": 8.359999813139439, \"match_probability\": 0.9969656234315248, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115638.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188323.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38043696395261234, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6195630360473876, \"precision\": 0.9993086641663353, \"recall\": 0.38043696395261234, \"specificity\": 0.999999937438308, \"npv\": 0.9998527491075745, \"accuracy\": 0.9998526998828943, \"f1\": 0.5510783241477415, \"f2\": 0.4342193604203184, \"f0_5\": 0.7539972849368768, \"p4\": 0.7105558661894337, \"phi\": 0.6165369997455944}, {\"truth_threshold\": 8.379999812692404, \"match_probability\": 0.9970072735678748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115571.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3802165409378177, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6197834590621824, \"precision\": 0.9993082636553078, \"recall\": 0.3802165409378177, \"specificity\": 0.999999937438308, \"npv\": 0.9998526967275863, \"accuracy\": 0.9998526474999287, \"f1\": 0.5508469729178384, \"f2\": 0.4339896131791708, \"f0_5\": 0.7538238766445116, \"p4\": 0.7103635165720064, \"phi\": 0.6163582251318559}, {\"truth_threshold\": 8.399999812245369, \"match_probability\": 0.9970483537031342, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115541.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188420.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38011784406552157, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6198821559344785, \"precision\": 0.9993080841715606, \"recall\": 0.38011784406552157, \"specificity\": 0.999999937438308, \"npv\": 0.999852673273862, \"accuracy\": 0.9998526240448696, \"f1\": 0.5507433588666816, \"f2\": 0.43388673378571724, \"f0_5\": 0.7537461918337258, \"p4\": 0.710277351361487, \"phi\": 0.6162781599942025}, {\"truth_threshold\": 8.419999811798334, \"match_probability\": 0.997088871591877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115502.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37998953813153663, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6200104618684634, \"precision\": 0.9993078507033967, \"recall\": 0.37998953813153663, \"specificity\": 0.999999937438308, \"npv\": 0.999852642784022, \"accuracy\": 0.9998525935532927, \"f1\": 0.5506086384470722, \"f2\": 0.43375298364310144, \"f0_5\": 0.7536451652052946, \"p4\": 0.7101653009479617, \"phi\": 0.6161740597675232}, {\"truth_threshold\": 8.4399998113513, \"match_probability\": 0.9971288348844387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115433.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37976253532525556, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6202374646747445, \"precision\": 0.9993074372581441, \"recall\": 0.37976253532525556, \"specificity\": 0.999999937438308, \"npv\": 0.9998525888404636, \"accuracy\": 0.9998525396066567, \"f1\": 0.5503702255682116, \"f2\": 0.43351632957951924, \"f0_5\": 0.7534663249840408, \"p4\": 0.7099669591508472, \"phi\": 0.6159898393623987}, {\"truth_threshold\": 8.459999810904264, \"match_probability\": 0.997168251128283, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115387.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37961120012106814, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6203887998789318, \"precision\": 0.9993158159111774, \"recall\": 0.37961120012106814, \"specificity\": 0.9999999382203291, \"npv\": 0.9998525528782097, \"accuracy\": 0.9998525044240678, \"f1\": 0.5502125518862638, \"f2\": 0.43335887208839413, \"f0_5\": 0.7533509613815167, \"p4\": 0.7098357529161158, \"phi\": 0.6158696630544942}, {\"truth_threshold\": 8.47999981045723, \"match_probability\": 0.9972071277693515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115352.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188609.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.379496053770056, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.620503946229944, \"precision\": 0.9993156084587329, \"recall\": 0.379496053770056, \"specificity\": 0.9999999382203291, \"npv\": 0.9998525255155394, \"accuracy\": 0.9998524770598322, \"f1\": 0.5500915611170456, \"f2\": 0.43323881241666823, \"f0_5\": 0.7532601526737497, \"p4\": 0.709735053776624, \"phi\": 0.6157761786296612}, {\"truth_threshold\": 8.499999810010195, \"match_probability\": 0.9972454721533973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115297.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188664.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3793151095041798, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6206848904958202, \"precision\": 0.9993152822077381, \"recall\": 0.3793151095041798, \"specificity\": 0.9999999382203291, \"npv\": 0.9998524825170605, \"accuracy\": 0.9998524340588903, \"f1\": 0.5499013919592118, \"f2\": 0.43305013446312407, \"f0_5\": 0.7531173861639657, \"p4\": 0.7095767465383348, \"phi\": 0.6156292458626197}, {\"truth_threshold\": 8.51999980956316, \"match_probability\": 0.9972832915273011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115206.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3790157289915483, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6209842710084518, \"precision\": 0.9993147417270243, \"recall\": 0.3790157289915483, \"specificity\": 0.9999999382203291, \"npv\": 0.9998524113741307, \"accuracy\": 0.9998523629118775, \"f1\": 0.5495866388707346, \"f2\": 0.432737923972808, \"f0_5\": 0.7528809921827314, \"p4\": 0.7093146434382982, \"phi\": 0.6153860619065289}, {\"truth_threshold\": 8.539999809116125, \"match_probability\": 0.9973205930403709, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115159.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3788611038916177, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6211388961083824, \"precision\": 0.9993144622433572, \"recall\": 0.3788611038916177, \"specificity\": 0.9999999382203291, \"npv\": 0.9998523746299841, \"accuracy\": 0.9998523261656181, \"f1\": 0.5494240205725681, \"f2\": 0.4325766556831209, \"f0_5\": 0.7527588104791002, \"p4\": 0.7091791852280301, \"phi\": 0.6152604237731626}, {\"truth_threshold\": 8.55999980866909, \"match_probability\": 0.9973573837456264, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115092.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188869.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.378640680876823, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.621359319123177, \"precision\": 0.9993140634361081, \"recall\": 0.378640680876823, \"specificity\": 0.9999999382203291, \"npv\": 0.9998523222500352, \"accuracy\": 0.9998522737826526, \"f1\": 0.5491921399463654, \"f2\": 0.432346742899216, \"f0_5\": 0.7525845326916413, \"p4\": 0.7089859835260549, \"phi\": 0.6150812782529356}, {\"truth_threshold\": 8.579999808222055, \"match_probability\": 0.9973936706010663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115053.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188908.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37851237494283807, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6214876250571619, \"precision\": 0.9993225108789119, \"recall\": 0.37851237494283807, \"specificity\": 0.9999999390023502, \"npv\": 0.9998522917603321, \"accuracy\": 0.9998522440729111, \"f1\": 0.549058440628788, \"f2\": 0.43221322714551363, \"f0_5\": 0.752486968351243, \"p4\": 0.7088745597421451, \"phi\": 0.6149796472914425}, {\"truth_threshold\": 8.59999980777502, \"match_probability\": 0.9974294604709201, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115017.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37839393869608273, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6216060613039173, \"precision\": 0.9993222989704157, \"recall\": 0.37839393869608273, \"specificity\": 0.9999999390023502, \"npv\": 0.999852263615886, \"accuracy\": 0.99985221592684, \"f1\": 0.5489337940513918, \"f2\": 0.4320896750339422, \"f0_5\": 0.7523932380966087, \"p4\": 0.7087706630484012, \"phi\": 0.6148833525431195}, {\"truth_threshold\": 8.619999807327986, \"match_probability\": 0.9974647601268845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114945.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37815706620257206, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6218429337974279, \"precision\": 0.9993218747554837, \"recall\": 0.37815706620257206, \"specificity\": 0.9999999390023502, \"npv\": 0.9998522073269983, \"accuracy\": 0.999852159634698, \"f1\": 0.5486844366371986, \"f2\": 0.4318425507582651, \"f0_5\": 0.7522056715960804, \"p4\": 0.7085627659115207, \"phi\": 0.6146907178074911}, {\"truth_threshold\": 8.639999806880951, \"match_probability\": 0.9974995762493434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114912.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3780484996430463, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6219515003569537, \"precision\": 0.9993216801460997, \"recall\": 0.3780484996430463, \"specificity\": 0.9999999390023502, \"npv\": 0.999852181527927, \"accuracy\": 0.999852133834133, \"f1\": 0.5485701191786152, \"f2\": 0.43172927652885335, \"f0_5\": 0.7521196563519003, \"p4\": 0.7084674334627182, \"phi\": 0.6146024067160469}, {\"truth_threshold\": 8.659999806433916, \"match_probability\": 0.9975339154285738, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114876.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189085.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.377930063396291, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.622069936603709, \"precision\": 0.9993214677175218, \"recall\": 0.377930063396291, \"specificity\": 0.9999999390023502, \"npv\": 0.999852153383487, \"accuracy\": 0.9998521056880619, \"f1\": 0.5484453886826683, \"f2\": 0.43160569823519424, \"f0_5\": 0.7520257876317302, \"p4\": 0.7083634012422568, \"phi\": 0.6145060528744719}, {\"truth_threshold\": 8.679999805986881, \"match_probability\": 0.9975677841659352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114838.0, \"tn\": 1278737717.0, \"fp\": 75.0, \"fn\": 189123.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3778050473580492, \"tn_rate\": 0.9999999413484136, \"fp_rate\": 5.86515863292793e-08, \"fn_rate\": 0.6221949526419508, \"precision\": 0.9993473323296755, \"recall\": 0.3778050473580492, \"specificity\": 0.9999999413484136, \"npv\": 0.9998521236758156, \"accuracy\": 0.9998520783238263, \"f1\": 0.548317632510015, \"f2\": 0.4314762199259519, \"f0_5\": 0.7519384819273637, \"p4\": 0.708256828247378, \"phi\": 0.6144123527336168}, {\"truth_threshold\": 8.699999805539846, \"match_probability\": 0.9976011888750448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114772.0, \"tn\": 1278737718.0, \"fp\": 74.0, \"fn\": 189189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3775879142389978, \"tn_rate\": 0.9999999421304349, \"fp_rate\": 5.786956517822224e-08, \"fn_rate\": 0.6224120857610023, \"precision\": 0.9993556588823294, \"recall\": 0.3775879142389978, \"specificity\": 0.9999999421304349, \"npv\": 0.9998520720777986, \"accuracy\": 0.9998520275045314, \"f1\": 0.5480901704126244, \"f2\": 0.43124995303188574, \"f0_5\": 0.7517701694515586, \"p4\": 0.7080670377127452, \"phi\": 0.6142383130357464}, {\"truth_threshold\": 8.719999805092812, \"match_probability\": 0.9976341358829378, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114727.0, \"tn\": 1278737718.0, \"fp\": 74.0, \"fn\": 189234.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3774398689305536, \"tn_rate\": 0.9999999421304349, \"fp_rate\": 5.786956517822224e-08, \"fn_rate\": 0.6225601310694464, \"precision\": 0.9993554063117918, \"recall\": 0.3774398689305536, \"specificity\": 0.9999999421304349, \"npv\": 0.9998520368972567, \"accuracy\": 0.9998519923219426, \"f1\": 0.5479341487527521, \"f2\": 0.4310954461933874, \"f0_5\": 0.7516526570269862, \"p4\": 0.7079368235850003, \"phi\": 0.6141177969865036}, {\"truth_threshold\": 8.739999804645777, \"match_probability\": 0.9976666314312127, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114662.0, \"tn\": 1278737718.0, \"fp\": 74.0, \"fn\": 189299.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37722602570724534, \"tn_rate\": 0.9999999421304349, \"fp_rate\": 5.786956517822224e-08, \"fn_rate\": 0.6227739742927547, \"precision\": 0.9993550411379166, \"recall\": 0.37722602570724534, \"specificity\": 0.9999999421304349, \"npv\": 0.9998519860809227, \"accuracy\": 0.9998519415026478, \"f1\": 0.5477087249251845, \"f2\": 0.43087225119872535, \"f0_5\": 0.7514828189617317, \"p4\": 0.707748640736367, \"phi\": 0.6139436764987795}, {\"truth_threshold\": 8.759999804198742, \"match_probability\": 0.997698681677162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114602.0, \"tn\": 1278737718.0, \"fp\": 74.0, \"fn\": 189359.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3770286319626531, \"tn_rate\": 0.9999999421304349, \"fp_rate\": 5.786956517822224e-08, \"fn_rate\": 0.6229713680373469, \"precision\": 0.9993547036869092, \"recall\": 0.3770286319626531, \"specificity\": 0.9999999421304349, \"npv\": 0.9998519391735421, \"accuracy\": 0.9998518945925294, \"f1\": 0.5475005792607915, \"f2\": 0.43066620569401437, \"f0_5\": 0.7513259425829165, \"p4\": 0.707574832948861, \"phi\": 0.6137829060686012}, {\"truth_threshold\": 8.779999803751707, \"match_probability\": 0.9977302926948894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114548.0, \"tn\": 1278737718.0, \"fp\": 74.0, \"fn\": 189413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3768509775925201, \"tn_rate\": 0.9999999421304349, \"fp_rate\": 5.786956517822224e-08, \"fn_rate\": 0.6231490224074799, \"precision\": 0.9993543996789447, \"recall\": 0.3768509775925201, \"specificity\": 0.9999999421304349, \"npv\": 0.9998518969569034, \"accuracy\": 0.9998518523734229, \"f1\": 0.5473131971436968, \"f2\": 0.4304807488504028, \"f0_5\": 0.7511846694008386, \"p4\": 0.707418323346302, \"phi\": 0.613638176680841}, {\"truth_threshold\": 8.799999803304672, \"match_probability\": 0.9977614704764116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114498.0, \"tn\": 1278737718.0, \"fp\": 74.0, \"fn\": 189463.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3766864828053599, \"tn_rate\": 0.9999999421304349, \"fp_rate\": 5.786956517822224e-08, \"fn_rate\": 0.6233135171946401, \"precision\": 0.9993541179345738, \"recall\": 0.3766864828053599, \"specificity\": 0.9999999421304349, \"npv\": 0.9998518578674261, \"accuracy\": 0.9998518132816576, \"f1\": 0.547139652070446, \"f2\": 0.4303090161272865, \"f0_5\": 0.7510537895097271, \"p4\": 0.707273337227278, \"phi\": 0.61350413755682}, {\"truth_threshold\": 8.819999802857637, \"match_probability\": 0.997792220932747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114437.0, \"tn\": 1278737719.0, \"fp\": 73.0, \"fn\": 189524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37648579916502445, \"tn_rate\": 0.999999942912456, \"fp_rate\": 5.708754402716519e-08, \"fn_rate\": 0.6235142008349756, \"precision\": 0.9993625010916077, \"recall\": 0.37648579916502445, \"specificity\": 0.999999942912456, \"npv\": 0.999851810178384, \"accuracy\": 0.9998517663715393, \"f1\": 0.5469291778880735, \"f2\": 0.430099808021023, \"f0_5\": 0.7508979647008337, \"p4\": 0.7070974555497124, \"phi\": 0.6133432493089993}, {\"truth_threshold\": 8.839999802410603, \"match_probability\": 0.9978225498949904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114378.0, \"tn\": 1278737719.0, \"fp\": 73.0, \"fn\": 189583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37629169531617546, \"tn_rate\": 0.999999942912456, \"fp_rate\": 5.708754402716519e-08, \"fn_rate\": 0.6237083046838245, \"precision\": 0.9993621724580825, \"recall\": 0.37629169531617546, \"specificity\": 0.999999942912456, \"npv\": 0.9998517640528093, \"accuracy\": 0.9998517202432562, \"f1\": 0.5467242813303633, \"f2\": 0.4298971280806137, \"f0_5\": 0.7507433394813361, \"p4\": 0.7069261887519315, \"phi\": 0.6131850039837595}, {\"truth_threshold\": 8.859999801963568, \"match_probability\": 0.9978524631153733, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114308.0, \"tn\": 1278737719.0, \"fp\": 73.0, \"fn\": 189653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37606140261415116, \"tn_rate\": 0.999999942912456, \"fp_rate\": 5.708754402716519e-08, \"fn_rate\": 0.6239385973858489, \"precision\": 0.9993617821141623, \"recall\": 0.37606140261415116, \"specificity\": 0.999999942912456, \"npv\": 0.9998517093275567, \"accuracy\": 0.9998516655147848, \"f1\": 0.5464811087579062, \"f2\": 0.42965663703508805, \"f0_5\": 0.7505597615186117, \"p4\": 0.7067228693150223, \"phi\": 0.6129972023263335}, {\"truth_threshold\": 8.879999801516533, \"match_probability\": 0.997881966268312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114259.0, \"tn\": 1278737719.0, \"fp\": 73.0, \"fn\": 189702.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37590019772273414, \"tn_rate\": 0.999999942912456, \"fp_rate\": 5.708754402716519e-08, \"fn_rate\": 0.6240998022772658, \"precision\": 0.9993615085890214, \"recall\": 0.37590019772273414, \"specificity\": 0.999999942912456, \"npv\": 0.9998516710198835, \"accuracy\": 0.9998516272048549, \"f1\": 0.546310839531142, \"f2\": 0.42948827824287916, \"f0_5\": 0.7504311765965356, \"p4\": 0.7065804671607825, \"phi\": 0.6128657069371094}, {\"truth_threshold\": 8.899999801069498, \"match_probability\": 0.9979110649514407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114188.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189773.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3756666151249667, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6243333848750333, \"precision\": 0.9994310871486963, \"recall\": 0.3756666151249667, \"specificity\": 0.9999999491686252, \"npv\": 0.9998516155137801, \"accuracy\": 0.9998515779492305, \"f1\": 0.5460744977451735, \"f2\": 0.4292468895125694, \"f0_5\": 0.7502762910116391, \"p4\": 0.7063827547079619, \"phi\": 0.6126965804272352}, {\"truth_threshold\": 8.919999800622463, \"match_probability\": 0.9979397646866325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114119.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3754396123186856, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6245603876813144, \"precision\": 0.9994307433615918, \"recall\": 0.3754396123186856, \"specificity\": 0.9999999491686252, \"npv\": 0.9998515615703332, \"accuracy\": 0.9998515240025945, \"f1\": 0.5458345789140131, \"f2\": 0.42900976520795053, \"f0_5\": 0.7500949786840226, \"p4\": 0.706181987545036, \"phi\": 0.6125113144797173}, {\"truth_threshold\": 8.939999800175428, \"match_probability\": 0.9979680709210076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114041.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189920.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37518300045071573, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6248169995492843, \"precision\": 0.9994303542320299, \"recall\": 0.37518300045071573, \"specificity\": 0.9999999491686252, \"npv\": 0.9998515005907914, \"accuracy\": 0.9998514630194406, \"f1\": 0.5455632709589612, \"f2\": 0.42874168201812096, \"f0_5\": 0.7498898584269811, \"p4\": 0.7059548784742672, \"phi\": 0.6123018159319079}, {\"truth_threshold\": 8.959999799728394, \"match_probability\": 0.9979959890279272, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114006.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37506785409970356, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6249321459002964, \"precision\": 0.999430179449641, \"recall\": 0.37506785409970356, \"specificity\": 0.9999999491686252, \"npv\": 0.999851473228179, \"accuracy\": 0.999851435655205, \"f1\": 0.5454414973016419, \"f2\": 0.42862137805799616, \"f0_5\": 0.7497977625633842, \"p4\": 0.7058529170872694, \"phi\": 0.6122077868797611}, {\"truth_threshold\": 8.979999799281359, \"match_probability\": 0.9980235243079757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113906.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190055.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3747388645253832, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6252611354746168, \"precision\": 0.999438448714574, \"recall\": 0.3747388645253832, \"specificity\": 0.9999999499506463, \"npv\": 0.9998513950494107, \"accuracy\": 0.9998513582535097, \"f1\": 0.5450947644467627, \"f2\": 0.4282779396216313, \"f0_5\": 0.7495383902684903, \"p4\": 0.7055625088451118, \"phi\": 0.6119417385422017}, {\"truth_threshold\": 8.999999798834324, \"match_probability\": 0.9980506819899304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113865.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190096.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3746039787999118, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6253960212000882, \"precision\": 0.9994382466272854, \"recall\": 0.3746039787999118, \"specificity\": 0.9999999499506463, \"npv\": 0.9998513629960716, \"accuracy\": 0.9998513261982621, \"f1\": 0.5449520208667352, \"f2\": 0.4281369827782637, \"f0_5\": 0.7494303500040148, \"p4\": 0.7054429151811685, \"phi\": 0.6118315239708733}, {\"truth_threshold\": 9.019999798387289, \"match_probability\": 0.9980774672317183, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113783.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3743342073489691, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6256657926510308, \"precision\": 0.999437842016039, \"recall\": 0.3743342073489691, \"specificity\": 0.9999999499506463, \"npv\": 0.9998512988893996, \"accuracy\": 0.9998512620877671, \"f1\": 0.5446664496610883, \"f2\": 0.4278550430137528, \"f0_5\": 0.7492141294714288, \"p4\": 0.7052035911046661, \"phi\": 0.6116110352662827}, {\"truth_threshold\": 9.039999797940254, \"match_probability\": 0.99810388512136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113705.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190256.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3740775954809992, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6259224045190008, \"precision\": 0.9994374566006557, \"recall\": 0.3740775954809992, \"specificity\": 0.9999999499506463, \"npv\": 0.9998512379098901, \"accuracy\": 0.9998512011046132, \"f1\": 0.544394704713571, \"f2\": 0.4275868241360456, \"f0_5\": 0.7490082828636813, \"p4\": 0.7049757720081047, \"phi\": 0.6114012283436291}, {\"truth_threshold\": 9.05999979749322, \"match_probability\": 0.9981299406779027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113633.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190328.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37384072298748855, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6261592770125115, \"precision\": 0.9994371003632462, \"recall\": 0.37384072298748855, \"specificity\": 0.9999999499506463, \"npv\": 0.9998511816211185, \"accuracy\": 0.9998511448124712, \"f1\": 0.5441437731349573, \"f2\": 0.42733920954675336, \"f0_5\": 0.7488181203533711, \"p4\": 0.7047653307331657, \"phi\": 0.6112074965150768}, {\"truth_threshold\": 9.079999797046185, \"match_probability\": 0.9981556388523408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113561.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190400.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3736038504939778, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6263961495060222, \"precision\": 0.9994367436743674, \"recall\": 0.3736038504939778, \"specificity\": 0.9999999499506463, \"npv\": 0.9998511253323533, \"accuracy\": 0.9998510885203292, \"f1\": 0.5438927550253122, \"f2\": 0.4270915681373541, \"f0_5\": 0.7486278134274538, \"p4\": 0.7045547484574162, \"phi\": 0.6110137032826028}, {\"truth_threshold\": 9.09999979659915, \"match_probability\": 0.9981809845285239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113483.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190478.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37334723862600794, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6266527613739921, \"precision\": 0.9994539609846317, \"recall\": 0.37334723862600794, \"specificity\": 0.9999999515146887, \"npv\": 0.9998510643530978, \"accuracy\": 0.9998510291008459, \"f1\": 0.54362332517377, \"f2\": 0.4268239018075221, \"f0_5\": 0.7484293818695995, \"p4\": 0.7043286442626766, \"phi\": 0.6108090727087466}, {\"truth_threshold\": 9.119999796152115, \"match_probability\": 0.9982059825240535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113433.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37318274383884775, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6268172561611522, \"precision\": 0.9994537204282127, \"recall\": 0.37318274383884775, \"specificity\": 0.9999999515146887, \"npv\": 0.9998510252636861, \"accuracy\": 0.9998509900090806, \"f1\": 0.5434488904219846, \"f2\": 0.4266518924066773, \"f0_5\": 0.7482970310353972, \"p4\": 0.7041822173142841, \"phi\": 0.6106744128231368}, {\"truth_threshold\": 9.13999979570508, \"match_probability\": 0.9982306375911687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113387.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3730314086346604, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6269685913653397, \"precision\": 0.9994534989290342, \"recall\": 0.3730314086346604, \"specificity\": 0.9999999515146887, \"npv\": 0.99985098930143, \"accuracy\": 0.9998509540446566, \"f1\": 0.5432883735416018, \"f2\": 0.42649363232936605, \"f0_5\": 0.7481752065635817, \"p4\": 0.7040474442988846, \"phi\": 0.6105504995067641}, {\"truth_threshold\": 9.159999795258045, \"match_probability\": 0.9982549544176195, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113296.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190665.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3727320281220288, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6272679718779712, \"precision\": 0.9994530602163059, \"recall\": 0.3727320281220288, \"specificity\": 0.9999999515146887, \"npv\": 0.9998509181587136, \"accuracy\": 0.9998508828976438, \"f1\": 0.5429707250328885, \"f2\": 0.42618052034228054, \"f0_5\": 0.7479340316057845, \"p4\": 0.7037806579503083, \"phi\": 0.6103052925532995}, {\"truth_threshold\": 9.17999979481101, \"match_probability\": 0.9982789376275292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113236.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37253463437743656, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6274653656225634, \"precision\": 0.9994527705696482, \"recall\": 0.37253463437743656, \"specificity\": 0.9999999515146887, \"npv\": 0.9998508712514337, \"accuracy\": 0.9998508359875254, \"f1\": 0.5427612106629216, \"f2\": 0.4259740494243655, \"f0_5\": 0.7477748882986662, \"p4\": 0.7036046310870548, \"phi\": 0.6101435637506221}, {\"truth_threshold\": 9.199999794363976, \"match_probability\": 0.9983025917822457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113174.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37233066084135796, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6276693391586421, \"precision\": 0.9994524709456357, \"recall\": 0.37233066084135796, \"specificity\": 0.9999999515146887, \"npv\": 0.9998508227805823, \"accuracy\": 0.9998507875137365, \"f1\": 0.5425446491705357, \"f2\": 0.4257606765582207, \"f0_5\": 0.7476103341898918, \"p4\": 0.7034226332209136, \"phi\": 0.6099763989553179}, {\"truth_threshold\": 9.21999979391694, \"match_probability\": 0.9983259213811816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113131.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37218919532440015, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6278108046755998, \"precision\": 0.9994522629491223, \"recall\": 0.37218919532440015, \"specificity\": 0.9999999515146887, \"npv\": 0.9998507891637043, \"accuracy\": 0.9998507538948184, \"f1\": 0.542394415491641, \"f2\": 0.425612680459611, \"f0_5\": 0.7474961446111111, \"p4\": 0.7032963471024289, \"phi\": 0.6098604351813376}, {\"truth_threshold\": 9.239999793469906, \"match_probability\": 0.9983489308626438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113091.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.372057599494672, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.627942400505328, \"precision\": 0.9994520693220683, \"recall\": 0.372057599494672, \"specificity\": 0.9999999515146887, \"npv\": 0.9998507578921919, \"accuracy\": 0.9998507226214061, \"f1\": 0.5422546354234095, \"f2\": 0.4254750010722372, \"f0_5\": 0.7473898751343228, \"p4\": 0.7031788261753641, \"phi\": 0.6097525421103777}, {\"truth_threshold\": 9.259999793022871, \"match_probability\": 0.9983716246046509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113031.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 190930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3718602057500798, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6281397942499202, \"precision\": 0.9994606161355357, \"recall\": 0.3718602057500798, \"specificity\": 0.9999999522967098, \"npv\": 0.9998507109850437, \"accuracy\": 0.9998506764931231, \"f1\": 0.5420462147496841, \"f2\": 0.42526878645773764, \"f0_5\": 0.7472343384955489, \"p4\": 0.7030035557477143, \"phi\": 0.609593362858394}, {\"truth_threshold\": 9.279999792575836, \"match_probability\": 0.9983940069257424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112988.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 190973.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.371718740233122, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.628281259766878, \"precision\": 0.9994604109722333, \"recall\": 0.371718740233122, \"specificity\": 0.9999999522967098, \"npv\": 0.9998506773681733, \"accuracy\": 0.9998506428742049, \"f1\": 0.5418958777966956, \"f2\": 0.42512075840568053, \"f0_5\": 0.747119976407016, \"p4\": 0.7028771011082203, \"phi\": 0.6094773262299913}, {\"truth_threshold\": 9.299999792128801, \"match_probability\": 0.9984160820857753, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112926.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191035.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37151476669704336, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6284852333029566, \"precision\": 0.9994601148804729, \"recall\": 0.37151476669704336, \"specificity\": 0.9999999522967098, \"npv\": 0.9998506288973408, \"accuracy\": 0.9998505944004159, \"f1\": 0.541679058299836, \"f2\": 0.42490730574467334, \"f0_5\": 0.7469549906139495, \"p4\": 0.7026946818193822, \"phi\": 0.6093099787153112}, {\"truth_threshold\": 9.319999791681767, \"match_probability\": 0.9984378542867104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112882.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191079.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3713700112843424, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6286299887156576, \"precision\": 0.9994599045536244, \"recall\": 0.3713700112843424, \"specificity\": 0.9999999522967098, \"npv\": 0.9998505944986883, \"accuracy\": 0.9998505599996625, \"f1\": 0.5415251472761116, \"f2\": 0.42475581112699023, \"f0_5\": 0.7468378382312272, \"p4\": 0.7025651589157786, \"phi\": 0.6091911880840206}, {\"truth_threshold\": 9.339999791234732, \"match_probability\": 0.9984593276733903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112836.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.371218676080155, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.628781323919845, \"precision\": 0.9994596844911734, \"recall\": 0.371218676080155, \"specificity\": 0.9999999522967098, \"npv\": 0.9998505585364633, \"accuracy\": 0.9998505240352384, \"f1\": 0.5413642055568083, \"f2\": 0.42459741966267317, \"f0_5\": 0.7467153023827707, \"p4\": 0.7024296917100531, \"phi\": 0.6090669731151663}, {\"truth_threshold\": 9.359999790787697, \"match_probability\": 0.9984805063343047, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112758.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191203.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37096206421218514, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6290379357878149, \"precision\": 0.9994593109316693, \"recall\": 0.37096206421218514, \"specificity\": 0.9999999522967098, \"npv\": 0.9998504975570441, \"accuracy\": 0.9998504630520846, \"f1\": 0.5410912231872931, \"f2\": 0.4243288177664314, \"f0_5\": 0.7465073877471575, \"p4\": 0.7021998534183108, \"phi\": 0.6088562898370113}, {\"truth_threshold\": 9.379999790340662, \"match_probability\": 0.9985013943023475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112729.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191232.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3708666572356322, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6291333427643678, \"precision\": 0.9994591719124036, \"recall\": 0.3708666572356322, \"specificity\": 0.9999999522967098, \"npv\": 0.9998504748852106, \"accuracy\": 0.9998504403788607, \"f1\": 0.5409897036839744, \"f2\": 0.4242289449163577, \"f0_5\": 0.7464300423375856, \"p4\": 0.702114358010556, \"phi\": 0.6087779402875841}, {\"truth_threshold\": 9.399999789893627, \"match_probability\": 0.9985219955555633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112672.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37067913317826956, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6293208668217304, \"precision\": 0.9994588984591912, \"recall\": 0.37067913317826956, \"specificity\": 0.9999999522967098, \"npv\": 0.9998504303233341, \"accuracy\": 0.9998503958142483, \"f1\": 0.5407901241678545, \"f2\": 0.42403263040079725, \"f0_5\": 0.7462779493252686, \"p4\": 0.7019462477899562, \"phi\": 0.6086239135128704}, {\"truth_threshold\": 9.419999789446592, \"match_probability\": 0.998542314017884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112620.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191341.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.370508058599623, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.629491941400377, \"precision\": 0.999458648751786, \"recall\": 0.370508058599623, \"specificity\": 0.9999999522967098, \"npv\": 0.9998503896703976, \"accuracy\": 0.9998503551588124, \"f1\": 0.5406080039938365, \"f2\": 0.4238535217628573, \"f0_5\": 0.7461391176451102, \"p4\": 0.701792805955711, \"phi\": 0.6084833638617659}, {\"truth_threshold\": 9.439999788999557, \"match_probability\": 0.9985623535598561, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112571.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37034685370820597, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.629653146291794, \"precision\": 0.9994584132395766, \"recall\": 0.37034685370820597, \"specificity\": 0.9999999522967098, \"npv\": 0.9998503513628259, \"accuracy\": 0.9998503168488824, \"f1\": 0.5404363491465292, \"f2\": 0.42368473348408253, \"f0_5\": 0.7460082254346981, \"p4\": 0.7016481482706224, \"phi\": 0.6083508931391636}, {\"truth_threshold\": 9.459999788552523, \"match_probability\": 0.9985821179993586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112526.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191435.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3701988083997618, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6298011916002382, \"precision\": 0.9994581967722739, \"recall\": 0.3701988083997618, \"specificity\": 0.9999999522967098, \"npv\": 0.9998503161824054, \"accuracy\": 0.9998502816662936, \"f1\": 0.5402786713656049, \"f2\": 0.4235297128718014, \"f0_5\": 0.745887958383103, \"p4\": 0.701515240989536, \"phi\": 0.6082292109470377}, {\"truth_threshold\": 9.479999788105488, \"match_probability\": 0.9986016111023109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112447.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191514.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3699389066360487, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6300610933639513, \"precision\": 0.9994578163330607, \"recall\": 0.3699389066360487, \"specificity\": 0.9999999522967098, \"npv\": 0.9998502544212288, \"accuracy\": 0.9998502199013045, \"f1\": 0.5400017768429343, \"f2\": 0.4232575401700754, \"f0_5\": 0.7456766840010451, \"p4\": 0.7012817795504089, \"phi\": 0.6080155322170134}, {\"truth_threshold\": 9.499999787658453, \"match_probability\": 0.998620836583372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112391.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191570.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3697546724744293, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6302453275255707, \"precision\": 0.9994575463308789, \"recall\": 0.3697546724744293, \"specificity\": 0.9999999522967098, \"npv\": 0.9998502106411589, \"accuracy\": 0.9998501761185273, \"f1\": 0.539805433547944, \"f2\": 0.42306458801351504, \"f0_5\": 0.7455268125911254, \"p4\": 0.7011161833744035, \"phi\": 0.6078640182722486}, {\"truth_threshold\": 9.519999787211418, \"match_probability\": 0.99863979810663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112321.0, \"tn\": 1278737732.0, \"fp\": 60.0, \"fn\": 191640.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.369524379772405, \"tn_rate\": 0.9999999530787309, \"fp_rate\": 4.692126906342344e-08, \"fn_rate\": 0.630475620227595, \"precision\": 0.9994661019211433, \"recall\": 0.369524379772405, \"specificity\": 0.9999999530787309, \"npv\": 0.999850155916194, \"accuracy\": 0.9998501221718913, \"f1\": 0.5395612261073829, \"f2\": 0.4228236932748593, \"f0_5\": 0.7453433047771356, \"p4\": 0.7009101596504578, \"phi\": 0.6076772774134604}, {\"truth_threshold\": 9.539999786764383, \"match_probability\": 0.9986584992862828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112260.0, \"tn\": 1278737732.0, \"fp\": 60.0, \"fn\": 191701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36932369613206956, \"tn_rate\": 0.9999999530787309, \"fp_rate\": 4.692126906342344e-08, \"fn_rate\": 0.6306763038679304, \"precision\": 0.999465811965812, \"recall\": 0.36932369613206956, \"specificity\": 0.9999999530787309, \"npv\": 0.9998501082271988, \"accuracy\": 0.9998500744799377, \"f1\": 0.5393472197866345, \"f2\": 0.42261347243262126, \"f0_5\": 0.745179829563181, \"p4\": 0.7007295610803272, \"phi\": 0.6075121417388559}, {\"truth_threshold\": 9.559999786317348, \"match_probability\": 0.9986769436873105, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112191.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 191770.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3690966933257885, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6309033066742115, \"precision\": 0.9994832916106157, \"recall\": 0.3690966933257885, \"specificity\": 0.9999999546427732, \"npv\": 0.9998500542841492, \"accuracy\": 0.9998500220969722, \"f1\": 0.5391076619975493, \"f2\": 0.4223762944311882, \"f0_5\": 0.7450027026775765, \"p4\": 0.7005273403427477, \"phi\": 0.607330707418096}, {\"truth_threshold\": 9.579999785870314, \"match_probability\": 0.9986951348261374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112113.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 191848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3688400814578186, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6311599185421815, \"precision\": 0.9994829323087072, \"recall\": 0.3688400814578186, \"specificity\": 0.9999999546427732, \"npv\": 0.9998499933047916, \"accuracy\": 0.9998499611138183, \"f1\": 0.5388338315726741, \"f2\": 0.42210743101546294, \"f0_5\": 0.7447933620764106, \"p4\": 0.7002961113964431, \"phi\": 0.6071194218271995}, {\"truth_threshold\": 9.599999785423279, \"match_probability\": 0.9987130761712866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112060.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 191901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3686657169834288, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6313342830165712, \"precision\": 0.9994826878824096, \"recall\": 0.3686657169834288, \"specificity\": 0.9999999546427732, \"npv\": 0.9998499518701043, \"accuracy\": 0.9998499196765471, \"f1\": 0.5386477087283905, \"f2\": 0.42192472374962536, \"f0_5\": 0.7446510187618034, \"p4\": 0.7001388978486386, \"phi\": 0.6069758140258522}, {\"truth_threshold\": 9.619999784976244, \"match_probability\": 0.998730771144026, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112011.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 191950.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3685045120920118, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6314954879079882, \"precision\": 0.999482461697704, \"recall\": 0.3685045120920118, \"specificity\": 0.9999999546427732, \"npv\": 0.9998499135625661, \"accuracy\": 0.9998498813666171, \"f1\": 0.5384755907025935, \"f2\": 0.4217557927364217, \"f0_5\": 0.7445193469611306, \"p4\": 0.6999934799898619, \"phi\": 0.6068430143258567}, {\"truth_threshold\": 9.63999978452921, \"match_probability\": 0.9987482231190045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111963.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 191998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.368346597096338, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.631653402903662, \"precision\": 0.9994822399371547, \"recall\": 0.368346597096338, \"specificity\": 0.9999999546427732, \"npv\": 0.9998498760368173, \"accuracy\": 0.9998498438385225, \"f1\": 0.5383069459736238, \"f2\": 0.42159029720641783, \"f0_5\": 0.7443902957934698, \"p4\": 0.6998509650672097, \"phi\": 0.6067128966497763}, {\"truth_threshold\": 9.659999784082174, \"match_probability\": 0.9987654354248814, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111906.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192055.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3681590730389754, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6318409269610246, \"precision\": 0.999481976349541, \"recall\": 0.3681590730389754, \"specificity\": 0.9999999546427732, \"npv\": 0.9998498314749943, \"accuracy\": 0.99984979927391, \"f1\": 0.5381066298010458, \"f2\": 0.42139375572371907, \"f0_5\": 0.7442369619202546, \"p4\": 0.6996816452718112, \"phi\": 0.6065583456685144}, {\"truth_threshold\": 9.67999978363514, \"match_probability\": 0.9987824113449463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111845.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36795838939863995, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.63204161060136, \"precision\": 0.9994816939670965, \"recall\": 0.36795838939863995, \"specificity\": 0.9999999546427732, \"npv\": 0.9998497837860302, \"accuracy\": 0.9998497515819563, \"f1\": 0.5378921955254602, \"f2\": 0.42118340316340386, \"f0_5\": 0.7440727647214576, \"p4\": 0.6995003430950165, \"phi\": 0.6063929053860202}, {\"truth_threshold\": 9.699999783188105, \"match_probability\": 0.9987991541177315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111779.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3677412562795885, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6322587437204115, \"precision\": 0.9994813880915976, \"recall\": 0.3677412562795885, \"specificity\": 0.9999999546427732, \"npv\": 0.9998497321881397, \"accuracy\": 0.9998496999808262, \"f1\": 0.5376601138052612, \"f2\": 0.4209557868192736, \"f0_5\": 0.7438949886132071, \"p4\": 0.6993040631959352, \"phi\": 0.6062138535896973}, {\"truth_threshold\": 9.71999978274107, \"match_probability\": 0.9988156669376159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111738.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36760637055411716, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6323936294458828, \"precision\": 0.9994811978961681, \"recall\": 0.36760637055411716, \"specificity\": 0.9999999546427732, \"npv\": 0.9998497001349074, \"accuracy\": 0.9998496679255786, \"f1\": 0.5375159047231917, \"f2\": 0.42081437739146155, \"f0_5\": 0.7437844890134395, \"p4\": 0.6991820705179301, \"phi\": 0.6061025978173267}, {\"truth_threshold\": 9.739999782294035, \"match_probability\": 0.9988319529554216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111658.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192303.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36734317889466084, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6326568211053392, \"precision\": 0.9994808263811809, \"recall\": 0.36734317889466084, \"specificity\": 0.9999999546427732, \"npv\": 0.999849637592021, \"accuracy\": 0.9998496053787542, \"f1\": 0.5372344392400831, \"f2\": 0.4205384314079966, \"f0_5\": 0.74356874105151, \"p4\": 0.6989439008103043, \"phi\": 0.6058854545830704}, {\"truth_threshold\": 9.759999781847, \"match_probability\": 0.9988480152790014, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111602.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192359.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3671589447330414, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6328410552669586, \"precision\": 0.9994805660039405, \"recall\": 0.3671589447330414, \"specificity\": 0.9999999546427732, \"npv\": 0.9998495938120052, \"accuracy\": 0.999849561595977, \"f1\": 0.537037348930877, \"f2\": 0.4203452494305102, \"f0_5\": 0.7434176080234373, \"p4\": 0.6987770755433219, \"phi\": 0.6057334080196334}, {\"truth_threshold\": 9.779999781399965, \"match_probability\": 0.9988638569738193, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111548.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3669812903629084, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6330187096370916, \"precision\": 0.9994803146784224, \"recall\": 0.3669812903629084, \"specificity\": 0.9999999546427732, \"npv\": 0.999849551595565, \"accuracy\": 0.9998495193768706, \"f1\": 0.5368472472549553, \"f2\": 0.4201589513729331, \"f0_5\": 0.7432717871492633, \"p4\": 0.6986161252062995, \"phi\": 0.6055867555491857}, {\"truth_threshold\": 9.79999978095293, \"match_probability\": 0.9988794810635239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111477.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192484.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36674770776514093, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.6332522922348591, \"precision\": 0.9994979064492123, \"recall\": 0.36674770776514093, \"specificity\": 0.9999999562068156, \"npv\": 0.9998494960890048, \"accuracy\": 0.9998494654302345, \"f1\": 0.5365998064954006, \"f2\": 0.4199146135574144, \"f0_5\": 0.7430878571057189, \"p4\": 0.6984065689822996, \"phi\": 0.6053993106845543}, {\"truth_threshold\": 9.819999780505896, \"match_probability\": 0.998894890530513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111430.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192531.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36659308266521035, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.6334069173347897, \"precision\": 0.9994976947778197, \"recall\": 0.36659308266521035, \"specificity\": 0.9999999562068156, \"npv\": 0.9998494593450731, \"accuracy\": 0.9998494286839751, \"f1\": 0.5364342503375882, \"f2\": 0.4197524353401189, \"f0_5\": 0.742960775031504, \"p4\": 0.698266322614878, \"phi\": 0.6052716002903342}, {\"truth_threshold\": 9.83999978005886, \"match_probability\": 0.9989100883164911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111324.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192637.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3662443537164307, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.6337556462835693, \"precision\": 0.9994972167355001, \"recall\": 0.3662443537164307, \"specificity\": 0.9999999562068156, \"npv\": 0.9998493764757904, \"accuracy\": 0.9998493458094327, \"f1\": 0.5360607308211807, \"f2\": 0.41938662953653644, \"f0_5\": 0.742673930359809, \"p4\": 0.6979497947502342, \"phi\": 0.6049834736625589}, {\"truth_threshold\": 9.859999779611826, \"match_probability\": 0.9989250773230202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111279.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192682.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36609630840798657, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.6339036915920134, \"precision\": 0.9994970135177617, \"recall\": 0.36609630840798657, \"specificity\": 0.9999999562068156, \"npv\": 0.9998493412954387, \"accuracy\": 0.9998493106268439, \"f1\": 0.5359021035598706, \"f2\": 0.41923131695121757, \"f0_5\": 0.7425520585185392, \"p4\": 0.6978153242873308, \"phi\": 0.6048611142680039}, {\"truth_threshold\": 9.879999779164791, \"match_probability\": 0.9989398604120622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111227.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192734.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36592523382933995, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.63407476617066, \"precision\": 0.9994967784836858, \"recall\": 0.36592523382933995, \"specificity\": 0.9999999562068156, \"npv\": 0.9998493006425908, \"accuracy\": 0.999849269971408, \"f1\": 0.5357187581277514, \"f2\": 0.4190518315127339, \"f0_5\": 0.7424111558911911, \"p4\": 0.69765986529347, \"phi\": 0.6047196903658502}, {\"truth_threshold\": 9.899999778717756, \"match_probability\": 0.9989544404065152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111192.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192769.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36581008747832783, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.6341899125216722, \"precision\": 0.999496620163958, \"recall\": 0.36581008747832783, \"specificity\": 0.9999999562068156, \"npv\": 0.999849273280099, \"accuracy\": 0.9998492426071723, \"f1\": 0.5355953266908954, \"f2\": 0.41893101608629996, \"f0_5\": 0.7423162735178309, \"p4\": 0.6975551866021349, \"phi\": 0.6046244825818246}, {\"truth_threshold\": 9.919999778270721, \"match_probability\": 0.9989688200907413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111123.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36558308467204675, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.6344169153279533, \"precision\": 0.9994963077559611, \"recall\": 0.36558308467204675, \"specificity\": 0.9999999562068156, \"npv\": 0.9998492193369052, \"accuracy\": 0.9998491886605363, \"f1\": 0.5353519294695765, \"f2\": 0.4186928184364551, \"f0_5\": 0.742129115760201, \"p4\": 0.6973487190295767, \"phi\": 0.6044367433266276}, {\"truth_threshold\": 9.939999777823687, \"match_probability\": 0.9989830022110892, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111067.0, \"tn\": 1278737736.0, \"fp\": 56.0, \"fn\": 192894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3653988505104273, \"tn_rate\": 0.9999999562068156, \"fp_rate\": 4.3793184459195215e-08, \"fn_rate\": 0.6346011494895727, \"precision\": 0.9994960539222303, \"recall\": 0.3653988505104273, \"specificity\": 0.9999999562068156, \"npv\": 0.999849175556926, \"accuracy\": 0.9998491448777591, \"f1\": 0.5351543302078615, \"f2\": 0.4184994803940113, \"f0_5\": 0.7419771181356745, \"p4\": 0.6971810525381186, \"phi\": 0.6042843323719828}, {\"truth_threshold\": 9.959999777376652, \"match_probability\": 0.9989969894764078, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111031.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 192930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36528041426367197, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.634719585736328, \"precision\": 0.9995048881047117, \"recall\": 0.36528041426367197, \"specificity\": 0.9999999569888367, \"npv\": 0.9998491474127738, \"accuracy\": 0.9998491175135235, \"f1\": 0.5350285630302111, \"f2\": 0.41837549833073334, \"f0_5\": 0.7418833229765938, \"p4\": 0.6970743144316277, \"phi\": 0.6041890541101517}, {\"truth_threshold\": 9.979999776929617, \"match_probability\": 0.9990107845585551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110967.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 192994.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36506986093610694, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.6349301390638931, \"precision\": 0.9995046026913584, \"recall\": 0.36506986093610694, \"specificity\": 0.9999999569888367, \"npv\": 0.9998490973785193, \"accuracy\": 0.9998490674760638, \"f1\": 0.5348026304692, \"f2\": 0.4181545084432038, \"f0_5\": 0.7417094334729409, \"p4\": 0.6968825223187217, \"phi\": 0.6040147956193863}, {\"truth_threshold\": 9.999999776482582, \"match_probability\": 0.9990243900928982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110928.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.364941555002122, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.635058444997878, \"precision\": 0.9995584670697532, \"recall\": 0.364941555002122, \"specificity\": 0.9999999616809636, \"npv\": 0.9998490668896062, \"accuracy\": 0.9998490416754988, \"f1\": 0.5346726498898631, \"f2\": 0.4180217225986022, \"f0_5\": 0.741627210113001, \"p4\": 0.6967721577533784, \"phi\": 0.6039249135675981}, {\"truth_threshold\": 10.019999776035547, \"match_probability\": 0.9990378086788084, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110863.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193098.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36472771177881375, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6352722882211863, \"precision\": 0.9995582083092902, \"recall\": 0.36472771177881375, \"specificity\": 0.9999999616809636, \"npv\": 0.9998490160735751, \"accuracy\": 0.9998489908562039, \"f1\": 0.5344430705300176, \"f2\": 0.41779724380368355, \"f0_5\": 0.7414504105755816, \"p4\": 0.6965771790427043, \"phi\": 0.6037478544790501}, {\"truth_threshold\": 10.039999775588512, \"match_probability\": 0.9990510428801486, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110734.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193227.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3643033152279404, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6356966847720595, \"precision\": 0.9995576938699982, \"recall\": 0.3643033152279404, \"specificity\": 0.9999999616809636, \"npv\": 0.9998489152233134, \"accuracy\": 0.9998488899994494, \"f1\": 0.5339872306772371, \"f2\": 0.41735167458524514, \"f0_5\": 0.7410991670381064, \"p4\": 0.6961898673321182, \"phi\": 0.6033963064662473}, {\"truth_threshold\": 10.059999775141478, \"match_probability\": 0.9990640952257547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110675.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193286.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3641092113790914, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6358907886209086, \"precision\": 0.9995574581843142, \"recall\": 0.3641092113790914, \"specificity\": 0.9999999616809636, \"npv\": 0.9998488690980067, \"accuracy\": 0.9998488438711665, \"f1\": 0.5337786512654183, \"f2\": 0.4171478582326726, \"f0_5\": 0.7409383590165186, \"p4\": 0.6960125676970157, \"phi\": 0.6032354526863889}, {\"truth_threshold\": 10.079999774694443, \"match_probability\": 0.9990769682099103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110631.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193330.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36396445596639043, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6360355440336096, \"precision\": 0.99955728225515, \"recall\": 0.36396445596639043, \"specificity\": 0.9999999616809636, \"npv\": 0.9998488346994756, \"accuracy\": 0.999848809470413, \"f1\": 0.5336230618776242, \"f2\": 0.41699584779468746, \"f0_5\": 0.7408183682188244, \"p4\": 0.6958802799940733, \"phi\": 0.6031154660184016}, {\"truth_threshold\": 10.099999774247408, \"match_probability\": 0.9990896642928159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110566.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3637506127430822, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6362493872569178, \"precision\": 0.999557022103693, \"recall\": 0.3637506127430822, \"specificity\": 0.9999999616809636, \"npv\": 0.9998487838834682, \"accuracy\": 0.9998487586511181, \"f1\": 0.5333931534869361, \"f2\": 0.4167712684674008, \"f0_5\": 0.740641005545128, \"p4\": 0.6956847544607953, \"phi\": 0.6029381693097198}, {\"truth_threshold\": 10.119999773800373, \"match_probability\": 0.9991021859010499, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110506.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3635532189984899, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6364467810015101, \"precision\": 0.9995567816923703, \"recall\": 0.3635532189984899, \"specificity\": 0.9999999616809636, \"npv\": 0.999848736976389, \"accuracy\": 0.9998487117409998, \"f1\": 0.5331808663598028, \"f2\": 0.4165639449366292, \"f0_5\": 0.7404771764491457, \"p4\": 0.6955041628629341, \"phi\": 0.6027744645392888}, {\"truth_threshold\": 10.139999773353338, \"match_probability\": 0.9991145354280261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110430.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193531.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3633031869220064, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6366968130779935, \"precision\": 0.9995564767964953, \"recall\": 0.3633031869220064, \"specificity\": 0.9999999616809636, \"npv\": 0.9998486775607616, \"accuracy\": 0.9998486523215165, \"f1\": 0.5329118810925586, \"f2\": 0.4163013082032054, \"f0_5\": 0.7402695082433163, \"p4\": 0.6952752666086185, \"phi\": 0.6025670413389939}, {\"truth_threshold\": 10.159999772906303, \"match_probability\": 0.9991267152344423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110372.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36311237296890064, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6368876270310994, \"precision\": 0.9995562438304308, \"recall\": 0.36311237296890064, \"specificity\": 0.9999999616809636, \"npv\": 0.9998486322172612, \"accuracy\": 0.9998486069750688, \"f1\": 0.5327065364808317, \"f2\": 0.41610085465574376, \"f0_5\": 0.740110910688062, \"p4\": 0.6951004720668268, \"phi\": 0.6024086966521446}, {\"truth_threshold\": 10.179999772459269, \"match_probability\": 0.9991387276487257, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110333.0, \"tn\": 1278737751.0, \"fp\": 41.0, \"fn\": 193628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36298406703491565, \"tn_rate\": 0.9999999679371329, \"fp_rate\": 3.2062867193339354e-08, \"fn_rate\": 0.6370159329650843, \"precision\": 0.9996285357058727, \"recall\": 0.36298406703491565, \"specificity\": 0.9999999679371329, \"npv\": 0.9998486017286154, \"accuracy\": 0.9998485827381743, \"f1\": 0.5325787104637552, \"f2\": 0.41596856625381345, \"f0_5\": 0.7400359779303166, \"p4\": 0.6949916401493033, \"phi\": 0.6023240358878957}, {\"truth_threshold\": 10.199999772012234, \"match_probability\": 0.9991505749674697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110294.0, \"tn\": 1278737751.0, \"fp\": 41.0, \"fn\": 193667.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3628557611009307, \"tn_rate\": 0.9999999679371329, \"fp_rate\": 3.2062867193339354e-08, \"fn_rate\": 0.6371442388990692, \"precision\": 0.9996284044047673, \"recall\": 0.3628557611009307, \"specificity\": 0.9999999679371329, \"npv\": 0.9998485712390248, \"accuracy\": 0.9998485522465974, \"f1\": 0.5324405738892, \"f2\": 0.4158337599977077, \"f0_5\": 0.7399292366439868, \"p4\": 0.6948740088253204, \"phi\": 0.6022175243663929}, {\"truth_threshold\": 10.219999771565199, \"match_probability\": 0.9991622594558669, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110238.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 193723.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3626715269393113, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6373284730606887, \"precision\": 0.9996372803278986, \"recall\": 0.3626715269393113, \"specificity\": 0.999999968719154, \"npv\": 0.9998485274592214, \"accuracy\": 0.9998485092456556, \"f1\": 0.5322434633146566, \"f2\": 0.41564049159881217, \"f0_5\": 0.7397798604968909, \"p4\": 0.6947061210518436, \"phi\": 0.6020672826184497}, {\"truth_threshold\": 10.239999771118164, \"match_probability\": 0.999173783348135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110193.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 193768.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3625234816308671, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6374765183691329, \"precision\": 0.9996371322562209, \"recall\": 0.3625234816308671, \"specificity\": 0.999999968719154, \"npv\": 0.9998484922789298, \"accuracy\": 0.9998484740630668, \"f1\": 0.532083999285359, \"f2\": 0.4154849228212238, \"f0_5\": 0.7396565681245494, \"p4\": 0.6945702668464148, \"phi\": 0.6019443306334303}, {\"truth_threshold\": 10.25999977067113, \"match_probability\": 0.9991851488479381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110125.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 193836.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36229976872032926, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6377002312796708, \"precision\": 0.9996369082739527, \"recall\": 0.36229976872032926, \"specificity\": 0.999999968719154, \"npv\": 0.9998484391176051, \"accuracy\": 0.999848420898266, \"f1\": 0.5318429656674538, \"f2\": 0.41524982107964575, \"f0_5\": 0.7394701465577791, \"p4\": 0.6943648663501805, \"phi\": 0.6017584888762035}, {\"truth_threshold\": 10.279999770224094, \"match_probability\": 0.9991963581288007, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110086.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 193875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3621714627863443, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6378285372136557, \"precision\": 0.9996367796887202, \"recall\": 0.3621714627863443, \"specificity\": 0.999999968719154, \"npv\": 0.9998484086280244, \"accuracy\": 0.999848390406689, \"f1\": 0.531704690077206, \"f2\": 0.4151149724352738, \"f0_5\": 0.7393631668379306, \"p4\": 0.6942470035077448, \"phi\": 0.601651877268922}, {\"truth_threshold\": 10.29999976977706, \"match_probability\": 0.9992074133345185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110026.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 193935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36197406904175206, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6380259309582479, \"precision\": 0.9996365816873513, \"recall\": 0.36197406904175206, \"specificity\": 0.999999968719154, \"npv\": 0.9998483617209807, \"accuracy\": 0.9998483434965707, \"f1\": 0.5314919075326006, \"f2\": 0.41490749749228834, \"f0_5\": 0.7391984950787732, \"p4\": 0.6940655911302758, \"phi\": 0.6014878225257304}, {\"truth_threshold\": 10.319999769330025, \"match_probability\": 0.9992183165795613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109927.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194034.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3616483693631749, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6383516306368251, \"precision\": 0.9996362545127174, \"recall\": 0.3616483693631749, \"specificity\": 0.999999968719154, \"npv\": 0.9998482843243682, \"accuracy\": 0.9998482660948754, \"f1\": 0.5311406814711738, \"f2\": 0.41456512278145224, \"f0_5\": 0.738926554355907, \"p4\": 0.6937660354384547, \"phi\": 0.6012170343639764}, {\"truth_threshold\": 10.33999976888299, \"match_probability\": 0.9992290699494722, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109870.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194091.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36146084530581224, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6385391546941878, \"precision\": 0.9996360658720772, \"recall\": 0.36146084530581224, \"specificity\": 0.999999968719154, \"npv\": 0.9998482397626877, \"accuracy\": 0.9998482215302631, \"f1\": 0.5309383841825109, \"f2\": 0.4143679747524805, \"f0_5\": 0.7387698510357033, \"p4\": 0.6935934365962222, \"phi\": 0.6010610707073951}, {\"truth_threshold\": 10.359999768435955, \"match_probability\": 0.9992396755012607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109780.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3611647546889239, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.638835245311076, \"precision\": 0.9996357676197414, \"recall\": 0.3611647546889239, \"specificity\": 0.999999968719154, \"npv\": 0.9998481694021475, \"accuracy\": 0.9998481511650855, \"f1\": 0.5306188539348109, \"f2\": 0.41405665387307794, \"f0_5\": 0.7385222289943639, \"p4\": 0.6933207223598362, \"phi\": 0.6008147299004305}, {\"truth_threshold\": 10.37999976798892, \"match_probability\": 0.9992501352637905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109736.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3610199992762229, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.638980000723777, \"precision\": 0.9996356216295, \"recall\": 0.3610199992762229, \"specificity\": 0.999999968719154, \"npv\": 0.9998481350036649, \"accuracy\": 0.999848116764332, \"f1\": 0.5304625885526313, \"f2\": 0.4139044371690228, \"f0_5\": 0.738401082004939, \"p4\": 0.6931873107610895, \"phi\": 0.6006942598623731}, {\"truth_threshold\": 10.399999767541885, \"match_probability\": 0.9992604512381623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109656.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194305.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36075680761676665, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6392431923832333, \"precision\": 0.9996353558926487, \"recall\": 0.36075680761676665, \"specificity\": 0.999999968719154, \"npv\": 0.9998480724609752, \"accuracy\": 0.9998480542175077, \"f1\": 0.5301783845069707, \"f2\": 0.41362765363549947, \"f0_5\": 0.7381806676584831, \"p4\": 0.6929446016690842, \"phi\": 0.6004751615296234}, {\"truth_threshold\": 10.41999976709485, \"match_probability\": 0.9992706253980917, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109603.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194358.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3605824431423768, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6394175568576231, \"precision\": 0.9996351796284304, \"recall\": 0.3605824431423768, \"specificity\": 0.999999968719154, \"npv\": 0.9998480310264475, \"accuracy\": 0.9998480127802364, \"f1\": 0.5299900387810563, \"f2\": 0.41344426614519797, \"f0_5\": 0.7380345385322942, \"p4\": 0.692783705517616, \"phi\": 0.600329964863526}, {\"truth_threshold\": 10.439999766647816, \"match_probability\": 0.9992806596902816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109551.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36041136856373024, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6395886314362698, \"precision\": 0.999644128113879, \"recall\": 0.36041136856373024, \"specificity\": 0.9999999695011751, \"npv\": 0.9998479903738257, \"accuracy\": 0.9998479729066359, \"f1\": 0.5298064809418911, \"f2\": 0.4132646363379844, \"f0_5\": 0.7378950615703987, \"p4\": 0.692626861409175, \"phi\": 0.6001902130237385}, {\"truth_threshold\": 10.45999976620078, \"match_probability\": 0.9992905560347891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109495.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194466.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3602271344021108, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6397728655978892, \"precision\": 0.9996439461719648, \"recall\": 0.3602271344021108, \"specificity\": 0.9999999695011751, \"npv\": 0.9998479465939547, \"accuracy\": 0.9998479291238587, \"f1\": 0.5296073713104149, \"f2\": 0.4130708371498546, \"f0_5\": 0.737740484060709, \"p4\": 0.6924566861857807, \"phi\": 0.6000367237977029}, {\"truth_threshold\": 10.479999765753746, \"match_probability\": 0.9993003163253892, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109434.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194527.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36002645076177536, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6399735492382247, \"precision\": 0.9996437477734236, \"recall\": 0.36002645076177536, \"specificity\": 0.9999999695011751, \"npv\": 0.9998478989051711, \"accuracy\": 0.9998478814319051, \"f1\": 0.5293904226551276, \"f2\": 0.41285971582647774, \"f0_5\": 0.737571998765254, \"p4\": 0.6922712138512921, \"phi\": 0.5998694855019849}, {\"truth_threshold\": 10.499999765306711, \"match_probability\": 0.9993099424299317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109406.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194555.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35993433368096567, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6400656663190344, \"precision\": 0.9996436566311846, \"recall\": 0.35993433368096567, \"specificity\": 0.9999999695011751, \"npv\": 0.9998478770152391, \"accuracy\": 0.9998478595405165, \"f1\": 0.5292908182271181, \"f2\": 0.41276280117015984, \"f0_5\": 0.7374946241343002, \"p4\": 0.6921860430571402, \"phi\": 0.5997927047734699}, {\"truth_threshold\": 10.519999764859676, \"match_probability\": 0.9993194361906943, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109364.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194597.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35979615805975107, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6402038419402489, \"precision\": 0.999643519830352, \"recall\": 0.35979615805975107, \"specificity\": 0.9999999695011751, \"npv\": 0.9998478441803431, \"accuracy\": 0.9998478267034336, \"f1\": 0.5291413862842435, \"f2\": 0.4126174215070851, \"f0_5\": 0.7373785183656902, \"p4\": 0.6920582444241504, \"phi\": 0.5996775152543542}, {\"truth_threshold\": 10.539999764412642, \"match_probability\": 0.9993287994247311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109302.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194659.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3595921845236724, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6404078154763275, \"precision\": 0.9996433176941861, \"recall\": 0.3595921845236724, \"specificity\": 0.9999999695011751, \"npv\": 0.9998477957097861, \"accuracy\": 0.9998477782296447, \"f1\": 0.5289207407658323, \"f2\": 0.4124027965906647, \"f0_5\": 0.7372070279566991, \"p4\": 0.6918694961577686, \"phi\": 0.5995074331462684}, {\"truth_threshold\": 10.559999763965607, \"match_probability\": 0.9993380339242153, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109224.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194737.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35933557265570254, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6406644273442974, \"precision\": 0.9996430630680102, \"recall\": 0.35933557265570254, \"specificity\": 0.9999999695011751, \"npv\": 0.999847734730705, \"accuracy\": 0.9998477172464909, \"f1\": 0.5286430604224344, \"f2\": 0.41213275607177385, \"f0_5\": 0.7369911189142431, \"p4\": 0.6916318807853757, \"phi\": 0.5992933903421691}, {\"truth_threshold\": 10.579999763518572, \"match_probability\": 0.9993471414567788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109158.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194803.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35911843953665107, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6408815604633489, \"precision\": 0.9996428473309706, \"recall\": 0.35911843953665107, \"specificity\": 0.9999999695011751, \"npv\": 0.9998476831330267, \"accuracy\": 0.9998476656453607, \"f1\": 0.5284080182399954, \"f2\": 0.41190423541611165, \"f0_5\": 0.7368082845876268, \"p4\": 0.6914306840854942, \"phi\": 0.5991122174923523}, {\"truth_threshold\": 10.599999763071537, \"match_probability\": 0.9993561237658463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109105.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3589440750622613, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6410559249377388, \"precision\": 0.9996426738987026, \"recall\": 0.3589440750622613, \"specificity\": 0.9999999695011751, \"npv\": 0.9998476416985315, \"accuracy\": 0.9998476242080895, \"f1\": 0.5282192178743903, \"f2\": 0.41172070992341064, \"f0_5\": 0.7366613687094635, \"p4\": 0.6912690256804318, \"phi\": 0.5989666905450225}, {\"truth_threshold\": 10.619999762624502, \"match_probability\": 0.9993649825709646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109032.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3587039126730074, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6412960873269926, \"precision\": 0.9996424347443409, \"recall\": 0.3587039126730074, \"specificity\": 0.9999999695011751, \"npv\": 0.9998475846283831, \"accuracy\": 0.9998475671341122, \"f1\": 0.5279590927579462, \"f2\": 0.4114679054882766, \"f0_5\": 0.7364588751021621, \"p4\": 0.6910462307471228, \"phi\": 0.5987661898799438}, {\"truth_threshold\": 10.639999762177467, \"match_probability\": 0.9993737195681286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108911.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195050.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35830583528807974, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6416941647119203, \"precision\": 0.9996420376319413, \"recall\": 0.35830583528807974, \"specificity\": 0.9999999695011751, \"npv\": 0.9998474900326721, \"accuracy\": 0.9998474725320402, \"f1\": 0.5275277238920736, \"f2\": 0.4110488121172046, \"f0_5\": 0.7361228829311088, \"p4\": 0.6906765997792859, \"phi\": 0.5984337052575678}, {\"truth_threshold\": 10.659999761730433, \"match_probability\": 0.9993823364301017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108805.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3579571063393001, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6420428936606999, \"precision\": 0.9996416890228217, \"recall\": 0.3579571063393001, \"specificity\": 0.9999999695011751, \"npv\": 0.999847407163717, \"accuracy\": 0.9998473896574978, \"f1\": 0.5271496227032134, \"f2\": 0.41068160955636346, \"f0_5\": 0.7358281811947731, \"p4\": 0.6903524410625954, \"phi\": 0.5981422859198077}, {\"truth_threshold\": 10.679999761283398, \"match_probability\": 0.9993908348067326, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108738.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3577366833245054, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6422633166754945, \"precision\": 0.9996414683251055, \"recall\": 0.3577366833245054, \"specificity\": 0.9999999695011751, \"npv\": 0.9998473547842901, \"accuracy\": 0.9998473372745322, \"f1\": 0.5269105340433883, \"f2\": 0.410449479511498, \"f0_5\": 0.7356417330452231, \"p4\": 0.690147379564113, \"phi\": 0.5979580136730621}, {\"truth_threshold\": 10.699999760836363, \"match_probability\": 0.999399216325268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108669.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195292.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3575096805182244, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6424903194817756, \"precision\": 0.9996412407550502, \"recall\": 0.3575096805182244, \"specificity\": 0.9999999695011751, \"npv\": 0.999847300841304, \"accuracy\": 0.9998472833278962, \"f1\": 0.526664227262043, \"f2\": 0.4102103956658553, \"f0_5\": 0.7354495778925897, \"p4\": 0.6899360600709837, \"phi\": 0.597768181408573}, {\"truth_threshold\": 10.719999760389328, \"match_probability\": 0.99940748259066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108579.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195382.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.357213589901336, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.642786410098664, \"precision\": 0.9996409434900293, \"recall\": 0.357213589901336, \"specificity\": 0.9999999695011751, \"npv\": 0.9998472304808961, \"accuracy\": 0.9998472129627186, \"f1\": 0.5263428337360845, \"f2\": 0.40989850973451863, \"f0_5\": 0.7351987248673881, \"p4\": 0.6896602171809906, \"phi\": 0.5975204835023403}, {\"truth_threshold\": 10.739999759942293, \"match_probability\": 0.9994156351858707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108520.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195441.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.357019486052487, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.642980513947513, \"precision\": 0.9996407483488241, \"recall\": 0.357019486052487, \"specificity\": 0.9999999695011751, \"npv\": 0.9998471843557452, \"accuracy\": 0.9998471668344356, \"f1\": 0.5261320663240571, \"f2\": 0.409694028177224, \"f0_5\": 0.7350341440022108, \"p4\": 0.6894792584569013, \"phi\": 0.5973580480470992}, {\"truth_threshold\": 10.759999759495258, \"match_probability\": 0.9994236756721719, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108418.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3566839166866802, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6433160833133198, \"precision\": 0.9996404104852614, \"recall\": 0.3566839166866802, \"specificity\": 0.9999999695011751, \"npv\": 0.9998471046139689, \"accuracy\": 0.9998470870872345, \"f1\": 0.5257675465183382, \"f2\": 0.4093404747108097, \"f0_5\": 0.7347493660111495, \"p4\": 0.6891661744446383, \"phi\": 0.5970771232276749}, {\"truth_threshold\": 10.779999759048223, \"match_probability\": 0.9994316055894407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108374.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195587.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3565391612739792, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6434608387260208, \"precision\": 0.99964026454392, \"recall\": 0.3565391612739792, \"specificity\": 0.9999999695011751, \"npv\": 0.9998470702155595, \"accuracy\": 0.999847052686481, \"f1\": 0.5256102470087833, \"f2\": 0.40918794463612423, \"f0_5\": 0.7346264233412372, \"p4\": 0.6890310245750455, \"phi\": 0.5969558991717232}, {\"truth_threshold\": 10.799999758601189, \"match_probability\": 0.9994394264564512, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108335.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3564108553399943, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6435891446600057, \"precision\": 0.9996401350877516, \"recall\": 0.3564108553399943, \"specificity\": 0.9999999695011751, \"npv\": 0.9998470397260623, \"accuracy\": 0.9998470221949041, \"f1\": 0.5254707943783574, \"f2\": 0.40905273905051887, \"f0_5\": 0.7345174023705789, \"p4\": 0.6889111852268937, \"phi\": 0.5968484300000809}, {\"truth_threshold\": 10.819999758154154, \"match_probability\": 0.9994471397711634, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108252.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195709.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35613779399330836, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6438622060066916, \"precision\": 0.9996398592680832, \"recall\": 0.35613779399330836, \"specificity\": 0.9999999695011751, \"npv\": 0.999846974838164, \"accuracy\": 0.9998469573025737, \"f1\": 0.5251739227462814, \"f2\": 0.40876496731828704, \"f0_5\": 0.7342852297778532, \"p4\": 0.6886559940599797, \"phi\": 0.5966196491407073}, {\"truth_threshold\": 10.839999757707119, \"match_probability\": 0.9994547470110056, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108200.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35596671941466174, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6440332805853383, \"precision\": 0.999639686249873, \"recall\": 0.35596671941466174, \"specificity\": 0.9999999695011751, \"npv\": 0.9998469341855092, \"accuracy\": 0.9998469166471378, \"f1\": 0.5249878699660359, \"f2\": 0.4085846582125139, \"f0_5\": 0.734139665661126, \"p4\": 0.6884960122548546, \"phi\": 0.5964762718600487}, {\"truth_threshold\": 10.859999757260084, \"match_probability\": 0.9994622496331557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108135.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3557528761913535, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6442471238086465, \"precision\": 0.9996394697431915, \"recall\": 0.3557528761913535, \"specificity\": 0.9999999695011751, \"npv\": 0.9998468833696953, \"accuracy\": 0.9998468658278429, \"f1\": 0.5247552379681415, \"f2\": 0.40835925191349365, \"f0_5\": 0.7339575949186663, \"p4\": 0.6882959233066644, \"phi\": 0.5962970017958811}, {\"truth_threshold\": 10.87999975681305, \"match_probability\": 0.9994696490748174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108053.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195908.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3554831047404108, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6445168952595892, \"precision\": 0.9996391962402398, \"recall\": 0.3554831047404108, \"specificity\": 0.9999999695011751, \"npv\": 0.999846819263599, \"accuracy\": 0.9998468017173479, \"f1\": 0.5244616590584221, \"f2\": 0.4080748616247311, \"f0_5\": 0.73372772225459, \"p4\": 0.6880433262019552, \"phi\": 0.5960707688293211}, {\"truth_threshold\": 10.899999756366014, \"match_probability\": 0.9994769467534924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107989.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195972.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35527255141284575, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6447274485871543, \"precision\": 0.9996389824860221, \"recall\": 0.35527255141284575, \"specificity\": 0.9999999695011751, \"npv\": 0.9998467692295784, \"accuracy\": 0.9998467516798882, \"f1\": 0.5242324430992089, \"f2\": 0.40785287399386044, \"f0_5\": 0.7335481670975569, \"p4\": 0.6878460397414556, \"phi\": 0.5958941370995745}, {\"truth_threshold\": 10.91999975591898, \"match_probability\": 0.9994841440672497, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107924.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196037.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3550587081895375, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6449412918104626, \"precision\": 0.999638765132499, \"recall\": 0.3550587081895375, \"specificity\": 0.9999999695011751, \"npv\": 0.9998467184137813, \"accuracy\": 0.9998467008605935, \"f1\": 0.5239995727367184, \"f2\": 0.4076273958364021, \"f0_5\": 0.7333656785079905, \"p4\": 0.6876455471669333, \"phi\": 0.5957146919113249}, {\"truth_threshold\": 10.939999755471945, \"match_probability\": 0.9994912423949907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107862.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196099.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35485473465345885, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6451452653465412, \"precision\": 0.9996385575666583, \"recall\": 0.35485473465345885, \"specificity\": 0.9999999695011751, \"npv\": 0.9998466699433334, \"accuracy\": 0.9998466523868045, \"f1\": 0.5237773817443707, \"f2\": 0.40741230372919257, \"f0_5\": 0.7331914922542535, \"p4\": 0.6874541920040232, \"phi\": 0.595543478442158}, {\"truth_threshold\": 10.95999975502491, \"match_probability\": 0.9994982430967109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107780.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3545849632025161, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6454150367974839, \"precision\": 0.9996382826774501, \"recall\": 0.3545849632025161, \"specificity\": 0.9999999695011751, \"npv\": 0.9998466058372645, \"accuracy\": 0.9998465882763093, \"f1\": 0.5234834134732138, \"f2\": 0.4071277961233335, \"f0_5\": 0.7329609364055399, \"p4\": 0.6872009351016893, \"phi\": 0.5953169592178157}, {\"truth_threshold\": 10.979999754577875, \"match_probability\": 0.9995051475137581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107711.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196250.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.354357960396235, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.645642039603765, \"precision\": 0.9996380510440835, \"recall\": 0.354357960396235, \"specificity\": 0.9999999695011751, \"npv\": 0.9998465518943591, \"accuracy\": 0.9998465343296733, \"f1\": 0.5232359592043934, \"f2\": 0.406888366069958, \"f0_5\": 0.7327667726586853, \"p4\": 0.6869876747591248, \"phi\": 0.5951262848014709}, {\"truth_threshold\": 10.99999975413084, \"match_probability\": 0.9995119569690871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107663.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196298.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35420004540056127, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6457999545994387, \"precision\": 0.9996378897327812, \"recall\": 0.35420004540056127, \"specificity\": 0.9999999695011751, \"npv\": 0.9998465143688633, \"accuracy\": 0.9998464968015787, \"f1\": 0.5230637681793118, \"f2\": 0.40672179130910446, \"f0_5\": 0.7326316161950218, \"p4\": 0.6868392366914193, \"phi\": 0.5949936057024945}, {\"truth_threshold\": 11.019999753683805, \"match_probability\": 0.9995186727675113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107599.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196362.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3539894920729962, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6460105079270038, \"precision\": 0.9996376744272469, \"recall\": 0.3539894920729962, \"specificity\": 0.9999999695011751, \"npv\": 0.9998464643348731, \"accuracy\": 0.999846446764119, \"f1\": 0.5228341176727834, \"f2\": 0.4064996728327246, \"f0_5\": 0.7324512976625328, \"p4\": 0.6866412131789372, \"phi\": 0.5948166542156726}, {\"truth_threshold\": 11.03999975323677, \"match_probability\": 0.9995252961959493, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107537.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196424.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3537855185369176, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6462144814630825, \"precision\": 0.9996374656057113, \"recall\": 0.3537855185369176, \"specificity\": 0.9999999695011751, \"npv\": 0.9998464158644499, \"accuracy\": 0.9998463982903301, \"f1\": 0.5226115756298948, \"f2\": 0.40628447507216153, \"f0_5\": 0.7322764941812561, \"p4\": 0.6864492621846003, \"phi\": 0.5946451822659695}, {\"truth_threshold\": 11.059999752789736, \"match_probability\": 0.9995318285236707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107471.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196490.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3535683854178661, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6464316145821339, \"precision\": 0.9996372430471584, \"recall\": 0.3535683854178661, \"specificity\": 0.9999999695011751, \"npv\": 0.9998463642669079, \"accuracy\": 0.9998463466891999, \"f1\": 0.5223746023413558, \"f2\": 0.40605537142744874, \"f0_5\": 0.7320902832557449, \"p4\": 0.6862448020025912, \"phi\": 0.5944625932778137}, {\"truth_threshold\": 11.079999752342701, \"match_probability\": 0.9995382710025367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107393.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196568.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3533117735498962, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6466882264501038, \"precision\": 0.9996369796708615, \"recall\": 0.3533117735498962, \"specificity\": 0.9999999695011751, \"npv\": 0.9998463032880013, \"accuracy\": 0.9998462857060461, \"f1\": 0.5220944449711103, \"f2\": 0.4057845831104018, \"f0_5\": 0.7318700430291308, \"p4\": 0.686003000548709, \"phi\": 0.5942467339856424}, {\"truth_threshold\": 11.099999751895666, \"match_probability\": 0.9995446248672375, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107328.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3530979303265879, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.646902069673412, \"precision\": 0.9996367598982928, \"recall\": 0.3530979303265879, \"specificity\": 0.9999999695011751, \"npv\": 0.9998462524722516, \"accuracy\": 0.9998462348867512, \"f1\": 0.5218608993309476, \"f2\": 0.4055589017926846, \"f0_5\": 0.7316863663694781, \"p4\": 0.6858013612525188, \"phi\": 0.5940667913472064}, {\"truth_threshold\": 11.119999751448631, \"match_probability\": 0.9995508913355277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107226.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196735.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3527623609607812, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6472376390392188, \"precision\": 0.9996364144874843, \"recall\": 0.3527623609607812, \"specificity\": 0.9999999695011751, \"npv\": 0.9998461727306238, \"accuracy\": 0.99984615513955, \"f1\": 0.5214942634950125, \"f2\": 0.4052047110253199, \"f0_5\": 0.7313978726393924, \"p4\": 0.6854846893137416, \"phi\": 0.5937843099335021}, {\"truth_threshold\": 11.139999751001596, \"match_probability\": 0.9995570716084575, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107181.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196780.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.352614315652337, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.647385684347663, \"precision\": 0.9996362618914382, \"recall\": 0.352614315652337, \"specificity\": 0.9999999695011751, \"npv\": 0.9998461375504981, \"accuracy\": 0.9998461199569613, \"f1\": 0.5213324545638053, \"f2\": 0.40504843303120636, \"f0_5\": 0.7312704938724771, \"p4\": 0.6853448826188846, \"phi\": 0.5936596430638816}, {\"truth_threshold\": 11.159999750554562, \"match_probability\": 0.9995631668706008, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107089.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35231164524396225, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6476883547560378, \"precision\": 0.9996639439906652, \"recall\": 0.35231164524396225, \"specificity\": 0.9999999718472385, \"npv\": 0.9998460656270541, \"accuracy\": 0.9998460503736191, \"f1\": 0.5210053370827515, \"f2\": 0.40472981604255276, \"f0_5\": 0.7310218564537907, \"p4\": 0.6850621548128637, \"phi\": 0.5934129993413191}, {\"truth_threshold\": 11.179999750107527, \"match_probability\": 0.9995691782902804, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107048.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196913.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35217675951849087, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6478232404815092, \"precision\": 0.9996638153225506, \"recall\": 0.35217675951849087, \"specificity\": 0.9999999718472385, \"npv\": 0.9998460335740574, \"accuracy\": 0.9998460183183715, \"f1\": 0.5208578136213796, \"f2\": 0.40458740007014743, \"f0_5\": 0.7309056298195951, \"p4\": 0.6849346103416042, \"phi\": 0.5932993439674963}, {\"truth_threshold\": 11.199999749660492, \"match_probability\": 0.9995751070197908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106974.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196987.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35193330723349375, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6480666927665062, \"precision\": 0.9996635828427249, \"recall\": 0.35193330723349375, \"specificity\": 0.9999999718472385, \"npv\": 0.9998459757223125, \"accuracy\": 0.9998459604625589, \"f1\": 0.5205914772575194, \"f2\": 0.4043303342621332, \"f0_5\": 0.7306957230932745, \"p4\": 0.6847042810447569, \"phi\": 0.593094154766618}, {\"truth_threshold\": 11.219999749213457, \"match_probability\": 0.9995809541956164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106915.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35173920338464476, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6482607966153553, \"precision\": 0.9996633972566876, \"recall\": 0.35173920338464476, \"specificity\": 0.9999999718472385, \"npv\": 0.9998459295972775, \"accuracy\": 0.9998459143342758, \"f1\": 0.5203790592632973, \"f2\": 0.4041253557807521, \"f0_5\": 0.7305282433568153, \"p4\": 0.6845205228411761, \"phi\": 0.5929305071120802}, {\"truth_threshold\": 11.239999748766422, \"match_probability\": 0.9995867209386486, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106826.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197135.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3514464026634996, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6485535973365004, \"precision\": 0.9996631169171455, \"recall\": 0.3514464026634996, \"specificity\": 0.9999999718472385, \"npv\": 0.9998458600188428, \"accuracy\": 0.9998458447509336, \"f1\": 0.520058516684801, \"f2\": 0.4038161163554108, \"f0_5\": 0.7302753999472251, \"p4\": 0.6842431311901694, \"phi\": 0.5926835633245535}, {\"truth_threshold\": 11.259999748319387, \"match_probability\": 0.9995924083543983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106767.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197194.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3512522988146506, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6487477011853494, \"precision\": 0.9996629308165501, \"recall\": 0.3512522988146506, \"specificity\": 0.9999999718472385, \"npv\": 0.9998458138938184, \"accuracy\": 0.9998457986226506, \"f1\": 0.5198459456038017, \"f2\": 0.4036110919996038, \"f0_5\": 0.7301076489421792, \"p4\": 0.6840591115691967, \"phi\": 0.5925198023070043}, {\"truth_threshold\": 11.279999747872353, \"match_probability\": 0.9995980175332065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106709.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197252.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35106148486154476, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6489385151384552, \"precision\": 0.9996627476696801, \"recall\": 0.35106148486154476, \"specificity\": 0.9999999718472385, \"npv\": 0.9998457685505783, \"accuracy\": 0.9998457532762028, \"f1\": 0.5196369178926045, \"f2\": 0.40340952480324577, \"f0_5\": 0.7299426355889189, \"p4\": 0.6838781091945559, \"phi\": 0.5923587727864916}, {\"truth_threshold\": 11.299999747425318, \"match_probability\": 0.9996035495504519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106629.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35079829320208844, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6492017067979116, \"precision\": 0.99966249472648, \"recall\": 0.35079829320208844, \"specificity\": 0.9999999718472385, \"npv\": 0.9998457060081848, \"accuracy\": 0.9998456907293785, \"f1\": 0.519348506913834, \"f2\": 0.4031314720731579, \"f0_5\": 0.7297148590035052, \"p4\": 0.6836282850871211, \"phi\": 0.5921365912695271}, {\"truth_threshold\": 11.319999746978283, \"match_probability\": 0.9996090054667556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106548.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3505318116468889, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.649468188353111, \"precision\": 0.9996622382346319, \"recall\": 0.3505318116468889, \"specificity\": 0.9999999718472385, \"npv\": 0.9998456426840194, \"accuracy\": 0.9998456274007186, \"f1\": 0.5190563762803103, \"f2\": 0.4028499094090567, \"f0_5\": 0.729484031839101, \"p4\": 0.6833751422867135, \"phi\": 0.591911547543086}, {\"truth_threshold\": 11.339999746531248, \"match_probability\": 0.9996143863281827, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106472.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197489.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3502817795704054, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6497182204295946, \"precision\": 0.999661997220866, \"recall\": 0.3502817795704054, \"specificity\": 0.9999999718472385, \"npv\": 0.9998455832687604, \"accuracy\": 0.9998455679812354, \"f1\": 0.5187821735624372, \"f2\": 0.40258569579053083, \"f0_5\": 0.7292672669463954, \"p4\": 0.6831374461475656, \"phi\": 0.5917003176009948}, {\"truth_threshold\": 11.359999746084213, \"match_probability\": 0.9996196931664414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106414.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197547.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3500909656172996, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6499090343827004, \"precision\": 0.9996618130577736, \"recall\": 0.3500909656172996, \"specificity\": 0.9999999718472385, \"npv\": 0.9998455379255412, \"accuracy\": 0.9998455226347877, \"f1\": 0.5185728452697418, \"f2\": 0.402384038647986, \"f0_5\": 0.7291017196040895, \"p4\": 0.682955929463445, \"phi\": 0.5915390650738511}, {\"truth_threshold\": 11.379999745637178, \"match_probability\": 0.9996249269990801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106339.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3498442234365593, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6501557765634407, \"precision\": 0.9996615746180963, \"recall\": 0.3498442234365593, \"specificity\": 0.9999999718472385, \"npv\": 0.9998454792920741, \"accuracy\": 0.9998454639971397, \"f1\": 0.5183020743975669, \"f2\": 0.40212324887178297, \"f0_5\": 0.7288874936425662, \"p4\": 0.6827210592994147, \"phi\": 0.5913304837023736}, {\"truth_threshold\": 11.399999745190144, \"match_probability\": 0.9996300888296803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106246.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197715.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34953826313244135, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6504617368675587, \"precision\": 0.9996612784855384, \"recall\": 0.34953826313244135, \"specificity\": 0.9999999718472385, \"npv\": 0.9998454065865845, \"accuracy\": 0.9998453912864563, \"f1\": 0.5179661810195421, \"f2\": 0.4017998284581046, \"f0_5\": 0.7286216086101971, \"p4\": 0.682429584600676, \"phi\": 0.5910717406123394}, {\"truth_threshold\": 11.419999744743109, \"match_probability\": 0.9996351796480484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106176.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197785.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34930797043041706, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6506920295695829, \"precision\": 0.9996610552479945, \"recall\": 0.34930797043041706, \"specificity\": 0.9999999718472385, \"npv\": 0.9998453518620295, \"accuracy\": 0.9998453365579849, \"f1\": 0.5177132575766811, \"f2\": 0.4015563637243808, \"f0_5\": 0.7284213010541857, \"p4\": 0.6822100227198761, \"phi\": 0.5908769130376776}, {\"truth_threshold\": 11.439999744296074, \"match_probability\": 0.9996402004304035, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106106.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34907767772839277, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6509223222716072, \"precision\": 0.9996608317160031, \"recall\": 0.34907767772839277, \"specificity\": 0.9999999718472385, \"npv\": 0.9998452971374804, \"accuracy\": 0.9998452818295135, \"f1\": 0.5174602477914085, \"f2\": 0.40131287320743186, \"f0_5\": 0.7282208395273215, \"p4\": 0.6819903126656727, \"phi\": 0.5906820212234432}, {\"truth_threshold\": 11.459999743849039, \"match_probability\": 0.9996451521395642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106055.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34890989304548936, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6510901069545106, \"precision\": 0.999660668671235, \"recall\": 0.34890989304548936, \"specificity\": 0.9999999718472385, \"npv\": 0.9998452572667412, \"accuracy\": 0.999845241955913, \"f1\": 0.5172758576960971, \"f2\": 0.4011354567357699, \"f0_5\": 0.7280746919301136, \"p4\": 0.6818301448077896, \"phi\": 0.5905399881282386}, {\"truth_threshold\": 11.479999743402004, \"match_probability\": 0.9996500357251314, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105998.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34872236898812675, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6512776310118732, \"precision\": 0.9996604862591244, \"recall\": 0.34872236898812675, \"specificity\": 0.9999999718472385, \"npv\": 0.9998452127053307, \"accuracy\": 0.9998451973913005, \"f1\": 0.5170697203624435, \"f2\": 0.40093715153743387, \"f0_5\": 0.7279112535829704, \"p4\": 0.6816510404297054, \"phi\": 0.5903812048339384}, {\"truth_threshold\": 11.49999974295497, \"match_probability\": 0.9996548521236697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105918.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 198043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34845917732867043, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6515408226713295, \"precision\": 0.9996602299110935, \"recall\": 0.34845917732867043, \"specificity\": 0.9999999718472385, \"npv\": 0.9998451501630068, \"accuracy\": 0.999845134844476, \"f1\": 0.5167803081126575, \"f2\": 0.40065879960478074, \"f0_5\": 0.7276816937056269, \"p4\": 0.6813994997060476, \"phi\": 0.5901582790551739}, {\"truth_threshold\": 11.519999742507935, \"match_probability\": 0.9996596022588853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105894.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34838021983083356, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6516197801691664, \"precision\": 0.9996695900084018, \"recall\": 0.34838021983083356, \"specificity\": 0.9999999726292597, \"npv\": 0.9998451314004322, \"accuracy\": 0.999845116862264, \"f1\": 0.5166947229744565, \"f2\": 0.400575590513651, \"f0_5\": 0.7276167860190716, \"p4\": 0.6813250956246119, \"phi\": 0.5900941713075178}, {\"truth_threshold\": 11.5399997420609, \"match_probability\": 0.9996642870418024, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105849.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34823217452238936, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6517678254776106, \"precision\": 0.9996694495863397, \"recall\": 0.34823217452238936, \"specificity\": 0.9999999726292597, \"npv\": 0.9998450962203798, \"accuracy\": 0.9998450816796752, \"f1\": 0.5165318596054606, \"f2\": 0.400418996949448, \"f0_5\": 0.7274875360310764, \"p4\": 0.6811834858284654, \"phi\": 0.5899687249300418}, {\"truth_threshold\": 11.559999741613865, \"match_probability\": 0.9996689073709372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105808.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34809728879691804, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.651902711203082, \"precision\": 0.9996693215422843, \"recall\": 0.34809728879691804, \"specificity\": 0.9999999726292597, \"npv\": 0.9998450641674452, \"accuracy\": 0.9998450496244277, \"f1\": 0.5163834418404896, \"f2\": 0.4002763135296027, \"f0_5\": 0.7273697192345184, \"p4\": 0.6810544100056801, \"phi\": 0.5898544061220745}, {\"truth_threshold\": 11.57999974116683, \"match_probability\": 0.9996734641324683, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105706.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3477617194311112, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6522382805688888, \"precision\": 0.9996690025628658, \"recall\": 0.3477617194311112, \"specificity\": 0.9999999726292597, \"npv\": 0.9998449844260074, \"accuracy\": 0.9998449698772265, \"f1\": 0.5160140785253672, \"f2\": 0.3999213066128929, \"f0_5\": 0.7270763833958112, \"p4\": 0.6807330727644616, \"phi\": 0.589569907096061}, {\"truth_threshold\": 11.599999740719795, \"match_probability\": 0.9996779582004064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105643.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34755445599928936, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6524455440007106, \"precision\": 0.9996688052385548, \"recall\": 0.34755445599928936, \"specificity\": 0.9999999726292597, \"npv\": 0.9998449351739491, \"accuracy\": 0.9998449206216022, \"f1\": 0.5157858504683392, \"f2\": 0.39970201025786933, \"f0_5\": 0.7268950408230387, \"p4\": 0.6805344415495765, \"phi\": 0.5893941185280456}, {\"truth_threshold\": 11.61999974027276, \"match_probability\": 0.9996823904367605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105560.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34728139465260344, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6527186053473966, \"precision\": 0.9996685449121644, \"recall\": 0.34728139465260344, \"specificity\": 0.9999999726292597, \"npv\": 0.9998448702863243, \"accuracy\": 0.9998448557292718, \"f1\": 0.5154850618718808, \"f2\": 0.3994130640914942, \"f0_5\": 0.7266559370874011, \"p4\": 0.6802725681478707, \"phi\": 0.5891624440226105}, {\"truth_threshold\": 11.639999739825726, \"match_probability\": 0.9996867616917028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105471.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198490.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3469885939314583, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6530114060685417, \"precision\": 0.9996872156505915, \"recall\": 0.3469885939314583, \"specificity\": 0.999999974193302, \"npv\": 0.9998448007082799, \"accuracy\": 0.9998447877096003, \"f1\": 0.5151649103097945, \"f2\": 0.3991037940043047, \"f0_5\": 0.726407310424435, \"p4\": 0.6799937228101572, \"phi\": 0.5889195048147235}, {\"truth_threshold\": 11.65999973937869, \"match_probability\": 0.9996910728037302, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105429.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198532.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34685041831024377, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6531495816897562, \"precision\": 0.9996870910849406, \"recall\": 0.34685041831024377, \"specificity\": 0.999999974193302, \"npv\": 0.999844767873586, \"accuracy\": 0.9998447548725174, \"f1\": 0.5150125908901063, \"f2\": 0.398957546548642, \"f0_5\": 0.7262861165954129, \"p4\": 0.6798610143455515, \"phi\": 0.5888021888542566}, {\"truth_threshold\": 11.679999738931656, \"match_probability\": 0.9996953245998244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105398.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198563.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3467484315422044, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6532515684577955, \"precision\": 0.9996869990799669, \"recall\": 0.3467484315422044, \"specificity\": 0.999999974193302, \"npv\": 0.9998447436384561, \"accuracy\": 0.999844730635623, \"f1\": 0.514900144604682, \"f2\": 0.3988495960341337, \"f0_5\": 0.726196628013532, \"p4\": 0.6797630282732798, \"phi\": 0.5887155835118055}, {\"truth_threshold\": 11.699999738484621, \"match_probability\": 0.99969951789561, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105353.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34660038623376027, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6533996137662398, \"precision\": 0.9996868654280455, \"recall\": 0.34660038623376027, \"specificity\": 0.999999974193302, \"npv\": 0.9998447084584311, \"accuracy\": 0.9998446954530342, \"f1\": 0.5147368858205874, \"f2\": 0.39869288466050573, \"f0_5\": 0.7260666708017174, \"p4\": 0.6796207381271253, \"phi\": 0.5885898434115914}, {\"truth_threshold\": 11.719999738037586, \"match_probability\": 0.9997036534955098, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105293.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198668.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.346402992489168, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6535970075108319, \"precision\": 0.9996866870478325, \"recall\": 0.346402992489168, \"specificity\": 0.999999974193302, \"npv\": 0.9998446615517348, \"accuracy\": 0.9998446485429159, \"f1\": 0.5145191515977786, \"f2\": 0.398483919556151, \"f0_5\": 0.7258932941752325, \"p4\": 0.6794309215280065, \"phi\": 0.5884221481615222}, {\"truth_threshold\": 11.739999737590551, \"match_probability\": 0.9997077321928985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105208.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3461233513509957, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6538766486490043, \"precision\": 0.9996864339943559, \"recall\": 0.3461233513509957, \"specificity\": 0.999999974193302, \"npv\": 0.9998445951005893, \"accuracy\": 0.9998445820869148, \"f1\": 0.5142105854810094, \"f2\": 0.3981878531661475, \"f0_5\": 0.7256474807738732, \"p4\": 0.679161825905378, \"phi\": 0.5881844980744193}, {\"truth_threshold\": 11.759999737143517, \"match_probability\": 0.9997117547702536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105121.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34583713042133696, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6541628695786631, \"precision\": 0.9996861745630219, \"recall\": 0.34583713042133696, \"specificity\": 0.999999974193302, \"npv\": 0.9998445270858967, \"accuracy\": 0.9998445140672433, \"f1\": 0.5138946262053457, \"f2\": 0.39788478105190167, \"f0_5\": 0.7253956446312815, \"p4\": 0.6788861691697762, \"phi\": 0.5879411567765098}, {\"truth_threshold\": 11.779999736696482, \"match_probability\": 0.9997157219993051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105046.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3455903882405967, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6544096117594034, \"precision\": 0.9996859505705231, \"recall\": 0.3455903882405967, \"specificity\": 0.999999974193302, \"npv\": 0.9998444684525483, \"accuracy\": 0.9998444554295953, \"f1\": 0.5136221396440446, \"f2\": 0.3976234799454624, \"f0_5\": 0.7251783502720645, \"p4\": 0.6786483475272421, \"phi\": 0.5877312989571764}, {\"truth_threshold\": 11.799999736249447, \"match_probability\": 0.999719634641183, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104994.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198967.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34541931366195006, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.65458068633805, \"precision\": 0.9996857950812649, \"recall\": 0.34541931366195006, \"specificity\": 0.999999974193302, \"npv\": 0.9998444278000974, \"accuracy\": 0.9998444147741594, \"f1\": 0.5134331569630405, \"f2\": 0.39744229375919377, \"f0_5\": 0.7250275871498435, \"p4\": 0.6784833563659494, \"phi\": 0.5875857535521786}, {\"truth_threshold\": 11.819999735802412, \"match_probability\": 0.9997234934465619, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104922.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 199039.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3451824411684394, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6548175588315607, \"precision\": 0.999685579534086, \"recall\": 0.3451824411684394, \"specificity\": 0.999999974193302, \"npv\": 0.999844371512094, \"accuracy\": 0.9998443584820175, \"f1\": 0.5131714092869929, \"f2\": 0.3971913970255883, \"f0_5\": 0.7248186951577894, \"p4\": 0.6782547697293441, \"phi\": 0.5873841696271049}, {\"truth_threshold\": 11.839999735355377, \"match_probability\": 0.9997272991558049, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104858.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 199103.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34497188784087435, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6550281121591257, \"precision\": 0.9996853876881715, \"recall\": 0.34497188784087435, \"specificity\": 0.999999974193302, \"npv\": 0.9998443214783186, \"accuracy\": 0.9998443084445578, \"f1\": 0.5129386672928101, \"f2\": 0.3969683547418672, \"f0_5\": 0.7246328737776856, \"p4\": 0.6780514475951928, \"phi\": 0.5872049258390488}, {\"truth_threshold\": 11.859999734908342, \"match_probability\": 0.9997310524991047, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104807.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 199154.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34480410315797094, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6551958968420291, \"precision\": 0.999685234643266, \"recall\": 0.34480410315797094, \"specificity\": 0.999999974193302, \"npv\": 0.9998442816076574, \"accuracy\": 0.9998442685709573, \"f1\": 0.5127531488425909, \"f2\": 0.3967906024453995, \"f0_5\": 0.7244847031954001, \"p4\": 0.6778893348860761, \"phi\": 0.5870620517766958}, {\"truth_threshold\": 11.879999734461308, \"match_probability\": 0.9997347541966228, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104732.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 199229.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3445573609772306, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6554426390227693, \"precision\": 0.9996850093065432, \"recall\": 0.3445573609772306, \"specificity\": 0.999999974193302, \"npv\": 0.9998442229743378, \"accuracy\": 0.9998442099333094, \"f1\": 0.5124802434883027, \"f2\": 0.3965291770690644, \"f0_5\": 0.7242666533890441, \"p4\": 0.6776507880783255, \"phi\": 0.5868518796934612}, {\"truth_threshold\": 11.899999734014273, \"match_probability\": 0.9997384049586276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104647.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 199314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3442777198390583, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6557222801609417, \"precision\": 0.9996847535345815, \"recall\": 0.3442777198390583, \"specificity\": 0.999999974193302, \"npv\": 0.9998441565232506, \"accuracy\": 0.9998441434773083, \"f1\": 0.5121708296524333, \"f2\": 0.3962328590771542, \"f0_5\": 0.7240193114250962, \"p4\": 0.6773802250365349, \"phi\": 0.5866135936657016}, {\"truth_threshold\": 11.919999733567238, \"match_probability\": 0.9997420054856294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104569.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 199392.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34402110797108837, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6559788920289116, \"precision\": 0.99968451846045, \"recall\": 0.34402110797108837, \"specificity\": 0.999999974193302, \"npv\": 0.9998440955446136, \"accuracy\": 0.9998440824941545, \"f1\": 0.5118867836784046, \"f2\": 0.3959609101773189, \"f0_5\": 0.7237921339370875, \"p4\": 0.6771317471175002, \"phi\": 0.5863948460246691}, {\"truth_threshold\": 11.939999733120203, \"match_probability\": 0.9997455564685144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104497.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199464.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3437842354775777, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6562157645224223, \"precision\": 0.9996938648604693, \"recall\": 0.3437842354775777, \"specificity\": 0.9999999749753231, \"npv\": 0.9998440392567697, \"accuracy\": 0.9998440269838478, \"f1\": 0.5116257435922544, \"f2\": 0.3957101516011006, \"f0_5\": 0.7235862657306631, \"p4\": 0.6769033120289796, \"phi\": 0.586195657766835}, {\"truth_threshold\": 11.959999732673168, \"match_probability\": 0.9997490585886768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104437.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3435868417329855, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6564131582670145, \"precision\": 0.9996936890369392, \"recall\": 0.3435868417329855, \"specificity\": 0.9999999749753231, \"npv\": 0.9998439923501362, \"accuracy\": 0.9998439800737294, \"f1\": 0.5114070954631148, \"f2\": 0.3955009153132628, \"f0_5\": 0.7234112410419526, \"p4\": 0.6767119131959768, \"phi\": 0.5860272776311601}, {\"truth_threshold\": 11.979999732226133, \"match_probability\": 0.9997525125181488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104362.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199599.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3433400995522452, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6566599004477548, \"precision\": 0.9996934689733127, \"recall\": 0.3433400995522452, \"specificity\": 0.9999999749753231, \"npv\": 0.9998439337168507, \"accuracy\": 0.9998439214360816, \"f1\": 0.5111336949467987, \"f2\": 0.39523934320933046, \"f0_5\": 0.7231922964449502, \"p4\": 0.6764725076405553, \"phi\": 0.5858167344253088}, {\"truth_threshold\": 11.999999731779099, \"match_probability\": 0.9997559189197288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104288.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199673.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3430966472672481, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6569033527327519, \"precision\": 0.9996932515337423, \"recall\": 0.3430966472672481, \"specificity\": 0.9999999749753231, \"npv\": 0.999843875865349, \"accuracy\": 0.9998438635802689, \"f1\": 0.5108638413249698, \"f2\": 0.3949812296048067, \"f0_5\": 0.7229760925959562, \"p4\": 0.6762361229989086, \"phi\": 0.5856089242973256}, {\"truth_threshold\": 12.019999731332064, \"match_probability\": 0.9997592784471085, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104250.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34297163122900637, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6570283687709937, \"precision\": 0.9996931397556625, \"recall\": 0.34297163122900637, \"specificity\": 0.9999999749753231, \"npv\": 0.9998438461578236, \"accuracy\": 0.9998438338705273, \"f1\": 0.5107252298263534, \"f2\": 0.39484867353570796, \"f0_5\": 0.7228650000208019, \"p4\": 0.6761146701636208, \"phi\": 0.5855021823352862}, {\"truth_threshold\": 12.039999730885029, \"match_probability\": 0.9997625917449974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104156.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199805.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3426623810291452, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6573376189708549, \"precision\": 0.9996928629016777, \"recall\": 0.3426623810291452, \"specificity\": 0.9999999749753231, \"npv\": 0.9998437726707949, \"accuracy\": 0.9998437603780086, \"f1\": 0.5103822378592132, \"f2\": 0.3945207388911784, \"f0_5\": 0.7225899907452759, \"p4\": 0.6758140412206046, \"phi\": 0.5852380528110277}, {\"truth_threshold\": 12.059999730437994, \"match_probability\": 0.9997658594492459, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104099.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34247485697178254, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6575251430282174, \"precision\": 0.9996926947786923, \"recall\": 0.34247485697178254, \"specificity\": 0.9999999749753231, \"npv\": 0.9998437281095168, \"accuracy\": 0.9998437158133961, \"f1\": 0.5101741764112014, \"f2\": 0.39432186215648024, \"f0_5\": 0.7224230900018738, \"p4\": 0.6756316109585225, \"phi\": 0.585077831107666}, {\"truth_threshold\": 12.07999972999096, \"match_probability\": 0.9997690821869673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104026.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3422346945825287, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6577653054174714, \"precision\": 0.9996924791942955, \"recall\": 0.3422346945825287, \"specificity\": 0.9999999749753231, \"npv\": 0.9998436710398156, \"accuracy\": 0.9998436587394188, \"f1\": 0.5099076268507103, \"f2\": 0.3940671352873168, \"f0_5\": 0.7222091855933063, \"p4\": 0.6753978243065771, \"phi\": 0.5848725708105128}, {\"truth_threshold\": 12.099999729543924, \"match_probability\": 0.9997722605766569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103977.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199984.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3420734896911117, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6579265103088883, \"precision\": 0.9996923343172226, \"recall\": 0.3420734896911117, \"specificity\": 0.9999999749753231, \"npv\": 0.9998436327327596, \"accuracy\": 0.9998436204294888, \"f1\": 0.5097286565188617, \"f2\": 0.3938961384335983, \"f0_5\": 0.7220655086062858, \"p4\": 0.6752408057753306, \"phi\": 0.5847347529500045}, {\"truth_threshold\": 12.11999972909689, \"match_probability\": 0.999775395228311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103897.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200064.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34181029803165536, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6581897019683446, \"precision\": 0.9996920974896324, \"recall\": 0.34181029803165536, \"specificity\": 0.9999999749753231, \"npv\": 0.9998435701906334, \"accuracy\": 0.9998435578826643, \"f1\": 0.5094363676481404, \"f2\": 0.3936169326088653, \"f0_5\": 0.7218307657463001, \"p4\": 0.6749842878607125, \"phi\": 0.5845096743852956}, {\"truth_threshold\": 12.139999728649855, \"match_probability\": 0.9997784867435432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103830.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3415898750168607, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6584101249831393, \"precision\": 0.9996918988658027, \"recall\": 0.3415898750168607, \"specificity\": 0.9999999749753231, \"npv\": 0.9998435178116089, \"accuracy\": 0.9998435054996989, \"f1\": 0.5091914874835407, \"f2\": 0.3933830716841478, \"f0_5\": 0.7216340079148301, \"p4\": 0.6747693001852427, \"phi\": 0.5843211043978405}, {\"truth_threshold\": 12.15999972820282, \"match_probability\": 0.9997815357156987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103754.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200207.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3413398429403772, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6586601570596228, \"precision\": 0.9996916732507275, \"recall\": 0.3413398429403772, \"specificity\": 0.9999999749753231, \"npv\": 0.9998434583966026, \"accuracy\": 0.9998434460802157, \"f1\": 0.5089136155508195, \"f2\": 0.39311776785917263, \"f0_5\": 0.7214106423957558, \"p4\": 0.6745252635365023, \"phi\": 0.584107130445131}, {\"truth_threshold\": 12.179999727755785, \"match_probability\": 0.9997845427299689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103678.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200283.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3410898108638937, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6589101891361063, \"precision\": 0.999691447304985, \"recall\": 0.3410898108638937, \"specificity\": 0.9999999749753231, \"npv\": 0.9998433989816033, \"accuracy\": 0.9998433866607324, \"f1\": 0.5086356400136385, \"f2\": 0.39285243347373433, \"f0_5\": 0.7211870879422817, \"p4\": 0.6742810459615936, \"phi\": 0.5838930781048248}, {\"truth_threshold\": 12.19999972730875, \"match_probability\": 0.9997875083635023, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103566.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3407213425406549, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6592786574593451, \"precision\": 0.9996911137280643, \"recall\": 0.3407213425406549, \"specificity\": 0.9999999749753231, \"npv\": 0.99984331142267, \"accuracy\": 0.9998432990951782, \"f1\": 0.5082258028898884, \"f2\": 0.39246135866525395, \"f0_5\": 0.7208572943942602, \"p4\": 0.6739208161758101, \"phi\": 0.5835774894904138}, {\"truth_threshold\": 12.219999726861715, \"match_probability\": 0.9997904331855156, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103485.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200476.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34045486098545535, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6595451390145446, \"precision\": 0.999690872030681, \"recall\": 0.34045486098545535, \"specificity\": 0.9999999749753231, \"npv\": 0.9998432480988081, \"accuracy\": 0.9998432357665185, \"f1\": 0.5079292624387084, \"f2\": 0.3921784864036454, \"f0_5\": 0.7206185265497633, \"p4\": 0.6736600473687598, \"phi\": 0.5833491449431346}, {\"truth_threshold\": 12.23999972641468, \"match_probability\": 0.9997933177574019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103401.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200560.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34017850974302627, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6598214902569738, \"precision\": 0.9996906209816983, \"recall\": 0.34017850974302627, \"specificity\": 0.9999999749753231, \"npv\": 0.9998431824296264, \"accuracy\": 0.9998431700923527, \"f1\": 0.5076216144567667, \"f2\": 0.391885100702885, \"f0_5\": 0.7203706877453173, \"p4\": 0.6733894025242676, \"phi\": 0.5831122487731097}, {\"truth_threshold\": 12.259999725967646, \"match_probability\": 0.9997961626328384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103335.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3399613766239748, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6600386233760253, \"precision\": 0.9996904234426848, \"recall\": 0.3399613766239748, \"specificity\": 0.9999999749753231, \"npv\": 0.9998431308324184, \"accuracy\": 0.9998431184912225, \"f1\": 0.5073798020268678, \"f2\": 0.3916545571557545, \"f0_5\": 0.720175794399167, \"p4\": 0.6731765971611204, \"phi\": 0.5829260485517991}, {\"truth_threshold\": 12.27999972552061, \"match_probability\": 0.9997989683578922, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103259.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200702.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3397113445474913, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6602886554525087, \"precision\": 0.999690195660803, \"recall\": 0.3397113445474913, \"specificity\": 0.9999999749753231, \"npv\": 0.9998430714174581, \"accuracy\": 0.9998430590717393, \"f1\": 0.5071012542602614, \"f2\": 0.39138905419081443, \"f0_5\": 0.7199511940038348, \"p4\": 0.6729313784894215, \"phi\": 0.5827115624956363}, {\"truth_threshold\": 12.299999725073576, \"match_probability\": 0.9998017354711247, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103144.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200817.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33933300653702286, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6606669934629772, \"precision\": 0.9996898503527952, \"recall\": 0.33933300653702286, \"specificity\": 0.9999999749753231, \"npv\": 0.9998429815132552, \"accuracy\": 0.9998429691606792, \"f1\": 0.5066795697762669, \"f2\": 0.39098724810844415, \"f0_5\": 0.7196109758394788, \"p4\": 0.6725599773376938, \"phi\": 0.5823868610782573}, {\"truth_threshold\": 12.319999724626541, \"match_probability\": 0.9998044645036945, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103078.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3391158734179714, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6608841265820287, \"precision\": 0.9996896518281447, \"recall\": 0.3391158734179714, \"specificity\": 0.9999999749753231, \"npv\": 0.9998429299160679, \"accuracy\": 0.999842917559549, \"f1\": 0.5064374519432728, \"f2\": 0.3907566147113546, \"f0_5\": 0.7194155228705711, \"p4\": 0.6723466366410628, \"phi\": 0.5822004289374311}, {\"truth_threshold\": 12.339999724179506, \"match_probability\": 0.9998071559794593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102996.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200965.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3388461019670287, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6611538980329713, \"precision\": 0.9996894048219901, \"recall\": 0.3388461019670287, \"specificity\": 0.9999999749753231, \"npv\": 0.9998428658104789, \"accuracy\": 0.9998428534490539, \"f1\": 0.506136529488512, \"f2\": 0.3904700380325005, \"f0_5\": 0.7191724866040194, \"p4\": 0.6720813850078249, \"phi\": 0.5819687179574975}, {\"truth_threshold\": 12.359999723732471, \"match_probability\": 0.9998098104150758, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102905.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201056.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3385467214543971, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6614532785456029, \"precision\": 0.9996891302447127, \"recall\": 0.3385467214543971, \"specificity\": 0.9999999749753231, \"npv\": 0.9998427946689202, \"accuracy\": 0.999842782302041, \"f1\": 0.5058024369743769, \"f2\": 0.39015196609596287, \"f0_5\": 0.7189025148489121, \"p4\": 0.671786771059888, \"phi\": 0.5817114672718338}, {\"truth_threshold\": 12.379999723285437, \"match_probability\": 0.9998124283200986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102840.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201121.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3383328782310889, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6616671217689112, \"precision\": 0.9996889338206704, \"recall\": 0.3383328782310889, \"specificity\": 0.9999999749753231, \"npv\": 0.9998427438535274, \"accuracy\": 0.9998427314827462, \"f1\": 0.5055637079587939, \"f2\": 0.38992474497920704, \"f0_5\": 0.7187095096925148, \"p4\": 0.6715761717456707, \"phi\": 0.5815276471309883}, {\"truth_threshold\": 12.399999722838402, \"match_probability\": 0.999815010197078, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102774.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201187.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3381157451120374, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6618842548879627, \"precision\": 0.9996887341205766, \"recall\": 0.3381157451120374, \"specificity\": 0.9999999749753231, \"npv\": 0.9998426922563646, \"accuracy\": 0.999842679881616, \"f1\": 0.5053212281232253, \"f2\": 0.38969400523262426, \"f0_5\": 0.7185133916399253, \"p4\": 0.6713621952017929, \"phi\": 0.5813409395349567}, {\"truth_threshold\": 12.419999722391367, \"match_probability\": 0.9998175565416553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102731.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201230.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33797427959507964, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6620257204049204, \"precision\": 0.9996886038749355, \"recall\": 0.33797427959507964, \"specificity\": 0.9999999749753231, \"npv\": 0.9998426586400341, \"accuracy\": 0.9998426462626979, \"f1\": 0.5051632064987559, \"f2\": 0.3895436623649048, \"f0_5\": 0.7183855398433315, \"p4\": 0.6712227117799741, \"phi\": 0.58121926445044}, {\"truth_threshold\": 12.439999721944332, \"match_probability\": 0.9998200678426586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102650.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201311.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3377077980398801, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6622922019601198, \"precision\": 0.999688358232212, \"recall\": 0.3377077980398801, \"specificity\": 0.9999999749753231, \"npv\": 0.9998425953162549, \"accuracy\": 0.9998425829340382, \"f1\": 0.5048654470874945, \"f2\": 0.38926043172451663, \"f0_5\": 0.718144535595203, \"p4\": 0.6709598042232551, \"phi\": 0.5809899933584187}, {\"truth_threshold\": 12.459999721497297, \"match_probability\": 0.9998225445821961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102599.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201362.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3375400133569767, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6624599866430233, \"precision\": 0.9996882033693524, \"recall\": 0.3375400133569767, \"specificity\": 0.9999999749753231, \"npv\": 0.9998425554457314, \"accuracy\": 0.9998425430604375, \"f1\": 0.5046779080749252, \"f2\": 0.38908208346764256, \"f0_5\": 0.7179926800422682, \"p4\": 0.6707941626942868, \"phi\": 0.5808455910723763}, {\"truth_threshold\": 12.479999721050262, \"match_probability\": 0.9998249872357476, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102532.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201429.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33731959034218206, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6626804096578179, \"precision\": 0.9996879996879997, \"recall\": 0.33731959034218206, \"specificity\": 0.9999999749753231, \"npv\": 0.9998425030668131, \"accuracy\": 0.999842490677472, \"f1\": 0.5044314617797183, \"f2\": 0.3888477618461053, \"f0_5\": 0.7177930516915727, \"p4\": 0.6705764292467178, \"phi\": 0.5806558315481218}, {\"truth_threshold\": 12.499999720603228, \"match_probability\": 0.9998273962722566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102490.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33718141472096747, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6628185852790325, \"precision\": 0.9996878718714032, \"recall\": 0.33718141472096747, \"specificity\": 0.9999999749753231, \"npv\": 0.9998424702322701, \"accuracy\": 0.9998424578403892, \"f1\": 0.5042769316305971, \"f2\": 0.388700861521004, \"f0_5\": 0.717667835120559, \"p4\": 0.670439866634514, \"phi\": 0.5805368461985211}, {\"truth_threshold\": 12.519999720156193, \"match_probability\": 0.9998297721542191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102437.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3370070502465777, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6629929497534223, \"precision\": 0.9996877104294958, \"recall\": 0.3370070502465777, \"specificity\": 0.9999999749753231, \"npv\": 0.9998424287982072, \"accuracy\": 0.999842416403118, \"f1\": 0.5040818837192136, \"f2\": 0.38851547394283453, \"f0_5\": 0.7175097396184283, \"p4\": 0.6702674572856174, \"phi\": 0.5803866632175144}, {\"truth_threshold\": 12.539999719709158, \"match_probability\": 0.9998321153377727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102363.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3367635979615806, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6632364020384194, \"precision\": 0.9996874847404659, \"recall\": 0.3367635979615806, \"specificity\": 0.9999999749753231, \"npv\": 0.9998423709468796, \"accuracy\": 0.9998423585473054, \"f1\": 0.5038094675604642, \"f2\": 0.3882566059720582, \"f0_5\": 0.7172888453501621, \"p4\": 0.6700265847199469, \"phi\": 0.5801769087600593}, {\"truth_threshold\": 12.559999719262123, \"match_probability\": 0.9998344262727838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102303.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33656620421698835, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6634337957830116, \"precision\": 0.9996873015097474, \"recall\": 0.33656620421698835, \"specificity\": 0.9999999749753231, \"npv\": 0.9998423240404026, \"accuracy\": 0.9998423116371871, \"f1\": 0.5035885167464115, \"f2\": 0.3880466916860305, \"f0_5\": 0.7171096073046301, \"p4\": 0.6698311541294032, \"phi\": 0.5800067819094323}, {\"truth_threshold\": 12.579999718815088, \"match_probability\": 0.9998367054029336, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102203.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201758.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.336237214642668, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.663762785357332, \"precision\": 0.9996869956472832, \"recall\": 0.336237214642668, \"specificity\": 0.9999999749753231, \"npv\": 0.999842245862951, \"accuracy\": 0.9998422334536564, \"f1\": 0.5032201203359954, \"f2\": 0.3876967920739197, \"f0_5\": 0.7168106090466979, \"p4\": 0.6695051804426273, \"phi\": 0.5797231262476972}, {\"truth_threshold\": 12.599999718368053, \"match_probability\": 0.9998389531658027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102148.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33605627037679175, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6639437296232082, \"precision\": 0.9996868271677432, \"recall\": 0.33605627037679175, \"specificity\": 0.9999999749753231, \"npv\": 0.9998422028653577, \"accuracy\": 0.9998421904527146, \"f1\": 0.5030174249829493, \"f2\": 0.38750432465569673, \"f0_5\": 0.7166460169416612, \"p4\": 0.6693257583516381, \"phi\": 0.5795670564769578}, {\"truth_threshold\": 12.619999717921019, \"match_probability\": 0.9998411699929557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102088.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33585887663219954, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6641411233678005, \"precision\": 0.9996866431649041, \"recall\": 0.33585887663219954, \"specificity\": 0.9999999749753231, \"npv\": 0.9998421559588966, \"accuracy\": 0.9998421435425963, \"f1\": 0.502796240158983, \"f2\": 0.3872943418788374, \"f0_5\": 0.7164663459851413, \"p4\": 0.6691299145124948, \"phi\": 0.5793967506142625}, {\"truth_threshold\": 12.639999717473984, \"match_probability\": 0.9998433563100231, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101979.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3355002779961903, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6644997220038097, \"precision\": 0.9996863083392967, \"recall\": 0.3355002779961903, \"specificity\": 0.9999999749753231, \"npv\": 0.9998420707455035, \"accuracy\": 0.999842058322548, \"f1\": 0.5023942537909019, \"f2\": 0.3869128242484947, \"f0_5\": 0.7161396338508859, \"p4\": 0.6687738358118853, \"phi\": 0.5790872335280387}, {\"truth_threshold\": 12.659999717026949, \"match_probability\": 0.9998455125367829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101879.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3351712884218699, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6648287115781301, \"precision\": 0.9996860005298741, \"recall\": 0.3351712884218699, \"specificity\": 0.9999999749753231, \"npv\": 0.9998419925680914, \"accuracy\": 0.9998419801390174, \"f1\": 0.502025269050341, \"f2\": 0.38656275256022554, \"f0_5\": 0.7158395458154454, \"p4\": 0.6684468221373134, \"phi\": 0.5788031273650014}, {\"truth_threshold\": 12.679999716579914, \"match_probability\": 0.9998476390872413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101806.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202155.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33493112603261604, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.665068873967384, \"precision\": 0.999685775447279, \"recall\": 0.33493112603261604, \"specificity\": 0.9999999749753231, \"npv\": 0.9998419354985884, \"accuracy\": 0.99984192306504, \"f1\": 0.5017557953568146, \"f2\": 0.38630716667602655, \"f0_5\": 0.7156202684331652, \"p4\": 0.6682078988618059, \"phi\": 0.578595641804399}, {\"truth_threshold\": 12.69999971613288, \"match_probability\": 0.9998497363697118, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101717.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202244.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33463832531147086, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6653616746885291, \"precision\": 0.9996855005946005, \"recall\": 0.33463832531147086, \"specificity\": 0.9999999749753231, \"npv\": 0.9998418659207098, \"accuracy\": 0.9998418534816979, \"f1\": 0.5014271277513495, \"f2\": 0.3859955236556357, \"f0_5\": 0.7153526865900469, \"p4\": 0.6679163764503124, \"phi\": 0.5783425792908723}, {\"truth_threshold\": 12.719999715685844, \"match_probability\": 0.999851804786893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101645.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202316.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3344014528179602, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6655985471820398, \"precision\": 0.9996852778897882, \"recall\": 0.3344014528179602, \"specificity\": 0.9999999749753231, \"npv\": 0.9998418096329948, \"accuracy\": 0.9998417971895559, \"f1\": 0.5011611338188237, \"f2\": 0.38574337714541174, \"f0_5\": 0.7151360197222617, \"p4\": 0.6676803510385995, \"phi\": 0.5781377735329882}, {\"truth_threshold\": 12.73999971523881, \"match_probability\": 0.9998538447359463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101551.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.334092202618099, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.665907797381901, \"precision\": 0.9996849866611539, \"recall\": 0.334092202618099, \"specificity\": 0.9999999749753231, \"npv\": 0.9998417361462656, \"accuracy\": 0.9998417236970372, \"f1\": 0.5008137218156353, \"f2\": 0.385414144389025, \"f0_5\": 0.7148528846546425, \"p4\": 0.6673719546378969, \"phi\": 0.5778702790294269}, {\"truth_threshold\": 12.759999714791775, \"match_probability\": 0.9998558566085717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101482.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202479.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33386519981181795, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.666134800188182, \"precision\": 0.9996847725436886, \"recall\": 0.33386519981181795, \"specificity\": 0.9999999749753231, \"npv\": 0.999841682203886, \"accuracy\": 0.999841669750401, \"f1\": 0.500558604106295, \"f2\": 0.3851724436333935, \"f0_5\": 0.7146448606160134, \"p4\": 0.6671453966286446, \"phi\": 0.577673847874967}, {\"truth_threshold\": 12.77999971434474, \"match_probability\": 0.9998578407910829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101407.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202554.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33361845763107767, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6663815423689223, \"precision\": 0.999684539476927, \"recall\": 0.33361845763107767, \"specificity\": 0.9999999749753231, \"npv\": 0.9998416235708714, \"accuracy\": 0.999841611112753, \"f1\": 0.5002812037493833, \"f2\": 0.3849096967014681, \"f0_5\": 0.7144185640191795, \"p4\": 0.6668989630204863, \"phi\": 0.5774602599877297}, {\"truth_threshold\": 12.799999713897705, \"match_probability\": 0.9998597976644809, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101323.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33334210638864853, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6666578936113514, \"precision\": 0.9996842780326575, \"recall\": 0.33334210638864853, \"specificity\": 0.9999999749753231, \"npv\": 0.9998415579019031, \"accuracy\": 0.9998415454385874, \"f1\": 0.49997039347077343, \"f2\": 0.38461538461538464, \"f0_5\": 0.7141648845965708, \"p4\": 0.6666227408399593, \"phi\": 0.5772209477552683}, {\"truth_threshold\": 12.81999971345067, \"match_probability\": 0.9998617276045275, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101246.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202715.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33308878441642187, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6669112155835781, \"precision\": 0.9996840379944312, \"recall\": 0.33308878441642187, \"specificity\": 0.9999999749753231, \"npv\": 0.9998414977053565, \"accuracy\": 0.9998414852372689, \"f1\": 0.4996853708552237, \"f2\": 0.38434556555884725, \"f0_5\": 0.7139321339269723, \"p4\": 0.666369335949085, \"phi\": 0.5770014910436642}, {\"truth_threshold\": 12.839999713003635, \"match_probability\": 0.9998636309818171, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101169.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33283546244419515, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6671645375558048, \"precision\": 0.9996837975909328, \"recall\": 0.33283546244419515, \"specificity\": 0.9999999749753231, \"npv\": 0.999841437508817, \"accuracy\": 0.9998414250359503, \"f1\": 0.49940023990403837, \"f2\": 0.384075714952792, \"f0_5\": 0.713699180969715, \"p4\": 0.6661157383555185, \"phi\": 0.576781950858617}, {\"truth_threshold\": 12.8599997125566, \"match_probability\": 0.9998655081618473, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101080.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33254266172304997, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.66745733827695, \"precision\": 0.9996835192657647, \"recall\": 0.33254266172304997, \"specificity\": 0.9999999749753231, \"npv\": 0.9998413679310079, \"accuracy\": 0.9998413554526081, \"f1\": 0.4990705379030446, \"f2\": 0.3837637703917215, \"f0_5\": 0.7134296712774683, \"p4\": 0.6658223786806096, \"phi\": 0.576528092493383}, {\"truth_threshold\": 12.879999712109566, \"match_probability\": 0.9998673595050896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101021.0, \"tn\": 1278737761.0, \"fp\": 31.0, \"fn\": 202940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.332348557874201, \"tn_rate\": 0.9999999757573443, \"fp_rate\": 2.4242655682768778e-08, \"fn_rate\": 0.6676514421257991, \"precision\": 0.999693227249337, \"recall\": 0.332348557874201, \"specificity\": 0.9999999757573443, \"npv\": 0.9998413218065221, \"accuracy\": 0.9998413101061604, \"f1\": 0.4988531232330814, \"f2\": 0.3835572437003378, \"f0_5\": 0.7132548868984663, \"p4\": 0.6656288586029424, \"phi\": 0.5763625956746175}, {\"truth_threshold\": 12.899999711662531, \"match_probability\": 0.9998691853670579, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100939.0, \"tn\": 1278737761.0, \"fp\": 31.0, \"fn\": 203022.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3320787864232582, \"tn_rate\": 0.9999999757573443, \"fp_rate\": 2.4242655682768778e-08, \"fn_rate\": 0.6679212135767417, \"precision\": 0.9996929781123106, \"recall\": 0.3320787864232582, \"specificity\": 0.9999999757573443, \"npv\": 0.9998412577011394, \"accuracy\": 0.9998412459956654, \"f1\": 0.4985491355317326, \"f2\": 0.38326977082564434, \"f0_5\": 0.7130061694646114, \"p4\": 0.6653581859411349, \"phi\": 0.5761285375556959}, {\"truth_threshold\": 12.919999711215496, \"match_probability\": 0.999870986098377, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100853.0, \"tn\": 1278737761.0, \"fp\": 31.0, \"fn\": 203108.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3317958553893427, \"tn_rate\": 0.9999999757573443, \"fp_rate\": 2.4242655682768778e-08, \"fn_rate\": 0.6682041446106572, \"precision\": 0.9996927163871377, \"recall\": 0.3317958553893427, \"specificity\": 0.9999999757573443, \"npv\": 0.9998411904686737, \"accuracy\": 0.9998411787578291, \"f1\": 0.4982301868616384, \"f2\": 0.38296823641632893, \"f0_5\": 0.7127450717105515, \"p4\": 0.6650740738666041, \"phi\": 0.5758829597969705}, {\"truth_threshold\": 12.939999710768461, \"match_probability\": 0.9998727620448491, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100770.0, \"tn\": 1278737761.0, \"fp\": 31.0, \"fn\": 203191.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3315227940426568, \"tn_rate\": 0.9999999757573443, \"fp_rate\": 2.4242655682768778e-08, \"fn_rate\": 0.6684772059573432, \"precision\": 0.999692463368419, \"recall\": 0.3315227940426568, \"specificity\": 0.9999999757573443, \"npv\": 0.999841125581535, \"accuracy\": 0.9998411138654987, \"f1\": 0.4979222357830033, \"f2\": 0.38267718329542133, \"f0_5\": 0.7124928411332574, \"p4\": 0.6647996433986924, \"phi\": 0.5756458493872987}, {\"truth_threshold\": 12.959999710321426, \"match_probability\": 0.999874513547521, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100701.0, \"tn\": 1278737761.0, \"fp\": 31.0, \"fn\": 203260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3312957912363757, \"tn_rate\": 0.9999999757573443, \"fp_rate\": 2.4242655682768778e-08, \"fn_rate\": 0.6687042087636242, \"precision\": 0.9996922527101616, \"recall\": 0.3312957912363757, \"specificity\": 0.9999999757573443, \"npv\": 0.9998410716392214, \"accuracy\": 0.9998410599188625, \"f1\": 0.4976661321050772, \"f2\": 0.3824351955375155, \"f0_5\": 0.7122829751205635, \"p4\": 0.664571330772701, \"phi\": 0.5754486591574539}, {\"truth_threshold\": 12.979999709874392, \"match_probability\": 0.9998762409427487, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100622.0, \"tn\": 1278737762.0, \"fp\": 30.0, \"fn\": 203339.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3310358894726626, \"tn_rate\": 0.9999999765393655, \"fp_rate\": 2.346063453171172e-08, \"fn_rate\": 0.6689641105273374, \"precision\": 0.9997019433294917, \"recall\": 0.3310358894726626, \"specificity\": 0.9999999765393655, \"npv\": 0.9998410098793127, \"accuracy\": 0.9998409989357087, \"f1\": 0.49737403395343205, \"f2\": 0.38215839622756165, \"f0_5\": 0.7120465234110186, \"p4\": 0.6643108343403448, \"phi\": 0.5752256662664633}, {\"truth_threshold\": 12.999999709427357, \"match_probability\": 0.9998779445622623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100552.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33080559677063837, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6691944032293616, \"precision\": 0.9997116751672781, \"recall\": 0.33080559677063837, \"specificity\": 0.9999999773213866, \"npv\": 0.9998409551553634, \"accuracy\": 0.9998409449890726, \"f1\": 0.49711525626510966, \"f2\": 0.38191313595533355, \"f0_5\": 0.7118372894794595, \"p4\": 0.6640799685713175, \"phi\": 0.5750283312229711}, {\"truth_threshold\": 13.019999708980322, \"match_probability\": 0.9998796247332291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100496.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3306213626090189, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6693786373909811, \"precision\": 0.9997115145486197, \"recall\": 0.3306213626090189, \"specificity\": 0.9999999773213866, \"npv\": 0.999840911376109, \"accuracy\": 0.9998409012062955, \"f1\": 0.49690718591001914, \"f2\": 0.38171667670691123, \"f0_5\": 0.7116665557225226, \"p4\": 0.6638942828785148, \"phi\": 0.5748681260862539}, {\"truth_threshold\": 13.039999708533287, \"match_probability\": 0.9998812817783169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100439.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3304338385516563, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6695661614483437, \"precision\": 0.9997113508778914, \"recall\": 0.3304338385516563, \"specificity\": 0.9999999773213866, \"npv\": 0.999840866815086, \"accuracy\": 0.9998408566416831, \"f1\": 0.496695340838565, \"f2\": 0.38151669209123673, \"f0_5\": 0.7114926618619418, \"p4\": 0.6637051755256349, \"phi\": 0.5747050142957282}, {\"truth_threshold\": 13.059999708086252, \"match_probability\": 0.9998829160157551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100379.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203582.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33023644480706404, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.669763555192936, \"precision\": 0.99971117839216, \"recall\": 0.33023644480706404, \"specificity\": 0.9999999773213866, \"npv\": 0.9998408199087504, \"accuracy\": 0.9998408097315648, \"f1\": 0.4964722815052588, \"f2\": 0.3813061632574917, \"f0_5\": 0.7113094942835317, \"p4\": 0.6635059996964694, \"phi\": 0.5745332676618786}, {\"truth_threshold\": 13.079999707639217, \"match_probability\": 0.9998845277593964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100325.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203636.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33005879043693104, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6699412095630689, \"precision\": 0.9997110229786556, \"recall\": 0.33005879043693104, \"specificity\": 0.9999999773213866, \"npv\": 0.999840777693052, \"accuracy\": 0.9998407675124582, \"f1\": 0.496271471501181, \"f2\": 0.3811166708960202, \"f0_5\": 0.7111445368930374, \"p4\": 0.6633266401168267, \"phi\": 0.5743786517971498}, {\"truth_threshold\": 13.099999707192183, \"match_probability\": 0.9998861173187764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100260.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3298449472136228, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6701550527863772, \"precision\": 0.9997108356848707, \"recall\": 0.3298449472136228, \"specificity\": 0.9999999773213866, \"npv\": 0.9998407268778644, \"accuracy\": 0.9998407166931633, \"f1\": 0.4960296846011132, \"f2\": 0.38088855761537777, \"f0_5\": 0.7109458430303056, \"p4\": 0.6631106168882743, \"phi\": 0.5741924849058512}, {\"truth_threshold\": 13.119999706745148, \"match_probability\": 0.9998876849991732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100201.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3296508433647738, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6703491566352262, \"precision\": 0.9997106654694203, \"recall\": 0.3296508433647738, \"specificity\": 0.9999999773213866, \"npv\": 0.9998406807533139, \"accuracy\": 0.9998406705648804, \"f1\": 0.49581014916215355, \"f2\": 0.3806814814364542, \"f0_5\": 0.7107653632315242, \"p4\": 0.6629144136239737, \"phi\": 0.5740234503922995}, {\"truth_threshold\": 13.139999706298113, \"match_probability\": 0.9998892311016662, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100123.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32939423149680386, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6706057685031961, \"precision\": 0.9997104401310009, \"recall\": 0.32939423149680386, \"specificity\": 0.9999999773213866, \"npv\": 0.9998406197751011, \"accuracy\": 0.9998406095817265, \"f1\": 0.49551981747679485, \"f2\": 0.38040769120878787, \"f0_5\": 0.710526577240838, \"p4\": 0.6626548498678626, \"phi\": 0.5737999046280455}, {\"truth_threshold\": 13.159999705851078, \"match_probability\": 0.9998907559231927, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100028.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32908169140119947, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6709183085988005, \"precision\": 0.9997101652058327, \"recall\": 0.32908169140119947, \"specificity\": 0.9999999773213866, \"npv\": 0.999840545506775, \"accuracy\": 0.9998405353073724, \"f1\": 0.4951660569578583, \"f2\": 0.38007418491208683, \"f0_5\": 0.7102354623545667, \"p4\": 0.6623384429249856, \"phi\": 0.5735275197008003}, {\"truth_threshold\": 13.179999705404043, \"match_probability\": 0.9998922597566062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99979.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3289204865097825, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6710795134902175, \"precision\": 0.9997100231981442, \"recall\": 0.3289204865097825, \"specificity\": 0.9999999773213866, \"npv\": 0.9998405071999585, \"accuracy\": 0.9998404969974424, \"f1\": 0.49498352596362594, \"f2\": 0.37990214704997216, \"f0_5\": 0.7100851855061059, \"p4\": 0.6621751268209354, \"phi\": 0.5733869758559528}, {\"truth_threshold\": 13.199999704957008, \"match_probability\": 0.9998937428907317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99950.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204011.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3288250795332296, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6711749204667704, \"precision\": 0.9997099390872083, \"recall\": 0.3288250795332296, \"specificity\": 0.9999999773213866, \"npv\": 0.9998404845285787, \"accuracy\": 0.9998404743242185, \"f1\": 0.4948754765559241, \"f2\": 0.3798003226877779, \"f0_5\": 0.7099962067236179, \"p4\": 0.6620784328968021, \"phi\": 0.5733037806211615}, {\"truth_threshold\": 13.219999704509974, \"match_probability\": 0.9998952056104213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99901.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204060.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3286638746418126, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6713361253581874, \"precision\": 0.9997097968578005, \"recall\": 0.3286638746418126, \"specificity\": 0.9999999773213866, \"npv\": 0.9998404462217669, \"accuracy\": 0.9998404360142886, \"f1\": 0.4946928750578745, \"f2\": 0.37962826442838965, \"f0_5\": 0.7098457966038588, \"p4\": 0.6619149901828043, \"phi\": 0.5731631819310123}, {\"truth_threshold\": 13.239999704062939, \"match_probability\": 0.9998966481966088, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99828.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204133.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32842371225255873, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6715762877474413, \"precision\": 0.9997496319589797, \"recall\": 0.32842371225255873, \"specificity\": 0.9999999804494712, \"npv\": 0.9998403891529396, \"accuracy\": 0.9998403820676525, \"f1\": 0.4944256514137697, \"f2\": 0.3793730623388212, \"f0_5\": 0.7096377028973248, \"p4\": 0.6616757322289457, \"phi\": 0.572965134996604}, {\"truth_threshold\": 13.259999703615904, \"match_probability\": 0.9998980709263633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99778.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204183.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32825921746539855, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6717407825346015, \"precision\": 0.9997495065278599, \"recall\": 0.32825921746539855, \"specificity\": 0.9999999804494712, \"npv\": 0.9998403500643638, \"accuracy\": 0.9998403429758872, \"f1\": 0.49423920904290625, \"f2\": 0.37919745950091477, \"f0_5\": 0.7094840103360055, \"p4\": 0.6615087507283617, \"phi\": 0.5728215817938453}, {\"truth_threshold\": 13.279999703168869, \"match_probability\": 0.9998994740729429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99673.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204288.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32791377841236213, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6720862215876379, \"precision\": 0.9997492427129933, \"recall\": 0.32791377841236213, \"specificity\": 0.9999999804494712, \"npv\": 0.9998402679783643, \"accuracy\": 0.9998402608831801, \"f1\": 0.4938475297218692, \"f2\": 0.3788286500925094, \"f0_5\": 0.7091609712089454, \"p4\": 0.6611578191827753, \"phi\": 0.572520002942835}, {\"truth_threshold\": 13.299999702721834, \"match_probability\": 0.9999008579058464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99628.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204333.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32776573310391793, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.672234266896082, \"precision\": 0.9997491294792932, \"recall\": 0.32776573310391793, \"specificity\": 0.9999999804494712, \"npv\": 0.9998402327986544, \"accuracy\": 0.9998402257005914, \"f1\": 0.49367960477089495, \"f2\": 0.3786705708944984, \"f0_5\": 0.7090224076359325, \"p4\": 0.6610073076922092, \"phi\": 0.5723907062378011}, {\"truth_threshold\": 13.3199997022748, \"match_probability\": 0.9999022226908654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99579.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204382.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32760452821250097, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.672395471787499, \"precision\": 0.9997490060640135, \"recall\": 0.32760452821250097, \"specificity\": 0.9999999804494712, \"npv\": 0.999840194491862, \"accuracy\": 0.9998401873906614, \"f1\": 0.493496710567071, \"f2\": 0.3784984279120117, \"f0_5\": 0.7088714465308517, \"p4\": 0.6608433407259285, \"phi\": 0.5722498832782067}, {\"truth_threshold\": 13.339999701827765, \"match_probability\": 0.9999035686901352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99492.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204469.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3273183072828422, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6726816927171578, \"precision\": 0.9997487866394686, \"recall\": 0.3273183072828422, \"specificity\": 0.9999999804494712, \"npv\": 0.9998401264777684, \"accuracy\": 0.9998401193709897, \"f1\": 0.49317187058526113, \"f2\": 0.37819275468863683, \"f0_5\": 0.7086032058504705, \"p4\": 0.6605520185581139, \"phi\": 0.5719997652776951}, {\"truth_threshold\": 13.35999970138073, \"match_probability\": 0.999904896162185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99411.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204550.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3270518257276427, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6729481742723573, \"precision\": 0.9997485820024941, \"recall\": 0.3270518257276427, \"specificity\": 0.9999999804494712, \"npv\": 0.9998400631543104, \"accuracy\": 0.99984005604233, \"f1\": 0.49286930740684737, \"f2\": 0.3779081260263974, \"f0_5\": 0.7083532253582346, \"p4\": 0.6602805605912154, \"phi\": 0.5717667984700293}, {\"truth_threshold\": 13.379999700933695, \"match_probability\": 0.9999062053619875, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99349.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204612.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32684785219156404, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6731521478084359, \"precision\": 0.9997484251413851, \"recall\": 0.32684785219156404, \"specificity\": 0.9999999804494712, \"npv\": 0.9998400146845083, \"accuracy\": 0.9998400075685411, \"f1\": 0.4926376337287862, \"f2\": 0.37769023842435245, \"f0_5\": 0.7081617262355354, \"p4\": 0.6600726298944397, \"phi\": 0.5715884140621879}, {\"truth_threshold\": 13.39999970048666, \"match_probability\": 0.9999074965410077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99279.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204682.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3266175594895398, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6733824405104603, \"precision\": 0.9997482478047208, \"recall\": 0.3266175594895398, \"specificity\": 0.9999999804494712, \"npv\": 0.999839959960544, \"accuracy\": 0.9998399528400697, \"f1\": 0.4923759810546415, \"f2\": 0.3774442116020402, \"f0_5\": 0.7079453547392456, \"p4\": 0.6598377149655353, \"phi\": 0.571386945398944}, {\"truth_threshold\": 13.419999700039625, \"match_probability\": 0.9999087699472513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99195.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204766.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32634120824711066, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6736587917528893, \"precision\": 0.9997480346704294, \"recall\": 0.32634120824711066, \"specificity\": 0.9999999804494712, \"npv\": 0.9998398942917945, \"accuracy\": 0.999839887165904, \"f1\": 0.492061877915874, \"f2\": 0.3771489448422282, \"f0_5\": 0.7076854807295806, \"p4\": 0.659555600567173, \"phi\": 0.571145089223646}, {\"truth_threshold\": 13.43999969959259, \"match_probability\": 0.999910025825312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99100.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3260286681515063, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6739713318484937, \"precision\": 0.9997477931904162, \"recall\": 0.3260286681515063, \"specificity\": 0.9999999804494712, \"npv\": 0.9998398200235765, \"accuracy\": 0.9998398128915499, \"f1\": 0.49170648447229626, \"f2\": 0.3768149667406608, \"f0_5\": 0.7073912751744922, \"p4\": 0.65923625768478, \"phi\": 0.5708714379739405}, {\"truth_threshold\": 13.459999699145555, \"match_probability\": 0.9999112644164184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99018.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32575889670056357, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6742411032994364, \"precision\": 0.999747584382541, \"recall\": 0.32575889670056357, \"specificity\": 0.9999999804494712, \"npv\": 0.9998397559183867, \"accuracy\": 0.9998397487810549, \"f1\": 0.49139958908596443, \"f2\": 0.37652665210014247, \"f0_5\": 0.7071370725276483, \"p4\": 0.6589603708446378, \"phi\": 0.5706351282473064}, {\"truth_threshold\": 13.47999969869852, \"match_probability\": 0.999912485958481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98935.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205026.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32548583535387765, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6745141646461223, \"precision\": 0.9997473726758286, \"recall\": 0.32548583535387765, \"specificity\": 0.9999999804494712, \"npv\": 0.9998396910314346, \"accuracy\": 0.9998396838887245, \"f1\": 0.4910888238637351, \"f2\": 0.3762347848044271, \"f0_5\": 0.7068795271798697, \"p4\": 0.6586808894632896, \"phi\": 0.5703958370265623}, {\"truth_threshold\": 13.499999698251486, \"match_probability\": 0.9999136906861367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98841.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205120.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3251765851540165, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6748234148459835, \"precision\": 0.9997471324823498, \"recall\": 0.3251765851540165, \"specificity\": 0.9999999804494712, \"npv\": 0.999839617545017, \"accuracy\": 0.9998396103962057, \"f1\": 0.4907367182438119, \"f2\": 0.37590419179895185, \"f0_5\": 0.7065875540622655, \"p4\": 0.6583640885109946, \"phi\": 0.5701247112664484}, {\"truth_threshold\": 13.519999697804451, \"match_probability\": 0.9999148788307943, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98757.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205204.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32490023391158734, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6750997660884127, \"precision\": 0.999746917454597, \"recall\": 0.32490023391158734, \"specificity\": 0.9999999804494712, \"npv\": 0.9998395518763127, \"accuracy\": 0.9998395447220401, \"f1\": 0.4904219316040254, \"f2\": 0.3756087282618783, \"f0_5\": 0.7063263761838622, \"p4\": 0.6580807379501753, \"phi\": 0.5698823195695988}, {\"truth_threshold\": 13.539999697357416, \"match_probability\": 0.9999160506206793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98684.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205277.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32466007152233345, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6753399284776666, \"precision\": 0.9997467302880183, \"recall\": 0.32466007152233345, \"specificity\": 0.9999999804494712, \"npv\": 0.9998394948070886, \"accuracy\": 0.9998394876480627, \"f1\": 0.4901482603620831, \"f2\": 0.37535192571162973, \"f0_5\": 0.7060991961900237, \"p4\": 0.657834299539323, \"phi\": 0.5696715859068956}, {\"truth_threshold\": 13.559999696910381, \"match_probability\": 0.9999172062808771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98579.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205382.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32431463246929704, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.675685367530703, \"precision\": 0.9997464605898341, \"recall\": 0.32431463246929704, \"specificity\": 0.9999999804494712, \"npv\": 0.9998394127212296, \"accuracy\": 0.9998394055553557, \"f1\": 0.4897544495919914, \"f2\": 0.3749825021606028, \"f0_5\": 0.70577209730561, \"p4\": 0.6574795177268877, \"phi\": 0.5693683391109366}, {\"truth_threshold\": 13.579999696463346, \"match_probability\": 0.9999183460333761, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98478.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205483.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32398235299923345, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6760176470007665, \"precision\": 0.9997462006233313, \"recall\": 0.32398235299923345, \"specificity\": 0.9999999804494712, \"npv\": 0.9998393337624637, \"accuracy\": 0.9998393265899898, \"f1\": 0.48937544724497095, \"f2\": 0.3746270961930145, \"f0_5\": 0.705457087881623, \"p4\": 0.6571378995849869, \"phi\": 0.5690764921448437}, {\"truth_threshold\": 13.599999696016312, \"match_probability\": 0.9999194700971109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98402.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205559.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32373232092274995, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.67626767907725, \"precision\": 0.9997460046531947, \"recall\": 0.32373232092274995, \"specificity\": 0.9999999804494712, \"npv\": 0.9998392743479549, \"accuracy\": 0.9998392671705065, \"f1\": 0.48909013191248246, \"f2\": 0.3743596259827692, \"f0_5\": 0.7052198105405285, \"p4\": 0.6568806125961336, \"phi\": 0.5688567858335136}, {\"truth_threshold\": 13.619999695569277, \"match_probability\": 0.9999205786880038, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98316.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205645.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3234493898888344, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6765506101111656, \"precision\": 0.9997457825322094, \"recall\": 0.3234493898888344, \"specificity\": 0.9999999804494712, \"npv\": 0.9998392071157562, \"accuracy\": 0.9998391999326702, \"f1\": 0.48876714508006425, \"f2\": 0.3740569250143625, \"f0_5\": 0.7049510629907145, \"p4\": 0.6565892358241371, \"phi\": 0.5686080684454418}, {\"truth_threshold\": 13.639999695122242, \"match_probability\": 0.9999216720190062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98222.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32314013968897326, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6768598603110267, \"precision\": 0.9997455393039991, \"recall\": 0.32314013968897326, \"specificity\": 0.9999999804494712, \"npv\": 0.9998391336294099, \"accuracy\": 0.9998391264401515, \"f1\": 0.4884139549685735, \"f2\": 0.37372602049629744, \"f0_5\": 0.7046570122060581, \"p4\": 0.6562704669713484, \"phi\": 0.5683360900912853}, {\"truth_threshold\": 13.659999694675207, \"match_probability\": 0.9999227503001397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98159.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3229328762571514, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6770671237428486, \"precision\": 0.9997453760286809, \"recall\": 0.3229328762571514, \"specificity\": 0.9999999804494712, \"npv\": 0.9998390843779285, \"accuracy\": 0.9998390771845272, \"f1\": 0.4881771500329483, \"f2\": 0.37350421756614016, \"f0_5\": 0.7044597579722606, \"p4\": 0.6560566558845894, \"phi\": 0.568153733877244}, {\"truth_threshold\": 13.679999694228172, \"match_probability\": 0.9999238137385363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98071.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3226433654317495, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6773566345682506, \"precision\": 0.999745147610504, \"recall\": 0.3226433654317495, \"specificity\": 0.9999999804494712, \"npv\": 0.9998390155822166, \"accuracy\": 0.9998390083830203, \"f1\": 0.4878462506560015, \"f2\": 0.3731943619952205, \"f0_5\": 0.7041839892581981, \"p4\": 0.6557577729747776, \"phi\": 0.5678989160954434}, {\"truth_threshold\": 13.699999693781137, \"match_probability\": 0.999924862538478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98024.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3224887403318189, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6775112596681812, \"precision\": 0.9997450254464605, \"recall\": 0.3224887403318189, \"specificity\": 0.9999999804494712, \"npv\": 0.999838978839056, \"accuracy\": 0.9998389716367609, \"f1\": 0.48766946095868263, \"f2\": 0.373028853947772, \"f0_5\": 0.7040365894474954, \"p4\": 0.6555980342344501, \"phi\": 0.56776277339702}, {\"truth_threshold\": 13.719999693334103, \"match_probability\": 0.9999258969014363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97897.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206064.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.322070923572432, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6779290764275681, \"precision\": 0.9997446947570515, \"recall\": 0.322070923572432, \"specificity\": 0.9999999804494712, \"npv\": 0.9998388795543595, \"accuracy\": 0.9998388723436771, \"f1\": 0.4871915457981552, \"f2\": 0.37258157084290505, \"f0_5\": 0.703637897847909, \"p4\": 0.6551660228026633, \"phi\": 0.5673947351041613}, {\"truth_threshold\": 13.739999692887068, \"match_probability\": 0.9999269170261104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97808.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3217781228512868, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6782218771487132, \"precision\": 0.9997444625024277, \"recall\": 0.3217781228512868, \"specificity\": 0.9999999804494712, \"npv\": 0.9998388099769066, \"accuracy\": 0.9998388027603349, \"f1\": 0.48685644882701085, \"f2\": 0.3722680689393207, \"f0_5\": 0.7033581526061675, \"p4\": 0.6548629462642747, \"phi\": 0.5671366762162053}, {\"truth_threshold\": 13.759999692440033, \"match_probability\": 0.9999279231084656, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97760.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206201.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32162020785561307, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6783797921443869, \"precision\": 0.9997443370660122, \"recall\": 0.32162020785561307, \"specificity\": 0.9999999804494712, \"npv\": 0.9998387724519922, \"accuracy\": 0.9998387652322402, \"f1\": 0.4866756607408661, \"f2\": 0.3720989716274534, \"f0_5\": 0.7032071598228171, \"p4\": 0.6546993767796497, \"phi\": 0.5669974496501393}, {\"truth_threshold\": 13.779999691992998, \"match_probability\": 0.9999289153417709, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97672.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3213306970302111, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6786693029697889, \"precision\": 0.9997441067791232, \"recall\": 0.3213306970302111, \"specificity\": 0.9999999804494712, \"npv\": 0.9998387036563232, \"accuracy\": 0.9998386964307333, \"f1\": 0.4863441036902041, \"f2\": 0.371788927791367, \"f0_5\": 0.7029301229652724, \"p4\": 0.654399294460403, \"phi\": 0.5667421121411985}, {\"truth_threshold\": 13.799999691545963, \"match_probability\": 0.9999298939166361, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97598.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32108724474521405, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.678912755254786, \"precision\": 0.9997439128074327, \"recall\": 0.32108724474521405, \"specificity\": 0.9999999804494712, \"npv\": 0.999838645805427, \"accuracy\": 0.9998386385749207, \"f1\": 0.48606518187975617, \"f2\": 0.371528176954579, \"f0_5\": 0.702696942773665, \"p4\": 0.6541467470201835, \"phi\": 0.5665273074601144}, {\"truth_threshold\": 13.819999691098928, \"match_probability\": 0.9999308590210483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97547.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206414.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32091946006231065, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6790805399376894, \"precision\": 0.9997437789529783, \"recall\": 0.32091946006231065, \"specificity\": 0.9999999804494712, \"npv\": 0.9998386059352187, \"accuracy\": 0.9998385987013201, \"f1\": 0.4858728921408701, \"f2\": 0.3713484531938091, \"f0_5\": 0.7025361217661098, \"p4\": 0.6539725846617754, \"phi\": 0.5663792189900269}, {\"truth_threshold\": 13.839999690651894, \"match_probability\": 0.9999318108404078, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97472.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206489.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3206727178815703, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6793272821184296, \"precision\": 0.9997435818538006, \"recall\": 0.3206727178815703, \"specificity\": 0.9999999804494712, \"npv\": 0.9998385473025652, \"accuracy\": 0.9998385400636722, \"f1\": 0.4855900243612034, \"f2\": 0.3710841281890994, \"f0_5\": 0.7022994485185511, \"p4\": 0.6537163012245085, \"phi\": 0.566161371483484}, {\"truth_threshold\": 13.859999690204859, \"match_probability\": 0.9999327495575641, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97409.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206552.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3204654544497485, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6795345455502515, \"precision\": 0.9997639379259381, \"recall\": 0.3204654544497485, \"specificity\": 0.9999999820135135, \"npv\": 0.999838498051394, \"accuracy\": 0.9998384923717185, \"f1\": 0.4853547520758957, \"f2\": 0.37086263664302094, \"f0_5\": 0.7021085817996249, \"p4\": 0.653503065947991, \"phi\": 0.565984126045259}, {\"truth_threshold\": 13.879999689757824, \"match_probability\": 0.9999336753528504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97322.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206639.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32017923352008976, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6798207664799103, \"precision\": 0.9997637269505367, \"recall\": 0.32017923352008976, \"specificity\": 0.9999999820135135, \"npv\": 0.9998384300375314, \"accuracy\": 0.999838424352047, \"f1\": 0.485026388840436, \"f2\": 0.3705559519612181, \"f0_5\": 0.7018335854940065, \"p4\": 0.6532053460729962, \"phi\": 0.5657312387257198}, {\"truth_threshold\": 13.899999689310789, \"match_probability\": 0.9999345884041188, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97216.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206745.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3198305045713101, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6801694954286899, \"precision\": 0.9997634693898538, \"recall\": 0.3198305045713101, \"specificity\": 0.9999999820135135, \"npv\": 0.999838347170079, \"accuracy\": 0.9998383414775045, \"f1\": 0.4846261216350947, \"f2\": 0.37018223524331667, \"f0_5\": 0.7014981592311922, \"p4\": 0.6528422543214646, \"phi\": 0.5654229703341004}, {\"truth_threshold\": 13.919999688863754, \"match_probability\": 0.999935488886774, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97136.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3195673129118538, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6804326870881462, \"precision\": 0.9997632746323037, \"recall\": 0.3195673129118538, \"specificity\": 0.9999999820135135, \"npv\": 0.9998382846286147, \"accuracy\": 0.9998382789306801, \"f1\": 0.4843238930993219, \"f2\": 0.3699001449349316, \"f0_5\": 0.7012447353944646, \"p4\": 0.6525679660013834, \"phi\": 0.5651902036449243}, {\"truth_threshold\": 13.93999968841672, \"match_probability\": 0.9999363769738071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97046.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31927122229496546, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6807287777050345, \"precision\": 0.9997630551463392, \"recall\": 0.31927122229496546, \"specificity\": 0.9999999820135135, \"npv\": 0.9998382142694766, \"accuracy\": 0.9998382085655025, \"f1\": 0.4839837418646984, \"f2\": 0.3695827522463408, \"f0_5\": 0.7009593535162091, \"p4\": 0.652259127215739, \"phi\": 0.5649282265161406}, {\"truth_threshold\": 13.959999687969685, \"match_probability\": 0.9999372528358289, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96985.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31907053865463003, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6809294613453699, \"precision\": 0.99976290615207, \"recall\": 0.31907053865463003, \"specificity\": 0.9999999820135135, \"npv\": 0.999838166581622, \"accuracy\": 0.9998381608735489, \"f1\": 0.4837531080956383, \"f2\": 0.3693676057925798, \"f0_5\": 0.7007657591912057, \"p4\": 0.6520496437733774, \"phi\": 0.5647505951635412}, {\"truth_threshold\": 13.97999968752265, \"match_probability\": 0.9999381166411027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96878.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31871851981010724, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6812814801898928, \"precision\": 0.9997626443483555, \"recall\": 0.31871851981010724, \"specificity\": 0.9999999820135135, \"npv\": 0.9998380829324454, \"accuracy\": 0.9998380772171712, \"f1\": 0.48334838423198007, \"f2\": 0.36899016945408286, \"f0_5\": 0.7004258457267213, \"p4\": 0.6516818777696549, \"phi\": 0.5644388773115637}, {\"truth_threshold\": 13.999999687075615, \"match_probability\": 0.999938968555576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96788.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207173.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3184224291932189, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6815775708067812, \"precision\": 0.9997624236915227, \"recall\": 0.3184224291932189, \"specificity\": 0.9999999820135135, \"npv\": 0.9998380125733356, \"accuracy\": 0.9998380068519936, \"f1\": 0.4830077949557354, \"f2\": 0.36867265199157434, \"f0_5\": 0.7001396112585991, \"p4\": 0.6513722342997729, \"phi\": 0.564176551408119}, {\"truth_threshold\": 14.01999968662858, \"match_probability\": 0.9999398087429128, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96722.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3182052960741674, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6817947039258326, \"precision\": 0.9997622616155873, \"recall\": 0.3182052960741674, \"specificity\": 0.9999999820135135, \"npv\": 0.9998379609766614, \"accuracy\": 0.9998379552508635, \"f1\": 0.48275793224957947, \"f2\": 0.3684397781788511, \"f0_5\": 0.6999295164131235, \"p4\": 0.6511449835703098, \"phi\": 0.5639841015547108}, {\"truth_threshold\": 14.039999686181545, \"match_probability\": 0.9999406373645255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96649.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3179651336849135, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6820348663150865, \"precision\": 0.9997620820920226, \"recall\": 0.3179651336849135, \"specificity\": 0.9999999820135135, \"npv\": 0.999837903907619, \"accuracy\": 0.9998378981768862, \"f1\": 0.4824814730688685, \"f2\": 0.36818217835058775, \"f0_5\": 0.6996969517077416, \"p4\": 0.650893454023583, \"phi\": 0.5637711638604107}, {\"truth_threshold\": 14.05999968573451, \"match_probability\": 0.999941454579605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96546.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3176262744233635, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6823737255766364, \"precision\": 0.9997618283300024, \"recall\": 0.3176262744233635, \"specificity\": 0.9999999820135135, \"npv\": 0.9998378233855565, \"accuracy\": 0.9998378176478497, \"f1\": 0.4820912291214141, \"f2\": 0.36781866683734465, \"f0_5\": 0.6993684777837178, \"p4\": 0.650538240519107, \"phi\": 0.5634705806961168}, {\"truth_threshold\": 14.079999685287476, \"match_probability\": 0.9999422605451516, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96474.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207487.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3173894019298528, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6826105980701471, \"precision\": 0.9997616506212629, \"recall\": 0.3173894019298528, \"specificity\": 0.9999999820135135, \"npv\": 0.9998377670982971, \"accuracy\": 0.9998377613557077, \"f1\": 0.4818183180258604, \"f2\": 0.36756452781708415, \"f0_5\": 0.6991386319858425, \"p4\": 0.6502897162628987, \"phi\": 0.5632603690835695}, {\"truth_threshold\": 14.09999968484044, \"match_probability\": 0.9999430554160051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96389.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207572.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3171097607916805, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6828902392083195, \"precision\": 0.9997614404845869, \"recall\": 0.3171097607916805, \"specificity\": 0.9999999820135135, \"npv\": 0.9998377006480685, \"accuracy\": 0.9998376948997066, \"f1\": 0.4814960049753605, \"f2\": 0.36726446668942647, \"f0_5\": 0.698867039148271, \"p4\": 0.6499960866065629, \"phi\": 0.5630121016042811}, {\"truth_threshold\": 14.119999684393406, \"match_probability\": 0.9999438393448746, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96327.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207634.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31690578725560187, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6830942127443981, \"precision\": 0.9997612869745719, \"recall\": 0.31690578725560187, \"specificity\": 0.9999999820135135, \"npv\": 0.9998376521784957, \"accuracy\": 0.9998376464259178, \"f1\": 0.48126081971267337, \"f2\": 0.36704557405383653, \"f0_5\": 0.6986687671626333, \"p4\": 0.6497817504004748, \"phi\": 0.5628309433328045}, {\"truth_threshold\": 14.139999683946371, \"match_probability\": 0.9999446124823679, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96273.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207688.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31672813288546886, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6832718671145311, \"precision\": 0.9997611531112404, \"recall\": 0.31672813288546886, \"specificity\": 0.9999999820135135, \"npv\": 0.999837609963065, \"accuracy\": 0.9998376042068112, \"f1\": 0.481055921570391, \"f2\": 0.3668549087749783, \"f0_5\": 0.6984959623881767, \"p4\": 0.6495949608952503, \"phi\": 0.5626731128140737}, {\"truth_threshold\": 14.159999683499336, \"match_probability\": 0.99994537497702, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96175.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207786.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3164057231026349, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6835942768973651, \"precision\": 0.9997609097902244, \"recall\": 0.3164057231026349, \"specificity\": 0.9999999820135135, \"npv\": 0.9998375333498852, \"accuracy\": 0.9998375275869512, \"f1\": 0.4806839281385649, \"f2\": 0.36650884651558413, \"f0_5\": 0.6981820768838757, \"p4\": 0.6492557116576426, \"phi\": 0.5623865665489802}, {\"truth_threshold\": 14.179999683052301, \"match_probability\": 0.9999461269753221, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96104.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3161721405048674, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6838278594951326, \"precision\": 0.9997607331967086, \"recall\": 0.3161721405048674, \"specificity\": 0.9999999820135135, \"npv\": 0.9998374778444256, \"accuracy\": 0.9998374720766445, \"f1\": 0.48041430885205255, \"f2\": 0.3662580956438824, \"f0_5\": 0.6979544467506889, \"p4\": 0.6490097186687529, \"phi\": 0.5621788754928914}, {\"truth_threshold\": 14.199999682605267, \"match_probability\": 0.9999468686217494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96045.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31597803665601837, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6840219633439816, \"precision\": 0.9997605862514053, \"recall\": 0.31597803665601837, \"specificity\": 0.9999999820135135, \"npv\": 0.999837431720175, \"accuracy\": 0.9998374259483616, \"f1\": 0.48019018621149967, \"f2\": 0.36604970455335417, \"f0_5\": 0.6977651463966419, \"p4\": 0.6488051673265299, \"phi\": 0.5620062287774497}, {\"truth_threshold\": 14.219999682158232, \"match_probability\": 0.999947600058789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95945.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.315649047081698, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6843509529183021, \"precision\": 0.9997603367789263, \"recall\": 0.315649047081698, \"specificity\": 0.9999999820135135, \"npv\": 0.9998373535434889, \"accuracy\": 0.9998373477648309, \"f1\": 0.47981016630451906, \"f2\": 0.36569645650443816, \"f0_5\": 0.6974440016690098, \"p4\": 0.6484581907148155, \"phi\": 0.5617134860728256}, {\"truth_threshold\": 14.239999681711197, \"match_probability\": 0.999948321426967, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95897.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208064.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3154911320860242, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6845088679139758, \"precision\": 0.9997602168473728, \"recall\": 0.3154911320860242, \"specificity\": 0.9999999820135135, \"npv\": 0.999837316018684, \"accuracy\": 0.9998373102367363, \"f1\": 0.47962768923754817, \"f2\": 0.3655268783104278, \"f0_5\": 0.6972897194902573, \"p4\": 0.6482915169667345, \"phi\": 0.5615729153859377}, {\"truth_threshold\": 14.259999681264162, \"match_probability\": 0.9999490328648757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95849.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3153332170903504, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6846667829096496, \"precision\": 0.9997600967957276, \"recall\": 0.3153332170903504, \"specificity\": 0.9999999820135135, \"npv\": 0.9998372784938818, \"accuracy\": 0.9998372727086416, \"f1\": 0.4794451683577894, \"f2\": 0.3653572877055704, \"f0_5\": 0.6971353511315022, \"p4\": 0.6481247620735551, \"phi\": 0.5614323095137099}, {\"truth_threshold\": 14.279999680817127, \"match_probability\": 0.9999497345092002, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95769.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208192.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3150700254308941, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6849299745691059, \"precision\": 0.9997598964422917, \"recall\": 0.3150700254308941, \"specificity\": 0.9999999820135135, \"npv\": 0.9998372159525512, \"accuracy\": 0.9998372101618171, \"f1\": 0.47914086948690815, \"f2\": 0.365074609114114, \"f0_5\": 0.6968778788262466, \"p4\": 0.6478466567681189, \"phi\": 0.5611978881318527}, {\"truth_threshold\": 14.299999680370092, \"match_probability\": 0.9999504264947446, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95690.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208271.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.314810123667181, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.685189876332819, \"precision\": 0.9997596982646035, \"recall\": 0.314810123667181, \"specificity\": 0.9999999820135135, \"npv\": 0.9998371541929947, \"accuracy\": 0.999837148396828, \"f1\": 0.47884025480766823, \"f2\": 0.3647954301643009, \"f0_5\": 0.696623389481562, \"p4\": 0.6475718061544973, \"phi\": 0.5609663009132243}, {\"truth_threshold\": 14.319999679923058, \"match_probability\": 0.9999511089544578, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95598.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31450745325880625, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6854925467411938, \"precision\": 0.9997594670626745, \"recall\": 0.31450745325880625, \"specificity\": 0.9999999820135135, \"npv\": 0.999837082270483, \"accuracy\": 0.9998370764679798, \"f1\": 0.47849002207306635, \"f2\": 0.3644702679827521, \"f0_5\": 0.6963267268317199, \"p4\": 0.6472514490318978, \"phi\": 0.5606964838821733}, {\"truth_threshold\": 14.339999679476023, \"match_probability\": 0.9999517820194591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95501.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208460.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3141883333717155, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6858116666282845, \"precision\": 0.999759222813115, \"recall\": 0.3141883333717155, \"specificity\": 0.9999999820135135, \"npv\": 0.9998370064391503, \"accuracy\": 0.9998370006299552, \"f1\": 0.4781205802470681, \"f2\": 0.36412738453279325, \"f0_5\": 0.696013596537897, \"p4\": 0.6469133568779412, \"phi\": 0.5604118622354423}, {\"truth_threshold\": 14.359999679028988, \"match_probability\": 0.9999524458190633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95420.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208541.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31392185181651594, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6860781481834841, \"precision\": 0.999759018471758, \"recall\": 0.31392185181651594, \"specificity\": 0.9999999820135135, \"npv\": 0.9998369431160875, \"accuracy\": 0.9998369373012954, \"f1\": 0.4778119397902875, \"f2\": 0.36384102031058035, \"f0_5\": 0.6957518451058939, \"p4\": 0.6466307770916736, \"phi\": 0.5601740777211565}, {\"truth_threshold\": 14.379999678581953, \"match_probability\": 0.9999531004808055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95347.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31368168942726204, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.686318310572738, \"precision\": 0.9997588340148894, \"recall\": 0.31368168942726204, \"specificity\": 0.9999999820135135, \"npv\": 0.9998368860471613, \"accuracy\": 0.9998368802273181, \"f1\": 0.4775336750715572, \"f2\": 0.3635829086632693, \"f0_5\": 0.695515733666355, \"p4\": 0.646375907017475, \"phi\": 0.5599596916154855}, {\"truth_threshold\": 14.399999678134918, \"match_probability\": 0.9999537461304658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95272.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31343494724652177, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6865650527534782, \"precision\": 0.9997586442100844, \"recall\": 0.31343494724652177, \"specificity\": 0.9999999820135135, \"npv\": 0.9998368274147095, \"accuracy\": 0.9998368215896701, \"f1\": 0.4772476806860761, \"f2\": 0.36331769553037474, \"f0_5\": 0.695272943817404, \"p4\": 0.6461138570882455, \"phi\": 0.5597393464259672}, {\"truth_threshold\": 14.419999677687883, \"match_probability\": 0.9999543828920934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95163.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208798.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31307634861051253, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6869236513894875, \"precision\": 0.9997583678272015, \"recall\": 0.31307634861051253, \"specificity\": 0.9999999820135135, \"npv\": 0.9998367422022253, \"accuracy\": 0.9998367363696219, \"f1\": 0.47683184390713196, \"f2\": 0.3629321983478639, \"f0_5\": 0.6949197099480798, \"p4\": 0.645732654571749, \"phi\": 0.5594189567379108}, {\"truth_threshold\": 14.439999677240849, \"match_probability\": 0.9999550108880298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95072.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31277696809788097, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.687223031902119, \"precision\": 0.9997581366002418, \"recall\": 0.31277696809788097, \"specificity\": 0.9999999820135135, \"npv\": 0.9998366710615385, \"accuracy\": 0.9998366652226091, \"f1\": 0.4764845034280903, \"f2\": 0.3626103121502984, \"f0_5\": 0.6946244635349921, \"p4\": 0.645414078858902, \"phi\": 0.559151334870657}, {\"truth_threshold\": 14.459999676793814, \"match_probability\": 0.9999556302389335, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94987.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208974.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31249732695970867, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6875026730402913, \"precision\": 0.9997579202189243, \"recall\": 0.31249732695970867, \"specificity\": 0.9999999820135135, \"npv\": 0.9998366046114556, \"accuracy\": 0.999836598766608, \"f1\": 0.47615992139779584, \"f2\": 0.3623096088504135, \"f0_5\": 0.6943484000754385, \"p4\": 0.6451162413724355, \"phi\": 0.558901242684126}, {\"truth_threshold\": 14.479999676346779, \"match_probability\": 0.999956241063802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94888.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209073.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31217162728113146, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6878283727188685, \"precision\": 0.9997576677097492, \"recall\": 0.31217162728113146, \"specificity\": 0.9999999820135135, \"npv\": 0.9998365272166644, \"accuracy\": 0.9998365213649127, \"f1\": 0.47578170440642614, \"f2\": 0.36195932878379256, \"f0_5\": 0.6940265211635375, \"p4\": 0.6447690230182485, \"phi\": 0.5586098177366412}, {\"truth_threshold\": 14.499999675899744, \"match_probability\": 0.9999568434799949, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94810.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209151.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3119150154131616, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6880849845868384, \"precision\": 0.9997574683918046, \"recall\": 0.3119150154131616, \"specificity\": 0.9999999820135135, \"npv\": 0.9998364662389585, \"accuracy\": 0.9998364603817589, \"f1\": 0.4754835830027533, \"f2\": 0.3616833132800835, \"f0_5\": 0.6937726568251101, \"p4\": 0.6444952101802046, \"phi\": 0.558380103109051}, {\"truth_threshold\": 14.51999967545271, \"match_probability\": 0.9999574376032573, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94714.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.311599185421814, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.688400814578186, \"precision\": 0.9997572226268512, \"recall\": 0.311599185421814, \"specificity\": 0.9999999820135135, \"npv\": 0.9998363911894845, \"accuracy\": 0.9998363853255696, \"f1\": 0.47511650422124013, \"f2\": 0.3613435567889356, \"f0_5\": 0.6934598899706989, \"p4\": 0.6441579106676861, \"phi\": 0.5580972476538838}, {\"truth_threshold\": 14.539999675005674, \"match_probability\": 0.9999580235477409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94634.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209327.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31133599376235765, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6886640062376423, \"precision\": 0.9997570174419219, \"recall\": 0.31133599376235765, \"specificity\": 0.9999999820135135, \"npv\": 0.9998363286482649, \"accuracy\": 0.9998363227787451, \"f1\": 0.4748104701744527, \"f2\": 0.36106038835529314, \"f0_5\": 0.6931989821107577, \"p4\": 0.6438765753018273, \"phi\": 0.5578614252518778}, {\"truth_threshold\": 14.55999967455864, \"match_probability\": 0.9999586014260262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94537.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209424.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3110168738752669, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6889831261247331, \"precision\": 0.9997567681895093, \"recall\": 0.3110168738752669, \"specificity\": 0.9999999820135135, \"npv\": 0.9998362528170466, \"accuracy\": 0.9998362469407205, \"f1\": 0.4744392390865224, \"f2\": 0.36071700025335696, \"f0_5\": 0.6928823030162665, \"p4\": 0.6435351479205548, \"phi\": 0.5575753568458945}, {\"truth_threshold\": 14.579999674111605, \"match_probability\": 0.9999591713491449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94451.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31073394284135136, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6892660571586486, \"precision\": 0.999756546774774, \"recall\": 0.31073394284135136, \"specificity\": 0.9999999820135135, \"npv\": 0.9998361855852543, \"accuracy\": 0.9998361797028842, \"f1\": 0.4741099551997189, \"f2\": 0.3604125105508739, \"f0_5\": 0.6926012345697118, \"p4\": 0.6432321561705308, \"phi\": 0.5573216064200545}, {\"truth_threshold\": 14.59999967366457, \"match_probability\": 0.9999597334266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94348.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209613.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31039508357980133, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6896049164201986, \"precision\": 0.9997562810609192, \"recall\": 0.31039508357980133, \"specificity\": 0.9999999820135135, \"npv\": 0.9998361050634685, \"accuracy\": 0.9998360991738476, \"f1\": 0.47371539318960065, \"f2\": 0.3600477784180459, \"f0_5\": 0.6922642326233225, \"p4\": 0.6428689202132, \"phi\": 0.5570175439406352}, {\"truth_threshold\": 14.619999673217535, \"match_probability\": 0.9999602877663878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94266.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31012531212885863, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6898746878711414, \"precision\": 0.9997560691066827, \"recall\": 0.31012531212885863, \"specificity\": 0.9999999820135135, \"npv\": 0.9998360409587551, \"accuracy\": 0.9998360350633526, \"f1\": 0.4734011299435028, \"f2\": 0.3597573681450662, \"f0_5\": 0.6919956483247371, \"p4\": 0.6425794685690746, \"phi\": 0.5567753560965484}, {\"truth_threshold\": 14.6399996727705, \"match_probability\": 0.9999608344750182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94206.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3099279183842664, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6900720816157336, \"precision\": 0.9997559137845037, \"recall\": 0.3099279183842664, \"specificity\": 0.9999999820135135, \"npv\": 0.9998359940528725, \"accuracy\": 0.9998359881532343, \"f1\": 0.47317109922398853, \"f2\": 0.3595448497908132, \"f0_5\": 0.6917989592833947, \"p4\": 0.6423675208816557, \"phi\": 0.5565980787342417}, {\"truth_threshold\": 14.659999672323465, \"match_probability\": 0.9999613736575348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94135.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3096943357864989, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.690305664213501, \"precision\": 0.9997557297308779, \"recall\": 0.3096943357864989, \"specificity\": 0.9999999820135135, \"npv\": 0.9998359385475837, \"accuracy\": 0.9998359326429276, \"f1\": 0.4728988066382162, \"f2\": 0.3592933445903136, \"f0_5\": 0.6915660313873343, \"p4\": 0.6421165480352943, \"phi\": 0.5563882275768194}, {\"truth_threshold\": 14.67999967187643, \"match_probability\": 0.999961905417536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94088.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3095397106865683, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6904602893134316, \"precision\": 0.9997556077397967, \"recall\": 0.3095397106865683, \"specificity\": 0.9999999820135135, \"npv\": 0.9998359018046494, \"accuracy\": 0.9998358958966682, \"f1\": 0.4727185031853534, \"f2\": 0.3591268402349699, \"f0_5\": 0.6914117327180135, \"p4\": 0.6419503107648874, \"phi\": 0.5562492684849112}, {\"truth_threshold\": 14.699999671429396, \"match_probability\": 0.9999624298571944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94017.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30930612808880087, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6906938719111991, \"precision\": 0.9997554232241599, \"recall\": 0.30930612808880087, \"specificity\": 0.9999999820135135, \"npv\": 0.999835846299371, \"accuracy\": 0.9998358403863615, \"f1\": 0.47244604913052984, \"f2\": 0.35887528972031113, \"f0_5\": 0.6911784814760903, \"p4\": 0.6416990346902017, \"phi\": 0.5560392857240911}, {\"truth_threshold\": 14.71999967098236, \"match_probability\": 0.999962947077276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93975.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209986.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3091679524675863, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6908320475324137, \"precision\": 0.9997553139428499, \"recall\": 0.3091679524675863, \"specificity\": 0.9999999820135135, \"npv\": 0.9998358134652654, \"accuracy\": 0.9998358075492787, \"f1\": 0.47228483336223076, \"f2\": 0.358726472353154, \"f0_5\": 0.6910404101459954, \"p4\": 0.641550306506302, \"phi\": 0.5559150332437511}, {\"truth_threshold\": 14.739999670535326, \"match_probability\": 0.99996345717716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93892.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3088948911209004, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6911051088790996, \"precision\": 0.9997550976947239, \"recall\": 0.3088948911209004, \"specificity\": 0.9999999820135135, \"npv\": 0.9998357485788252, \"accuracy\": 0.9998357426569483, \"f1\": 0.4719661402044858, \"f2\": 0.3584323528221604, \"f0_5\": 0.690767354157685, \"p4\": 0.6412562030990182, \"phi\": 0.5556694049936431}, {\"truth_threshold\": 14.759999670088291, \"match_probability\": 0.999963960254858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93830.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30869091758482176, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6913090824151783, \"precision\": 0.9997549359104131, \"recall\": 0.30869091758482176, \"specificity\": 0.9999999820135135, \"npv\": 0.9998357001094416, \"accuracy\": 0.9998356941831593, \"f1\": 0.4717279934843922, \"f2\": 0.35821262475213733, \"f0_5\": 0.6905632104896721, \"p4\": 0.6410363481760082, \"phi\": 0.5554858528018882}, {\"truth_threshold\": 14.779999669641256, \"match_probability\": 0.9999644564070327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93728.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210233.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30835534821901495, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6916446517809851, \"precision\": 0.9997546692835276, \"recall\": 0.30835534821901495, \"specificity\": 0.9999999820135135, \"npv\": 0.999835620369498, \"accuracy\": 0.9998356144359581, \"f1\": 0.47133604216116187, \"f2\": 0.357851091367942, \"f0_5\": 0.6902270367397436, \"p4\": 0.6406743472713434, \"phi\": 0.5551837478377654}, {\"truth_threshold\": 14.799999669194221, \"match_probability\": 0.9999649457290162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93633.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210328.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30804280812341056, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6919571918765894, \"precision\": 0.9997544204322201, \"recall\": 0.30804280812341056, \"specificity\": 0.9999999820135135, \"npv\": 0.999835546101915, \"accuracy\": 0.9998355401616041, \"f1\": 0.470970808592188, \"f2\": 0.3575143184421535, \"f0_5\": 0.6899135701496496, \"p4\": 0.6403368488968034, \"phi\": 0.5549022276798405}, {\"truth_threshold\": 14.819999668747187, \"match_probability\": 0.9999654283148285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93579.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210382.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30786515375327755, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6921348462467224, \"precision\": 0.9997542787547274, \"recall\": 0.30786515375327755, \"specificity\": 0.9999999820135135, \"npv\": 0.9998355038866622, \"accuracy\": 0.9998354979424976, \"f1\": 0.47076312433501105, \"f2\": 0.3573228678387654, \"f0_5\": 0.6897352325946499, \"p4\": 0.6401448610654956, \"phi\": 0.5547421420299603}, {\"truth_threshold\": 14.839999668300152, \"match_probability\": 0.9999659042571957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93458.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210503.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3074670763683499, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6925329236316501, \"precision\": 0.9997539606978958, \"recall\": 0.3074670763683499, \"specificity\": 0.9999999820135135, \"npv\": 0.9998354092932384, \"accuracy\": 0.9998354033404256, \"f1\": 0.4702975528504788, \"f2\": 0.35689381933438985, \"f0_5\": 0.6893352117247026, \"p4\": 0.6397142796301462, \"phi\": 0.5543832637994713}, {\"truth_threshold\": 14.859999667853117, \"match_probability\": 0.9999663736475676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93383.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3072203341876096, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6927796658123904, \"precision\": 0.9997537631415541, \"recall\": 0.3072203341876096, \"specificity\": 0.9999999820135135, \"npv\": 0.9998353506609599, \"accuracy\": 0.9998353447027777, \"f1\": 0.4700088331441715, \"f2\": 0.3566278403666221, \"f0_5\": 0.6890869780175181, \"p4\": 0.6394471216660373, \"phi\": 0.554160701975166}, {\"truth_threshold\": 14.879999667406082, \"match_probability\": 0.9999668365761353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93309.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210652.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3069768819026125, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6930231180973875, \"precision\": 0.999753567908113, \"recall\": 0.3069768819026125, \"specificity\": 0.9999999820135135, \"npv\": 0.9998352928104518, \"accuracy\": 0.999835286846965, \"f1\": 0.46972385619681195, \"f2\": 0.35636537791710204, \"f0_5\": 0.6888418385652211, \"p4\": 0.6391833240267953, \"phi\": 0.5539410200272934}, {\"truth_threshold\": 14.899999666959047, \"match_probability\": 0.9999672931318484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93220.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210741.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30668408118146734, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6933159188185326, \"precision\": 0.9997533326898534, \"recall\": 0.30668408118146734, \"specificity\": 0.9999999820135135, \"npv\": 0.9998352232334983, \"accuracy\": 0.9998352172636228, \"f1\": 0.46938097300127896, \"f2\": 0.3560496743149997, \"f0_5\": 0.6885467247127854, \"p4\": 0.638865788082949, \"phi\": 0.5536766925325436}, {\"truth_threshold\": 14.919999666512012, \"match_probability\": 0.9999677434024328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93127.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210834.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3063781208773494, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6936218791226506, \"precision\": 0.9997530864197531, \"recall\": 0.3063781208773494, \"specificity\": 0.9999999820135135, \"npv\": 0.999835150529501, \"accuracy\": 0.9998351445529394, \"f1\": 0.46902251511542115, \"f2\": 0.3557197359193396, \"f0_5\": 0.6882380154930597, \"p4\": 0.6385336703191805, \"phi\": 0.5534003502967222}, {\"truth_threshold\": 14.939999666064978, \"match_probability\": 0.9999681874744061, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93032.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.306065580781745, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6939344192182549, \"precision\": 0.9997528343452797, \"recall\": 0.306065580781745, \"specificity\": 0.9999999820135135, \"npv\": 0.9998350762619878, \"accuracy\": 0.9998350702785853, \"f1\": 0.4686561750659923, \"f2\": 0.3553826536654089, \"f0_5\": 0.687922316657818, \"p4\": 0.6381940820932256, \"phi\": 0.5531179227102933}, {\"truth_threshold\": 14.959999665617943, \"match_probability\": 0.9999686254330958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92958.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211003.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30582212849674795, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.694177871503252, \"precision\": 0.999752637635646, \"recall\": 0.30582212849674795, \"specificity\": 0.9999999820135135, \"npv\": 0.9998350184115115, \"accuracy\": 0.9998350124227727, \"f1\": 0.4683706939552882, \"f2\": 0.35512005042690964, \"f0_5\": 0.6876761579262745, \"p4\": 0.6379293306536237, \"phi\": 0.5528978265578072}, {\"truth_threshold\": 14.979999665170908, \"match_probability\": 0.9999690573626547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92881.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211080.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30556880652452123, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6944311934754788, \"precision\": 0.999752432618617, \"recall\": 0.30556880652452123, \"specificity\": 0.9999999820135135, \"npv\": 0.9998349582157527, \"accuracy\": 0.9998349522214541, \"f1\": 0.46807352626207904, \"f2\": 0.3548467695843661, \"f0_5\": 0.6874197907862464, \"p4\": 0.6376536318637204, \"phi\": 0.5526687145615838}, {\"truth_threshold\": 14.999999664723873, \"match_probability\": 0.9999694833460775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92805.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30531877444803773, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6946812255519622, \"precision\": 0.9997522299306244, \"recall\": 0.30531877444803773, \"specificity\": 0.9999999820135135, \"npv\": 0.9998348988017641, \"accuracy\": 0.9998348928019709, \"f1\": 0.46778010479121146, \"f2\": 0.35457700630868544, \"f0_5\": 0.6871665237615009, \"p4\": 0.637381299124849, \"phi\": 0.5524424848973379}, {\"truth_threshold\": 15.019999664276838, \"match_probability\": 0.999969903465216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92742.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211219.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3051115110162159, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6948884889837841, \"precision\": 0.9997520616611869, \"recall\": 0.3051115110162159, \"specificity\": 0.9999999820135135, \"npv\": 0.9998348495507, \"accuracy\": 0.9998348435463467, \"f1\": 0.46753678861481224, \"f2\": 0.35435336299842046, \"f0_5\": 0.6869564058007084, \"p4\": 0.6371553879343732, \"phi\": 0.5522548821810762}, {\"truth_threshold\": 15.039999663829803, \"match_probability\": 0.9999703178007961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92670.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3048746385227052, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6951253614772948, \"precision\": 0.999751869073177, \"recall\": 0.3048746385227052, \"specificity\": 0.9999999820135135, \"npv\": 0.9998347932637754, \"accuracy\": 0.9998347872542047, \"f1\": 0.4672586183424345, \"f2\": 0.3540977442747129, \"f0_5\": 0.6867160788045049, \"p4\": 0.6368970240580579, \"phi\": 0.5520404010333336}, {\"truth_threshold\": 15.059999663382769, \"match_probability\": 0.9999707264324323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92611.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3046805346738562, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6953194653261439, \"precision\": 0.9997517110348252, \"recall\": 0.3046805346738562, \"specificity\": 0.9999999820135135, \"npv\": 0.9998347471397726, \"accuracy\": 0.9998347411259216, \"f1\": 0.4670305979651786, \"f2\": 0.3538882579607758, \"f0_5\": 0.6865189911889897, \"p4\": 0.636685166213872, \"phi\": 0.5518645835260081}, {\"truth_threshold\": 15.079999662935734, \"match_probability\": 0.9999711294386433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92526.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211435.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30440089353568384, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6955991064643161, \"precision\": 0.9997514829981955, \"recall\": 0.30440089353568384, \"specificity\": 0.9999999820135135, \"npv\": 0.9998346806899455, \"accuracy\": 0.9998346746699206, \"f1\": 0.466701974729515, \"f2\": 0.35358642242812366, \"f0_5\": 0.686234808805664, \"p4\": 0.636379720570347, \"phi\": 0.5516111886225057}, {\"truth_threshold\": 15.099999662488699, \"match_probability\": 0.999971526896867, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92440.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3041179625017683, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6958820374982316, \"precision\": 0.9997512518520922, \"recall\": 0.3041179625017683, \"specificity\": 0.9999999820135135, \"npv\": 0.9998346134583647, \"accuracy\": 0.9998346074320843, \"f1\": 0.4663693419167356, \"f2\": 0.3532809959741865, \"f0_5\": 0.6859469912275364, \"p4\": 0.6360704087333617, \"phi\": 0.5513546941169046}, {\"truth_threshold\": 15.119999662041664, \"match_probability\": 0.9999719188834754, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92349.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211612.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30381858198913675, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6961814180108632, \"precision\": 0.999751006798597, \"recall\": 0.30381858198913675, \"specificity\": 0.9999999820135135, \"npv\": 0.999834542317981, \"accuracy\": 0.9998345362850716, \"f1\": 0.4660172127983287, \"f2\": 0.3529577684419087, \"f0_5\": 0.6856421198932658, \"p4\": 0.6357428145498168, \"phi\": 0.5510831571826519}, {\"truth_threshold\": 15.13999966159463, \"match_probability\": 0.9999723054737893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92293.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211668.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30363434782751736, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6963656521724827, \"precision\": 0.9997508557563153, \"recall\": 0.30363434782751736, \"specificity\": 0.9999999820135135, \"npv\": 0.9998344985392882, \"accuracy\": 0.9998344925022944, \"f1\": 0.465800437572708, \"f2\": 0.35275883683953035, \"f0_5\": 0.6854543429017045, \"p4\": 0.6355410650804273, \"phi\": 0.5509159910280831}, {\"truth_threshold\": 15.159999661147594, \"match_probability\": 0.9999726867420932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92191.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211770.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30329877846171055, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6967012215382895, \"precision\": 0.9997505801722081, \"recall\": 0.30329877846171055, \"specificity\": 0.9999999820135135, \"npv\": 0.9998344187995364, \"accuracy\": 0.9998344127550932, \"f1\": 0.46540543951536567, \"f2\": 0.35239645336827574, \"f0_5\": 0.6851119992509107, \"p4\": 0.6351732928195575, \"phi\": 0.5506113794481169}, {\"truth_threshold\": 15.17999966070056, \"match_probability\": 0.9999730627616485, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92154.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.303177052319212, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.696822947680788, \"precision\": 0.9997504800546774, \"recall\": 0.303177052319212, \"specificity\": 0.9999999820135135, \"npv\": 0.9998343898743355, \"accuracy\": 0.9998343838271869, \"f1\": 0.46526210562985626, \"f2\": 0.3522649865713165, \"f0_5\": 0.6849877131248802, \"p4\": 0.6350397893969133, \"phi\": 0.5505008414425371}, {\"truth_threshold\": 15.199999660253525, \"match_probability\": 0.9999734336047086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92049.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211912.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3028316132661756, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6971683867338244, \"precision\": 0.9997501954991745, \"recall\": 0.3028316132661756, \"specificity\": 0.9999999820135135, \"npv\": 0.9998343077893148, \"accuracy\": 0.9998343017344798, \"f1\": 0.46485520146048437, \"f2\": 0.35189186461515876, \"f0_5\": 0.6846347112453868, \"p4\": 0.634660650139964, \"phi\": 0.550187031606261}, {\"truth_threshold\": 15.21999965980649, \"match_probability\": 0.9999737993425322, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91966.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211995.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30255855191948966, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6974414480805103, \"precision\": 0.9997499701051212, \"recall\": 0.30255855191948966, \"specificity\": 0.9999999820135135, \"npv\": 0.99983424290307, \"accuracy\": 0.9998342368421494, \"f1\": 0.4645334006819043, \"f2\": 0.35159687819469304, \"f0_5\": 0.6843553593673029, \"p4\": 0.6343606581041253, \"phi\": 0.5499388457186245}, {\"truth_threshold\": 15.239999659359455, \"match_probability\": 0.9999741600453972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91912.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30238089754935665, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6976191024506433, \"precision\": 0.9997498232446838, \"recall\": 0.30238089754935665, \"specificity\": 0.9999999820135135, \"npv\": 0.9998342006879273, \"accuracy\": 0.9998341946230429, \"f1\": 0.46432396386929903, \"f2\": 0.35140493921373567, \"f0_5\": 0.6841734640859549, \"p4\": 0.6341653441961489, \"phi\": 0.5497773152411219}, {\"truth_threshold\": 15.25999965891242, \"match_probability\": 0.9999745157826142, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91846.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3021637644303052, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6978362355696948, \"precision\": 0.9997496435141343, \"recall\": 0.3021637644303052, \"specificity\": 0.9999999820135135, \"npv\": 0.9998341490916465, \"accuracy\": 0.9998341430219128, \"f1\": 0.4640679079402774, \"f2\": 0.35117032559896555, \"f0_5\": 0.6839509887003546, \"p4\": 0.633926478912158, \"phi\": 0.5495798246463236}, {\"truth_threshold\": 15.279999658465385, \"match_probability\": 0.99997486662254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91763.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212198.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30189070308361926, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6981092969163807, \"precision\": 0.9997494171224369, \"recall\": 0.30189070308361926, \"specificity\": 0.9999999820135135, \"npv\": 0.9998340842054222, \"accuracy\": 0.9998340781295824, \"f1\": 0.4637457769736726, \"f2\": 0.3508752475853261, \"f0_5\": 0.683670960579939, \"p4\": 0.6336258559321615, \"phi\": 0.5493313645038468}, {\"truth_threshold\": 15.29999965801835, \"match_probability\": 0.9999752126325899, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91721.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212240.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3017525274624047, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6982474725375953, \"precision\": 0.9997493024066969, \"recall\": 0.3017525274624047, \"specificity\": 0.9999999820135135, \"npv\": 0.9998340513714324, \"accuracy\": 0.9998340452924995, \"f1\": 0.4635827194500954, \"f2\": 0.35072591672606357, \"f0_5\": 0.6835291540040273, \"p4\": 0.6334736349644361, \"phi\": 0.5492055948667176}, {\"truth_threshold\": 15.319999657571316, \"match_probability\": 0.999975553879252, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91624.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30143340757531395, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6985665924246861, \"precision\": 0.9997490370661342, \"recall\": 0.30143340757531395, \"specificity\": 0.9999999820135135, \"npv\": 0.9998339755405595, \"accuracy\": 0.9998339694544749, \"f1\": 0.4632060019008716, \"f2\": 0.35038099688640306, \"f0_5\": 0.6832013767823082, \"p4\": 0.6331218237678282, \"phi\": 0.548915016797179}, {\"truth_threshold\": 15.339999657124281, \"match_probability\": 0.9999758904280986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91546.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.301176795707344, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.698823204292656, \"precision\": 0.9997488232917253, \"recall\": 0.301176795707344, \"specificity\": 0.9999999820135135, \"npv\": 0.9998339145631648, \"accuracy\": 0.999833908471321, \"f1\": 0.4629029403585063, \"f2\": 0.3501036015398348, \"f0_5\": 0.6829375280684296, \"p4\": 0.6328386673702, \"phi\": 0.5486812444876611}, {\"truth_threshold\": 15.359999656677246, \"match_probability\": 0.9999762223437998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91446.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212515.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30084780613302364, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6991521938669764, \"precision\": 0.9997485486886267, \"recall\": 0.30084780613302364, \"specificity\": 0.9999999820135135, \"npv\": 0.9998338363870288, \"accuracy\": 0.9998338302877905, \"f1\": 0.46251422502086337, \"f2\": 0.349747918057879, \"f0_5\": 0.6825989009266433, \"p4\": 0.632475311161609, \"phi\": 0.5483813906582271}, {\"truth_threshold\": 15.379999656230211, \"match_probability\": 0.9999765496901353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91348.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212613.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30052539635018966, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6994746036498103, \"precision\": 0.9997482789944293, \"recall\": 0.30052539635018966, \"specificity\": 0.9999999820135135, \"npv\": 0.9998337597744272, \"accuracy\": 0.9998337536679305, \"f1\": 0.4621330931976162, \"f2\": 0.3493992954487211, \"f0_5\": 0.6822666537206193, \"p4\": 0.6321188561633637, \"phi\": 0.5480873747921698}, {\"truth_threshold\": 15.399999655783176, \"match_probability\": 0.9999768725300071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91265.0, \"tn\": 1278737771.0, \"fp\": 21.0, \"fn\": 212696.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30025233500350373, \"tn_rate\": 0.9999999835775558, \"fp_rate\": 1.6422444172198204e-08, \"fn_rate\": 0.6997476649964962, \"precision\": 0.9997699537716627, \"recall\": 0.30025233500350373, \"specificity\": 0.9999999835775558, \"npv\": 0.9998336948885136, \"accuracy\": 0.9998336903392707, \"f1\": 0.4618124868752957, \"f2\": 0.3491045267111917, \"f0_5\": 0.6819931101994455, \"p4\": 0.6318188640511154, \"phi\": 0.5478442417077182}, {\"truth_threshold\": 15.419999655336142, \"match_probability\": 0.9999771909254513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91206.0, \"tn\": 1278737771.0, \"fp\": 21.0, \"fn\": 212755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3000582311546547, \"tn_rate\": 0.9999999835775558, \"fp_rate\": 1.6422444172198204e-08, \"fn_rate\": 0.6999417688453453, \"precision\": 0.9997698049919431, \"recall\": 0.3000582311546547, \"specificity\": 0.9999999835775558, \"npv\": 0.9998336487646122, \"accuracy\": 0.9998336442109876, \"f1\": 0.4615828415842586, \"f2\": 0.34889458950584934, \"f0_5\": 0.6817926978227425, \"p4\": 0.6316039034269461, \"phi\": 0.547667077497218}, {\"truth_threshold\": 15.439999654889107, \"match_probability\": 0.99997750493765, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91131.0, \"tn\": 1278737771.0, \"fp\": 21.0, \"fn\": 212830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2998114889739144, \"tn_rate\": 0.9999999835775558, \"fp_rate\": 1.6422444172198204e-08, \"fn_rate\": 0.7001885110260856, \"precision\": 0.9997696155871512, \"recall\": 0.2998114889739144, \"specificity\": 0.9999999835775558, \"npv\": 0.9998335901325403, \"accuracy\": 0.9998335855733398, \"f1\": 0.46129082060068893, \"f2\": 0.3486276928161984, \"f0_5\": 0.6815377320815055, \"p4\": 0.6313304581487156, \"phi\": 0.5474417860138107}, {\"truth_threshold\": 15.459999654442072, \"match_probability\": 0.9999778146269432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91078.0, \"tn\": 1278737771.0, \"fp\": 21.0, \"fn\": 212883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2996371244995246, \"tn_rate\": 0.9999999835775558, \"fp_rate\": 1.6422444172198204e-08, \"fn_rate\": 0.7003628755004754, \"precision\": 0.9997694815530357, \"recall\": 0.2996371244995246, \"specificity\": 0.9999999835775558, \"npv\": 0.9998335486992135, \"accuracy\": 0.9998335441360685, \"f1\": 0.46108439224421605, \"f2\": 0.3484390673502976, \"f0_5\": 0.6813574182659866, \"p4\": 0.6311370949388124, \"phi\": 0.5472825241224776}, {\"truth_threshold\": 15.479999653995037, \"match_probability\": 0.9999781200528404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90997.0, \"tn\": 1278737771.0, \"fp\": 21.0, \"fn\": 212964.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2993706429443251, \"tn_rate\": 0.9999999835775558, \"fp_rate\": 1.6422444172198204e-08, \"fn_rate\": 0.7006293570556749, \"precision\": 0.9997692764068645, \"recall\": 0.2993706429443251, \"specificity\": 0.9999999835775558, \"npv\": 0.9998334853765888, \"accuracy\": 0.9998334808074087, \"f1\": 0.4607688003666018, \"f2\": 0.3481507611362179, \"f0_5\": 0.6810816232132245, \"p4\": 0.6308413716897561, \"phi\": 0.5470390343184981}, {\"truth_threshold\": 15.499999653548002, \"match_probability\": 0.9999784212740318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90892.0, \"tn\": 1278737771.0, \"fp\": 21.0, \"fn\": 213069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29902520389128867, \"tn_rate\": 0.9999999835775558, \"fp_rate\": 1.6422444172198204e-08, \"fn_rate\": 0.7009747961087113, \"precision\": 0.9997690099325729, \"recall\": 0.29902520389128867, \"specificity\": 0.9999999835775558, \"npv\": 0.9998334032917168, \"accuracy\": 0.9998333987147017, \"f1\": 0.4603595070832721, \"f2\": 0.3477769776630238, \"f0_5\": 0.6807237126898368, \"p4\": 0.6304576558102549, \"phi\": 0.5467232380361224}, {\"truth_threshold\": 15.519999653100967, \"match_probability\": 0.9999787183483999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90812.0, \"tn\": 1278737771.0, \"fp\": 21.0, \"fn\": 213149.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29876201223183235, \"tn_rate\": 0.9999999835775558, \"fp_rate\": 1.6422444172198204e-08, \"fn_rate\": 0.7012379877681676, \"precision\": 0.999768806491033, \"recall\": 0.29876201223183235, \"specificity\": 0.9999999835775558, \"npv\": 0.999833340750871, \"accuracy\": 0.9998333361678773, \"f1\": 0.4600475184526614, \"f2\": 0.3474921499345286, \"f0_5\": 0.6804507165517996, \"p4\": 0.630165019373627, \"phi\": 0.5464825088924083}, {\"truth_threshold\": 15.539999652653933, \"match_probability\": 0.9999790113330304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90733.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213228.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29850211046811925, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7014978895318807, \"precision\": 0.9997796216103049, \"recall\": 0.29850211046811925, \"specificity\": 0.9999999843595769, \"npv\": 0.9998332789919239, \"accuracy\": 0.9998332751847234, \"f1\": 0.4597404703152156, \"f2\": 0.3472111140619487, \"f0_5\": 0.6801849550131714, \"p4\": 0.62987689490835, \"phi\": 0.5462476955068598}, {\"truth_threshold\": 15.559999652206898, \"match_probability\": 0.9999793002842231, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90645.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213316.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29821259964271735, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7017874003572827, \"precision\": 0.9997794077097005, \"recall\": 0.29821259964271735, \"specificity\": 0.9999999843595769, \"npv\": 0.9998332101970111, \"accuracy\": 0.9998332063832165, \"f1\": 0.45939699867722855, \"f2\": 0.34689772515918377, \"f0_5\": 0.6798840720589361, \"p4\": 0.6295544480427249, \"phi\": 0.5459826570389014}, {\"truth_threshold\": 15.579999651759863, \"match_probability\": 0.999979585257503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90562.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2979395382960314, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7020604617039686, \"precision\": 0.9997792055816829, \"recall\": 0.2979395382960314, \"specificity\": 0.9999999843595769, \"npv\": 0.9998331453109088, \"accuracy\": 0.9998331414908861, \"f1\": 0.4590729020664414, \"f2\": 0.34660210375482425, \"f0_5\": 0.679599993396259, \"p4\": 0.6292500510134037, \"phi\": 0.5457325596531595}, {\"truth_threshold\": 15.599999651312828, \"match_probability\": 0.9999798663076307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90472.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213489.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.297643447679143, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7023565523208569, \"precision\": 0.9997789859877116, \"recall\": 0.297643447679143, \"specificity\": 0.9999999843595769, \"npv\": 0.9998330749524942, \"accuracy\": 0.9998330711257086, \"f1\": 0.45872131787564047, \"f2\": 0.34628150797344637, \"f0_5\": 0.6792916361954503, \"p4\": 0.628919684239405, \"phi\": 0.5454612401679344}, {\"truth_threshold\": 15.619999650865793, \"match_probability\": 0.9999801434886131, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90388.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213573.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29736709643671394, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7026329035632861, \"precision\": 0.9997787806388815, \"recall\": 0.29736709643671394, \"specificity\": 0.9999999843595769, \"npv\": 0.9998330092846496, \"accuracy\": 0.9998330054515429, \"f1\": 0.45839302784955205, \"f2\": 0.3459822453860358, \"f0_5\": 0.679003535193429, \"p4\": 0.6286110620772429, \"phi\": 0.5452078868643736}, {\"truth_threshold\": 15.639999650418758, \"match_probability\": 0.9999804168537135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90317.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213644.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29713351383894643, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7028664861610535, \"precision\": 0.9997786067724188, \"recall\": 0.29713351383894643, \"specificity\": 0.9999999843595769, \"npv\": 0.9998329537796923, \"accuracy\": 0.9998329499412362, \"f1\": 0.45811543553353046, \"f2\": 0.3457292672301924, \"f0_5\": 0.678759794321135, \"p4\": 0.6283499918962625, \"phi\": 0.5449936511800242}, {\"truth_threshold\": 15.659999649971724, \"match_probability\": 0.9999806864554623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90245.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213716.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29689664134543575, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7031033586545642, \"precision\": 0.9997784301778098, \"recall\": 0.29689664134543575, \"specificity\": 0.9999999843595769, \"npv\": 0.9998328974929813, \"accuracy\": 0.9998328936490942, \"f1\": 0.45783383135561834, \"f2\": 0.34547269791418633, \"f0_5\": 0.6785124078788489, \"p4\": 0.6280850470560548, \"phi\": 0.5447763120786051}, {\"truth_threshold\": 15.679999649524689, \"match_probability\": 0.9999809523456668, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90190.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2967156970795595, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7032843029204404, \"precision\": 0.9997782950892362, \"recall\": 0.2967156970795595, \"specificity\": 0.9999999843595769, \"npv\": 0.9998328544961926, \"accuracy\": 0.9998328506481524, \"f1\": 0.45761864774425315, \"f2\": 0.3452766884064518, \"f0_5\": 0.6783232877206863, \"p4\": 0.627882524432499, \"phi\": 0.5446102307369914}, {\"truth_threshold\": 15.699999649077654, \"match_probability\": 0.9999812145754207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90094.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.296399867088212, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.703600132911788, \"precision\": 0.9997780589031671, \"recall\": 0.296399867088212, \"specificity\": 0.9999999843595769, \"npv\": 0.999832779447261, \"accuracy\": 0.999832775591963, \"f1\": 0.4572429106134619, \"f2\": 0.3449345231623069, \"f0_5\": 0.677992886997172, \"p4\": 0.6275287515601471, \"phi\": 0.5443202219214961}, {\"truth_threshold\": 15.719999648630619, \"match_probability\": 0.9999814731951148, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90018.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2961498350117285, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7038501649882716, \"precision\": 0.999777871565339, \"recall\": 0.2961498350117285, \"specificity\": 0.9999999843595769, \"npv\": 0.9998327200335315, \"accuracy\": 0.9998327161724798, \"f1\": 0.4569453221962492, \"f2\": 0.3446636066658396, \"f0_5\": 0.6777310487823608, \"p4\": 0.6272484296241289, \"phi\": 0.5440905220123297}, {\"truth_threshold\": 15.739999648183584, \"match_probability\": 0.9999817282544463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89962.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29596560085010903, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.704034399149891, \"precision\": 0.9997777333244426, \"recall\": 0.29596560085010903, \"specificity\": 0.9999999843595769, \"npv\": 0.9998326762549985, \"accuracy\": 0.9998326723897026, \"f1\": 0.45672597304686213, \"f2\": 0.34446396380528493, \"f0_5\": 0.6775379619183327, \"p4\": 0.6270417340910865, \"phi\": 0.5439212073939325}, {\"truth_threshold\": 15.75999964773655, \"match_probability\": 0.9999819798024282, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89872.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214089.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2956695102332207, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7043304897667793, \"precision\": 0.9997775107907266, \"recall\": 0.2956695102332207, \"specificity\": 0.9999999843595769, \"npv\": 0.9998326058966499, \"accuracy\": 0.9998326020245252, \"f1\": 0.4563733169482015, \"f2\": 0.34414307333182204, \"f0_5\": 0.6772273706198222, \"p4\": 0.6267092911907549, \"phi\": 0.5436489841715922}, {\"truth_threshold\": 15.779999647289515, \"match_probability\": 0.9999822278873987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89815.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214146.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2954819861758581, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7045180138241419, \"precision\": 0.999777369622085, \"recall\": 0.2954819861758581, \"specificity\": 0.9999999843595769, \"npv\": 0.9998325613363677, \"accuracy\": 0.9998325574599127, \"f1\": 0.4561498847118813, \"f2\": 0.34393981981788785, \"f0_5\": 0.6770304884207924, \"p4\": 0.6264985821029372, \"phi\": 0.5434765056250305}, {\"truth_threshold\": 15.79999964684248, \"match_probability\": 0.9999824725570307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89739.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214222.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2952319540993746, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7047680459006254, \"precision\": 0.9997771811183279, \"recall\": 0.2952319540993746, \"specificity\": 0.9999999843595769, \"npv\": 0.999832501922664, \"accuracy\": 0.9998324980404295, \"f1\": 0.45585187442852787, \"f2\": 0.34366878752576396, \"f0_5\": 0.6767677681799465, \"p4\": 0.6262174410953475, \"phi\": 0.5432464490694167}, {\"truth_threshold\": 15.819999646395445, \"match_probability\": 0.9999827138583409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89669.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214292.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29500166139735035, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7049983386026497, \"precision\": 0.9997770072138167, \"recall\": 0.29500166139735035, \"specificity\": 0.9999999843595769, \"npv\": 0.9998324471995222, \"accuracy\": 0.9998324433119581, \"f1\": 0.45557728947034165, \"f2\": 0.3434191246027485, \"f0_5\": 0.6765255757736711, \"p4\": 0.6259582974962953, \"phi\": 0.5430344686722189}, {\"truth_threshold\": 15.83999964594841, \"match_probability\": 0.9999829518376988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89589.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214372.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.294738469737894, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.705261530262106, \"precision\": 0.9997768081331116, \"recall\": 0.294738469737894, \"specificity\": 0.9999999843595769, \"npv\": 0.9998323846587961, \"accuracy\": 0.9998323807651336, \"f1\": 0.4552633584876896, \"f2\": 0.34313376276281105, \"f0_5\": 0.6762485337343014, \"p4\": 0.6256619006999365, \"phi\": 0.5427921040187558}, {\"truth_threshold\": 15.859999645501375, \"match_probability\": 0.9999831865408356, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89522.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214439.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29451804672309934, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7054819532769007, \"precision\": 0.9997766411293024, \"recall\": 0.29451804672309934, \"specificity\": 0.9999999843595769, \"npv\": 0.999832332280944, \"accuracy\": 0.9998323283821682, \"f1\": 0.4550003430723527, \"f2\": 0.34289474530905034, \"f0_5\": 0.6760163049798453, \"p4\": 0.6254134771911305, \"phi\": 0.5425890403439431}, {\"truth_threshold\": 15.87999964505434, \"match_probability\": 0.999983418012853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89466.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29433381256147995, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.70566618743852, \"precision\": 0.9997765013521668, \"recall\": 0.29433381256147995, \"specificity\": 0.9999999843595769, \"npv\": 0.999832288502445, \"accuracy\": 0.999832284599391, \"f1\": 0.4547804405675987, \"f2\": 0.3426949507021213, \"f0_5\": 0.6758220590568133, \"p4\": 0.6252057057772551, \"phi\": 0.5424192571743474}, {\"truth_threshold\": 15.899999644607306, \"match_probability\": 0.9999836462982317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89332.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2938929665318906, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7061070334681094, \"precision\": 0.9997761661742323, \"recall\": 0.2938929665318906, \"specificity\": 0.9999999843595769, \"npv\": 0.9998321837467663, \"accuracy\": 0.9998321798334601, \"f1\": 0.4542539910961499, \"f2\": 0.3422168011547691, \"f0_5\": 0.6753567221929059, \"p4\": 0.6247080430351869, \"phi\": 0.54201277447495}, {\"truth_threshold\": 15.91999964416027, \"match_probability\": 0.9999838714408402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89247.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214714.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29361332539371826, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7063866746062817, \"precision\": 0.9997759530397571, \"recall\": 0.29361332539371826, \"specificity\": 0.9999999843595769, \"npv\": 0.9998321172972802, \"accuracy\": 0.999832113377459, \"f1\": 0.4539198632854222, \"f2\": 0.3419134464424865, \"f0_5\": 0.6750611546543344, \"p4\": 0.6243919986900123, \"phi\": 0.5417547729256865}, {\"truth_threshold\": 15.939999643713236, \"match_probability\": 0.9999840934839433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89174.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29337316300446437, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7066268369955356, \"precision\": 0.9997757696706057, \"recall\": 0.29337316300446437, \"specificity\": 0.9999999843595769, \"npv\": 0.9998320602289049, \"accuracy\": 0.9998320563034817, \"f1\": 0.4536327911383551, \"f2\": 0.34165288673586514, \"f0_5\": 0.6748070714974339, \"p4\": 0.6241203472596197, \"phi\": 0.5415330970378068}, {\"truth_threshold\": 15.959999643266201, \"match_probability\": 0.9999843124702101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89116.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214845.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29318234905135854, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7068176509486415, \"precision\": 0.9997756237659308, \"recall\": 0.29318234905135854, \"specificity\": 0.9999999843595769, \"npv\": 0.9998320148869128, \"accuracy\": 0.999832010957034, \"f1\": 0.4534046304092883, \"f2\": 0.3414458459133473, \"f0_5\": 0.6746050370549806, \"p4\": 0.6239043661570441, \"phi\": 0.5413569062971636}, {\"truth_threshold\": 15.979999642819166, \"match_probability\": 0.9999845284417223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89035.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214926.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29291586749615905, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.707084132503841, \"precision\": 0.9997754196844647, \"recall\": 0.29291586749615905, \"specificity\": 0.9999999843595769, \"npv\": 0.9998319515644823, \"accuracy\": 0.9998319476283742, \"f1\": 0.45308587945528933, \"f2\": 0.3411566718956793, \"f0_5\": 0.6743226478798996, \"p4\": 0.6236025171383904, \"phi\": 0.5411107508363313}, {\"truth_threshold\": 15.999999642372131, \"match_probability\": 0.9999847414399821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88975.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214986.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2927184737515668, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7072815262484332, \"precision\": 0.9997752682734985, \"recall\": 0.2927184737515668, \"specificity\": 0.9999999843595769, \"npv\": 0.9998319046589835, \"accuracy\": 0.9998319007182559, \"f1\": 0.45284968291615346, \"f2\": 0.3409424457730034, \"f0_5\": 0.6741132919457952, \"p4\": 0.6233787596134724, \"phi\": 0.5409283412593905}, {\"truth_threshold\": 16.019999641925097, \"match_probability\": 0.9999849515059211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88913.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2925145002154882, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7074854997845118, \"precision\": 0.9997751116008681, \"recall\": 0.2925145002154882, \"specificity\": 0.9999999843595769, \"npv\": 0.9998318561899727, \"accuracy\": 0.9998318522444669, \"f1\": 0.45260553737140297, \"f2\": 0.34072105808118935, \"f0_5\": 0.6738967974497229, \"p4\": 0.623147395232083, \"phi\": 0.5407397867375596}, {\"truth_threshold\": 16.03999964147806, \"match_probability\": 0.9999851586799067, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88835.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215126.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29225788834751826, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7077421116524817, \"precision\": 0.9997749141860334, \"recall\": 0.29225788834751826, \"specificity\": 0.9999999843595769, \"npv\": 0.9998317952128367, \"accuracy\": 0.9998317912613132, \"f1\": 0.4522982770559244, \"f2\": 0.34044250819537686, \"f0_5\": 0.6736242020925687, \"p4\": 0.6228561096305627, \"phi\": 0.5405024795804857}, {\"truth_threshold\": 16.059999641031027, \"match_probability\": 0.9999853630017509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88755.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29199469668806194, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.708005303311938, \"precision\": 0.9997747113489158, \"recall\": 0.29199469668806194, \"specificity\": 0.9999999843595769, \"npv\": 0.9998317326721922, \"accuracy\": 0.9998317287144887, \"f1\": 0.45198301148863357, \"f2\": 0.3401567814051459, \"f0_5\": 0.6733443490056308, \"p4\": 0.6225571068458428, \"phi\": 0.5402589793748068}, {\"truth_threshold\": 16.079999640583992, \"match_probability\": 0.9999855645107176, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88670.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29171505554988963, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7082849444501104, \"precision\": 0.9997744954335326, \"recall\": 0.29171505554988963, \"specificity\": 0.9999999843595769, \"npv\": 0.9998316662227659, \"accuracy\": 0.9998316622584876, \"f1\": 0.4516479010622665, \"f2\": 0.3398531582925397, \"f0_5\": 0.6730467071795191, \"p4\": 0.6222391405037486, \"phi\": 0.5400001401308298}, {\"truth_threshold\": 16.099999640136957, \"match_probability\": 0.9999857632455306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88595.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215366.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29146831336914936, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7085316866308506, \"precision\": 0.9997743045759747, \"recall\": 0.29146831336914936, \"specificity\": 0.9999999843595769, \"npv\": 0.9998316075909265, \"accuracy\": 0.9998316036208398, \"f1\": 0.4513520948809912, \"f2\": 0.3395852226861864, \"f0_5\": 0.6727838267612971, \"p4\": 0.6219583456183919, \"phi\": 0.5397716495138082}, {\"truth_threshold\": 16.119999639689922, \"match_probability\": 0.99998595924438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88524.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215437.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29123473077138184, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7087652692286182, \"precision\": 0.9997741235995663, \"recall\": 0.29123473077138184, \"specificity\": 0.9999999843595769, \"npv\": 0.9998315520861248, \"accuracy\": 0.999831548110533, \"f1\": 0.45107196086674056, \"f2\": 0.3393315485883035, \"f0_5\": 0.6725347458052047, \"p4\": 0.621692322046357, \"phi\": 0.5395552559299296}, {\"truth_threshold\": 16.139999639242887, \"match_probability\": 0.9999861525449308, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88443.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29096824921618236, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7090317507838176, \"precision\": 0.9997739167787663, \"recall\": 0.29096824921618236, \"specificity\": 0.9999999843595769, \"npv\": 0.999831488763753, \"accuracy\": 0.9998314847818732, \"f1\": 0.45075224756895604, \"f2\": 0.3390421120181062, \"f0_5\": 0.672250320379804, \"p4\": 0.6213885872868116, \"phi\": 0.5393082783747042}, {\"truth_threshold\": 16.159999638795853, \"match_probability\": 0.999986343184329, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88339.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2906261000588891, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7093738999411109, \"precision\": 0.9997736506750868, \"recall\": 0.2906261000588891, \"specificity\": 0.9999999843595769, \"npv\": 0.9998314074609664, \"accuracy\": 0.9998314034710014, \"f1\": 0.45034155791190866, \"f2\": 0.3386704370408594, \"f0_5\": 0.6718847211045988, \"p4\": 0.6209982264821198, \"phi\": 0.5389910055009957}, {\"truth_threshold\": 16.179999638348818, \"match_probability\": 0.9999865311992094, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88266.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2903859376696353, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7096140623303647, \"precision\": 0.9997734635162993, \"recall\": 0.2903859376696353, \"specificity\": 0.9999999843595769, \"npv\": 0.9998313503926722, \"accuracy\": 0.9998313463970242, \"f1\": 0.45005315528225837, \"f2\": 0.33840951438890293, \"f0_5\": 0.6716278220375739, \"p4\": 0.620723967430598, \"phi\": 0.538768192780342}, {\"truth_threshold\": 16.199999637901783, \"match_probability\": 0.9999867166257028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88193.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215768.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2901457752803814, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7098542247196187, \"precision\": 0.999773276047748, \"recall\": 0.2901457752803814, \"specificity\": 0.9999999843595769, \"npv\": 0.9998312933243846, \"accuracy\": 0.9998312893230469, \"f1\": 0.44976464528500104, \"f2\": 0.3381485625244909, \"f0_5\": 0.6713706945508082, \"p4\": 0.6204494971064972, \"phi\": 0.5385452879007028}, {\"truth_threshold\": 16.219999637454748, \"match_probability\": 0.9999868994994422, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88119.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28990232299538427, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7100976770046157, \"precision\": 0.9997730856941875, \"recall\": 0.28990232299538427, \"specificity\": 0.9999999843595769, \"npv\": 0.9998312354743462, \"accuracy\": 0.9998312314672342, \"f1\": 0.4494720734506503, \"f2\": 0.337884006156522, \"f0_5\": 0.671109811322479, \"p4\": 0.6201710510308982, \"phi\": 0.5383192353508721}, {\"truth_threshold\": 16.239999637007713, \"match_probability\": 0.9999870798555704, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88026.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2895963626912663, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7104036373087337, \"precision\": 0.9997728460123118, \"recall\": 0.2895963626912663, \"specificity\": 0.9999999843595769, \"npv\": 0.999831162770929, \"accuracy\": 0.9998311587565508, \"f1\": 0.4491042251796524, \"f2\": 0.33755148056968, \"f0_5\": 0.6707816107720093, \"p4\": 0.6198208034261401, \"phi\": 0.5380350076351962}, {\"truth_threshold\": 16.25999963656068, \"match_probability\": 0.9999872577287463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87926.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216035.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28926737311694595, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.710732626883054, \"precision\": 0.9997725877242853, \"recall\": 0.28926737311694595, \"specificity\": 0.9999999843595769, \"npv\": 0.9998310845952234, \"accuracy\": 0.9998310805730202, \"f1\": 0.44870849461734547, \"f2\": 0.3371938732464584, \"f0_5\": 0.6704282914852572, \"p4\": 0.6194438090453654, \"phi\": 0.5377292188599132}, {\"truth_threshold\": 16.279999636113644, \"match_probability\": 0.9999874331531516, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87847.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216114.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2890074713532328, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7109925286467672, \"precision\": 0.999772383261065, \"recall\": 0.2890074713532328, \"specificity\": 0.9999999843595769, \"npv\": 0.9998310228364247, \"accuracy\": 0.999831018808031, \"f1\": 0.4483957246546954, \"f2\": 0.3369113246724159, \"f0_5\": 0.6701488643316057, \"p4\": 0.6191457016864333, \"phi\": 0.5374875227557324}, {\"truth_threshold\": 16.29999963566661, \"match_probability\": 0.9999876061624977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87766.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216195.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2887409897980333, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7112590102019667, \"precision\": 0.9997721732394687, \"recall\": 0.2887409897980333, \"specificity\": 0.9999999843595769, \"npv\": 0.9998309595141198, \"accuracy\": 0.9998309554793713, \"f1\": 0.44807490548747025, \"f2\": 0.33662158741360665, \"f0_5\": 0.669862083177506, \"p4\": 0.6188397886871643, \"phi\": 0.5372395948943732}, {\"truth_threshold\": 16.319999635219574, \"match_probability\": 0.9999877767900316, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87697.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216264.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28851398699175224, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7114860130082478, \"precision\": 0.9997719940262435, \"recall\": 0.28851398699175224, \"specificity\": 0.9999999843595769, \"npv\": 0.9998309055729037, \"accuracy\": 0.9998309015327352, \"f1\": 0.4478015104243792, \"f2\": 0.3363747457924869, \"f0_5\": 0.6696175642801403, \"p4\": 0.6185789893463209, \"phi\": 0.5370283068308913}, {\"truth_threshold\": 16.33999963477254, \"match_probability\": 0.9999879450685429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87601.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216360.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28819815700040463, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7118018429995954, \"precision\": 0.9997717442165691, \"recall\": 0.28819815700040463, \"specificity\": 0.9999999843595769, \"npv\": 0.9998308305242647, \"accuracy\": 0.9998308264765459, \"f1\": 0.44742097440638234, \"f2\": 0.3360312704982489, \"f0_5\": 0.6692770209872487, \"p4\": 0.6182158212050491, \"phi\": 0.5367342025052628}, {\"truth_threshold\": 16.359999634325504, \"match_probability\": 0.9999881110303698, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87551.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28803366221324445, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7119663377867556, \"precision\": 0.9997716138904432, \"recall\": 0.28803366221324445, \"specificity\": 0.9999999843595769, \"npv\": 0.9998307914364363, \"accuracy\": 0.9998307873847806, \"f1\": 0.44722270465760144, \"f2\": 0.3358523570773698, \"f0_5\": 0.6690994963660403, \"p4\": 0.6180265249263066, \"phi\": 0.5365809593428233}, {\"truth_threshold\": 16.37999963387847, \"match_probability\": 0.9999882747074051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87455.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216506.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2877178322218969, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7122821677781032, \"precision\": 0.999771363246642, \"recall\": 0.2877178322218969, \"specificity\": 0.9999999843595769, \"npv\": 0.9998307163878144, \"accuracy\": 0.9998307123285912, \"f1\": 0.44684188475255215, \"f2\": 0.3355088048282884, \"f0_5\": 0.6687583446634683, \"p4\": 0.6176627949973388, \"phi\": 0.5362866097552001}, {\"truth_threshold\": 16.399999633431435, \"match_probability\": 0.9999884361311029, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87386.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2874908294156158, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7125091705843842, \"precision\": 0.9997711827563325, \"recall\": 0.2874908294156158, \"specificity\": 0.9999999843595769, \"npv\": 0.9998306624466244, \"accuracy\": 0.9998306583819551, \"f1\": 0.44656805504807506, \"f2\": 0.33526184538653364, \"f0_5\": 0.6685128942677693, \"p4\": 0.6174011355384765, \"phi\": 0.5360749461862421}, {\"truth_threshold\": 16.4199996329844, \"match_probability\": 0.999988595332484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87281.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216680.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2871453903625794, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7128546096374206, \"precision\": 0.9997709075497417, \"recall\": 0.2871453903625794, \"specificity\": 0.9999999843595769, \"npv\": 0.9998305803622161, \"accuracy\": 0.999830576289248, \"f1\": 0.44615117236020874, \"f2\": 0.33488598736134506, \"f0_5\": 0.6681389847894483, \"p4\": 0.6170025907759539, \"phi\": 0.535752689045332}, {\"truth_threshold\": 16.439999632537365, \"match_probability\": 0.9999887523421424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87196.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216765.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28686574922440705, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7131342507755929, \"precision\": 0.9997706842781141, \"recall\": 0.28686574922440705, \"specificity\": 0.9999999843595769, \"npv\": 0.999830513912943, \"accuracy\": 0.9998305098332471, \"f1\": 0.44581353198168605, \"f2\": 0.33458167697573404, \"f0_5\": 0.6678359437827902, \"p4\": 0.6166796341536804, \"phi\": 0.5354916722139635}, {\"truth_threshold\": 16.45999963209033, \"match_probability\": 0.9999889071902507, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87126.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216835.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2866354565223828, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7133645434776172, \"precision\": 0.999770500080325, \"recall\": 0.2866354565223828, \"specificity\": 0.9999999843595769, \"npv\": 0.9998304591900188, \"accuracy\": 0.9998304551047756, \"f1\": 0.4455353650024162, \"f2\": 0.33433103861119423, \"f0_5\": 0.6675861434843574, \"p4\": 0.6164134511321382, \"phi\": 0.5352766216326703}, {\"truth_threshold\": 16.479999631643295, \"match_probability\": 0.9999890599065664, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87067.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28644135267353377, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7135586473264662, \"precision\": 0.9997703445979308, \"recall\": 0.28644135267353377, \"specificity\": 0.9999999843595769, \"npv\": 0.999830413066416, \"accuracy\": 0.9998304089764926, \"f1\": 0.4453008326343569, \"f2\": 0.33411976535979265, \"f0_5\": 0.6673754309690653, \"p4\": 0.6161889432531793, \"phi\": 0.5350952976103285}, {\"truth_threshold\": 16.49999963119626, \"match_probability\": 0.9999892105204371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86980.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.286155131743875, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7138448682561249, \"precision\": 0.9997701149425288, \"recall\": 0.286155131743875, \"specificity\": 0.9999999843595769, \"npv\": 0.9998303450536533, \"accuracy\": 0.999830340956821, \"f1\": 0.44495486762106706, \"f2\": 0.3338081919247431, \"f0_5\": 0.6670644409711624, \"p4\": 0.615857632595049, \"phi\": 0.5348278093809927}, {\"truth_threshold\": 16.519999630749226, \"match_probability\": 0.9999893590608068, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86929.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217032.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2859873470609716, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7140126529390284, \"precision\": 0.9997699801032789, \"recall\": 0.2859873470609716, \"specificity\": 0.9999999843595769, \"npv\": 0.9998303051841072, \"accuracy\": 0.9998303010832204, \"f1\": 0.4447519889488629, \"f2\": 0.3336255260812731, \"f0_5\": 0.6668819820884164, \"p4\": 0.6156632736378703, \"phi\": 0.534670943736948}, {\"truth_threshold\": 16.53999963030219, \"match_probability\": 0.9999895055562203, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86833.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217128.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28567151706962407, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.714328482930376, \"precision\": 0.9997697258586347, \"recall\": 0.28567151706962407, \"specificity\": 0.9999999843595769, \"npv\": 0.9998302301355584, \"accuracy\": 0.9998302260270311, \"f1\": 0.44436995604046936, \"f2\": 0.3332816456935112, \"f0_5\": 0.6665382200367531, \"p4\": 0.6152971356709893, \"phi\": 0.5343755423458529}, {\"truth_threshold\": 16.559999629855156, \"match_probability\": 0.9999896500348305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86735.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217226.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2853491072867901, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7146508927132099, \"precision\": 0.9997694657368451, \"recall\": 0.2853491072867901, \"specificity\": 0.9999999843595769, \"npv\": 0.9998301535235097, \"accuracy\": 0.9998301494071711, \"f1\": 0.4439797704726707, \"f2\": 0.3329305488488783, \"f0_5\": 0.6661868779580357, \"p4\": 0.6149229842756022, \"phi\": 0.5340738182742125}, {\"truth_threshold\": 16.57999962940812, \"match_probability\": 0.9999897925244019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86646.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217315.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28505630656564496, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.714943693434355, \"precision\": 0.9997692289940692, \"recall\": 0.28505630656564496, \"specificity\": 0.9999999843595769, \"npv\": 0.9998300839472716, \"accuracy\": 0.9998300798238289, \"f1\": 0.443625248638727, \"f2\": 0.33261164981458874, \"f0_5\": 0.6658674351585014, \"p4\": 0.6145828557024653, \"phi\": 0.5337996558245975}, {\"truth_threshold\": 16.599999628961086, \"match_probability\": 0.999989933052317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86580.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217381.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2848391734465935, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7151608265534065, \"precision\": 0.9997690531177829, \"recall\": 0.2848391734465935, \"specificity\": 0.9999999843595769, \"npv\": 0.9998300323514159, \"accuracy\": 0.9998300282226987, \"f1\": 0.44336224046947853, \"f2\": 0.33237513474667624, \"f0_5\": 0.6656303191612043, \"p4\": 0.6143304174730467, \"phi\": 0.5335962534059481}, {\"truth_threshold\": 16.61999962851405, \"match_probability\": 0.9999900716455815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86509.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217452.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.284605590848826, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.715394409151174, \"precision\": 0.9997688636179778, \"recall\": 0.284605590848826, \"specificity\": 0.9999999843595769, \"npv\": 0.9998299768467891, \"accuracy\": 0.9998299727123919, \"f1\": 0.44307920817434504, \"f2\": 0.3321206751061332, \"f0_5\": 0.6653750248047539, \"p4\": 0.6140586570754354, \"phi\": 0.5333773551324874}, {\"truth_threshold\": 16.639999628067017, \"match_probability\": 0.9999902083308292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86427.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217534.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28433581939788327, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7156641806021167, \"precision\": 0.999768644371696, \"recall\": 0.28433581939788327, \"specificity\": 0.9999999843595769, \"npv\": 0.9998299127428617, \"accuracy\": 0.9998299086018969, \"f1\": 0.44275219770086677, \"f2\": 0.33182675761408165, \"f0_5\": 0.6650799000844941, \"p4\": 0.6137445371962464, \"phi\": 0.5331244312278001}, {\"truth_threshold\": 16.65999962761998, \"match_probability\": 0.9999903431343274, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86344.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28406275805119735, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7159372419488026, \"precision\": 0.9997684220276968, \"recall\": 0.28406275805119735, \"specificity\": 0.9999999843595769, \"npv\": 0.9998298478571874, \"accuracy\": 0.9998298437095665, \"f1\": 0.44242105937359893, \"f2\": 0.33152921806654545, \"f0_5\": 0.6647808726904285, \"p4\": 0.6134263070546451, \"phi\": 0.5328683006640248}, {\"truth_threshold\": 16.679999627172947, \"match_probability\": 0.9999904760819817, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86302.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217659.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2839245824299828, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7160754175700172, \"precision\": 0.9997683093533514, \"recall\": 0.2839245824299828, \"specificity\": 0.9999999843595769, \"npv\": 0.999829815023476, \"accuracy\": 0.9998298108724837, \"f1\": 0.44225344173330633, \"f2\": 0.3313786414328127, \"f0_5\": 0.6646294410927086, \"p4\": 0.6132651676574649, \"phi\": 0.5327386455170557}, {\"truth_threshold\": 16.699999626725912, \"match_probability\": 0.999990607199341, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86225.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2836712604577561, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7163287395422439, \"precision\": 0.9997681024986955, \"recall\": 0.2836712604577561, \"specificity\": 0.9999999843595769, \"npv\": 0.9998297548283439, \"accuracy\": 0.9998297506711652, \"f1\": 0.4419460490100101, \"f2\": 0.331102559041663, \"f0_5\": 0.6643516128584879, \"p4\": 0.6129695579929252, \"phi\": 0.5325008624450295}, {\"truth_threshold\": 16.719999626278877, \"match_probability\": 0.9999907365116024, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86157.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28344754754721824, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7165524524527818, \"precision\": 0.9997679195144876, \"recall\": 0.28344754754721824, \"specificity\": 0.9999999843595769, \"npv\": 0.9998297016690124, \"accuracy\": 0.9998296975063644, \"f1\": 0.4416744844132076, \"f2\": 0.3308587188685897, \"f0_5\": 0.6641060386730366, \"p4\": 0.6127082982121131, \"phi\": 0.5322907838995211}, {\"truth_threshold\": 16.739999625831842, \"match_probability\": 0.9999908640436167, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86034.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217927.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28304289037080416, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7169571096291959, \"precision\": 0.9997675877937109, \"recall\": 0.28304289037080416, \"specificity\": 0.9999999843595769, \"npv\": 0.9998296055131773, \"accuracy\": 0.9998296013406217, \"f1\": 0.4411830314218684, \"f2\": 0.3304175903181355, \"f0_5\": 0.6636613147334756, \"p4\": 0.6122352436380071, \"phi\": 0.531910578167047}, {\"truth_threshold\": 16.759999625384808, \"match_probability\": 0.9999909898198919, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85945.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.282750089649659, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.717249910350341, \"precision\": 0.9997673471761763, \"recall\": 0.282750089649659, \"specificity\": 0.9999999843595769, \"npv\": 0.9998295359370155, \"accuracy\": 0.9998295317572795, \"f1\": 0.4408272338854039, \"f2\": 0.330098347760693, \"f0_5\": 0.6633391013875747, \"p4\": 0.6118925646409719, \"phi\": 0.5316353004453868}, {\"truth_threshold\": 16.779999624937773, \"match_probability\": 0.9999911138645989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85865.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218096.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2824868979902027, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7175131020097973, \"precision\": 0.9997671304651569, \"recall\": 0.2824868979902027, \"specificity\": 0.9999999843595769, \"npv\": 0.9998294733966536, \"accuracy\": 0.9998294692104551, \"f1\": 0.44050727723254823, \"f2\": 0.3298113509032986, \"f0_5\": 0.6630491690360324, \"p4\": 0.6115842604944485, \"phi\": 0.5313877381275848}, {\"truth_threshold\": 16.799999624490738, \"match_probability\": 0.999991236201576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85806.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218155.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28229279414135366, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7177072058586463, \"precision\": 0.9997669703819355, \"recall\": 0.28229279414135366, \"specificity\": 0.9999999843595769, \"npv\": 0.9998294272731417, \"accuracy\": 0.999829423082172, \"f1\": 0.44027122505368316, \"f2\": 0.3295996681186476, \"f0_5\": 0.6628351602512108, \"p4\": 0.6113567173012278, \"phi\": 0.5312050870177853}, {\"truth_threshold\": 16.819999624043703, \"match_probability\": 0.9999913568543333, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85747.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218214.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2820986902925046, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7179013097074953, \"precision\": 0.9997668100784685, \"recall\": 0.2820986902925046, \"specificity\": 0.9999999843595769, \"npv\": 0.999829381149634, \"accuracy\": 0.999829376953889, \"f1\": 0.44003510140405616, \"f2\": 0.32938796614349447, \"f0_5\": 0.6626209953495129, \"p4\": 0.611129030586119, \"phi\": 0.5310223730999631}, {\"truth_threshold\": 16.83999962359667, \"match_probability\": 0.9999914758460567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85622.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218339.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28168745332460415, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7183125466753959, \"precision\": 0.9997664697227996, \"recall\": 0.28168745332460415, \"specificity\": 0.9999999843595769, \"npv\": 0.9998292834303522, \"accuracy\": 0.9998292792244758, \"f1\": 0.4395346031729735, \"f2\": 0.3289393815991874, \"f0_5\": 0.6621667396203419, \"p4\": 0.6106461687156459, \"phi\": 0.530635059551949}, {\"truth_threshold\": 16.859999623149633, \"match_probability\": 0.9999915931996138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85533.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.281394652603459, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.718605347396541, \"precision\": 0.9997662267833974, \"recall\": 0.281394652603459, \"specificity\": 0.9999999843595769, \"npv\": 0.9998292138542352, \"accuracy\": 0.9998292096411335, \"f1\": 0.4391780526502257, \"f2\": 0.3286199368832109, \"f0_5\": 0.661842881086025, \"p4\": 0.6103019773450791, \"phi\": 0.5303591199631931}, {\"truth_threshold\": 16.8799996227026, \"match_probability\": 0.9999917089375568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85467.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218494.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28117751948440756, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7188224805155925, \"precision\": 0.9997660462994373, \"recall\": 0.28117751948440756, \"specificity\": 0.9999999843595769, \"npv\": 0.9998291622584693, \"accuracy\": 0.9998291580400034, \"f1\": 0.4389135391631232, \"f2\": 0.3283830170802048, \"f0_5\": 0.6616024857990832, \"p4\": 0.6100465225147235, \"phi\": 0.5301543978849175}, {\"truth_threshold\": 16.899999622255564, \"match_probability\": 0.9999918230821278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85386.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.280911037929208, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.719088962070792, \"precision\": 0.9997658244151465, \"recall\": 0.280911037929208, \"specificity\": 0.9999999843595769, \"npv\": 0.9998290989364003, \"accuracy\": 0.9998290947113436, \"f1\": 0.43858878641487337, \"f2\": 0.32809221902017294, \"f0_5\": 0.6613071865052627, \"p4\": 0.6097327629463685, \"phi\": 0.5299030399925657}, {\"truth_threshold\": 16.91999962180853, \"match_probability\": 0.9999919356552621, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85310.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218651.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2806610058527245, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7193389941472754, \"precision\": 0.999765615844369, \"recall\": 0.2806610058527245, \"specificity\": 0.9999999843595769, \"npv\": 0.9998290395231081, \"accuracy\": 0.9998290352918604, \"f1\": 0.4382839572453512, \"f2\": 0.3278193385358146, \"f0_5\": 0.661029845912091, \"p4\": 0.6094381236168178, \"phi\": 0.5296670895820886}, {\"truth_threshold\": 16.939999621361494, \"match_probability\": 0.9999920466785936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85225.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2803813647145522, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7196186352854478, \"precision\": 0.9997653821338495, \"recall\": 0.2803813647145522, \"specificity\": 0.9999999843595769, \"npv\": 0.9998289730740398, \"accuracy\": 0.9998289688358594, \"f1\": 0.43794288885577304, \"f2\": 0.32751410549163046, \"f0_5\": 0.6607193526229531, \"p4\": 0.6091083084018504, \"phi\": 0.5294030731305517}, {\"truth_threshold\": 16.95999962091446, \"match_probability\": 0.9999921561734584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85179.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2802300295103648, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7197699704896352, \"precision\": 0.9997652554607448, \"recall\": 0.2802300295103648, \"specificity\": 0.9999999843595769, \"npv\": 0.9998289371133713, \"accuracy\": 0.9998289328714354, \"f1\": 0.4377582485353068, \"f2\": 0.32734890391785665, \"f0_5\": 0.6605511843997041, \"p4\": 0.608929694803502, \"phi\": 0.5292601387308115}, {\"truth_threshold\": 16.979999620467424, \"match_probability\": 0.9999922641608986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85076.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2798911702488148, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7201088297511852, \"precision\": 0.9997649713265019, \"recall\": 0.2798911702488148, \"specificity\": 0.9999999843595769, \"npv\": 0.9998288565927531, \"accuracy\": 0.9998288523423988, \"f1\": 0.4373446564385167, \"f2\": 0.326978953679647, \"f0_5\": 0.6601742855147475, \"p4\": 0.6085294359809299, \"phi\": 0.5289399499335841}, {\"truth_threshold\": 16.99999962002039, \"match_probability\": 0.9999923706616665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85024.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2797200956701682, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7202799043298318, \"precision\": 0.9997648276186445, \"recall\": 0.2797200956701682, \"specificity\": 0.9999999843595769, \"npv\": 0.9998288159415722, \"accuracy\": 0.9998288116869629, \"f1\": 0.43713576946311744, \"f2\": 0.3267921604319511, \"f0_5\": 0.6599838233170894, \"p4\": 0.6083271954945245, \"phi\": 0.5287782275906303}, {\"truth_threshold\": 17.019999619573355, \"match_probability\": 0.9999924756962293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84931.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27941413536605025, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7205858646339498, \"precision\": 0.9997645701639769, \"recall\": 0.27941413536605025, \"specificity\": 0.9999999843595769, \"npv\": 0.999828743238507, \"accuracy\": 0.9998287389762796, \"f1\": 0.43676204385567946, \"f2\": 0.32645805065363875, \"f0_5\": 0.6596428821076014, \"p4\": 0.6079652145927159, \"phi\": 0.5284888700322629}, {\"truth_threshold\": 17.03999961912632, \"match_probability\": 0.9999925792847717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84840.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219121.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2791147548534187, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7208852451465813, \"precision\": 0.9997643176997407, \"recall\": 0.2791147548534187, \"specificity\": 0.9999999843595769, \"npv\": 0.9998286720989586, \"accuracy\": 0.9998286678292667, \"f1\": 0.43639618230496807, \"f2\": 0.32613107978448597, \"f0_5\": 0.6593088913445891, \"p4\": 0.6076106681640682, \"phi\": 0.5282055818209447}, {\"truth_threshold\": 17.059999618679285, \"match_probability\": 0.9999926814472012, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84781.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219180.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27892065100456964, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7210793489954304, \"precision\": 0.9997641537246023, \"recall\": 0.27892065100456964, \"specificity\": 0.9999999843595769, \"npv\": 0.9998286259755207, \"accuracy\": 0.9998286217009836, \"f1\": 0.43615888384152773, \"f2\": 0.3259190632340108, \"f0_5\": 0.6590921458723655, \"p4\": 0.6073806121364379, \"phi\": 0.5280218302488751}, {\"truth_threshold\": 17.07999961823225, \"match_probability\": 0.9999927822031508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84673.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219288.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27856534226430363, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7214346577356964, \"precision\": 0.9997638529748621, \"recall\": 0.27856534226430363, \"specificity\": 0.9999999843595769, \"npv\": 0.9998285415461876, \"accuracy\": 0.9998285372627707, \"f1\": 0.4357243203466322, \"f2\": 0.3255309153065234, \"f0_5\": 0.6586949790970745, \"p4\": 0.6069591145382485, \"phi\": 0.5276853057178144}, {\"truth_threshold\": 17.099999617785215, \"match_probability\": 0.9999928815719834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84598.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27831860008356335, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7216813999164366, \"precision\": 0.9997636436691957, \"recall\": 0.27831860008356335, \"specificity\": 0.9999999843595769, \"npv\": 0.9998284829147147, \"accuracy\": 0.9998284786251227, \"f1\": 0.4354223980194504, \"f2\": 0.32526133020418896, \"f0_5\": 0.6584188545731617, \"p4\": 0.6066661197801463, \"phi\": 0.5274514818363318}, {\"truth_threshold\": 17.11999961733818, \"match_probability\": 0.9999929795727952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84488.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219473.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2779567115518109, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7220432884481891, \"precision\": 0.9997633360155251, \"recall\": 0.2779567115518109, \"specificity\": 0.9999999843595769, \"npv\": 0.9998283969219003, \"accuracy\": 0.9998283926232391, \"f1\": 0.4349793677230358, \"f2\": 0.3248658824687469, \"f0_5\": 0.6580134051305855, \"p4\": 0.6062359663075103, \"phi\": 0.5271083525686395}, {\"truth_threshold\": 17.139999616891146, \"match_probability\": 0.9999930762244198, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84419.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219542.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2777297087455299, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7222702912544702, \"precision\": 0.9997631426236692, \"recall\": 0.2777297087455299, \"specificity\": 0.9999999843595769, \"npv\": 0.9998283429809605, \"accuracy\": 0.999828338676603, \"f1\": 0.43470133882595263, \"f2\": 0.32461779474160624, \"f0_5\": 0.6577587939855107, \"p4\": 0.6059658827497286, \"phi\": 0.5268930029213252}, {\"truth_threshold\": 17.15999961644411, \"match_probability\": 0.9999931715454312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84335.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27745335750310074, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7225466424968993, \"precision\": 0.9997629067630845, \"recall\": 0.27745335750310074, \"specificity\": 0.9999999843595769, \"npv\": 0.9998282773137374, \"accuracy\": 0.9998282730024373, \"f1\": 0.434362735504074, \"f2\": 0.324315739359898, \"f0_5\": 0.6574485368291234, \"p4\": 0.605636814428736, \"phi\": 0.5266307193077379}, {\"truth_threshold\": 17.179999615997076, \"match_probability\": 0.9999932655541479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84266.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27722635469681967, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7227736453031803, \"precision\": 0.9997627126687706, \"recall\": 0.27722635469681967, \"specificity\": 0.9999999843595769, \"npv\": 0.9998282233728105, \"accuracy\": 0.9998282190558012, \"f1\": 0.4340844874525753, \"f2\": 0.3240675932406759, \"f0_5\": 0.6571934394521958, \"p4\": 0.6053662854786491, \"phi\": 0.5264151743184882}, {\"truth_threshold\": 17.19999961555004, \"match_probability\": 0.9999933582686362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84180.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219781.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27694342366290414, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7230565763370959, \"precision\": 0.9997624703087886, \"recall\": 0.27694342366290414, \"specificity\": 0.9999999843595769, \"npv\": 0.9998281561420983, \"accuracy\": 0.9998281518179649, \"f1\": 0.43373754704877615, \"f2\": 0.3237582727969207, \"f0_5\": 0.6568751843511075, \"p4\": 0.605028822746198, \"phi\": 0.5261464004596396}, {\"truth_threshold\": 17.219999615103006, \"match_probability\": 0.9999934497067136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84107.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219854.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27670326127365025, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7232967387263498, \"precision\": 0.9997622641957992, \"recall\": 0.27670326127365025, \"specificity\": 0.9999999843595769, \"npv\": 0.9998280990741752, \"accuracy\": 0.9998280947439876, \"f1\": 0.4334429304693781, \"f2\": 0.3234956779805088, \"f0_5\": 0.6566047693174846, \"p4\": 0.6047421262129623, \"phi\": 0.5259181474530981}, {\"truth_threshold\": 17.23999961465597, \"match_probability\": 0.9999935398859523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84023.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219938.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2764269100312211, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7235730899687789, \"precision\": 0.9997620265816308, \"recall\": 0.2764269100312211, \"specificity\": 0.9999999843595769, \"npv\": 0.9998280334069842, \"accuracy\": 0.9998280290698219, \"f1\": 0.4331037824352326, \"f2\": 0.3231934775868979, \"f0_5\": 0.656293301548272, \"p4\": 0.6044119494025426, \"phi\": 0.525655377549364}, {\"truth_threshold\": 17.259999614208937, \"match_probability\": 0.9999936288236828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83939.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220022.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27615055878879197, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.723849441211208, \"precision\": 0.999761788492002, \"recall\": 0.27615055878879197, \"specificity\": 0.9999999843595769, \"npv\": 0.9998279677398018, \"accuracy\": 0.9998279633956563, \"f1\": 0.4327644875232007, \"f2\": 0.32289123813377874, \"f0_5\": 0.6559815066341356, \"p4\": 0.6040814731955536, \"phi\": 0.5253924762584237}, {\"truth_threshold\": 17.279999613761902, \"match_probability\": 0.9999937165369968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83841.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220120.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.275828149005958, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.724171850994042, \"precision\": 0.9997615101179332, \"recall\": 0.275828149005958, \"specificity\": 0.9999999843595769, \"npv\": 0.9998278911280998, \"accuracy\": 0.9998278867757963, \"f1\": 0.4323684576945093, \"f2\": 0.3225385760614909, \"f0_5\": 0.6556173317381002, \"p4\": 0.6036955386731145, \"phi\": 0.5250855917635391}, {\"truth_threshold\": 17.299999613314867, \"match_probability\": 0.9999938030427508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83782.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.275634045157109, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.724365954842891, \"precision\": 0.9997613422114031, \"recall\": 0.275634045157109, \"specificity\": 0.9999999843595769, \"npv\": 0.9998278450047339, \"accuracy\": 0.9998278406475133, \"f1\": 0.43212993503763897, \"f2\": 0.3223262334512629, \"f0_5\": 0.6553978681694512, \"p4\": 0.6034629932781801, \"phi\": 0.5249007482693208}, {\"truth_threshold\": 17.319999612867832, \"match_probability\": 0.9999938883575692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83718.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220243.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2754234918295439, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.724576508170456, \"precision\": 0.9997611598079725, \"recall\": 0.2754234918295439, \"specificity\": 0.9999999843595769, \"npv\": 0.9998277949726129, \"accuracy\": 0.9998277906100537, \"f1\": 0.4318711165104888, \"f2\": 0.3220958739040707, \"f0_5\": 0.6551596226716313, \"p4\": 0.6032105729783449, \"phi\": 0.5247001664626368}, {\"truth_threshold\": 17.339999612420797, \"match_probability\": 0.9999939724978475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83626.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220335.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27512082142116917, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7248791785788309, \"precision\": 0.9997608971140282, \"recall\": 0.27512082142116917, \"specificity\": 0.9999999843595769, \"npv\": 0.9998277230514478, \"accuracy\": 0.9998277186812056, \"f1\": 0.4314989151382715, \"f2\": 0.32176469230236476, \"f0_5\": 0.6548168100916928, \"p4\": 0.6028474127544959, \"phi\": 0.5244116957402742}, {\"truth_threshold\": 17.359999611973763, \"match_probability\": 0.9999940554797557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83550.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2748707893446857, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7251292106553143, \"precision\": 0.9997606796697379, \"recall\": 0.2748707893446857, \"specificity\": 0.9999999843595769, \"npv\": 0.9998276636383193, \"accuracy\": 0.9998276592617223, \"f1\": 0.43119131114672116, \"f2\": 0.3214910721294368, \"f0_5\": 0.6545333189187157, \"p4\": 0.6025471382232311, \"phi\": 0.5241732741287444}, {\"truth_threshold\": 17.379999611526728, \"match_probability\": 0.9999941373192409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83490.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2746733956000934, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7253266043999066, \"precision\": 0.9997605077236259, \"recall\": 0.2746733956000934, \"specificity\": 0.9999999843595769, \"npv\": 0.9998276167332227, \"accuracy\": 0.999827612351604, \"f1\": 0.4309483806530037, \"f2\": 0.32127503359361653, \"f0_5\": 0.6543093192643898, \"p4\": 0.6023099049451597, \"phi\": 0.5239849699295871}, {\"truth_threshold\": 17.399999611079693, \"match_probability\": 0.9999942180320309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83384.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 220577.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27432466665131383, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7256753333486862, \"precision\": 0.9997602033475612, \"recall\": 0.27432466665131383, \"specificity\": 0.9999999843595769, \"npv\": 0.9998275338675631, \"accuracy\": 0.9998275294770615, \"f1\": 0.43051901952938443, \"f2\": 0.3208933167493812, \"f0_5\": 0.6539131744087381, \"p4\": 0.6018904161752697, \"phi\": 0.5236521337360376}, {\"truth_threshold\": 17.419999610632658, \"match_probability\": 0.9999942976336369, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83287.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220674.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27400554676422306, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7259944532357769, \"precision\": 0.9997719251914629, \"recall\": 0.27400554676422306, \"specificity\": 0.9999999851415982, \"npv\": 0.9998274580378138, \"accuracy\": 0.9998274544208722, \"f1\": 0.4301270183103647, \"f2\": 0.32054420197821654, \"f0_5\": 0.6535543052645622, \"p4\": 0.6015072083921917, \"phi\": 0.5233505141819091}, {\"truth_threshold\": 17.439999610185623, \"match_probability\": 0.9999943761393564, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83219.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220742.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27378183385368515, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7262181661463148, \"precision\": 0.9997717388692664, \"recall\": 0.27378183385368515, \"specificity\": 0.9999999851415982, \"npv\": 0.9998274048787267, \"accuracy\": 0.9998274012560714, \"f1\": 0.42985131676476435, \"f2\": 0.32029925747566357, \"f0_5\": 0.6532995872277689, \"p4\": 0.6012375655427687, \"phi\": 0.5231367620818224}, {\"truth_threshold\": 17.45999960973859, \"match_probability\": 0.9999944535642766, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83130.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27348903313254, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.72651096686746, \"precision\": 0.9997714945459356, \"recall\": 0.27348903313254, \"specificity\": 0.9999999851415982, \"npv\": 0.9998273353028712, \"accuracy\": 0.9998273316727292, \"f1\": 0.42949032574720364, \"f2\": 0.31997862960000556, \"f0_5\": 0.6529658773684054, \"p4\": 0.6008843502628367, \"phi\": 0.5228568663059971}, {\"truth_threshold\": 17.479999609291553, \"match_probability\": 0.9999945299232769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83030.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220931.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27316004355821966, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7268399564417803, \"precision\": 0.9997712194005949, \"recall\": 0.27316004355821966, \"specificity\": 0.9999999851415982, \"npv\": 0.9998272571277641, \"accuracy\": 0.9998272534891987, \"f1\": 0.4290845197798506, \"f2\": 0.3196183211396166, \"f0_5\": 0.6525904768791352, \"p4\": 0.6004870723068251, \"phi\": 0.5225421978527482}, {\"truth_threshold\": 17.49999960884452, \"match_probability\": 0.9999946052310316, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82925.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221036.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27281460450518324, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7271853954948168, \"precision\": 0.9997709297839507, \"recall\": 0.27281460450518324, \"specificity\": 0.9999999851415982, \"npv\": 0.9998271750439149, \"accuracy\": 0.9998271713964916, \"f1\": 0.4286581977488014, \"f2\": 0.3192399375417697, \"f0_5\": 0.6521957979478935, \"p4\": 0.6000694663510099, \"phi\": 0.5222115919627929}, {\"truth_threshold\": 17.519999608397484, \"match_probability\": 0.9999946795020134, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82884.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221077.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27267971877971187, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7273202812202881, \"precision\": 0.9997708164963873, \"recall\": 0.27267971877971187, \"specificity\": 0.9999999851415982, \"npv\": 0.9998271429921299, \"accuracy\": 0.999827139341244, \"f1\": 0.42849166632201496, \"f2\": 0.31909217114649735, \"f0_5\": 0.6520415436149742, \"p4\": 0.5999062719313396, \"phi\": 0.5220824414148348}, {\"truth_threshold\": 17.53999960795045, \"match_probability\": 0.9999947527504954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82785.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221176.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27235401910113466, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7276459808988653, \"precision\": 0.9997705424858703, \"recall\": 0.27235401910113466, \"specificity\": 0.9999999851415982, \"npv\": 0.9998270655988036, \"accuracy\": 0.9998270619395487, \"f1\": 0.4280894082970279, \"f2\": 0.31873533089798006, \"f0_5\": 0.6516687474514977, \"p4\": 0.5995119174793819, \"phi\": 0.5217704583371109}, {\"truth_threshold\": 17.559999607503414, \"match_probability\": 0.9999948249905545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82673.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221288.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2719855507778958, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7280144492221041, \"precision\": 0.9997702317031877, \"recall\": 0.2719855507778958, \"specificity\": 0.9999999851415982, \"npv\": 0.9998269780427319, \"accuracy\": 0.9998269743739945, \"f1\": 0.427634080170075, \"f2\": 0.31833156724187855, \"f0_5\": 0.6512464374559852, \"p4\": 0.599065267519109, \"phi\": 0.5214172827940926}, {\"truth_threshold\": 17.57999960705638, \"match_probability\": 0.9999948962360736, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82573.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221388.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27165656120357545, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7283434387964245, \"precision\": 0.9997699535063929, \"recall\": 0.27165656120357545, \"specificity\": 0.9999999851415982, \"npv\": 0.9998268998676808, \"accuracy\": 0.9998268961904639, \"f1\": 0.42722731423634014, \"f2\": 0.3179710051169253, \"f0_5\": 0.650868870885613, \"p4\": 0.5986660131935955, \"phi\": 0.5211017452715964}, {\"truth_threshold\": 17.599999606609344, \"match_probability\": 0.9999949665007445, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82500.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27141639881432156, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7285836011856784, \"precision\": 0.9997697499969704, \"recall\": 0.27141639881432156, \"specificity\": 0.9999999851415982, \"npv\": 0.9998268427999012, \"accuracy\": 0.9998268391164866, \"f1\": 0.4269302421858828, \"f2\": 0.3177077596943228, \"f0_5\": 0.6505929464684238, \"p4\": 0.5983742832538065, \"phi\": 0.5208712822104755}, {\"truth_threshold\": 17.61999960616231, \"match_probability\": 0.9999950357980707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82416.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221545.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2711400475718925, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7288599524281075, \"precision\": 0.9997695153757505, \"recall\": 0.2711400475718925, \"specificity\": 0.9999999851415982, \"npv\": 0.9998267771328752, \"accuracy\": 0.999826773442321, \"f1\": 0.4265882669592853, \"f2\": 0.3174048105222375, \"f0_5\": 0.650275129753622, \"p4\": 0.5980383071846092, \"phi\": 0.5206059656314674}, {\"truth_threshold\": 17.639999605715275, \"match_probability\": 0.9999951041413695, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82358.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221603.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27094923361878664, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7290507663812134, \"precision\": 0.9997693530961312, \"recall\": 0.27094923361878664, \"specificity\": 0.9999999851415982, \"npv\": 0.9998267317913623, \"accuracy\": 0.9998267280958731, \"f1\": 0.42635205441866963, \"f2\": 0.3171956084518738, \"f0_5\": 0.6500554881138619, \"p4\": 0.5978061443753196, \"phi\": 0.5204226919305168}, {\"truth_threshold\": 17.65999960526824, \"match_probability\": 0.999995171543775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82269.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221692.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27065643289764146, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7293435671023585, \"precision\": 0.9997691036360101, \"recall\": 0.27065643289764146, \"specificity\": 0.9999999851415982, \"npv\": 0.9998266622156003, \"accuracy\": 0.9998266585125309, \"f1\": 0.4259894523998768, \"f2\": 0.3168745551299868, \"f0_5\": 0.6497181387840717, \"p4\": 0.5974496093159686, \"phi\": 0.5201413360545261}, {\"truth_threshold\": 17.679999604821205, \"match_probability\": 0.9999952380182406, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82212.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221749.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27046890884027885, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7295310911597211, \"precision\": 0.9997689435857523, \"recall\": 0.27046890884027885, \"specificity\": 0.9999999851415982, \"npv\": 0.9998266176558479, \"accuracy\": 0.9998266139479186, \"f1\": 0.42575713634668766, \"f2\": 0.3166689135835757, \"f0_5\": 0.6495018842285724, \"p4\": 0.5972210850023031, \"phi\": 0.5199610618865698}, {\"truth_threshold\": 17.69999960437417, \"match_probability\": 0.9999953035775414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82130.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27019913738933615, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7298008626106639, \"precision\": 0.999768712948423, \"recall\": 0.27019913738933615, \"specificity\": 0.9999999851415982, \"npv\": 0.9998265535523513, \"accuracy\": 0.9998265498374235, \"f1\": 0.4254228069721064, \"f2\": 0.3163730466959375, \"f0_5\": 0.6491905077329, \"p4\": 0.5968920816456151, \"phi\": 0.5197016104406302}, {\"truth_threshold\": 17.719999603927135, \"match_probability\": 0.9999953682342764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82058.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221903.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2699622648958255, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7300377351041746, \"precision\": 0.9997685100576288, \"recall\": 0.2699622648958255, \"specificity\": 0.9999999851415982, \"npv\": 0.9998264972663611, \"accuracy\": 0.9998264935452815, \"f1\": 0.42512913236520755, \"f2\": 0.3161132303121685, \"f0_5\": 0.6489168376118393, \"p4\": 0.5966029580642401, \"phi\": 0.5194736925998844}, {\"truth_threshold\": 17.7399996034801, \"match_probability\": 0.999995432000871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81951.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222010.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2696102460513026, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7303897539486973, \"precision\": 0.999768207880932, \"recall\": 0.2696102460513026, \"specificity\": 0.9999999851415982, \"npv\": 0.9998264136191373, \"accuracy\": 0.9998264098889038, \"f1\": 0.424692496845291, \"f2\": 0.31572706104264553, \"f0_5\": 0.6485096725283734, \"p4\": 0.5961728686679286, \"phi\": 0.519134796562332}, {\"truth_threshold\": 17.759999603033066, \"match_probability\": 0.9999954948895802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81853.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222108.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26928783626846864, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7307121637315314, \"precision\": 0.9997679304279852, \"recall\": 0.26928783626846864, \"specificity\": 0.9999999851415982, \"npv\": 0.9998263370076735, \"accuracy\": 0.9998263332690438, \"f1\": 0.4242923751985963, \"f2\": 0.31537331742846664, \"f0_5\": 0.6481362707043641, \"p4\": 0.5957785141910003, \"phi\": 0.5188242116283127}, {\"truth_threshold\": 17.77999960258603, \"match_probability\": 0.9999955569124898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81779.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2690443839834716, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7309556160165285, \"precision\": 0.9997677204821633, \"recall\": 0.2690443839834716, \"specificity\": 0.9999999851415982, \"npv\": 0.9998262791582087, \"accuracy\": 0.9998262754132312, \"f1\": 0.42399010781342755, \"f2\": 0.3151061694982129, \"f0_5\": 0.6478540068731353, \"p4\": 0.5954804566113299, \"phi\": 0.5185895650844211}, {\"truth_threshold\": 17.799999602138996, \"match_probability\": 0.999995618081519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81658.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222303.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2686463065985439, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7313536934014561, \"precision\": 0.9997673763727855, \"recall\": 0.2686463065985439, \"specificity\": 0.9999999851415982, \"npv\": 0.9998261845665306, \"accuracy\": 0.9998261808111591, \"f1\": 0.4234956098724711, \"f2\": 0.3146692808825445, \"f0_5\": 0.647391896541609, \"p4\": 0.5949925728386869, \"phi\": 0.5182056574311699}, {\"truth_threshold\": 17.81999960169196, \"match_probability\": 0.9999956784084236, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81557.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222404.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2683140271284803, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7316859728715197, \"precision\": 0.9997670883593214, \"recall\": 0.2683140271284803, \"specificity\": 0.9999999851415982, \"npv\": 0.9998261056098543, \"accuracy\": 0.9998261018457933, \"f1\": 0.42308260945123294, \"f2\": 0.3143045428619876, \"f0_5\": 0.6470056246182162, \"p4\": 0.594584836680284, \"phi\": 0.517884987725781}, {\"truth_threshold\": 17.839999601244926, \"match_probability\": 0.999995737904797, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81464.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222497.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26800806682436235, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7319919331756377, \"precision\": 0.9997668225273983, \"recall\": 0.26800806682436235, \"specificity\": 0.9999999851415982, \"npv\": 0.9998260329071833, \"accuracy\": 0.9998260291351099, \"f1\": 0.4227021305299862, \"f2\": 0.31396864475957104, \"f0_5\": 0.6466495103136565, \"p4\": 0.5942089980027158, \"phi\": 0.5175895419578279}, {\"truth_threshold\": 17.85999960079789, \"match_probability\": 0.9999957965820732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81372.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26770539641598756, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7322946035840124, \"precision\": 0.99976655895615, \"recall\": 0.26770539641598756, \"specificity\": 0.9999999851415982, \"npv\": 0.9998259609862717, \"accuracy\": 0.9998259572062618, \"f1\": 0.4223255620834977, \"f2\": 0.3136363110770215, \"f0_5\": 0.6462968110877249, \"p4\": 0.5938368241308821, \"phi\": 0.5172971070412965}, {\"truth_threshold\": 17.879999600350857, \"match_probability\": 0.9999958544515287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81303.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2674783936097065, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7325216063902935, \"precision\": 0.9997663608863531, \"recall\": 0.2674783936097065, \"specificity\": 0.9999999851415982, \"npv\": 0.9998259070455949, \"accuracy\": 0.9998259032596256, \"f1\": 0.42204301772982455, \"f2\": 0.3133870298789823, \"f0_5\": 0.6460320159428143, \"p4\": 0.5935574476620099, \"phi\": 0.5170776723460192}, {\"truth_threshold\": 17.899999599903822, \"match_probability\": 0.9999959115242849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81211.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222750.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26717572320133176, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7328242767986682, \"precision\": 0.999766096269851, \"recall\": 0.26717572320133176, \"specificity\": 0.9999999851415982, \"npv\": 0.9998258351247015, \"accuracy\": 0.9998258313307775, \"f1\": 0.4216661344631624, \"f2\": 0.3130546136920484, \"f0_5\": 0.6456785942014467, \"p4\": 0.593184617162091, \"phi\": 0.5167849478498933}, {\"truth_threshold\": 17.919999599456787, \"match_probability\": 0.9999959678113101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81135.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26692569112484826, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7330743088751518, \"precision\": 0.9997658772210858, \"recall\": 0.26692569112484826, \"specificity\": 0.9999999851415982, \"npv\": 0.9998257757117973, \"accuracy\": 0.9998257719112943, \"f1\": 0.42135466029627516, \"f2\": 0.31277997344637387, \"f0_5\": 0.6453863249848467, \"p4\": 0.5928763431772903, \"phi\": 0.5165430068730046}, {\"truth_threshold\": 17.939999599009752, \"match_probability\": 0.9999960233234213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81025.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222936.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2665638025930958, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7334361974069041, \"precision\": 0.9997655594491881, \"recall\": 0.2665638025930958, \"specificity\": 0.9999999851415982, \"npv\": 0.9998256897194486, \"accuracy\": 0.9998256859094107, \"f1\": 0.4209036246282516, \"f2\": 0.3123824108172795, \"f0_5\": 0.6449628027006847, \"p4\": 0.5924297020460024, \"phi\": 0.5161926283519032}, {\"truth_threshold\": 17.959999598562717, \"match_probability\": 0.999996078071287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80959.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223002.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2663466694740444, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7336533305259556, \"precision\": 0.9997653683716565, \"recall\": 0.2663466694740444, \"specificity\": 0.9999999851415982, \"npv\": 0.9998256381240465, \"accuracy\": 0.9998256343082804, \"f1\": 0.42063287949519274, \"f2\": 0.3121438408663641, \"f0_5\": 0.6447084044066236, \"p4\": 0.5921614586302859, \"phi\": 0.5159822870642106}, {\"truth_threshold\": 17.979999598115683, \"match_probability\": 0.9999961320654285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80841.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223120.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2659584617763463, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7340415382236537, \"precision\": 0.9997650259708137, \"recall\": 0.2659584617763463, \"specificity\": 0.9999999851415982, \"npv\": 0.9998255458777346, \"accuracy\": 0.9998255420517144, \"f1\": 0.4201485885645534, \"f2\": 0.3117172461872563, \"f0_5\": 0.6442530375310208, \"p4\": 0.591681387519659, \"phi\": 0.5156060085401061}, {\"truth_threshold\": 17.999999597668648, \"match_probability\": 0.9999961853162226, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80696.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26548142689358173, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7345185731064182, \"precision\": 0.9997646038530632, \"recall\": 0.26548142689358173, \"specificity\": 0.9999999851415982, \"npv\": 0.9998254325242393, \"accuracy\": 0.9998254286855951, \"f1\": 0.4195530784348387, \"f2\": 0.31119293452901103, \"f0_5\": 0.6436925374229645, \"p4\": 0.591090617294556, \"phi\": 0.515143256108185}, {\"truth_threshold\": 18.019999597221613, \"match_probability\": 0.9999962378339025, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80636.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223325.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2652840331489895, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7347159668510105, \"precision\": 0.9997644287396937, \"recall\": 0.2652840331489895, \"specificity\": 0.9999999851415982, \"npv\": 0.9998253856193521, \"accuracy\": 0.9998253817754768, \"f1\": 0.4193065291095534, \"f2\": 0.31097594367600745, \"f0_5\": 0.6434603028179916, \"p4\": 0.5908458852509648, \"phi\": 0.5149516507357853}, {\"truth_threshold\": 18.039999596774578, \"match_probability\": 0.9999962896285616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80580.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223381.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26509979898737007, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7349002010126299, \"precision\": 0.9997642650653233, \"recall\": 0.26509979898737007, \"specificity\": 0.9999999851415982, \"npv\": 0.9998253418414614, \"accuracy\": 0.9998253379926996, \"f1\": 0.4190763469939671, \"f2\": 0.3107734007588456, \"f0_5\": 0.6432433899517368, \"p4\": 0.5906173230218985, \"phi\": 0.5147727547263441}, {\"truth_threshold\": 18.059999596327543, \"match_probability\": 0.9999963407101535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80509.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223452.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2648662163896026, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7351337836103974, \"precision\": 0.9997640572223326, \"recall\": 0.2648662163896026, \"specificity\": 0.9999999851415982, \"npv\": 0.9998252863373556, \"accuracy\": 0.9998252824823929, \"f1\": 0.41878441255796656, \"f2\": 0.31051658011743544, \"f0_5\": 0.6429681522761723, \"p4\": 0.5903273363776701, \"phi\": 0.5145458507458018}, {\"truth_threshold\": 18.07999959588051, \"match_probability\": 0.9999963910884953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80431.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223530.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26460960452163274, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7353903954783673, \"precision\": 0.999763828464885, \"recall\": 0.26460960452163274, \"specificity\": 0.9999999851415982, \"npv\": 0.9998252253610209, \"accuracy\": 0.999825221499239, \"f1\": 0.4184635715419174, \"f2\": 0.31023440670094904, \"f0_5\": 0.6426654904987688, \"p4\": 0.5900084983470795, \"phi\": 0.5142964605796254}, {\"truth_threshold\": 18.099999595433474, \"match_probability\": 0.9999964407732684, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80365.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223596.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26439247140258126, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7356075285974187, \"precision\": 0.9997636345541401, \"recall\": 0.26439247140258126, \"specificity\": 0.9999999851415982, \"npv\": 0.9998251737656667, \"accuracy\": 0.9998251698981089, \"f1\": 0.41819198896824467, \"f2\": 0.3099956180548484, \"f0_5\": 0.6424091562389588, \"p4\": 0.5897384985074615, \"phi\": 0.5140853436597299}, {\"truth_threshold\": 18.11999959498644, \"match_probability\": 0.9999964897740216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80300.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 223661.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.264178628179273, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.735821371820727, \"precision\": 0.9997883387078701, \"recall\": 0.264178628179273, \"specificity\": 0.9999999867056404, \"npv\": 0.9998251229523389, \"accuracy\": 0.9998251206424846, \"f1\": 0.4179266052180973, \"f2\": 0.3097609016163887, \"f0_5\": 0.6421647108499445, \"p4\": 0.5894745615560137, \"phi\": 0.5138837414451907}, {\"truth_threshold\": 18.139999594539404, \"match_probability\": 0.9999965381001715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80219.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 223742.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2639121466240735, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7360878533759265, \"precision\": 0.9997881250311581, \"recall\": 0.2639121466240735, \"specificity\": 0.9999999867056404, \"npv\": 0.9998250596307817, \"accuracy\": 0.9998250573138249, \"f1\": 0.4175930577281967, \"f2\": 0.30946777976668105, \"f0_5\": 0.6418495611332923, \"p4\": 0.5891426922006064, \"phi\": 0.5136244231621407}, {\"truth_threshold\": 18.15999959409237, \"match_probability\": 0.9999965857610057, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80128.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 223833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2636127661114419, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7363872338885581, \"precision\": 0.9997878844594174, \"recall\": 0.2636127661114419, \"specificity\": 0.9999999867056404, \"npv\": 0.9998249884917577, \"accuracy\": 0.999824986166812, \"f1\": 0.41721816373605203, \"f2\": 0.3091384263292358, \"f0_5\": 0.6414951140117302, \"p4\": 0.588769497913605, \"phi\": 0.5133329340594188}, {\"truth_threshold\": 18.179999593645334, \"match_probability\": 0.9999966327656835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80036.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 223925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2633100957030672, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7366899042969328, \"precision\": 0.9997876406880442, \"recall\": 0.2633100957030672, \"specificity\": 0.9999999867056404, \"npv\": 0.9998249165709966, \"accuracy\": 0.9998249142379639, \"f1\": 0.4168389694125735, \"f2\": 0.3088054066025309, \"f0_5\": 0.6411363516204642, \"p4\": 0.5883918218973478, \"phi\": 0.5130380734688772}, {\"truth_threshold\": 18.1999995931983, \"match_probability\": 0.9999966791232384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79927.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224034.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26295149706705795, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7370485029329421, \"precision\": 0.9997873511458021, \"recall\": 0.26295149706705795, \"specificity\": 0.9999999867056404, \"npv\": 0.999824831360543, \"accuracy\": 0.9998248290179156, \"f1\": 0.41638947135359006, \"f2\": 0.30841078941925687, \"f0_5\": 0.6407107482801244, \"p4\": 0.5879438617203614, \"phi\": 0.51268850834333}, {\"truth_threshold\": 18.219999592751265, \"match_probability\": 0.9999967248425794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79879.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26279358207138415, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7372064179286159, \"precision\": 0.9997872233904075, \"recall\": 0.26279358207138415, \"specificity\": 0.9999999867056404, \"npv\": 0.9998247938366781, \"accuracy\": 0.9998247914898208, \"f1\": 0.4161914462938021, \"f2\": 0.3082369919891336, \"f0_5\": 0.6405231378649496, \"p4\": 0.5877464239414332, \"phi\": 0.5125344958141904}, {\"truth_threshold\": 18.23999959230423, \"match_probability\": 0.9999967699324929, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79800.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26253368030767105, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7374663196923289, \"precision\": 0.9997870127917612, \"recall\": 0.26253368030767105, \"specificity\": 0.9999999867056404, \"npv\": 0.9998247320786566, \"accuracy\": 0.9998247297248317, \"f1\": 0.41586542219720773, \"f2\": 0.30795092234774374, \"f0_5\": 0.6402141107040911, \"p4\": 0.587421246424644, \"phi\": 0.5122809160708659}, {\"truth_threshold\": 18.259999591857195, \"match_probability\": 0.999996814401644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79683.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224278.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26214876250571617, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7378512374942838, \"precision\": 0.9997867001254706, \"recall\": 0.26214876250571617, \"specificity\": 0.9999999867056404, \"npv\": 0.9998246406142591, \"accuracy\": 0.9998246382501009, \"f1\": 0.4153823297129497, \"f2\": 0.30752718549119135, \"f0_5\": 0.6397558613978718, \"p4\": 0.5869391329422685, \"phi\": 0.5119051305392507}, {\"truth_threshold\": 18.27999959141016, \"match_probability\": 0.9999968582585792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79611.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2619118900122055, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7380881099877945, \"precision\": 0.9997865072587532, \"recall\": 0.2619118900122055, \"specificity\": 0.9999999867056404, \"npv\": 0.9998245843284843, \"accuracy\": 0.999824581957959, \"f1\": 0.4150848955522708, \"f2\": 0.3072663863055319, \"f0_5\": 0.6394735193333687, \"p4\": 0.5866421378239013, \"phi\": 0.5116737407622047}, {\"truth_threshold\": 18.299999590963125, \"match_probability\": 0.9999969015117268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79550.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26171120637187006, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7382887936281299, \"precision\": 0.9997863435846519, \"recall\": 0.26171120637187006, \"specificity\": 0.9999999867056404, \"npv\": 0.99982453664193, \"accuracy\": 0.9998245342660053, \"f1\": 0.4148328153355166, \"f2\": 0.30704540875444164, \"f0_5\": 0.6392341083427484, \"p4\": 0.5863903319449347, \"phi\": 0.5114776203093926}, {\"truth_threshold\": 18.31999959051609, \"match_probability\": 0.9999969441693992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79504.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224457.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2615598711676827, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7384401288323174, \"precision\": 0.9997862199922033, \"recall\": 0.2615598711676827, \"specificity\": 0.9999999867056404, \"npv\": 0.9998245006815807, \"accuracy\": 0.9998244983015813, \"f1\": 0.4146426690170595, \"f2\": 0.3068787561806904, \"f0_5\": 0.6390534446864776, \"p4\": 0.5862003331883939, \"phi\": 0.5113296764594102}, {\"truth_threshold\": 18.339999590069056, \"match_probability\": 0.9999969862397944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79424.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224537.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2612966795082264, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7387033204917736, \"precision\": 0.9997860047078965, \"recall\": 0.2612966795082264, \"specificity\": 0.9999999867056404, \"npv\": 0.9998244381418488, \"accuracy\": 0.9998244357547568, \"f1\": 0.4143118710909176, \"f2\": 0.306588897424119, \"f0_5\": 0.6387389923197555, \"p4\": 0.5858696702309913, \"phi\": 0.5110722808265045}, {\"truth_threshold\": 18.35999958962202, \"match_probability\": 0.9999970277309974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79355.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224606.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2610696767019453, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7389303232980546, \"precision\": 0.9997858186766114, \"recall\": 0.2610696767019453, \"specificity\": 0.9999999867056404, \"npv\": 0.9998243842013365, \"accuracy\": 0.9998243818081207, \"f1\": 0.4140264469795191, \"f2\": 0.3063388654865289, \"f0_5\": 0.638467517044842, \"p4\": 0.5855842382463001, \"phi\": 0.5108501729510663}, {\"truth_threshold\": 18.379999589174986, \"match_probability\": 0.9999970686509823, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79298.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224663.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2608821526445827, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7391178473554173, \"precision\": 0.9997856647544601, \"recall\": 0.2608821526445827, \"specificity\": 0.9999999867056404, \"npv\": 0.9998243396417871, \"accuracy\": 0.9998243372435083, \"f1\": 0.41379058433087385, \"f2\": 0.3061322972700649, \"f0_5\": 0.6382430729160797, \"p4\": 0.5853482821269066, \"phi\": 0.5106666196872269}, {\"truth_threshold\": 18.39999958872795, \"match_probability\": 0.9999971090076128, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79232.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224729.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2606650195255312, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7393349804744688, \"precision\": 0.9997854862521924, \"recall\": 0.2606650195255312, \"specificity\": 0.9999999867056404, \"npv\": 0.9998242880465243, \"accuracy\": 0.9998242856423781, \"f1\": 0.4135173925523864, \"f2\": 0.3058930903031674, \"f0_5\": 0.6379829843290277, \"p4\": 0.5850748836645876, \"phi\": 0.5104540018907826}, {\"truth_threshold\": 18.419999588280916, \"match_probability\": 0.999997148808645, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79128.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26032287036823804, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.739677129631762, \"precision\": 0.9997852043717228, \"recall\": 0.26032287036823804, \"specificity\": 0.9999999867056404, \"npv\": 0.999824206744909, \"accuracy\": 0.9998242043315063, \"f1\": 0.4130867175142128, \"f2\": 0.30551610863103856, \"f0_5\": 0.6375726986613294, \"p4\": 0.5846436681241858, \"phi\": 0.5101187879894434}, {\"truth_threshold\": 18.43999958783388, \"match_probability\": 0.9999971880617277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79044.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2600465191258089, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7399534808741911, \"precision\": 0.9997849761576504, \"recall\": 0.2600465191258089, \"specificity\": 0.9999999867056404, \"npv\": 0.9998241410782294, \"accuracy\": 0.9998241386573407, \"f1\": 0.41273869386092704, \"f2\": 0.30521157922781983, \"f0_5\": 0.6372409122790045, \"p4\": 0.5842950156353354, \"phi\": 0.5098478774442924}, {\"truth_threshold\": 18.459999587386847, \"match_probability\": 0.9999972267744046, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78989.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224972.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25986557485993267, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7401344251400673, \"precision\": 0.9997848264688758, \"recall\": 0.25986557485993267, \"specificity\": 0.9999999867056404, \"npv\": 0.9998240980821937, \"accuracy\": 0.9998240956563988, \"f1\": 0.41251073852316256, \"f2\": 0.30501216357107, \"f0_5\": 0.6370234763744285, \"p4\": 0.5840665552936236, \"phi\": 0.5096704175488531}, {\"truth_threshold\": 18.47999958693981, \"match_probability\": 0.9999972649541156, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78868.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225093.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.259467497475005, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.740532502524995, \"precision\": 0.9997844964188376, \"recall\": 0.259467497475005, \"specificity\": 0.9999999867056404, \"npv\": 0.9998240034909286, \"accuracy\": 0.9998240010543268, \"f1\": 0.41200900623227094, \"f2\": 0.304573389489229, \"f0_5\": 0.6365445737779277, \"p4\": 0.5835634516392849, \"phi\": 0.5092797881687197}, {\"truth_threshold\": 18.499999586492777, \"match_probability\": 0.9999973026081981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78787.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225174.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2592010159198055, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7407989840801945, \"precision\": 0.9997842749099031, \"recall\": 0.2592010159198055, \"specificity\": 0.9999999867056404, \"npv\": 0.999823940169513, \"accuracy\": 0.999823937725667, \"f1\": 0.41167295860384306, \"f2\": 0.30427961886165195, \"f0_5\": 0.6362235677358816, \"p4\": 0.5832262855373991, \"phi\": 0.5090181250026536}, {\"truth_threshold\": 18.519999586045742, \"match_probability\": 0.9999973397438885, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78728.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225233.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2590069120709565, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7409930879290435, \"precision\": 0.9997841132770334, \"recall\": 0.2590069120709565, \"specificity\": 0.9999999867056404, \"npv\": 0.9998238940465117, \"accuracy\": 0.999823891597384, \"f1\": 0.41142809362800686, \"f2\": 0.3040656146468107, \"f0_5\": 0.6359895369671745, \"p4\": 0.5829805044611401, \"phi\": 0.5088274461633582}, {\"truth_threshold\": 18.539999585598707, \"match_probability\": 0.9999973763683236, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78639.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225322.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2587141113498113, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7412858886501886, \"precision\": 0.9997838689991864, \"recall\": 0.2587141113498113, \"specificity\": 0.9999999867056404, \"npv\": 0.999823824471145, \"accuracy\": 0.9998238220140417, \"f1\": 0.41105857816040586, \"f2\": 0.30374275782155274, \"f0_5\": 0.6356361696452387, \"p4\": 0.5826094450616965, \"phi\": 0.508539676746532}, {\"truth_threshold\": 18.559999585151672, \"match_probability\": 0.999997412488542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78552.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2584278904201526, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7415721095798474, \"precision\": 0.9997836296758263, \"recall\": 0.2584278904201526, \"specificity\": 0.9999999867056404, \"npv\": 0.999823756459279, \"accuracy\": 0.9998237539943702, \"f1\": 0.4106972002195906, \"f2\": 0.3034271132938251, \"f0_5\": 0.635290349817303, \"p4\": 0.5822463691831232, \"phi\": 0.5082582166164735}, {\"truth_threshold\": 18.579999584704638, \"match_probability\": 0.9999974481114852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78453.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225508.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2581021907415754, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7418978092584246, \"precision\": 0.9997833566968268, \"recall\": 0.2581021907415754, \"specificity\": 0.9999999867056404, \"npv\": 0.9998236790664772, \"accuracy\": 0.9998236765926749, \"f1\": 0.4102857770421331, \"f2\": 0.303067879973484, \"f0_5\": 0.6348963568296697, \"p4\": 0.5818327864311975, \"phi\": 0.5079377447306566}, {\"truth_threshold\": 18.599999584257603, \"match_probability\": 0.9999974832439992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78380.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225581.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2578620283523215, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7421379716476785, \"precision\": 0.9997831549676646, \"recall\": 0.2578620283523215, \"specificity\": 0.9999999867056404, \"npv\": 0.9998236219990653, \"accuracy\": 0.9998236195186976, \"f1\": 0.40998226792691667, \"f2\": 0.30280295555464554, \"f0_5\": 0.6346055130847916, \"p4\": 0.581527529490785, \"phi\": 0.5077013076349476}, {\"truth_threshold\": 18.619999583810568, \"match_probability\": 0.9999975178928361, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78272.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2575067196120555, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7424932803879445, \"precision\": 0.9997828558290437, \"recall\": 0.2575067196120555, \"specificity\": 0.9999999867056404, \"npv\": 0.9998235375705775, \"accuracy\": 0.9998235350804846, \"f1\": 0.40953302812295617, \"f2\": 0.3024109577609102, \"f0_5\": 0.6341747188944722, \"p4\": 0.5810754613553059, \"phi\": 0.5073513082455268}, {\"truth_threshold\": 18.639999583363533, \"match_probability\": 0.9999975520646545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78128.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2570329746250341, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7429670253749658, \"precision\": 0.999782455691343, \"recall\": 0.2570329746250341, \"specificity\": 0.9999999867056404, \"npv\": 0.9998234249992827, \"accuracy\": 0.9998234224962006, \"f1\": 0.4089336466844279, \"f2\": 0.3018881922489295, \"f0_5\": 0.6335993875508684, \"p4\": 0.5804718574331018, \"phi\": 0.5068842665515161}, {\"truth_threshold\": 18.659999582916498, \"match_probability\": 0.9999975857660216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78044.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.256756623382605, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.743243376617395, \"precision\": 0.9997822215959314, \"recall\": 0.256756623382605, \"specificity\": 0.9999999867056404, \"npv\": 0.9998233593327057, \"accuracy\": 0.9998233568220348, \"f1\": 0.40858379883881035, \"f2\": 0.30158319196540706, \"f0_5\": 0.6332632808886653, \"p4\": 0.5801193075928461, \"phi\": 0.5066116267759043}, {\"truth_threshold\": 18.679999582469463, \"match_probability\": 0.9999976190034143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77955.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226006.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25646382266145984, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7435361773385402, \"precision\": 0.9997819730159544, \"recall\": 0.25646382266145984, \"specificity\": 0.9999999867056404, \"npv\": 0.9998232897574134, \"accuracy\": 0.9998232872386926, \"f1\": 0.4082129588173842, \"f2\": 0.3012599936930754, \"f0_5\": 0.6329067677304014, \"p4\": 0.5797454122029949, \"phi\": 0.5063225983049336}, {\"truth_threshold\": 18.69999958202243, \"match_probability\": 0.9999976517832202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77883.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25622695016794916, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7437730498320508, \"precision\": 0.9997817715019256, \"recall\": 0.25622695016794916, \"specificity\": 0.9999999867056404, \"npv\": 0.9998232334717907, \"accuracy\": 0.9998232309465507, \"f1\": 0.40791282691869557, \"f2\": 0.3009984973843357, \"f0_5\": 0.6326180508511747, \"p4\": 0.5794426632967413, \"phi\": 0.5060886567667019}, {\"truth_threshold\": 18.719999581575394, \"match_probability\": 0.999997684111739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77801.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25595717871700646, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7440428212829936, \"precision\": 0.9997815415456578, \"recall\": 0.25595717871700646, \"specificity\": 0.9999999867056404, \"npv\": 0.9998231693687282, \"accuracy\": 0.9998231668360555, \"f1\": 0.4075708721537853, \"f2\": 0.3007006466913305, \"f0_5\": 0.6322889051790135, \"p4\": 0.5790975695070796, \"phi\": 0.5058220915981929}, {\"truth_threshold\": 18.73999958112836, \"match_probability\": 0.9999977159951835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77737.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226224.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25574662538944143, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7442533746105586, \"precision\": 0.9997813617305862, \"recall\": 0.25574662538944143, \"specificity\": 0.9999999867056404, \"npv\": 0.9998231193370752, \"accuracy\": 0.999823116798596, \"f1\": 0.40730387854813144, \"f2\": 0.3004681516205189, \"f0_5\": 0.6320317670416943, \"p4\": 0.5788280084086502, \"phi\": 0.5056139431108648}, {\"truth_threshold\": 18.759999580681324, \"match_probability\": 0.9999977474396812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77661.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226300.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25549659331295793, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7445034066870421, \"precision\": 0.9997811478153402, \"recall\": 0.25549659331295793, \"specificity\": 0.9999999867056404, \"npv\": 0.9998230599244939, \"accuracy\": 0.9998230573791128, \"f1\": 0.40698670733337, \"f2\": 0.3001920338424859, \"f0_5\": 0.6317261373120342, \"p4\": 0.5785076542312494, \"phi\": 0.5053666554589135}, {\"truth_threshold\": 18.77999958023429, \"match_probability\": 0.9999977784512751, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77577.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2552202420705288, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7447797579294713, \"precision\": 0.9997809108951723, \"recall\": 0.2552202420705288, \"specificity\": 0.9999999867056404, \"npv\": 0.999822994257965, \"accuracy\": 0.9998229917049472, \"f1\": 0.4066360026732712, \"f2\": 0.29988681328366723, \"f0_5\": 0.6313879841194654, \"p4\": 0.5781532619048326, \"phi\": 0.5050931967060494}, {\"truth_threshold\": 18.799999579787254, \"match_probability\": 0.9999978090359253, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77511.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226450.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2550031089514773, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7449968910485226, \"precision\": 0.9997807243834486, \"recall\": 0.2550031089514773, \"specificity\": 0.9999999867056404, \"npv\": 0.9998229426628411, \"accuracy\": 0.9998229401038169, \"f1\": 0.4063603406651306, \"f2\": 0.29964696931741214, \"f0_5\": 0.6311220327224939, \"p4\": 0.5778745772448811, \"phi\": 0.5048782323758975}, {\"truth_threshold\": 18.81999957934022, \"match_probability\": 0.9999978391995092, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77450.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226511.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2548024253111419, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.745197574688858, \"precision\": 0.9997805517187964, \"recall\": 0.2548024253111419, \"specificity\": 0.9999999867056404, \"npv\": 0.9998228949764435, \"accuracy\": 0.9998228924118633, \"f1\": 0.4061054773115765, \"f2\": 0.29942527358075516, \"f0_5\": 0.6308760257335512, \"p4\": 0.5776168220875507, \"phi\": 0.5046794718217061}, {\"truth_threshold\": 18.839999578893185, \"match_probability\": 0.999997868947824, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77369.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226592.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25453594375594235, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7454640562440576, \"precision\": 0.9997803220220711, \"recall\": 0.25453594375594235, \"specificity\": 0.9999999867056404, \"npv\": 0.9998228316551684, \"accuracy\": 0.9998228290832035, \"f1\": 0.4057669261853378, \"f2\": 0.29913085839332526, \"f0_5\": 0.6305490582798836, \"p4\": 0.5772742850676948, \"phi\": 0.504415422854584}, {\"truth_threshold\": 18.85999957844615, \"match_probability\": 0.9999978982865868, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77250.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2541444461625011, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7458555538374989, \"precision\": 0.999779983692909, \"recall\": 0.2541444461625011, \"specificity\": 0.9999999867056404, \"npv\": 0.9998227386276307, \"accuracy\": 0.9998227360448021, \"f1\": 0.40526928767037046, \"f2\": 0.29869825560218727, \"f0_5\": 0.6300680718204196, \"p4\": 0.5767704880737077, \"phi\": 0.5040272482293034}, {\"truth_threshold\": 18.879999577999115, \"match_probability\": 0.9999979272214359, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77192.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226769.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25395363220939526, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7460463677906047, \"precision\": 0.9997798184149517, \"recall\": 0.25395363220939526, \"specificity\": 0.9999999867056404, \"npv\": 0.9998226932864841, \"accuracy\": 0.9998226906983544, \"f1\": 0.4050266285384474, \"f2\": 0.29848737832091954, \"f0_5\": 0.6298333705941772, \"p4\": 0.5765246965042435, \"phi\": 0.5038379454974972}, {\"truth_threshold\": 18.89999957755208, \"match_probability\": 0.9999979557579319, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77099.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2536476719052773, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7463523280947226, \"precision\": 0.9997795528813735, \"recall\": 0.2536476719052773, \"specificity\": 0.9999999867056404, \"npv\": 0.9998226205843094, \"accuracy\": 0.9998226179876709, \"f1\": 0.4046373829960874, \"f2\": 0.29814920801880956, \"f0_5\": 0.6294566681634486, \"p4\": 0.5761302489069512, \"phi\": 0.5035342598492728}, {\"truth_threshold\": 18.919999577105045, \"match_probability\": 0.9999979839015591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77005.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25333842170541615, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7466615782945838, \"precision\": 0.9997792838409805, \"recall\": 0.25333842170541615, \"specificity\": 0.9999999867056404, \"npv\": 0.9998225471004016, \"accuracy\": 0.9998225444951522, \"f1\": 0.4042437589078778, \"f2\": 0.2978073520380302, \"f0_5\": 0.6290754498414343, \"p4\": 0.575731141876828, \"phi\": 0.5032271225753514}, {\"truth_threshold\": 18.93999957665801, \"match_probability\": 0.9999980116577264, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76901.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227060.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25299627254812296, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.747003727451877, \"precision\": 0.9997789854130372, \"recall\": 0.25299627254812296, \"specificity\": 0.9999999867056404, \"npv\": 0.9998224657990694, \"accuracy\": 0.9998224631842805, \"f1\": 0.40380803352245725, \"f2\": 0.2974290704708214, \"f0_5\": 0.6286531302267864, \"p4\": 0.5752890861089995, \"phi\": 0.502887092597629}, {\"truth_threshold\": 18.959999576210976, \"match_probability\": 0.9999980390317678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76832.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227129.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2527692697418419, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7472307302581581, \"precision\": 0.9997787869718539, \"recall\": 0.2527692697418419, \"specificity\": 0.9999999867056404, \"npv\": 0.9998224118587699, \"accuracy\": 0.9998224092376443, \"f1\": 0.403518815157165, \"f2\": 0.2971780616124633, \"f0_5\": 0.6283726202529782, \"p4\": 0.5749955143195593, \"phi\": 0.5026613688880703}, {\"truth_threshold\": 18.97999957576394, \"match_probability\": 0.999998066028944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76744.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227217.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2524797589164399, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7475202410835601, \"precision\": 0.9997785333698102, \"recall\": 0.2524797589164399, \"specificity\": 0.9999999867056404, \"npv\": 0.9998223430653527, \"accuracy\": 0.9998223404361374, \"f1\": 0.4031498048444797, \"f2\": 0.29685789549011493, \"f0_5\": 0.6280145006996669, \"p4\": 0.5746207738199859, \"phi\": 0.502373342252511}, {\"truth_threshold\": 18.999999575316906, \"match_probability\": 0.9999980926544437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76688.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227273.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25229552475482053, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7477044752451795, \"precision\": 0.9997783716837234, \"recall\": 0.25229552475482053, \"specificity\": 0.9999999867056404, \"npv\": 0.9998222992877285, \"accuracy\": 0.9998222966533603, \"f1\": 0.40291489126951185, \"f2\": 0.2966541307138066, \"f0_5\": 0.6277863915216747, \"p4\": 0.5743821096917568, \"phi\": 0.5021899665853176}, {\"truth_threshold\": 19.01999957486987, \"match_probability\": 0.9999981189133836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76621.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227340.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25207510174002584, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7479248982599741, \"precision\": 0.999778177927399, \"recall\": 0.25207510174002584, \"specificity\": 0.9999999867056404, \"npv\": 0.9998222469109331, \"accuracy\": 0.9998222442703948, \"f1\": 0.4026337431259672, \"f2\": 0.2964103175131259, \"f0_5\": 0.627513255245998, \"p4\": 0.5740963677407074, \"phi\": 0.5019704826993796}, {\"truth_threshold\": 19.039999574422836, \"match_probability\": 0.9999981448108103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76523.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227438.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25175269195719185, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7482473080428081, \"precision\": 0.9997778939116801, \"recall\": 0.25175269195719185, \"specificity\": 0.9999999867056404, \"npv\": 0.9998221703001081, \"accuracy\": 0.9998221676505349, \"f1\": 0.402222333187035, \"f2\": 0.29605364968925646, \"f0_5\": 0.6271133103105777, \"p4\": 0.573678029080144, \"phi\": 0.5016492736532735}, {\"truth_threshold\": 19.0599995739758, \"match_probability\": 0.9999981703517008, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76476.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227485.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25159806685726127, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7484019331427387, \"precision\": 0.9997777574418574, \"recall\": 0.25159806685726127, \"specificity\": 0.9999999867056404, \"npv\": 0.9998221335581859, \"accuracy\": 0.9998221309042755, \"f1\": 0.40202494913971204, \"f2\": 0.2958825755201623, \"f0_5\": 0.6269213175873416, \"p4\": 0.573477233658993, \"phi\": 0.5014951514394727}, {\"truth_threshold\": 19.079999573528767, \"match_probability\": 0.9999981955409636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76404.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2513611943637506, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7486388056362494, \"precision\": 0.9997775480561626, \"recall\": 0.2513611943637506, \"specificity\": 0.9999999867056404, \"npv\": 0.9998220772726935, \"accuracy\": 0.9998220746121335, \"f1\": 0.4017224789816553, \"f2\": 0.2956204803194391, \"f0_5\": 0.6266269714341953, \"p4\": 0.5731694262110087, \"phi\": 0.5012589574453329}, {\"truth_threshold\": 19.099999573081732, \"match_probability\": 0.9999982203834397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76303.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.251028914893687, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7489710851063129, \"precision\": 0.9997772536687631, \"recall\": 0.251028914893687, \"specificity\": 0.9999999867056404, \"npv\": 0.999821998316666, \"accuracy\": 0.9998219956467675, \"f1\": 0.4012979875407922, \"f2\": 0.295252769772258, \"f0_5\": 0.6262136002009057, \"p4\": 0.5727372202388377, \"phi\": 0.5009274421165321}, {\"truth_threshold\": 19.119999572634697, \"match_probability\": 0.9999982448839032, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76179.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25062096782152976, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7493790321784702, \"precision\": 0.9997768911753898, \"recall\": 0.25062096782152976, \"specificity\": 0.9999999867056404, \"npv\": 0.9998219013805701, \"accuracy\": 0.9998218986991897, \"f1\": 0.40077652127936614, \"f2\": 0.2948012445435126, \"f0_5\": 0.6257053446024198, \"p4\": 0.5722059185290437, \"phi\": 0.5005201329962478}, {\"truth_threshold\": 19.139999572187662, \"match_probability\": 0.9999982690470628, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76061.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227900.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25023276012383167, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7497672398761683, \"precision\": 0.9997765451247403, \"recall\": 0.25023276012383167, \"specificity\": 0.9999999867056404, \"npv\": 0.999821809134948, \"accuracy\": 0.9998218064426236, \"f1\": 0.4002799712661069, \"f2\": 0.29437148682350794, \"f0_5\": 0.6252209123206192, \"p4\": 0.5716996352254148, \"phi\": 0.5001322244293219}, {\"truth_threshold\": 19.159999571740627, \"match_probability\": 0.9999982928775621, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75968.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227993.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24992679981971372, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7500732001802863, \"precision\": 0.9997762716325591, \"recall\": 0.24992679981971372, \"specificity\": 0.9999999867056404, \"npv\": 0.999821736432902, \"accuracy\": 0.9998217337319402, \"f1\": 0.39988840519442237, \"f2\": 0.2940327241453784, \"f0_5\": 0.624838583914157, \"p4\": 0.5713001404643664, \"phi\": 0.4998262877970162}, {\"truth_threshold\": 19.179999571293592, \"match_probability\": 0.9999983163799812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75861.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228100.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2495747809751909, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7504252190248091, \"precision\": 0.9997759561401197, \"recall\": 0.2495747809751909, \"specificity\": 0.9999999867056404, \"npv\": 0.9998216527864748, \"accuracy\": 0.9998216500755625, \"f1\": 0.3994376564807721, \"f2\": 0.29364290458782927, \"f0_5\": 0.624398121397988, \"p4\": 0.5708399879056071, \"phi\": 0.49947406441392866}, {\"truth_threshold\": 19.199999570846558, \"match_probability\": 0.9999983395588364, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75772.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24928198025404574, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7507180197459542, \"precision\": 0.999775693042526, \"recall\": 0.24928198025404574, \"specificity\": 0.9999999867056404, \"npv\": 0.99982158321142, \"accuracy\": 0.9998215804922203, \"f1\": 0.39906254114549045, \"f2\": 0.29331861294965367, \"f0_5\": 0.6240312822734333, \"p4\": 0.5704568206024679, \"phi\": 0.49918090427432066}, {\"truth_threshold\": 19.219999570399523, \"match_probability\": 0.9999983624185826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75715.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228246.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24909445619668313, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7509055438033169, \"precision\": 0.9997755242169757, \"recall\": 0.24909445619668313, \"specificity\": 0.9999999867056404, \"npv\": 0.9998215386521203, \"accuracy\": 0.9998215359276078, \"f1\": 0.39882220636145516, \"f2\": 0.29311089707458177, \"f0_5\": 0.6237961142811947, \"p4\": 0.570211218949664, \"phi\": 0.49899305957315315}, {\"truth_threshold\": 19.239999569952488, \"match_probability\": 0.999998384963613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75633.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228328.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2488246847457404, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7511753152542596, \"precision\": 0.9997752808988764, \"recall\": 0.2488246847457404, \"specificity\": 0.9999999867056404, \"npv\": 0.9998214745492751, \"accuracy\": 0.9998214718171128, \"f1\": 0.39847633498502416, \"f2\": 0.2928120455844162, \"f0_5\": 0.6234574923214647, \"p4\": 0.5698576197477048, \"phi\": 0.4987227027700389}, {\"truth_threshold\": 19.259999569505453, \"match_probability\": 0.9999984071982604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75553.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228408.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24856149308628409, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7514385069137159, \"precision\": 0.999775043006484, \"recall\": 0.24856149308628409, \"specificity\": 0.9999999867056404, \"npv\": 0.9998214120099218, \"accuracy\": 0.9998214092702883, \"f1\": 0.39813875546398053, \"f2\": 0.2925204465802601, \"f0_5\": 0.6231267763150299, \"p4\": 0.5695123289671995, \"phi\": 0.498458798752354}, {\"truth_threshold\": 19.27999956905842, \"match_probability\": 0.9999984291267976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75458.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228503.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24824895299067973, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7517510470093203, \"precision\": 0.9997747598542563, \"recall\": 0.24824895299067973, \"specificity\": 0.9999999867056404, \"npv\": 0.9998213377444499, \"accuracy\": 0.9998213349959343, \"f1\": 0.39773769489452765, \"f2\": 0.29217412583567653, \"f0_5\": 0.6227335973102741, \"p4\": 0.5691018902784619, \"phi\": 0.4981452311861052}, {\"truth_threshold\": 19.299999568611383, \"match_probability\": 0.9999984507534392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75375.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228586.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2479758916439938, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7520241083560062, \"precision\": 0.9997745118845501, \"recall\": 0.2479758916439938, \"specificity\": 0.9999999867056404, \"npv\": 0.9998212728598888, \"accuracy\": 0.9998212701036039, \"f1\": 0.39738713019272287, \"f2\": 0.29187150915866655, \"f0_5\": 0.6223896791070287, \"p4\": 0.5687429352539282, \"phi\": 0.49787111054628796}, {\"truth_threshold\": 19.31999956816435, \"match_probability\": 0.9999984720823414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75268.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228693.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24762387279947098, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.752376127200529, \"precision\": 0.9997741914059906, \"recall\": 0.24762387279947098, \"specificity\": 0.9999999867056404, \"npv\": 0.9998211892135392, \"accuracy\": 0.9998211864472262, \"f1\": 0.3969349709687116, \"f2\": 0.291481331454874, \"f0_5\": 0.6219457578156374, \"p4\": 0.5682796881367541, \"phi\": 0.4975175033026364}, {\"truth_threshold\": 19.339999567717314, \"match_probability\": 0.9999984931176031, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75180.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228781.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24733436197406905, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.752665638025931, \"precision\": 0.9997739271513492, \"recall\": 0.24733436197406905, \"specificity\": 0.9999999867056404, \"npv\": 0.9998211204202904, \"accuracy\": 0.9998211176457192, \"f1\": 0.39656291044894215, \"f2\": 0.29116038917431747, \"f0_5\": 0.6215801927741923, \"p4\": 0.5678982789541405, \"phi\": 0.4972264977196958}, {\"truth_threshold\": 19.35999956727028, \"match_probability\": 0.9999985138632671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75100.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24707117031461273, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7529288296853873, \"precision\": 0.9997736863825765, \"recall\": 0.24707117031461273, \"specificity\": 0.9999999867056404, \"npv\": 0.9998210578809813, \"accuracy\": 0.9998210550988949, \"f1\": 0.39622452371279787, \"f2\": 0.2908685854956114, \"f0_5\": 0.6212474914340642, \"p4\": 0.567551213164289, \"phi\": 0.49696179935339224}, {\"truth_threshold\": 19.379999566823244, \"match_probability\": 0.9999985343233202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75006.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24676192011475157, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7532380798852485, \"precision\": 0.9997734028231342, \"recall\": 0.24676192011475157, \"specificity\": 0.9999999867056404, \"npv\": 0.9998209843973033, \"accuracy\": 0.9998209816063761, \"f1\": 0.39582673674878094, \"f2\": 0.29052566995670354, \"f0_5\": 0.6208561169301369, \"p4\": 0.5671430084599247, \"phi\": 0.49665059854738564}, {\"truth_threshold\": 19.39999956637621, \"match_probability\": 0.9999985545016946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74931.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24651517793401126, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7534848220659888, \"precision\": 0.9997731760687409, \"recall\": 0.24651517793401126, \"specificity\": 0.9999999867056404, \"npv\": 0.9998209257667169, \"accuracy\": 0.9998209229687282, \"f1\": 0.39550921197437905, \"f2\": 0.2902520313110091, \"f0_5\": 0.620543500404967, \"p4\": 0.5668170009376596, \"phi\": 0.49640216013509925}, {\"truth_threshold\": 19.419999565929174, \"match_probability\": 0.9999985744022681, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74867.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229094.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24630462460644623, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7536953753935538, \"precision\": 0.9997729822124887, \"recall\": 0.24630462460644623, \"specificity\": 0.9999999867056404, \"npv\": 0.9998208757352886, \"accuracy\": 0.9998208729312685, \"f1\": 0.3952381580857607, \"f2\": 0.29001850118692707, \"f0_5\": 0.6202764885326688, \"p4\": 0.566538588387562, \"phi\": 0.4961900610167201}, {\"truth_threshold\": 19.43999956548214, \"match_probability\": 0.9999985940288653, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74792.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229169.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24605788242570592, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7539421175742941, \"precision\": 0.9997727546150864, \"recall\": 0.24605788242570592, \"specificity\": 0.9999999867056404, \"npv\": 0.9998208171047148, \"accuracy\": 0.9998208142936207, \"f1\": 0.3949204002428915, \"f2\": 0.2897448035994183, \"f0_5\": 0.6199632955734197, \"p4\": 0.5662120661830129, \"phi\": 0.4959413919555071}, {\"truth_threshold\": 19.459999565035105, \"match_probability\": 0.9999986133852581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74735.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229226.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2458703583683433, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7541296416316567, \"precision\": 0.9997725813356164, \"recall\": 0.2458703583683433, \"specificity\": 0.9999999867056404, \"npv\": 0.9998207725454834, \"accuracy\": 0.9998207697290082, \"f1\": 0.39467882010915917, \"f2\": 0.28953677215797974, \"f0_5\": 0.6197250604923304, \"p4\": 0.5659637232579231, \"phi\": 0.4957523200675986}, {\"truth_threshold\": 19.47999956458807, \"match_probability\": 0.9999986324751665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74638.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229323.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24555123848125254, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7544487615187475, \"precision\": 0.9997722858482352, \"recall\": 0.24555123848125254, \"specificity\": 0.9999999867056404, \"npv\": 0.999820696716625, \"accuracy\": 0.9998206938909836, \"f1\": 0.3942675428402392, \"f2\": 0.289182711493771, \"f0_5\": 0.6193192284522745, \"p4\": 0.5655407347359469, \"phi\": 0.4954304003157476}, {\"truth_threshold\": 19.499999564141035, \"match_probability\": 0.9999986513022592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74564.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24530778619625543, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7546922138037445, \"precision\": 0.9997720599080194, \"recall\": 0.24530778619625543, \"specificity\": 0.9999999867056404, \"npv\": 0.9998206388678129, \"accuracy\": 0.9998206360351709, \"f1\": 0.3939536431888668, \"f2\": 0.28891256756494954, \"f0_5\": 0.6190092730185875, \"p4\": 0.5652177287464032, \"phi\": 0.4951846713557429}, {\"truth_threshold\": 19.519999563694, \"match_probability\": 0.9999986698701544, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74467.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229494.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24498866630916466, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7550113336908353, \"precision\": 0.9997717630632083, \"recall\": 0.24498866630916466, \"specificity\": 0.9999999867056404, \"npv\": 0.9998205630389748, \"accuracy\": 0.9998205601971463, \"f1\": 0.39354199421316177, \"f2\": 0.2885584130546652, \"f0_5\": 0.6186025183710834, \"p4\": 0.5647939171553256, \"phi\": 0.4948623824213249}, {\"truth_threshold\": 19.539999563246965, \"match_probability\": 0.9999986881824207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74420.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229541.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24483404120923408, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7551659587907659, \"precision\": 0.9997716189529401, \"recall\": 0.24483404120923408, \"specificity\": 0.9999999867056404, \"npv\": 0.9998205262971709, \"accuracy\": 0.9998205234508869, \"f1\": 0.3933424595267417, \"f2\": 0.28838679326441297, \"f0_5\": 0.6184052424012272, \"p4\": 0.5645883968923062, \"phi\": 0.49470614630672927}, {\"truth_threshold\": 19.55999956279993, \"match_probability\": 0.9999987062425771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74345.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229616.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2445872990284938, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7554127009715063, \"precision\": 0.9997713886124634, \"recall\": 0.2445872990284938, \"specificity\": 0.9999999867056404, \"npv\": 0.9998204676666381, \"accuracy\": 0.9998204648132389, \"f1\": 0.3930239504338885, \"f2\": 0.2881129060010572, \"f0_5\": 0.6180901848825009, \"p4\": 0.5642602112698227, \"phi\": 0.49445673113959143}, {\"truth_threshold\": 19.579999562352896, \"match_probability\": 0.9999987240540947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74266.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24432739726478067, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7556726027352193, \"precision\": 0.9997711454841619, \"recall\": 0.24432739726478067, \"specificity\": 0.9999999867056404, \"npv\": 0.9998204059091511, \"accuracy\": 0.9998204030482498, \"f1\": 0.3926883175939341, \"f2\": 0.28782437697994073, \"f0_5\": 0.617757984205439, \"p4\": 0.56391421923916, \"phi\": 0.49419387773510803}, {\"truth_threshold\": 19.59999956190586, \"match_probability\": 0.9999987416203966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74189.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229772.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24407407529255398, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.755925924707446, \"precision\": 0.9997709080128292, \"recall\": 0.24407407529255398, \"specificity\": 0.9999999867056404, \"npv\": 0.9998203457151521, \"accuracy\": 0.9998203428469313, \"f1\": 0.3923610468390949, \"f2\": 0.2875431184837797, \"f0_5\": 0.6174338573699409, \"p4\": 0.5635766867691008, \"phi\": 0.49393754426572617}, {\"truth_threshold\": 19.619999561458826, \"match_probability\": 0.9999987589448586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74085.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24373192613526076, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7562680738647393, \"precision\": 0.9997705864888937, \"recall\": 0.24373192613526076, \"specificity\": 0.9999999867056404, \"npv\": 0.9998202644141779, \"accuracy\": 0.9998202615360595, \"f1\": 0.3919188071829298, \"f2\": 0.2871631835751264, \"f0_5\": 0.616995547738141, \"p4\": 0.5631203283525226, \"phi\": 0.4935911163593503}, {\"truth_threshold\": 19.63999956101179, \"match_probability\": 0.9999987760308101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74008.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24347860416303407, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.756521395836966, \"precision\": 0.9997703478554543, \"recall\": 0.24347860416303407, \"specificity\": 0.9999999867056404, \"npv\": 0.9998202042201959, \"accuracy\": 0.9998202013347409, \"f1\": 0.39159122295534754, \"f2\": 0.2868818461409647, \"f0_5\": 0.6166706384850873, \"p4\": 0.5627820988085916, \"phi\": 0.4933344697717966}, {\"truth_threshold\": 19.659999560564756, \"match_probability\": 0.9999987928815349, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73947.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24327792052269864, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7567220794773014, \"precision\": 0.9997701584554648, \"recall\": 0.24327792052269864, \"specificity\": 0.9999999867056404, \"npv\": 0.9998201565340595, \"accuracy\": 0.9998201536427873, \"f1\": 0.3913316134153602, \"f2\": 0.28665894458710134, \"f0_5\": 0.6164130059668199, \"p4\": 0.5625139397650497, \"phi\": 0.4931310575459304}, {\"truth_threshold\": 19.67999956011772, \"match_probability\": 0.9999988095002714, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73867.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230094.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24301472886324232, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7569852711367577, \"precision\": 0.9997699095880028, \"recall\": 0.24301472886324232, \"specificity\": 0.9999999867056404, \"npv\": 0.9998200939948712, \"accuracy\": 0.9998200910959628, \"f1\": 0.39099101483412513, \"f2\": 0.286366582721318, \"f0_5\": 0.6160748093818651, \"p4\": 0.562161972733943, \"phi\": 0.4928641601964892}, {\"truth_threshold\": 19.699999559670687, \"match_probability\": 0.9999988258902134, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73800.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24279430584844766, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7572056941515524, \"precision\": 0.9997697007464406, \"recall\": 0.24279430584844766, \"specificity\": 0.9999999867056404, \"npv\": 0.9998200416183068, \"accuracy\": 0.9998200387129974, \"f1\": 0.39070565252608674, \"f2\": 0.2861217017495295, \"f0_5\": 0.6157912918099758, \"p4\": 0.5618669529191557, \"phi\": 0.49264052243169365}, {\"truth_threshold\": 19.719999559223652, \"match_probability\": 0.9999988420545107, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73710.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24249821523155932, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7575017847684407, \"precision\": 0.999769419615609, \"recall\": 0.24249821523155932, \"specificity\": 0.9999999867056404, \"npv\": 0.9998199712617366, \"accuracy\": 0.9998199683478198, \"f1\": 0.39032217068056174, \"f2\": 0.28579271711290033, \"f0_5\": 0.6154100479403676, \"p4\": 0.5614703021915265, \"phi\": 0.49233995365322225}, {\"truth_threshold\": 19.739999558776617, \"match_probability\": 0.9999988579962699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73644.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24228108211250785, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7577189178874921, \"precision\": 0.9997692130163859, \"recall\": 0.24228108211250785, \"specificity\": 0.9999999867056404, \"npv\": 0.9998199196669247, \"accuracy\": 0.9998199167466897, \"f1\": 0.39004083448527893, \"f2\": 0.28555143252643456, \"f0_5\": 0.6151301776630667, \"p4\": 0.5611791656551437, \"phi\": 0.49211941990285074}, {\"truth_threshold\": 19.759999558329582, \"match_probability\": 0.9999988737185547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73555.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24198828139136272, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7580117186086373, \"precision\": 0.9997689338335236, \"recall\": 0.24198828139136272, \"specificity\": 0.9999999867056404, \"npv\": 0.999819850092111, \"accuracy\": 0.9998198471633475, \"f1\": 0.3896613011312918, \"f2\": 0.285226024805028, \"f0_5\": 0.6147523857123037, \"p4\": 0.5607862244910792, \"phi\": 0.49182187693447904}, {\"truth_threshold\": 19.779999557882547, \"match_probability\": 0.9999988892243865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73448.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230513.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2416362625468399, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7583637374531601, \"precision\": 0.9997685972912271, \"recall\": 0.2416362625468399, \"specificity\": 0.9999999867056404, \"npv\": 0.9998197664459997, \"accuracy\": 0.9998197635069698, \"f1\": 0.38920477126642045, \"f2\": 0.28483474481291915, \"f0_5\": 0.6142975907504086, \"p4\": 0.560313282303523, \"phi\": 0.4914639183194301}, {\"truth_threshold\": 19.799999557435513, \"match_probability\": 0.9999989045167456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73350.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2413138527640059, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7586861472359941, \"precision\": 0.999768288194965, \"recall\": 0.2413138527640059, \"specificity\": 0.9999999867056404, \"npv\": 0.9998196898355547, \"accuracy\": 0.9998196868871098, \"f1\": 0.38878641394224656, \"f2\": 0.2844763192371148, \"f0_5\": 0.6138804778475768, \"p4\": 0.5598796119492456, \"phi\": 0.4911358395253244}, {\"truth_threshold\": 19.819999556988478, \"match_probability\": 0.9999989195985707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73278.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230683.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24107698027049523, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7589230197295048, \"precision\": 0.9997680605771199, \"recall\": 0.24107698027049523, \"specificity\": 0.9999999867056404, \"npv\": 0.9998196335503373, \"accuracy\": 0.9998196305949678, \"f1\": 0.3884789108721929, \"f2\": 0.28421295143502756, \"f0_5\": 0.6135736785784262, \"p4\": 0.5595606867867879, \"phi\": 0.49089466235325535}, {\"truth_threshold\": 19.839999556541443, \"match_probability\": 0.9999989344727602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73193.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230768.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2407973391323229, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7592026608676771, \"precision\": 0.9997677912853435, \"recall\": 0.2407973391323229, \"specificity\": 0.9999999867056404, \"npv\": 0.9998195671025194, \"accuracy\": 0.9998195641389668, \"f1\": 0.38811573530308535, \"f2\": 0.2839019932446585, \"f0_5\": 0.6132111038687937, \"p4\": 0.5591838392070182, \"phi\": 0.49060978673608957}, {\"truth_threshold\": 19.859999556094408, \"match_probability\": 0.9999989491421728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73073.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230888.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24040255164313842, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7595974483568616, \"precision\": 0.9997674100424134, \"recall\": 0.24040255164313842, \"specificity\": 0.9999999867056404, \"npv\": 0.9998194732938503, \"accuracy\": 0.9998194703187301, \"f1\": 0.38760273809113355, \"f2\": 0.2834629236252593, \"f0_5\": 0.6126985298186715, \"p4\": 0.5586511937337745, \"phi\": 0.49020732762187724}, {\"truth_threshold\": 19.879999555647373, \"match_probability\": 0.9999989636096278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73009.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230952.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2401919983155734, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7598080016844266, \"precision\": 0.9997672062005313, \"recall\": 0.2401919983155734, \"specificity\": 0.9999999867056404, \"npv\": 0.9998194232625673, \"accuracy\": 0.9998194202812705, \"f1\": 0.3873290060399961, \"f2\": 0.2832287197312374, \"f0_5\": 0.6124248194408328, \"p4\": 0.5583668163264783, \"phi\": 0.48999254762843714}, {\"truth_threshold\": 19.89999955520034, \"match_probability\": 0.9999989778779054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72962.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2400373732156428, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7599626267843572, \"precision\": 0.9997670562764631, \"recall\": 0.2400373732156428, \"specificity\": 0.9999999867056404, \"npv\": 0.9998193865208471, \"accuracy\": 0.9998193835350111, \"f1\": 0.38712792486867936, \"f2\": 0.28305671143361033, \"f0_5\": 0.6122236636084293, \"p4\": 0.558157843665076, \"phi\": 0.489834758609649}, {\"truth_threshold\": 19.919999554753304, \"match_probability\": 0.9999989919497478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72864.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231097.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23971496343280882, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7602850365671912, \"precision\": 0.9997667430468846, \"recall\": 0.23971496343280882, \"specificity\": 0.9999999867056404, \"npv\": 0.9998193099104604, \"accuracy\": 0.9998193069151512, \"f1\": 0.38670848790739887, \"f2\": 0.2826980154804167, \"f0_5\": 0.6118038237738986, \"p4\": 0.5577217507285194, \"phi\": 0.48950558816397516}, {\"truth_threshold\": 19.93999955430627, \"match_probability\": 0.9999990058278594, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72798.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231163.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23949783031375735, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7605021696862426, \"precision\": 0.9997665316212319, \"recall\": 0.23949783031375735, \"specificity\": 0.9999999867056404, \"npv\": 0.9998192583157168, \"accuracy\": 0.999819255314021, \"f1\": 0.3864258869991719, \"f2\": 0.282456413993151, \"f0_5\": 0.6115207628763099, \"p4\": 0.5574277788710549, \"phi\": 0.4892837771820251}, {\"truth_threshold\": 19.959999553859234, \"match_probability\": 0.9999990195149073, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72725.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231236.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23925766792450348, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7607423320754966, \"precision\": 0.9997662973247917, \"recall\": 0.23925766792450348, \"specificity\": 0.9999999867056404, \"npv\": 0.9998192012488096, \"accuracy\": 0.9998191982400437, \"f1\": 0.3861131979304651, \"f2\": 0.28218915928001703, \"f0_5\": 0.6112073877723224, \"p4\": 0.5571023685138077, \"phi\": 0.48903832364245536}, {\"truth_threshold\": 19.9799995534122, \"match_probability\": 0.999999033013522, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72629.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2389418379331559, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7610581620668441, \"precision\": 0.9997659884921399, \"recall\": 0.2389418379331559, \"specificity\": 0.9999999867056404, \"npv\": 0.9998191262019279, \"accuracy\": 0.9998191231838544, \"f1\": 0.38570180586128244, \"f2\": 0.2818376549294135, \"f0_5\": 0.610794809476154, \"p4\": 0.5566740158650846, \"phi\": 0.4887153478117718}, {\"truth_threshold\": 19.999999552965164, \"match_probability\": 0.9999990463262975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72571.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23875102398005008, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7612489760199499, \"precision\": 0.9997658015098915, \"recall\": 0.23875102398005008, \"specificity\": 0.9999999867056404, \"npv\": 0.9998190808611089, \"accuracy\": 0.9998190778374066, \"f1\": 0.3854531548350945, \"f2\": 0.2816252623343723, \"f0_5\": 0.6105452850602292, \"p4\": 0.5564149902915431, \"phi\": 0.4885201131296575}, {\"truth_threshold\": 20.01999955251813, \"match_probability\": 0.9999990594557926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72459.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231502.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23838255565681124, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7616174443431888, \"precision\": 0.9997654395937966, \"recall\": 0.23838255565681124, \"specificity\": 0.9999999867056404, \"npv\": 0.9998189933064358, \"accuracy\": 0.9998189902718524, \"f1\": 0.38497278429059845, \"f2\": 0.28121507078986585, \"f0_5\": 0.610062893081761, \"p4\": 0.555914313691713, \"phi\": 0.4881428872990846}, {\"truth_threshold\": 20.039999552071095, \"match_probability\": 0.9999990724045303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72373.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231588.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2380996246228957, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7619003753771043, \"precision\": 0.9997651609338306, \"recall\": 0.2380996246228957, \"specificity\": 0.9999999867056404, \"npv\": 0.999818926076965, \"accuracy\": 0.9998189230340161, \"f1\": 0.38460373427996736, \"f2\": 0.28090005387220024, \"f0_5\": 0.6096919906793525, \"p4\": 0.5555294273618125, \"phi\": 0.48785303382008405}, {\"truth_threshold\": 20.05999955162406, \"match_probability\": 0.9999990851749994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72310.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231651.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23789236119107385, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7621076388089262, \"precision\": 0.9997649563786691, \"recall\": 0.23789236119107385, \"specificity\": 0.9999999867056404, \"npv\": 0.9998188768274747, \"accuracy\": 0.9998188737783918, \"f1\": 0.38433327663917, \"f2\": 0.28066925897260536, \"f0_5\": 0.6094200101471676, \"p4\": 0.5552472338044531, \"phi\": 0.4876405899850905}, {\"truth_threshold\": 20.079999551177025, \"match_probability\": 0.9999990977696538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72228.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231733.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23762258974013115, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7623774102598688, \"precision\": 0.999764689597896, \"recall\": 0.23762258974013115, \"specificity\": 0.9999999867056404, \"npv\": 0.9998188127249708, \"accuracy\": 0.9998188096678967, \"f1\": 0.3839811167286008, \"f2\": 0.2803688254460678, \"f0_5\": 0.6090656574600171, \"p4\": 0.5548796273889534, \"phi\": 0.48736393710926895}, {\"truth_threshold\": 20.09999955072999, \"match_probability\": 0.9999991101909143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72109.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23723109214668986, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7627689078533101, \"precision\": 0.9997643013615063, \"recall\": 0.23723109214668986, \"specificity\": 0.9999999867056404, \"npv\": 0.9998187196981809, \"accuracy\": 0.9998187166294954, \"f1\": 0.38346978225782863, \"f2\": 0.27993276240906234, \"f0_5\": 0.6085507160760552, \"p4\": 0.5543455315295427, \"phi\": 0.48696217357045424}, {\"truth_threshold\": 20.119999550282955, \"match_probability\": 0.9999991224411678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72018.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23693171163405832, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7630682883659416, \"precision\": 0.9997640036093566, \"recall\": 0.23693171163405832, \"specificity\": 0.9999999867056404, \"npv\": 0.9998186485600592, \"accuracy\": 0.9998186454824826, \"f1\": 0.38307854338875946, \"f2\": 0.2795992480660062, \"f0_5\": 0.6081563787259269, \"p4\": 0.5539366104982127, \"phi\": 0.4866547188812619}, {\"truth_threshold\": 20.13999954983592, \"match_probability\": 0.9999991345227689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71952.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232009.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23671457851500685, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7632854214849931, \"precision\": 0.9997637871861496, \"recall\": 0.23671457851500685, \"specificity\": 0.9999999867056404, \"npv\": 0.9998185969653838, \"accuracy\": 0.9998185938813524, \"f1\": 0.38279466922033356, \"f2\": 0.2793573290532088, \"f0_5\": 0.6078700723341055, \"p4\": 0.5536397616948356, \"phi\": 0.48643160821090586}, {\"truth_threshold\": 20.159999549388885, \"match_probability\": 0.9999991464380393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71882.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232079.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2364842858129826, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7635157141870174, \"precision\": 0.9997635572122004, \"recall\": 0.2364842858129826, \"specificity\": 0.9999999867056404, \"npv\": 0.9998185422437642, \"accuracy\": 0.999818539152881, \"f1\": 0.3824934816154951, \"f2\": 0.2791007211842736, \"f0_5\": 0.6075661347934349, \"p4\": 0.553324674851939, \"phi\": 0.48619486382774724}, {\"truth_threshold\": 20.17999954894185, \"match_probability\": 0.9999991581892689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71797.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23620464467481025, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7637953553251897, \"precision\": 0.9997632773553903, \"recall\": 0.23620464467481025, \"specificity\": 0.9999999867056404, \"npv\": 0.9998184757960914, \"accuracy\": 0.99981847269688, \"f1\": 0.3821276029538953, \"f2\": 0.2787890884070149, \"f0_5\": 0.6071966807449718, \"p4\": 0.5529417268518746, \"phi\": 0.48590723346928105}, {\"truth_threshold\": 20.199999548494816, \"match_probability\": 0.9999991697787161, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71705.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232256.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2359019742664355, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7640980257335646, \"precision\": 0.9997629737040239, \"recall\": 0.2359019742664355, \"specificity\": 0.9999999867056404, \"npv\": 0.9998184038762672, \"accuracy\": 0.9998184007680319, \"f1\": 0.3817314065315705, \"f2\": 0.27845174538625594, \"f0_5\": 0.6067963219028889, \"p4\": 0.5525268179717788, \"phi\": 0.48559572395394884}, {\"truth_threshold\": 20.21999954804778, \"match_probability\": 0.9999991812086082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71635.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232326.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23567168156441123, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7643283184355888, \"precision\": 0.999762742142578, \"recall\": 0.23567168156441123, \"specificity\": 0.9999999867056404, \"npv\": 0.9998183491546688, \"accuracy\": 0.9998183460395604, \"f1\": 0.38142982271646614, \"f2\": 0.2781950390525485, \"f0_5\": 0.6064913668004924, \"p4\": 0.552210830751737, \"phi\": 0.4853585719416327}, {\"truth_threshold\": 20.239999547600746, \"match_probability\": 0.9999991924811419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71571.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23546112823684617, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7645388717631538, \"precision\": 0.9997625300329664, \"recall\": 0.23546112823684617, \"specificity\": 0.9999999867056404, \"npv\": 0.9998182991234983, \"accuracy\": 0.9998182960021009, \"f1\": 0.38115399055782334, \"f2\": 0.2779603116902485, \"f0_5\": 0.6062122975438454, \"p4\": 0.5519217042463531, \"phi\": 0.48514164581935904}, {\"truth_threshold\": 20.25999954715371, \"match_probability\": 0.9999992035984836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71499.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232462.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2352242557433355, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7647757442566645, \"precision\": 0.99976229095587, \"recall\": 0.2352242557433355, \"specificity\": 0.9999999867056404, \"npv\": 0.9998182428384376, \"accuracy\": 0.9998182397099589, \"f1\": 0.38084356698279787, \"f2\": 0.2776962155108128, \"f0_5\": 0.6058980551671539, \"p4\": 0.5515961809712377, \"phi\": 0.48489748795854676}, {\"truth_threshold\": 20.279999546706676, \"match_probability\": 0.9999992145627697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71405.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232556.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23491500554347433, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7650849944565257, \"precision\": 0.9997619781019854, \"recall\": 0.23491500554347433, \"specificity\": 0.9999999867056404, \"npv\": 0.9998181693551733, \"accuracy\": 0.9998181662174401, \"f1\": 0.3804381125410581, \"f2\": 0.27735137881370286, \"f0_5\": 0.6054873322942971, \"p4\": 0.5511707838293174, \"phi\": 0.4845785412007711}, {\"truth_threshold\": 20.29999954625964, \"match_probability\": 0.9999992253761075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71308.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23459588565638356, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7654041143436164, \"precision\": 0.9997616543988783, \"recall\": 0.23459588565638356, \"specificity\": 0.9999999867056404, \"npv\": 0.9998180935267098, \"accuracy\": 0.9998180903794155, \"f1\": 0.38001950512409205, \"f2\": 0.27699548388750816, \"f0_5\": 0.6050629517310665, \"p4\": 0.5507313245153476, \"phi\": 0.4842491951051807}, {\"truth_threshold\": 20.319999545812607, \"match_probability\": 0.9999992360405752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71217.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232744.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.234296505143752, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.765703494856248, \"precision\": 0.9997613499171744, \"recall\": 0.234296505143752, \"specificity\": 0.9999999867056404, \"npv\": 0.9998180223886771, \"accuracy\": 0.9998180192324027, \"f1\": 0.37962659417103106, \"f2\": 0.2766615543113937, \"f0_5\": 0.6046643131141779, \"p4\": 0.5503185990489158, \"phi\": 0.4839400172090325}, {\"truth_threshold\": 20.339999545365572, \"match_probability\": 0.9999992465582223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71134.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23402344379706608, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7659765562029339, \"precision\": 0.999761071523942, \"recall\": 0.23402344379706608, \"specificity\": 0.9999999867056404, \"npv\": 0.9998179575045463, \"accuracy\": 0.9998179543400723, \"f1\": 0.3792680586064962, \"f2\": 0.2763569400036519, \"f0_5\": 0.60430028968763, \"p4\": 0.5499417773421137, \"phi\": 0.48365784748291984}, {\"truth_threshold\": 20.359999544918537, \"match_probability\": 0.9999992569310698, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71052.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232909.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23375367234612335, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7662463276538767, \"precision\": 0.9997607958462902, \"recall\": 0.23375367234612335, \"specificity\": 0.9999999867056404, \"npv\": 0.9998178934021603, \"accuracy\": 0.9998178902295772, \"f1\": 0.3789136869050476, \"f2\": 0.2760559571626054, \"f0_5\": 0.6039402485732791, \"p4\": 0.549569139313473, \"phi\": 0.4833789156779506}, {\"truth_threshold\": 20.379999544471502, \"match_probability\": 0.9999992671611116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70953.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233008.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23342797266754617, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7665720273324539, \"precision\": 0.9997604621671129, \"recall\": 0.23342797266754617, \"specificity\": 0.9999999867056404, \"npv\": 0.9998178160102661, \"accuracy\": 0.999817812827882, \"f1\": 0.3784856413580099, \"f2\": 0.27569252432752517, \"f0_5\": 0.6035050294212211, \"p4\": 0.5491187743997417, \"phi\": 0.48304194197679046}, {\"truth_threshold\": 20.399999544024467, \"match_probability\": 0.9999992772503137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70901.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233060.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23325689808889957, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7667431019111004, \"precision\": 0.9997602865281029, \"recall\": 0.23325689808889957, \"specificity\": 0.9999999867056404, \"npv\": 0.9998177753599831, \"accuracy\": 0.999817772172446, \"f1\": 0.3782607187919302, \"f2\": 0.27550160791195266, \"f0_5\": 0.603276194495544, \"p4\": 0.5488820116946369, \"phi\": 0.48286485151124725}, {\"truth_threshold\": 20.419999543577433, \"match_probability\": 0.9999992872006149, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70837.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233124.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2330463447613345, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7669536552386654, \"precision\": 0.999760070003105, \"recall\": 0.2330463447613345, \"specificity\": 0.9999999867056404, \"npv\": 0.99981772532887, \"accuracy\": 0.9998177221349864, \"f1\": 0.3779838053439697, \"f2\": 0.2752666126783441, \"f0_5\": 0.6029943290254811, \"p4\": 0.5485904151052933, \"phi\": 0.4826468048355479}, {\"truth_threshold\": 20.439999543130398, \"match_probability\": 0.9999992970139275, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70745.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233216.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23274367435295976, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7672563256470403, \"precision\": 0.9997597580622368, \"recall\": 0.23274367435295976, \"specificity\": 0.9999999867056404, \"npv\": 0.9998176534091539, \"accuracy\": 0.9998176502061383, \"f1\": 0.3775855765458752, \"f2\": 0.27492876607135364, \"f0_5\": 0.6025887166976996, \"p4\": 0.5481708649927963, \"phi\": 0.4823331900847486}, {\"truth_threshold\": 20.459999542683363, \"match_probability\": 0.9999993066921377, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70688.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233273.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23255615029559712, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7674438497044028, \"precision\": 0.9997595643872428, \"recall\": 0.23255615029559712, \"specificity\": 0.9999999867056404, \"npv\": 0.9998176088502044, \"accuracy\": 0.9998176056415259, \"f1\": 0.3773387497130778, \"f2\": 0.27471942382295583, \"f0_5\": 0.6023371581561093, \"p4\": 0.5479107011781971, \"phi\": 0.4821387829688849}, {\"truth_threshold\": 20.479999542236328, \"match_probability\": 0.9999993162371051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70584.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233377.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23221400113830393, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7677859988616961, \"precision\": 0.9997592102094871, \"recall\": 0.23221400113830393, \"specificity\": 0.9999999867056404, \"npv\": 0.9998175275496753, \"accuracy\": 0.9998175243306541, \"f1\": 0.37688820542393514, \"f2\": 0.27433741823397034, \"f0_5\": 0.6018776700519302, \"p4\": 0.5474355717699365, \"phi\": 0.4817838731538196}, {\"truth_threshold\": 20.499999541789293, \"match_probability\": 0.9999993256506644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70496.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.231924490312902, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.768075509687098, \"precision\": 0.9997589097045935, \"recall\": 0.231924490312902, \"specificity\": 0.9999999867056404, \"npv\": 0.9998174587569303, \"accuracy\": 0.9998174555291472, \"f1\": 0.3765067801769949, \"f2\": 0.2740141344898811, \"f0_5\": 0.6014883628861476, \"p4\": 0.5470330899544352, \"phi\": 0.48148336055935803}, {\"truth_threshold\": 20.51999954134226, \"match_probability\": 0.9999993349346246, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70418.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23166787844493208, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7683321215550679, \"precision\": 0.9997586427202385, \"recall\": 0.23166787844493208, \"specificity\": 0.9999999867056404, \"npv\": 0.9998173977815505, \"accuracy\": 0.9998173945459934, \"f1\": 0.37616854880928213, \"f2\": 0.2737275505547397, \"f0_5\": 0.6011429039731877, \"p4\": 0.546675999899731, \"phi\": 0.4812168402692405}, {\"truth_threshold\": 20.539999540895224, \"match_probability\": 0.99999934409077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70346.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233615.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2314310059514214, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7685689940485786, \"precision\": 0.9997583957477651, \"recall\": 0.2314310059514214, \"specificity\": 0.9999999867056404, \"npv\": 0.9998173414965913, \"accuracy\": 0.9998173382538513, \"f1\": 0.3758562101281243, \"f2\": 0.27346298068662356, \"f0_5\": 0.6008236919918075, \"p4\": 0.5463460903047619, \"phi\": 0.48097069048578817}, {\"truth_threshold\": 20.55999954044819, \"match_probability\": 0.9999993531208601, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70239.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2310789871068986, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7689210128931014, \"precision\": 0.9997580277841038, \"recall\": 0.2310789871068986, \"specificity\": 0.9999999867056404, \"npv\": 0.9998172578508996, \"accuracy\": 0.9998172545974736, \"f1\": 0.3753918181162267, \"f2\": 0.2730697457429438, \"f0_5\": 0.6003487268904331, \"p4\": 0.5458552964675392, \"phi\": 0.4806046517179294}, {\"truth_threshold\": 20.579999540001154, \"match_probability\": 0.9999993620266305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70140.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233821.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2307532874283214, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7692467125716786, \"precision\": 0.9997576863320837, \"recall\": 0.2307532874283214, \"specificity\": 0.9999999867056404, \"npv\": 0.9998171804591038, \"accuracy\": 0.9998171771957783, \"f1\": 0.3749619104132921, \"f2\": 0.27270585326138935, \"f0_5\": 0.5999086537721373, \"p4\": 0.5454006519474436, \"phi\": 0.4802657319173265}, {\"truth_threshold\": 20.59999953955412, \"match_probability\": 0.9999993708097926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70047.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23044732712420343, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7695526728757965, \"precision\": 0.9997573646951359, \"recall\": 0.23044732712420343, \"specificity\": 0.9999999867056404, \"npv\": 0.9998171077577308, \"accuracy\": 0.999817104485095, \"f1\": 0.37455785041106876, \"f2\": 0.2723639638294497, \"f0_5\": 0.599494708301881, \"p4\": 0.5449730831507531, \"phi\": 0.47994713474469913}, {\"truth_threshold\": 20.619999539107084, \"match_probability\": 0.9999993794720347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69958.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234003.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23015452640305828, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7698454735969417, \"precision\": 0.9997570560914613, \"recall\": 0.23015452640305828, \"specificity\": 0.9999999867056404, \"npv\": 0.9998170381833086, \"accuracy\": 0.9998170349017528, \"f1\": 0.3741709811304608, \"f2\": 0.27203673300830056, \"f0_5\": 0.5990980730002518, \"p4\": 0.5445634696374351, \"phi\": 0.4796420425524416}, {\"truth_threshold\": 20.63999953866005, \"match_probability\": 0.9999993880150211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69883.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.229907784222318, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.770092215777682, \"precision\": 0.9997567954220314, \"recall\": 0.229907784222318, \"specificity\": 0.9999999867056404, \"npv\": 0.9998169795531849, \"accuracy\": 0.9998169762641048, \"f1\": 0.3738448246808306, \"f2\": 0.271760941524907, \"f0_5\": 0.5987634540347967, \"p4\": 0.5442179590691439, \"phi\": 0.47938479166802606}, {\"truth_threshold\": 20.659999538213015, \"match_probability\": 0.9999993964403938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69821.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234140.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22970381068623935, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7702961893137606, \"precision\": 0.9997565795125862, \"recall\": 0.22970381068623935, \"specificity\": 0.9999999867056404, \"npv\": 0.9998169310856212, \"accuracy\": 0.9998169277903158, \"f1\": 0.3735751031971728, \"f2\": 0.27153292960467673, \"f0_5\": 0.5984865758177856, \"p4\": 0.5439321083671337, \"phi\": 0.4791720266843012}, {\"truth_threshold\": 20.67999953776598, \"match_probability\": 0.9999994047497722, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69740.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22943732913103984, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7705626708689601, \"precision\": 0.9997562968590966, \"recall\": 0.22943732913103984, \"specificity\": 0.9999999867056404, \"npv\": 0.9998168677651016, \"accuracy\": 0.9998168644616561, \"f1\": 0.37322259029535637, \"f2\": 0.2712350099292082, \"f0_5\": 0.5981244929149606, \"p4\": 0.5435583460805452, \"phi\": 0.4788939171400615}, {\"truth_threshold\": 20.699999537318945, \"match_probability\": 0.9999994129447529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69666.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234295.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22919387684604275, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7708061231539572, \"precision\": 0.9997560380580629, \"recall\": 0.22919387684604275, \"specificity\": 0.9999999867056404, \"npv\": 0.9998168099167326, \"accuracy\": 0.9998168066058435, \"f1\": 0.37290040787487555, \"f2\": 0.27096280358172176, \"f0_5\": 0.5977933491564168, \"p4\": 0.5432165747157348, \"phi\": 0.47863970053548904}, {\"truth_threshold\": 20.71999953687191, \"match_probability\": 0.9999994210269112, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69587.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234374.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22893397508232963, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7710660249176704, \"precision\": 0.9997557611631516, \"recall\": 0.22893397508232963, \"specificity\": 0.9999999867056404, \"npv\": 0.9998167481596975, \"accuracy\": 0.9998167448408543, \"f1\": 0.37255631550064916, \"f2\": 0.270672170325054, \"f0_5\": 0.5974394593193069, \"p4\": 0.5428513840717986, \"phi\": 0.4783681580682628}, {\"truth_threshold\": 20.739999536424875, \"match_probability\": 0.9999994289978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69474.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234487.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2285622168633476, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7714377831366523, \"precision\": 0.9997553640039717, \"recall\": 0.2285622168633476, \"specificity\": 0.9999999867056404, \"npv\": 0.9998166598236984, \"accuracy\": 0.9998166564934647, \"f1\": 0.3720638796953825, \"f2\": 0.2702563923023959, \"f0_5\": 0.5969325944064957, \"p4\": 0.5423284355806072, \"phi\": 0.4779794811411524}, {\"truth_threshold\": 20.75999953597784, \"match_probability\": 0.9999994368589514, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69378.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22824638687200002, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.771753613128, \"precision\": 0.9997550255782117, \"recall\": 0.22824638687200002, \"specificity\": 0.9999999867056404, \"npv\": 0.9998165847771981, \"accuracy\": 0.9998165814372754, \"f1\": 0.3716452929643557, \"f2\": 0.2699031075154115, \"f0_5\": 0.5965013644781709, \"p4\": 0.541883616818843, \"phi\": 0.47764902930371844}, {\"truth_threshold\": 20.779999535530806, \"match_probability\": 0.9999994446118762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69305.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234656.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22800622448274613, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7719937755172539, \"precision\": 0.9997547676062434, \"recall\": 0.22800622448274613, \"specificity\": 0.9999999867056404, \"npv\": 0.9998165277105961, \"accuracy\": 0.999816524363298, \"f1\": 0.37132684853047154, \"f2\": 0.2696344285485299, \"f0_5\": 0.5961730686848493, \"p4\": 0.5415450342084479, \"phi\": 0.47739759515299235}, {\"truth_threshold\": 20.79999953508377, \"match_probability\": 0.9999994522580643, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69257.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234704.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22784830948707235, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7721516905129276, \"precision\": 0.999754597684557, \"recall\": 0.22784830948707235, \"specificity\": 0.9999999867056404, \"npv\": 0.9998164901873545, \"accuracy\": 0.9998164868352034, \"f1\": 0.3711173925274961, \"f2\": 0.26945774629255836, \"f0_5\": 0.5959570231491919, \"p4\": 0.5413222466303728, \"phi\": 0.47723219641502757}, {\"truth_threshold\": 20.819999534636736, \"match_probability\": 0.9999994597989851, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69109.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22736140491707818, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7726385950829219, \"precision\": 0.9997540722738189, \"recall\": 0.22736140491707818, \"specificity\": 0.9999999867056404, \"npv\": 0.9998163744907107, \"accuracy\": 0.9998163711235781, \"f1\": 0.3704712305708856, \"f2\": 0.26891289290800563, \"f0_5\": 0.595289983030846, \"p4\": 0.5406345283075622, \"phi\": 0.4767218558041219}, {\"truth_threshold\": 20.8399995341897, \"match_probability\": 0.999999467236088, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68994.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234967.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22698306690660974, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7730169330933903, \"precision\": 0.9997536624596078, \"recall\": 0.22698306690660974, \"specificity\": 0.9999999867056404, \"npv\": 0.9998162845913099, \"accuracy\": 0.999816281212518, \"f1\": 0.36996879122293364, \"f2\": 0.26848944044269585, \"f0_5\": 0.5947707347350454, \"p4\": 0.5400993274361686, \"phi\": 0.4763249299382225}, {\"truth_threshold\": 20.859999533742666, \"match_probability\": 0.9999994745708022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68939.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235022.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22680212264073352, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7731978773592665, \"precision\": 0.9997534659783051, \"recall\": 0.22680212264073352, \"specificity\": 0.9999999867056404, \"npv\": 0.9998162415959501, \"accuracy\": 0.9998162382115762, \"f1\": 0.3697283846003266, \"f2\": 0.26828689290161895, \"f0_5\": 0.5945221073328907, \"p4\": 0.5398431062377909, \"phi\": 0.47613497888369766}, {\"truth_threshold\": 20.87999953329563, \"match_probability\": 0.9999994818045373, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68854.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235107.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22652248150256118, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7734775184974388, \"precision\": 0.999753161708121, \"recall\": 0.22652248150256118, \"specificity\": 0.9999999867056404, \"npv\": 0.999816175148583, \"accuracy\": 0.9998161717555752, \"f1\": 0.3693567075787486, \"f2\": 0.2679738307718054, \"f0_5\": 0.5941374936361519, \"p4\": 0.5394468022711372, \"phi\": 0.4758412690488456}, {\"truth_threshold\": 20.899999532848597, \"match_probability\": 0.9999994889386836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68780.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2262790292175641, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.773720970782436, \"precision\": 0.9997528962018692, \"recall\": 0.2262790292175641, \"specificity\": 0.9999999867056404, \"npv\": 0.9998161173002942, \"accuracy\": 0.9998161138997625, \"f1\": 0.3690329919143251, \"f2\": 0.2677012488313856, \"f0_5\": 0.5938022857675659, \"p4\": 0.5391014622120909, \"phi\": 0.47558542105766644}, {\"truth_threshold\": 20.91999953240156, \"match_probability\": 0.999999495974612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68688.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235273.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22597635880918934, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7740236411908107, \"precision\": 0.9997525653154792, \"recall\": 0.22597635880918934, \"specificity\": 0.9999999867056404, \"npv\": 0.9998160453808093, \"accuracy\": 0.9998160419709144, \"f1\": 0.3686303553315838, \"f2\": 0.26736231938213334, \"f0_5\": 0.5933850627439394, \"p4\": 0.5386717013168694, \"phi\": 0.475267147756378}, {\"truth_threshold\": 20.939999531954527, \"match_probability\": 0.9999995029136749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68635.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235326.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22580199433479953, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7741980056652005, \"precision\": 0.9997523742935385, \"recall\": 0.22580199433479953, \"specificity\": 0.9999999867056404, \"npv\": 0.9998160039489369, \"accuracy\": 0.9998160005336433, \"f1\": 0.3683983113847343, \"f2\": 0.26716704450617207, \"f0_5\": 0.593144465050841, \"p4\": 0.5384239104537893, \"phi\": 0.4750836978812583}, {\"truth_threshold\": 20.959999531507492, \"match_probability\": 0.9999995097572058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68563.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235398.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22556512184128885, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7744348781587111, \"precision\": 0.9997521143190434, \"recall\": 0.22556512184128885, \"specificity\": 0.9999999867056404, \"npv\": 0.9998159476641345, \"accuracy\": 0.9998159442415012, \"f1\": 0.3680829761019592, \"f2\": 0.26690173961246444, \"f0_5\": 0.5928173327499953, \"p4\": 0.5380870412291852, \"phi\": 0.4748343694397861}, {\"truth_threshold\": 20.979999531060457, \"match_probability\": 0.9999995165065197, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68491.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235470.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22532824934777818, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7746717506522218, \"precision\": 0.9997518537980966, \"recall\": 0.22532824934777818, \"specificity\": 0.9999999867056404, \"npv\": 0.9998158913793385, \"accuracy\": 0.9998158879493593, \"f1\": 0.3677675189076138, \"f2\": 0.2666364049730915, \"f0_5\": 0.5924898744448462, \"p4\": 0.5377498863522437, \"phi\": 0.47458491003899866}, {\"truth_threshold\": 20.999999530613422, \"match_probability\": 0.9999995231629142, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68390.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235571.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22499596987771459, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7750040301222855, \"precision\": 0.9997514874208779, \"recall\": 0.22499596987771459, \"specificity\": 0.9999999867056404, \"npv\": 0.999815812424288, \"accuracy\": 0.9998158089839934, \"f1\": 0.36732479697503545, \"f2\": 0.26626414929791764, \"f0_5\": 0.5920299728699819, \"p4\": 0.5372764508835689, \"phi\": 0.47423475283671945}, {\"truth_threshold\": 21.019999530166388, \"match_probability\": 0.9999995297276678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68292.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235669.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2246735600948806, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7753264399051194, \"precision\": 0.9997511308905123, \"recall\": 0.2246735600948806, \"specificity\": 0.9999999867056404, \"npv\": 0.999815735814449, \"accuracy\": 0.9998157323641333, \"f1\": 0.3668949955677331, \"f2\": 0.26590289474852297, \"f0_5\": 0.5915831163363635, \"p4\": 0.5368165389127921, \"phi\": 0.4738947490813622}, {\"truth_threshold\": 21.039999529719353, \"match_probability\": 0.9999995362020428, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68171.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22427548270995293, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7757245172900471, \"precision\": 0.9997506892708394, \"recall\": 0.22427548270995293, \"specificity\": 0.9999999867056404, \"npv\": 0.9998156412247661, \"accuracy\": 0.9998156377620614, \"f1\": 0.3663640101142284, \"f2\": 0.265456779893336, \"f0_5\": 0.5910305472566078, \"p4\": 0.5362479547303323, \"phi\": 0.47347461176278927}, {\"truth_threshold\": 21.059999529272318, \"match_probability\": 0.9999995425872834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68100.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22404190011218544, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7759580998878145, \"precision\": 0.9997504294082241, \"recall\": 0.22404190011218544, \"specificity\": 0.9999999867056404, \"npv\": 0.9998155857217372, \"accuracy\": 0.9998155822517547, \"f1\": 0.36605227936077916, \"f2\": 0.2651949708752836, \"f0_5\": 0.590705880516074, \"p4\": 0.5359139446089157, \"phi\": 0.4732279112950672}, {\"truth_threshold\": 21.079999528825283, \"match_probability\": 0.9999995488846164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67999.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235962.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22370962064212185, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7762903793578781, \"precision\": 0.9997500588096918, \"recall\": 0.22370962064212185, \"specificity\": 0.9999999867056404, \"npv\": 0.9998155067667351, \"accuracy\": 0.9998155032863888, \"f1\": 0.36560862633980057, \"f2\": 0.2648224884333183, \"f0_5\": 0.5902434790156678, \"p4\": 0.5354383208079748, \"phi\": 0.47287674947437036}, {\"truth_threshold\": 21.099999528378248, \"match_probability\": 0.9999995550952523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67914.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22342997950394952, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7765700204960505, \"precision\": 0.999749746065861, \"recall\": 0.22342997950394952, \"specificity\": 0.9999999867056404, \"npv\": 0.9998154403194658, \"accuracy\": 0.9998154368303879, \"f1\": 0.3652350682456197, \"f2\": 0.26450896769293686, \"f0_5\": 0.5898538263112639, \"p4\": 0.5350376034390601, \"phi\": 0.472581015084563}, {\"truth_threshold\": 21.119999527931213, \"match_probability\": 0.9999995612203846, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67838.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236123.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22317994742746602, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.776820052572534, \"precision\": 0.9997494657726034, \"recall\": 0.22317994742746602, \"specificity\": 0.9999999867056404, \"npv\": 0.9998153809077971, \"accuracy\": 0.9998153774109045, \"f1\": 0.36490091873399744, \"f2\": 0.2642286081082871, \"f0_5\": 0.5895050410076106, \"p4\": 0.5346789739744288, \"phi\": 0.4723164369825599}, {\"truth_threshold\": 21.13999952748418, \"match_probability\": 0.9999995672611905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67738.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22285095785314563, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7771490421468543, \"precision\": 0.9997490960076747, \"recall\": 0.22285095785314563, \"specificity\": 0.9999999867056404, \"npv\": 0.9998153027345595, \"accuracy\": 0.999815299227374, \"f1\": 0.3644610401489309, \"f2\": 0.26385966333722605, \"f0_5\": 0.5890455510703831, \"p4\": 0.5342066018647846, \"phi\": 0.47196808197911216}, {\"truth_threshold\": 21.159999527037144, \"match_probability\": 0.9999995732188309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67628.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236333.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2224890693213932, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7775109306786068, \"precision\": 0.9997486880035479, \"recall\": 0.2224890693213932, \"specificity\": 0.9999999867056404, \"npv\": 0.9998152167440124, \"accuracy\": 0.9998152132254904, \"f1\": 0.3639769002653348, \"f2\": 0.2634537576870546, \"f0_5\": 0.5885393731691907, \"p4\": 0.5336863467065941, \"phi\": 0.47158459432638433}, {\"truth_threshold\": 21.17999952659011, \"match_probability\": 0.9999995790944508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67535.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236426.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22218310901727525, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7778168909827248, \"precision\": 0.999748342018001, \"recall\": 0.22218310901727525, \"specificity\": 0.9999999867056404, \"npv\": 0.999815144042925, \"accuracy\": 0.9998151405148069, \"f1\": 0.3635673583427767, \"f2\": 0.2631105286287319, \"f0_5\": 0.5881108175467502, \"p4\": 0.5332459658456867, \"phi\": 0.47126012955119173}, {\"truth_threshold\": 21.199999526143074, \"match_probability\": 0.9999995848891793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67476.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236485.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2219890051684262, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7780109948315738, \"precision\": 0.9997481220274695, \"recall\": 0.2219890051684262, \"specificity\": 0.9999999867056404, \"npv\": 0.9998150979207353, \"accuracy\": 0.9998150943865239, \"f1\": 0.3633074351063658, \"f2\": 0.26289275537134826, \"f0_5\": 0.5878386501560287, \"p4\": 0.5329663328691214, \"phi\": 0.47105417046311987}, {\"truth_threshold\": 21.21999952569604, \"match_probability\": 0.9999995906041301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67415.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236546.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22178832152809078, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7782116784719092, \"precision\": 0.9997478941748724, \"recall\": 0.22178832152809078, \"specificity\": 0.9999999867056404, \"npv\": 0.999815050235086, \"accuracy\": 0.9998150466945702, \"f1\": 0.36303861408265636, \"f2\": 0.26266757891521386, \"f0_5\": 0.5875570213129413, \"p4\": 0.5326770152088737, \"phi\": 0.470841135006078}, {\"truth_threshold\": 21.239999525249004, \"match_probability\": 0.9999995962404017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67330.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22150868038991844, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7784913196100816, \"precision\": 0.9997475759870521, \"recall\": 0.22150868038991844, \"specificity\": 0.9999999867056404, \"npv\": 0.9998149837878773, \"accuracy\": 0.9998149802385693, \"f1\": 0.36266388012108547, \"f2\": 0.26235377274310684, \"f0_5\": 0.5871641879553291, \"p4\": 0.5322735186612366, \"phi\": 0.4705441215171745}, {\"truth_threshold\": 21.25999952480197, \"match_probability\": 0.9999996017990771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67232.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236729.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22118627060708446, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7788137293929155, \"precision\": 0.999747208136924, \"recall\": 0.22118627060708446, \"specificity\": 0.9999999867056404, \"npv\": 0.9998149071781653, \"accuracy\": 0.9998149036187093, \"f1\": 0.3622316209153848, \"f2\": 0.261991921084442, \"f0_5\": 0.586710695567032, \"p4\": 0.5318078058151522, \"phi\": 0.4702014496342338}, {\"truth_threshold\": 21.279999524354935, \"match_probability\": 0.9999996072812246, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67159.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2209461082178306, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7790538917821694, \"precision\": 0.9997469334286054, \"recall\": 0.2209461082178306, \"specificity\": 0.9999999867056404, \"npv\": 0.9998148501117547, \"accuracy\": 0.999814846544732, \"f1\": 0.3619094835599792, \"f2\": 0.261722342597933, \"f0_5\": 0.5863724865322658, \"p4\": 0.5314605451830146, \"phi\": 0.46994603169723903}, {\"truth_threshold\": 21.2999995239079, \"match_probability\": 0.9999996126878977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67070.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22065330749668544, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7793466925033146, \"precision\": 0.9997465977014921, \"recall\": 0.22065330749668544, \"specificity\": 0.9999999867056404, \"npv\": 0.9998147805376467, \"accuracy\": 0.9998147769613898, \"f1\": 0.36151656928483644, \"f2\": 0.2613936369142222, \"f0_5\": 0.5859596826190048, \"p4\": 0.5310367653433115, \"phi\": 0.46963444386659187}, {\"truth_threshold\": 21.319999523460865, \"match_probability\": 0.9999996180201358, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66961.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237000.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2202947088606762, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7797052911393237, \"precision\": 0.9997461853145809, \"recall\": 0.2202947088606762, \"specificity\": 0.9999999867056404, \"npv\": 0.9998146953289208, \"accuracy\": 0.9998146917413414, \"f1\": 0.36103510280666096, \"f2\": 0.2609910026488476, \"f0_5\": 0.5854534136075668, \"p4\": 0.5305171434360266, \"phi\": 0.4692525544963603}, {\"truth_threshold\": 21.33999952301383, \"match_probability\": 0.9999996232789633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66895.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237066.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22007757574162476, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7799224242583752, \"precision\": 0.9997459349593496, \"recall\": 0.22007757574162476, \"specificity\": 0.9999999867056404, \"npv\": 0.9998146437346535, \"accuracy\": 0.9998146401402113, \"f1\": 0.36074343508424717, \"f2\": 0.26074717249422336, \"f0_5\": 0.5851464899957838, \"p4\": 0.5302021826780087, \"phi\": 0.4690211676218398}, {\"truth_threshold\": 21.359999522566795, \"match_probability\": 0.9999996284653911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66802.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237159.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21977161543750678, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7802283845624932, \"precision\": 0.999745581346623, \"recall\": 0.21977161543750678, \"specificity\": 0.9999999867056404, \"npv\": 0.9998145710336493, \"accuracy\": 0.9998145674295279, \"f1\": 0.3603322725066077, \"f2\": 0.2604035510496522, \"f0_5\": 0.5847135252093264, \"p4\": 0.5297579546278954, \"phi\": 0.4686949286338192}, {\"truth_threshold\": 21.37999952211976, \"match_probability\": 0.9999996335804159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66732.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237229.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21954132273548252, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7804586772645175, \"precision\": 0.9997453145365474, \"recall\": 0.21954132273548252, \"specificity\": 0.9999999867056404, \"npv\": 0.9998145163124705, \"accuracy\": 0.9998145127010565, \"f1\": 0.3600226592214939, \"f2\": 0.26014487838308803, \"f0_5\": 0.5843872655909289, \"p4\": 0.5294232651299315, \"phi\": 0.4684492225730989}, {\"truth_threshold\": 21.399999521672726, \"match_probability\": 0.9999996386250206, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66652.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237309.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2192781310760262, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7807218689239738, \"precision\": 0.9997450089246877, \"recall\": 0.2192781310760262, \"specificity\": 0.9999999867056404, \"npv\": 0.9998144537739877, \"accuracy\": 0.999814450154232, \"f1\": 0.3596686722607452, \"f2\": 0.2598492179026645, \"f0_5\": 0.5840140054009817, \"p4\": 0.52904042128498, \"phi\": 0.4681682577785679}, {\"truth_threshold\": 21.41999952122569, \"match_probability\": 0.9999996436001749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66571.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2190116495208267, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7809883504791734, \"precision\": 0.9997446987445185, \"recall\": 0.2190116495208267, \"specificity\": 0.9999999867056404, \"npv\": 0.9998143904537818, \"accuracy\": 0.9998143868255722, \"f1\": 0.3593101047364856, \"f2\": 0.25954982408423993, \"f0_5\": 0.5836356527029894, \"p4\": 0.5286524201892019, \"phi\": 0.4678836090635757}, {\"truth_threshold\": 21.439999520778656, \"match_probability\": 0.9999996485068348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66507.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21880109619326163, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7811989038067384, \"precision\": 0.9997444531296975, \"recall\": 0.21880109619326163, \"specificity\": 0.9999999867056404, \"npv\": 0.9998143404230075, \"accuracy\": 0.9998143367881126, \"f1\": 0.35902668124215553, \"f2\": 0.2593132392573739, \"f0_5\": 0.583336403201785, \"p4\": 0.5283455865631626, \"phi\": 0.4676585789338756}, {\"truth_threshold\": 21.45999952033162, \"match_probability\": 0.9999996533459433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66448.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237513.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2186069923444126, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7813930076555874, \"precision\": 0.9997442262845107, \"recall\": 0.2186069923444126, \"specificity\": 0.9999999867056404, \"npv\": 0.999814294300892, \"accuracy\": 0.9998142906598296, \"f1\": 0.3587653134499198, \"f2\": 0.259095116699641, \"f0_5\": 0.5830602943731452, \"p4\": 0.5280625169414155, \"phi\": 0.4674510333381617}, {\"truth_threshold\": 21.479999519884586, \"match_probability\": 0.9999996581184304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66363.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21832735120624028, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7816726487937598, \"precision\": 0.9997438987646882, \"recall\": 0.21832735120624028, \"specificity\": 0.9999999867056404, \"npv\": 0.9998142278537837, \"accuracy\": 0.9998142242038286, \"f1\": 0.3583886202175833, \"f2\": 0.2587808370456332, \"f0_5\": 0.5826621081300342, \"p4\": 0.5276543545759275, \"phi\": 0.467151864892775}, {\"truth_threshold\": 21.49999951943755, \"match_probability\": 0.9999996628252132, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66284.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237677.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21806744944252718, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7819325505574728, \"precision\": 0.9997435936109561, \"recall\": 0.21806744944252718, \"specificity\": 0.9999999867056404, \"npv\": 0.9998141660970675, \"accuracy\": 0.9998141624388395, \"f1\": 0.35803836202472844, \"f2\": 0.2584887044757028, \"f0_5\": 0.5822916026108422, \"p4\": 0.5272746324942819, \"phi\": 0.4668736423718251}, {\"truth_threshold\": 21.519999518990517, \"match_probability\": 0.9999996674671966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66236.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21790953444685338, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7820904655531467, \"precision\": 0.9997434078456825, \"recall\": 0.21790953444685338, \"specificity\": 0.9999999867056404, \"npv\": 0.9998141285740032, \"accuracy\": 0.9998141249107448, \"f1\": 0.35782547391508696, \"f2\": 0.2583111886230137, \"f0_5\": 0.5820662843403817, \"p4\": 0.5270437404144587, \"phi\": 0.4667045147902258}, {\"truth_threshold\": 21.539999518543482, \"match_probability\": 0.9999996720452723, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66165.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237796.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2176759518490859, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.782324048150914, \"precision\": 0.9997431325738116, \"recall\": 0.2176759518490859, \"specificity\": 0.9999999867056404, \"npv\": 0.9998140730711423, \"accuracy\": 0.999814069400438, \"f1\": 0.35751047568102057, \"f2\": 0.25804858871816955, \"f0_5\": 0.581732722102942, \"p4\": 0.5267019698976625, \"phi\": 0.4664542344945589}, {\"truth_threshold\": 21.559999518096447, \"match_probability\": 0.9999996765603204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66061.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237900.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2173338026917927, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7826661973082073, \"precision\": 0.9997427282908078, \"recall\": 0.2173338026917927, \"specificity\": 0.9999999867056404, \"npv\": 0.9998139917711883, \"accuracy\": 0.9998139880895663, \"f1\": 0.35704885160753325, \"f2\": 0.25766388282594416, \"f0_5\": 0.5812435220395831, \"p4\": 0.5262008249093226, \"phi\": 0.4660873841767688}, {\"truth_threshold\": 21.579999517649412, \"match_probability\": 0.9999996810132086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66015.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237946.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2171824674876053, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7828175325123947, \"precision\": 0.999742549067119, \"recall\": 0.2171824674876053, \"specificity\": 0.9999999867056404, \"npv\": 0.9998139558115975, \"accuracy\": 0.9998139521251422, \"f1\": 0.35684458895168286, \"f2\": 0.2574937045392846, \"f0_5\": 0.5810269165570887, \"p4\": 0.5259789659372845, \"phi\": 0.4659250313455832}, {\"truth_threshold\": 21.599999517202377, \"match_probability\": 0.9999996854047924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65928.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 238033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21689624655794656, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7831037534420534, \"precision\": 0.9997422094169384, \"recall\": 0.21689624655794656, \"specificity\": 0.9999999867056404, \"npv\": 0.999813887801074, \"accuracy\": 0.9998138841054707, \"f1\": 0.35645812719988323, \"f2\": 0.25717181220934177, \"f0_5\": 0.5806168657891538, \"p4\": 0.5255590294343306, \"phi\": 0.4656178179819139}, {\"truth_threshold\": 21.619999516755342, \"match_probability\": 0.9999996897359162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65843.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21661660541977426, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7833833945802258, \"precision\": 0.9997722372376933, \"recall\": 0.21661660541977426, \"specificity\": 0.9999999882696827, \"npv\": 0.999813821354311, \"accuracy\": 0.9998138192131403, \"f1\": 0.35608229971959254, \"f2\": 0.25685767830587763, \"f0_5\": 0.5802239364955154, \"p4\": 0.5251504188540765, \"phi\": 0.46532453955456715}, {\"truth_threshold\": 21.639999516308308, \"match_probability\": 0.9999996940074122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65736.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21626458657525144, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7837354134247486, \"precision\": 0.9997718665875804, \"recall\": 0.21626458657525144, \"specificity\": 0.9999999882696827, \"npv\": 0.9998137377092084, \"accuracy\": 0.9998137355567626, \"f1\": 0.3556065261609036, \"f2\": 0.2564616747100293, \"f0_5\": 0.5797183247643153, \"p4\": 0.5246328189290462, \"phi\": 0.4649461858477405}, {\"truth_threshold\": 21.659999515861273, \"match_probability\": 0.9999996982201012, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65651.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238310.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2159849454370791, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7840150545629209, \"precision\": 0.9997715712849876, \"recall\": 0.2159849454370791, \"specificity\": 0.9999999882696827, \"npv\": 0.9998136712621742, \"accuracy\": 0.9998136691007615, \"f1\": 0.3552283788792485, \"f2\": 0.2561470452825183, \"f0_5\": 0.5793161261857489, \"p4\": 0.5242211686241319, \"phi\": 0.4646454049550111}, {\"truth_threshold\": 21.679999515414238, \"match_probability\": 0.9999997023747929, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65568.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21571188409039319, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7842881159096068, \"precision\": 0.9997712821920315, \"recall\": 0.21571188409039319, \"specificity\": 0.9999999882696827, \"npv\": 0.9998136063786083, \"accuracy\": 0.9998136042084312, \"f1\": 0.35485896131448486, \"f2\": 0.2558397786218021, \"f0_5\": 0.5789229250582296, \"p4\": 0.5238187995819946, \"phi\": 0.46435151329182783}, {\"truth_threshold\": 21.699999514967203, \"match_probability\": 0.9999997064722858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65510.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238451.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21552107013728736, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7844789298627126, \"precision\": 0.999771079740557, \"recall\": 0.21552107013728736, \"specificity\": 0.9999999882696827, \"npv\": 0.9998135610382901, \"accuracy\": 0.9998135588619834, \"f1\": 0.35460071558868267, \"f2\": 0.2556250385330065, \"f0_5\": 0.5786478842386245, \"p4\": 0.5235373884039283, \"phi\": 0.46414603278279576}, {\"truth_threshold\": 21.71999951452017, \"match_probability\": 0.9999997105133673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65437.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21528090774803346, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7847190922519666, \"precision\": 0.9997708244209497, \"recall\": 0.21528090774803346, \"specificity\": 0.9999999882696827, \"npv\": 0.9998135039720333, \"accuracy\": 0.9998135017880061, \"f1\": 0.3542755669129132, \"f2\": 0.2553547345812365, \"f0_5\": 0.5783013915573317, \"p4\": 0.5231829202414036, \"phi\": 0.4638872814183511}, {\"truth_threshold\": 21.739999514073133, \"match_probability\": 0.9999997144988141, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65324.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238637.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21490914952905144, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7850908504709486, \"precision\": 0.999770428075116, \"recall\": 0.21490914952905144, \"specificity\": 0.9999999882696827, \"npv\": 0.9998134156366076, \"accuracy\": 0.9998134134406166, \"f1\": 0.3537720010831302, \"f2\": 0.2549362581301812, \"f0_5\": 0.5777643339931401, \"p4\": 0.5226336105433529, \"phi\": 0.46348646367464835}, {\"truth_threshold\": 21.7599995136261, \"match_probability\": 0.9999997184293921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65210.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238751.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2145341014143262, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7854658985856738, \"precision\": 0.9997700268302031, \"recall\": 0.2145341014143262, \"specificity\": 0.9999999882696827, \"npv\": 0.9998133265194684, \"accuracy\": 0.9998133243113917, \"f1\": 0.35326366655290287, \"f2\": 0.2545140035392317, \"f0_5\": 0.5772216527605907, \"p4\": 0.5220786843270533, \"phi\": 0.4630817473990535}, {\"truth_threshold\": 21.779999513179064, \"match_probability\": 0.9999997223058567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65123.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21424788048466745, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7857521195153325, \"precision\": 0.9997697196720808, \"recall\": 0.21424788048466745, \"specificity\": 0.9999999882696827, \"npv\": 0.9998132585090307, \"accuracy\": 0.9998132562917201, \"f1\": 0.3528755157830284, \"f2\": 0.2541917060505144, \"f0_5\": 0.5768069114440234, \"p4\": 0.5216546766012023, \"phi\": 0.4627726468995647}, {\"truth_threshold\": 21.79999951273203, \"match_probability\": 0.9999997261289529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65044.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21398797872095432, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7860120212790457, \"precision\": 0.9997694400467269, \"recall\": 0.21398797872095432, \"specificity\": 0.9999999882696827, \"npv\": 0.9998131967524343, \"accuracy\": 0.999813194526731, \"f1\": 0.3525228984878868, \"f2\": 0.2538990071847751, \"f0_5\": 0.5764298640368524, \"p4\": 0.5212692739304141, \"phi\": 0.46249179050853745}, {\"truth_threshold\": 21.819999512284994, \"match_probability\": 0.9999997298994154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64936.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2136326699806883, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7863673300193117, \"precision\": 0.9997690566734924, \"recall\": 0.2136326699806883, \"specificity\": 0.9999999882696827, \"npv\": 0.9998131123257074, \"accuracy\": 0.9998131100885179, \"f1\": 0.3520405950470573, \"f2\": 0.2534988034775276, \"f0_5\": 0.5759137229164634, \"p4\": 0.5207418017337891, \"phi\": 0.462107558803111}, {\"truth_threshold\": 21.83999951183796, \"match_probability\": 0.9999997336179689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64813.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239148.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21322801280427423, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7867719871957257, \"precision\": 0.9997686184981798, \"recall\": 0.21322801280427423, \"specificity\": 0.9999999882696827, \"npv\": 0.9998130161730635, \"accuracy\": 0.9998130139227753, \"f1\": 0.3514909609559938, \"f2\": 0.25304293370980235, \"f0_5\": 0.5753249312500333, \"p4\": 0.5201402342528285, \"phi\": 0.46166957217385196}, {\"truth_threshold\": 21.859999511390924, \"match_probability\": 0.999999737285328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64751.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239210.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2130240392681956, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7869759607318044, \"precision\": 0.9997683969984251, \"recall\": 0.2130240392681956, \"specificity\": 0.9999999882696827, \"npv\": 0.9998129677058841, \"accuracy\": 0.9998129654489865, \"f1\": 0.35121377062162523, \"f2\": 0.2528131125010737, \"f0_5\": 0.5750277518760268, \"p4\": 0.5198366673375533, \"phi\": 0.4614486408703798}, {\"truth_threshold\": 21.87999951094389, \"match_probability\": 0.9999997409021976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64694.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21283651521083297, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.787163484789167, \"precision\": 0.9997681929870652, \"recall\": 0.21283651521083297, \"specificity\": 0.9999999882696827, \"npv\": 0.9998129231473525, \"accuracy\": 0.999812920884374, \"f1\": 0.35095885208994493, \"f2\": 0.2526018056261631, \"f0_5\": 0.5747543075034159, \"p4\": 0.5195573815822534, \"phi\": 0.4612454332599953}, {\"truth_threshold\": 21.899999510496855, \"match_probability\": 0.9999997444692725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64608.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239353.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21255358417691744, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7874464158230826, \"precision\": 0.9997678844993269, \"recall\": 0.21255358417691744, \"specificity\": 0.9999999882696827, \"npv\": 0.9998128559186981, \"accuracy\": 0.9998128536465377, \"f1\": 0.3505740889458034, \"f2\": 0.2522829561402207, \"f0_5\": 0.5743413227416335, \"p4\": 0.5191356399360093, \"phi\": 0.46093866980832593}, {\"truth_threshold\": 21.91999951004982, \"match_probability\": 0.9999997479872386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64501.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239460.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21220156533239462, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7877984346676054, \"precision\": 0.9997674995349991, \"recall\": 0.21220156533239462, \"specificity\": 0.9999999882696827, \"npv\": 0.9998127722737571, \"accuracy\": 0.99981276999016, \"f1\": 0.35009512126944153, \"f2\": 0.251886188259552, \"f0_5\": 0.5738267870646323, \"p4\": 0.5186103041575395, \"phi\": 0.46055671380168245}, {\"truth_threshold\": 21.939999509602785, \"match_probability\": 0.9999997514567718, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64443.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2120107513792888, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7879892486207112, \"precision\": 0.999767290328586, \"recall\": 0.2120107513792888, \"specificity\": 0.9999999882696827, \"npv\": 0.9998127269335145, \"accuracy\": 0.9998127246437123, \"f1\": 0.34983537765424694, \"f2\": 0.25167109010217903, \"f0_5\": 0.5735475522122917, \"p4\": 0.5183252592677023, \"phi\": 0.46034953980434223}, {\"truth_threshold\": 21.95999950915575, \"match_probability\": 0.999999754878539, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64351.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239610.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21170808097091404, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.788291919029086, \"precision\": 0.9997669577105925, \"recall\": 0.21170808097091404, \"specificity\": 0.9999999882696827, \"npv\": 0.9998126550145174, \"accuracy\": 0.9998126527148641, \"f1\": 0.34942320275190253, \"f2\": 0.2513298599448528, \"f0_5\": 0.5731041546065815, \"p4\": 0.517872709741553, \"phi\": 0.46002072764419705}, {\"truth_threshold\": 21.979999508708715, \"match_probability\": 0.9999997582531976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64281.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239680.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21147778826888977, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7885222117311103, \"precision\": 0.9997667039940277, \"recall\": 0.21147778826888977, \"specificity\": 0.9999999882696827, \"npv\": 0.9998126002935485, \"accuracy\": 0.9998125979863927, \"f1\": 0.3491094534523444, \"f2\": 0.25107019544737297, \"f0_5\": 0.5727663972769962, \"p4\": 0.5175280417495586, \"phi\": 0.45977038698105577}, {\"truth_threshold\": 21.99999950826168, \"match_probability\": 0.9999997615813965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64199.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239762.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21120801681794704, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.788791983182053, \"precision\": 0.9997664060796712, \"recall\": 0.21120801681794704, \"specificity\": 0.9999999882696827, \"npv\": 0.9998125361918494, \"accuracy\": 0.9998125338758976, \"f1\": 0.3487417668228424, \"f2\": 0.2507659809164897, \"f0_5\": 0.5723703097445334, \"p4\": 0.517123917053462, \"phi\": 0.45947695733820093}, {\"truth_threshold\": 22.019999507814646, \"match_probability\": 0.999999764863775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64118.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21094153526274753, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7890584647372525, \"precision\": 0.9997661110504732, \"recall\": 0.21094153526274753, \"specificity\": 0.9999999882696827, \"npv\": 0.9998124728718866, \"accuracy\": 0.9998124705472379, \"f1\": 0.34837840334262443, \"f2\": 0.25046543805084, \"f0_5\": 0.5719785974133486, \"p4\": 0.5167243274087501, \"phi\": 0.45918692205132733}, {\"truth_threshold\": 22.03999950736761, \"match_probability\": 0.999999768100964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64037.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21067505370754802, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.789324946292452, \"precision\": 0.999765815275089, \"recall\": 0.21067505370754802, \"specificity\": 0.9999999882696827, \"npv\": 0.9998124095519316, \"accuracy\": 0.9998124072185781, \"f1\": 0.34801487990913366, \"f2\": 0.250164857144643, \"f0_5\": 0.5715864319517859, \"p4\": 0.5163243463015372, \"phi\": 0.4588967034910562}, {\"truth_threshold\": 22.059999506920576, \"match_probability\": 0.9999997712935859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63942.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240019.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21036251361194364, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7896374863880563, \"precision\": 0.9997654674234251, \"recall\": 0.21036251361194364, \"specificity\": 0.9999999882696827, \"npv\": 0.9998123352877973, \"accuracy\": 0.9998123329442241, \"f1\": 0.34758832131072687, \"f2\": 0.24981227550220697, \"f0_5\": 0.5711259063682923, \"p4\": 0.5158547330816079, \"phi\": 0.4585560897029626}, {\"truth_threshold\": 22.07999950647354, \"match_probability\": 0.9999997744422539, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63821.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240140.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20996443622701597, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.790035563772984, \"precision\": 0.9997650228711072, \"recall\": 0.20996443622701597, \"specificity\": 0.9999999882696827, \"npv\": 0.9998122406987578, \"accuracy\": 0.999812238342152, \"f1\": 0.34704470128902626, \"f2\": 0.24936312203050762, \"f0_5\": 0.5705384360947963, \"p4\": 0.5152558118181869, \"phi\": 0.4581218886774912}, {\"truth_threshold\": 22.099999506026506, \"match_probability\": 0.9999997775475732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63741.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240220.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20970124456755965, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7902987554324403, \"precision\": 0.9997647280255976, \"recall\": 0.20970124456755965, \"specificity\": 0.9999999882696827, \"npv\": 0.9998121781605599, \"accuracy\": 0.9998121757953277, \"f1\": 0.3466850866291197, \"f2\": 0.24906611441075335, \"f0_5\": 0.5701494673381218, \"p4\": 0.5148593486371557, \"phi\": 0.45783458753448697}, {\"truth_threshold\": 22.11999950557947, \"match_probability\": 0.9999997806101408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63636.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240325.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20935580551452324, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7906441944854767, \"precision\": 0.999764339916105, \"recall\": 0.20935580551452324, \"specificity\": 0.9999999882696827, \"npv\": 0.9998120960791869, \"accuracy\": 0.9998120937026205, \"f1\": 0.34621285485783926, \"f2\": 0.24867623554605528, \"f0_5\": 0.5696382694941502, \"p4\": 0.5143384071467392, \"phi\": 0.4574572310126728}, {\"truth_threshold\": 22.139999505132437, \"match_probability\": 0.9999997836305451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63560.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20910577343803974, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7908942265619603, \"precision\": 0.9997640581989776, \"recall\": 0.20910577343803974, \"specificity\": 0.9999999882696827, \"npv\": 0.9998120366679157, \"accuracy\": 0.9998120342831373, \"f1\": 0.3458708806756345, \"f2\": 0.24839399758796765, \"f0_5\": 0.5692677797660951, \"p4\": 0.5139609308230614, \"phi\": 0.45718390249654717}, {\"truth_threshold\": 22.159999504685402, \"match_probability\": 0.9999997866093666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63447.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240514.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2087340152190577, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7912659847809423, \"precision\": 0.9997636380826321, \"recall\": 0.2087340152190577, \"specificity\": 0.9999999882696827, \"npv\": 0.9998119483327493, \"accuracy\": 0.9998119459357477, \"f1\": 0.34536215751327487, \"f2\": 0.2479742923116127, \"f0_5\": 0.5687161734572228, \"p4\": 0.513399039362505, \"phi\": 0.45677720383365017}, {\"truth_threshold\": 22.179999504238367, \"match_probability\": 0.9999997895471778, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63366.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240595.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2084675336638582, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7915324663361418, \"precision\": 0.9997633360155251, \"recall\": 0.2084675336638582, \"specificity\": 0.9999999882696827, \"npv\": 0.9998118850128609, \"accuracy\": 0.999811882607088, \"f1\": 0.34499730496376674, \"f2\": 0.24767339600148527, \"f0_5\": 0.5683202238625255, \"p4\": 0.5129957931604165, \"phi\": 0.45648545356227843}, {\"truth_threshold\": 22.199999503791332, \"match_probability\": 0.9999997924445434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63285.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20820105210865866, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7917989478913413, \"precision\": 0.9997630331753554, \"recall\": 0.20820105210865866, \"specificity\": 0.9999999882696827, \"npv\": 0.9998118216929804, \"accuracy\": 0.9998118192784282, \"f1\": 0.34463229147663377, \"f2\": 0.2473724615836841, \"f0_5\": 0.5679238137629877, \"p4\": 0.5125921501085606, \"phi\": 0.45619351674439346}, {\"truth_threshold\": 22.219999503344297, \"match_probability\": 0.99999979530202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63197.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240764.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20791154128325673, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7920884587167433, \"precision\": 0.9997627032841866, \"recall\": 0.20791154128325673, \"specificity\": 0.9999999882696827, \"npv\": 0.9998117529010208, \"accuracy\": 0.9998117504769213, \"f1\": 0.3442355510889962, \"f2\": 0.24704547728950102, \"f0_5\": 0.5674926231436632, \"p4\": 0.5121531738651606, \"phi\": 0.4558761389758342}, {\"truth_threshold\": 22.239999502897263, \"match_probability\": 0.9999997981201569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63128.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20768453847697566, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7923154615230243, \"precision\": 0.999762443976371, \"recall\": 0.20768453847697566, \"specificity\": 0.9999999882696827, \"npv\": 0.999811698961877, \"accuracy\": 0.9998116965302852, \"f1\": 0.34392433751743373, \"f2\": 0.246789060404836, \"f0_5\": 0.5671541489902665, \"p4\": 0.5118086479872921, \"phi\": 0.4556271313523008}, {\"truth_threshold\": 22.259999502450228, \"match_probability\": 0.9999998008994958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63031.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2073654185898849, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7926345814101151, \"precision\": 0.999762078482378, \"recall\": 0.2073654185898849, \"specificity\": 0.9999999882696827, \"npv\": 0.9998116231343952, \"accuracy\": 0.9998116206922606, \"f1\": 0.34348663649467176, \"f2\": 0.24642854350256863, \"f0_5\": 0.566677754902049, \"p4\": 0.5113238253318784, \"phi\": 0.45527684689855047}, {\"truth_threshold\": 22.279999502003193, \"match_probability\": 0.9999998036405707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62956.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241005.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20711867640914458, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7928813235908554, \"precision\": 0.9997776719072574, \"recall\": 0.20711867640914458, \"specificity\": 0.9999999890517038, \"npv\": 0.999811564505054, \"accuracy\": 0.9998115628364479, \"f1\": 0.3431489844139634, \"f2\": 0.24614994831148235, \"f0_5\": 0.5663130283660255, \"p4\": 0.5109496067431789, \"phi\": 0.45500943798425386}, {\"truth_threshold\": 22.299999501556158, \"match_probability\": 0.9999998063439084, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62877.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241084.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20685877464543148, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7931412253545685, \"precision\": 0.9997773926316961, \"recall\": 0.20685877464543148, \"specificity\": 0.9999999890517038, \"npv\": 0.999811502748667, \"accuracy\": 0.9998115010714588, \"f1\": 0.3427921886755422, \"f2\": 0.24585625637837394, \"f0_5\": 0.5659241258269205, \"p4\": 0.5105539667599455, \"phi\": 0.45472378770388416}, {\"truth_threshold\": 22.319999501109123, \"match_probability\": 0.9999998090100285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62781.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241180.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2065429446540839, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.793457055345916, \"precision\": 0.9997770523130822, \"recall\": 0.2065429446540839, \"specificity\": 0.9999999890517038, \"npv\": 0.9998114277029412, \"accuracy\": 0.9998114260152694, \"f1\": 0.3423584072244217, \"f2\": 0.24549931606966469, \"f0_5\": 0.5654509394910482, \"p4\": 0.5100726763673258, \"phi\": 0.45437642672240236}, {\"truth_threshold\": 22.33999950066209, \"match_probability\": 0.9999998116394433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62694.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20625672372442516, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7937432762755748, \"precision\": 0.9997767429992983, \"recall\": 0.20625672372442516, \"specificity\": 0.9999999890517038, \"npv\": 0.9998113596927618, \"accuracy\": 0.9998113579955978, \"f1\": 0.341965096585749, \"f2\": 0.24517579261539615, \"f0_5\": 0.5650215485775776, \"p4\": 0.5096360203061269, \"phi\": 0.4540614013450076}, {\"truth_threshold\": 22.359999500215054, \"match_probability\": 0.9999998142326582, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62602.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241359.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2059540533160504, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7940459466839496, \"precision\": 0.9997764149738086, \"recall\": 0.2059540533160504, \"specificity\": 0.9999999890517038, \"npv\": 0.9998112877739616, \"accuracy\": 0.9998112860667497, \"f1\": 0.34154897879572366, \"f2\": 0.24483362795863772, \"f0_5\": 0.5645668936285341, \"p4\": 0.5091737648619685, \"phi\": 0.4537280331674476}, {\"truth_threshold\": 22.37999949976802, \"match_probability\": 0.9999998167901716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62519.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241442.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20568099196936449, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7943190080306355, \"precision\": 0.9997761182095853, \"recall\": 0.20568099196936449, \"specificity\": 0.9999999890517038, \"npv\": 0.999811222890705, \"accuracy\": 0.9998112211744193, \"f1\": 0.34117338892314747, \"f2\": 0.24452489367377542, \"f0_5\": 0.564156197605817, \"p4\": 0.5087562846304431, \"phi\": 0.4534270668296601}, {\"truth_threshold\": 22.399999499320984, \"match_probability\": 0.9999998193124748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62442.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241519.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2054276699971378, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7945723300028622, \"precision\": 0.9997758421929038, \"recall\": 0.2054276699971378, \"specificity\": 0.9999999890517038, \"npv\": 0.9998111626978118, \"accuracy\": 0.9998111609731007, \"f1\": 0.34082479797607645, \"f2\": 0.24423844168035672, \"f0_5\": 0.5637747501286601, \"p4\": 0.5083686053020071, \"phi\": 0.4531476783901058}, {\"truth_threshold\": 22.41999949887395, \"match_probability\": 0.999999821800053, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62373.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241588.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20520066719085672, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7947993328091433, \"precision\": 0.9997755942744482, \"recall\": 0.20520066719085672, \"specificity\": 0.9999999890517038, \"npv\": 0.9998111087587319, \"accuracy\": 0.9998111070264647, \"f1\": 0.34051229978053654, \"f2\": 0.24398172161369894, \"f0_5\": 0.5634325729120936, \"p4\": 0.5080208945043365, \"phi\": 0.4528971709270727}, {\"truth_threshold\": 22.439999498426914, \"match_probability\": 0.9999998242533837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62335.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20507565115261497, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.794924348847385, \"precision\": 0.9997754575053329, \"recall\": 0.20507565115261497, \"specificity\": 0.9999999890517038, \"npv\": 0.9998110790531541, \"accuracy\": 0.999811077316723, \"f1\": 0.3403401490540799, \"f2\": 0.24384032771263808, \"f0_5\": 0.5632439817333114, \"p4\": 0.5078292764047194, \"phi\": 0.4527591511215975}, {\"truth_threshold\": 22.45999949797988, \"match_probability\": 0.999999826672939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62262.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241699.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20483548876336108, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7951645112366389, \"precision\": 0.9997751942963582, \"recall\": 0.20483548876336108, \"specificity\": 0.9999999890517038, \"npv\": 0.9998110219871807, \"accuracy\": 0.9998110202427457, \"f1\": 0.3400093382154179, \"f2\": 0.24356867899727724, \"f0_5\": 0.5628813973041144, \"p4\": 0.5074609181754781, \"phi\": 0.45249388971542104}, {\"truth_threshold\": 22.479999497532845, \"match_probability\": 0.9999998290591833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62207.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20465454449748488, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7953454555025151, \"precision\": 0.9997749955802703, \"recall\": 0.20465454449748488, \"specificity\": 0.9999999890517038, \"npv\": 0.9998109789922737, \"accuracy\": 0.9998109772418039, \"f1\": 0.33976001004964745, \"f2\": 0.24336399165926614, \"f0_5\": 0.562607964257613, \"p4\": 0.5071831707746918, \"phi\": 0.4522939324913117}, {\"truth_threshold\": 22.49999949708581, \"match_probability\": 0.9999998314125756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62117.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20435845388059654, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7956415461194035, \"precision\": 0.9997746696496113, \"recall\": 0.20435845388059654, \"specificity\": 0.9999999890517038, \"npv\": 0.9998109086369791, \"accuracy\": 0.9998109068766264, \"f1\": 0.33935185691028485, \"f2\": 0.2430290107396467, \"f0_5\": 0.5621600586441261, \"p4\": 0.5067282718166332, \"phi\": 0.4519665389785295}, {\"truth_threshold\": 22.519999496638775, \"match_probability\": 0.999999833733568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62037.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20409526222114022, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7959047377788598, \"precision\": 0.9997743791397399, \"recall\": 0.20409526222114022, \"specificity\": 0.9999999890517038, \"npv\": 0.9998108460989477, \"accuracy\": 0.9998108443298019, \"f1\": 0.3389888856103079, \"f2\": 0.24273121031070627, \"f0_5\": 0.5617614300073348, \"p4\": 0.5063234964035598, \"phi\": 0.45167532333935667}, {\"truth_threshold\": 22.53999949619174, \"match_probability\": 0.9999998360226068, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61946.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242015.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20379588170850865, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7962041182914913, \"precision\": 0.9997740477727566, \"recall\": 0.20379588170850865, \"specificity\": 0.9999999890517038, \"npv\": 0.9998107749619466, \"accuracy\": 0.9998107731827891, \"f1\": 0.33857581281205507, \"f2\": 0.24239241699039915, \"f0_5\": 0.5613074278589564, \"p4\": 0.5058625821445133, \"phi\": 0.4513438371662025}, {\"truth_threshold\": 22.559999495744705, \"match_probability\": 0.9999998382801315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61885.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242076.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20359519806817322, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7964048019318268, \"precision\": 0.9997738251021826, \"recall\": 0.20359519806817322, \"specificity\": 0.9999999890517038, \"npv\": 0.9998107272767097, \"accuracy\": 0.9998107254908355, \"f1\": 0.3382988028207511, \"f2\": 0.242165286759544, \"f0_5\": 0.5610027612739934, \"p4\": 0.5055533298986419, \"phi\": 0.4511214958120697}, {\"truth_threshold\": 22.57999949529767, \"match_probability\": 0.9999998405065764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61779.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20324646911939362, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7967535308806064, \"precision\": 0.9997734371207094, \"recall\": 0.20324646911939362, \"specificity\": 0.9999999890517038, \"npv\": 0.9998106444138499, \"accuracy\": 0.999810642616293, \"f1\": 0.33781722141111237, \"f2\": 0.241770549851014, \"f0_5\": 0.5604726989673999, \"p4\": 0.5050153905261378, \"phi\": 0.4507348713114049}, {\"truth_threshold\": 22.599999494850636, \"match_probability\": 0.9999998427023691, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61695.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242266.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20297011787696448, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7970298821230355, \"precision\": 0.9997731287170429, \"recall\": 0.20297011787696448, \"specificity\": 0.9999999890517038, \"npv\": 0.999810578748952, \"accuracy\": 0.9998105769421274, \"f1\": 0.33743539256706867, \"f2\": 0.24145769294894223, \"f0_5\": 0.5600520700003813, \"p4\": 0.5045886021059955, \"phi\": 0.4504282539856128}, {\"truth_threshold\": 22.6199994944036, \"match_probability\": 0.9999998448679317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61616.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242345.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20271021611325138, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7972897838867486, \"precision\": 0.9997728379036184, \"recall\": 0.20271021611325138, \"specificity\": 0.9999999890517038, \"npv\": 0.9998105169926866, \"accuracy\": 0.9998105151771383, \"f1\": 0.3370761315240255, \"f2\": 0.24116342093850834, \"f0_5\": 0.5596560099258648, \"p4\": 0.5041868162298807, \"phi\": 0.45013969715023383}, {\"truth_threshold\": 22.639999493956566, \"match_probability\": 0.9999998470036803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61545.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2024766335154839, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7975233664845162, \"precision\": 0.9997725759027924, \"recall\": 0.2024766335154839, \"specificity\": 0.9999999890517038, \"npv\": 0.999810461490227, \"accuracy\": 0.9998104596668316, \"f1\": 0.3367531188443861, \"f2\": 0.24089891756947493, \"f0_5\": 0.5592996690276392, \"p4\": 0.50382538496731, \"phi\": 0.44988020337284185}, {\"truth_threshold\": 22.65999949350953, \"match_probability\": 0.9999998491100255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61438.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242523.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20212461467096107, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7978753853290389, \"precision\": 0.9997721799127774, \"recall\": 0.20212461467096107, \"specificity\": 0.9999999890517038, \"npv\": 0.9998103778456866, \"accuracy\": 0.9998103760104539, \"f1\": 0.3362660879607458, \"f2\": 0.24050024426601194, \"f0_5\": 0.5587619527474267, \"p4\": 0.5032800971010148, \"phi\": 0.4494888523367597}, {\"truth_threshold\": 22.679999493062496, \"match_probability\": 0.999999851187372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61354.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242607.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20184826342853196, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7981517365714681, \"precision\": 0.9997718680745665, \"recall\": 0.20184826342853196, \"specificity\": 0.9999999890517038, \"npv\": 0.9998103121808236, \"accuracy\": 0.9998103103362881, \"f1\": 0.3358835460639588, \"f2\": 0.2401872202891924, \"f0_5\": 0.5583392333551134, \"p4\": 0.5028515180455889, \"phi\": 0.4491813846264498}, {\"truth_threshold\": 22.69999949261546, \"match_probability\": 0.9999998532361191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61278.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242683.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20159823135204846, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7984017686479515, \"precision\": 0.9997715851987209, \"recall\": 0.20159823135204846, \"specificity\": 0.9999999890517038, \"npv\": 0.9998102527697645, \"accuracy\": 0.9998102509168049, \"f1\": 0.3355372851147013, \"f2\": 0.23990397263877927, \"f0_5\": 0.557956327201805, \"p4\": 0.5024633744893456, \"phi\": 0.44890301812569555}, {\"truth_threshold\": 22.719999492168427, \"match_probability\": 0.9999998552566605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61189.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242772.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2013054306309033, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7986945693690967, \"precision\": 0.9997712530431515, \"recall\": 0.2013054306309033, \"specificity\": 0.9999999890517038, \"npv\": 0.9998101831962964, \"accuracy\": 0.9998101813334627, \"f1\": 0.3351316120975781, \"f2\": 0.2395722318755692, \"f0_5\": 0.5575073846563151, \"p4\": 0.5020083764677391, \"phi\": 0.4485768167539706}, {\"truth_threshold\": 22.73999949172139, \"match_probability\": 0.9999998572493844, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61095.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242866.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20099618043104214, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7990038195689578, \"precision\": 0.9997709011765861, \"recall\": 0.20099618043104214, \"specificity\": 0.9999999890517038, \"npv\": 0.999810109714217, \"accuracy\": 0.9998101078409439, \"f1\": 0.33470293368395104, \"f2\": 0.23922180377821267, \"f0_5\": 0.557032587705622, \"p4\": 0.501527275309924, \"phi\": 0.4482320317388556}, {\"truth_threshold\": 22.759999491274357, \"match_probability\": 0.999999859214674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61001.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20068693023118098, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.799313069768819, \"precision\": 0.9997705482258461, \"recall\": 0.20068693023118098, \"specificity\": 0.9999999890517038, \"npv\": 0.9998100362321485, \"accuracy\": 0.9998100343484252, \"f1\": 0.33427403445706017, \"f2\": 0.23887132408511824, \"f0_5\": 0.5565571392337155, \"p4\": 0.5010456169595426, \"phi\": 0.44788698135786487}, {\"truth_threshold\": 22.779999490827322, \"match_probability\": 0.999999861152907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60940.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243021.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20048624659084555, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7995137534091544, \"precision\": 0.9997703186009121, \"recall\": 0.20048624659084555, \"specificity\": 0.9999999890517038, \"npv\": 0.9998099885469821, \"accuracy\": 0.9998099866564716, \"f1\": 0.33399558801364704, \"f2\": 0.2386438575248395, \"f0_5\": 0.5562482543078662, \"p4\": 0.5007327528636452, \"phi\": 0.44766292341727915}, {\"truth_threshold\": 22.799999490380287, \"match_probability\": 0.9999998630644555, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60889.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243072.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20031846190794214, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7996815380920579, \"precision\": 0.999770126266358, \"recall\": 0.20031846190794214, \"specificity\": 0.9999999890517038, \"npv\": 0.9998099486790596, \"accuracy\": 0.9998099467828709, \"f1\": 0.3337627170671812, \"f2\": 0.23845366388172443, \"f0_5\": 0.5559897949679768, \"p4\": 0.5004709973607847, \"phi\": 0.4474755101937903}, {\"truth_threshold\": 22.819999489933252, \"match_probability\": 0.9999998649496874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60821.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243140.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20009474899740426, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7999052510025957, \"precision\": 0.9997698693186488, \"recall\": 0.20009474899740426, \"specificity\": 0.9999999890517038, \"npv\": 0.9998098955218345, \"accuracy\": 0.9998098936180702, \"f1\": 0.3334521211855393, \"f2\": 0.23820004872015596, \"f0_5\": 0.5556448827975831, \"p4\": 0.5001217338853258, \"phi\": 0.4472255037505639}, {\"truth_threshold\": 22.839999489486217, \"match_probability\": 0.9999998668089647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60746.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243215.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19984800681666398, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8001519931833361, \"precision\": 0.9997695852534563, \"recall\": 0.19984800681666398, \"specificity\": 0.9999999890517038, \"npv\": 0.9998098368925488, \"accuracy\": 0.9998098349804223, \"f1\": 0.3331094178838071, \"f2\": 0.23792029478209376, \"f0_5\": 0.5552640671589266, \"p4\": 0.4997361769290283, \"phi\": 0.4469495992023489}, {\"truth_threshold\": 22.859999489039183, \"match_probability\": 0.9999998686426447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60661.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243300.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19956836567849165, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8004316343215083, \"precision\": 0.9997692624639473, \"recall\": 0.19956836567849165, \"specificity\": 0.9999999890517038, \"npv\": 0.9998097704460331, \"accuracy\": 0.9998097685244213, \"f1\": 0.33272085038229904, \"f2\": 0.2376032005790748, \"f0_5\": 0.5548319708192098, \"p4\": 0.4992987807719884, \"phi\": 0.4466367013811614}, {\"truth_threshold\": 22.879999488592148, \"match_probability\": 0.99999987045108, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60585.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243376.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19931833360200815, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8006816663979919, \"precision\": 0.9997689730853645, \"recall\": 0.19931833360200815, \"specificity\": 0.9999999890517038, \"npv\": 0.9998097110350385, \"accuracy\": 0.999809709104938, \"f1\": 0.3323732718894009, \"f2\": 0.2373196452955596, \"f0_5\": 0.5544451704654649, \"p4\": 0.49890730826420293, \"phi\": 0.44635674821748067}, {\"truth_threshold\": 22.899999488145113, \"match_probability\": 0.999999872234618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60526.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243435.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19912422975315913, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8008757702468409, \"precision\": 0.9997687479352494, \"recall\": 0.19912422975315913, \"specificity\": 0.9999999890517038, \"npv\": 0.9998096649133501, \"accuracy\": 0.999809662976655, \"f1\": 0.33210334128027086, \"f2\": 0.23709949356933338, \"f0_5\": 0.554144594329828, \"p4\": 0.4986031484872144, \"phi\": 0.4461392950555714}, {\"truth_threshold\": 22.919999487698078, \"match_probability\": 0.9999998739936015, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60427.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243534.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19879853007458193, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8012014699254181, \"precision\": 0.9997683691533893, \"recall\": 0.19879853007458193, \"specificity\": 0.9999999890517038, \"npv\": 0.99980958752273, \"accuracy\": 0.9998095855749597, \"f1\": 0.3316502104818305, \"f2\": 0.23673004070407472, \"f0_5\": 0.5536396536717211, \"p4\": 0.49809228016128865, \"phi\": 0.44577417773856215}, {\"truth_threshold\": 22.939999487251043, \"match_probability\": 0.9999998757283686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60335.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19849585966620717, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8015041403337928, \"precision\": 0.9997680160400338, \"recall\": 0.19849585966620717, \"specificity\": 0.9999999890517038, \"npv\": 0.9998095156041846, \"accuracy\": 0.9998095136461116, \"f1\": 0.3312288984655925, \"f2\": 0.23638665938459152, \"f0_5\": 0.5531697585251496, \"p4\": 0.4976169729298486, \"phi\": 0.44543460856008227}, {\"truth_threshold\": 22.95999948680401, \"match_probability\": 0.9999998774392526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60278.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243683.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19830833560884456, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8016916643911555, \"precision\": 0.9997677967226166, \"recall\": 0.19830833560884456, \"specificity\": 0.9999999890517038, \"npv\": 0.9998094710459607, \"accuracy\": 0.9998094690814991, \"f1\": 0.3309677614185745, \"f2\": 0.23617388742265716, \"f0_5\": 0.5528783095377424, \"p4\": 0.49732221758415707, \"phi\": 0.44522409339562363}, {\"truth_threshold\": 22.979999486356974, \"match_probability\": 0.9999998791265824, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60194.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243767.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19803198436641542, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8019680156335846, \"precision\": 0.9997674727610949, \"recall\": 0.19803198436641542, \"specificity\": 0.9999999890517038, \"npv\": 0.9998094053812168, \"accuracy\": 0.9998094034073335, \"f1\": 0.3305827788746434, \"f2\": 0.23586029409459802, \"f0_5\": 0.5524483611206458, \"p4\": 0.49688746209145784, \"phi\": 0.44491367900037077}, {\"truth_threshold\": 22.99999948590994, \"match_probability\": 0.9999998807906821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60121.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19779182197716155, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8022081780228385, \"precision\": 0.9997671904880685, \"recall\": 0.19779182197716155, \"specificity\": 0.9999999890517038, \"npv\": 0.9998093483154346, \"accuracy\": 0.9998093463333562, \"f1\": 0.3302480664440148, \"f2\": 0.2355877330269542, \"f0_5\": 0.5520742845284031, \"p4\": 0.4965092714474741, \"phi\": 0.44464373814539415}, {\"truth_threshold\": 23.019999485462904, \"match_probability\": 0.9999998824318719, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60019.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19745625261135474, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8025437473886452, \"precision\": 0.9997667949294554, \"recall\": 0.19745625261135474, \"specificity\": 0.9999999890517038, \"npv\": 0.9998092685796948, \"accuracy\": 0.999809266586155, \"f1\": 0.32978016121144854, \"f2\": 0.23520684203884856, \"f0_5\": 0.5515509297123837, \"p4\": 0.49598026752843866, \"phi\": 0.4442662858656637}, {\"truth_threshold\": 23.03999948501587, \"match_probability\": 0.9999998840504668, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59898.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244063.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19705817522642707, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8029418247735729, \"precision\": 0.9997663239417813, \"recall\": 0.19705817522642707, \"specificity\": 0.9999999890517038, \"npv\": 0.9998091739912357, \"accuracy\": 0.999809171984083, \"f1\": 0.32922475698938913, \"f2\": 0.23475492178755186, \"f0_5\": 0.5509290685032808, \"p4\": 0.4953518556597813, \"phi\": 0.44381810765231183}, {\"truth_threshold\": 23.059999484568834, \"match_probability\": 0.9999998856467781, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59835.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244126.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19685091179460523, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8031490882053948, \"precision\": 0.9997660779628732, \"recall\": 0.19685091179460523, \"specificity\": 0.9999999890517038, \"npv\": 0.9998091247427063, \"accuracy\": 0.9998091227284587, \"f1\": 0.32893543333058467, \"f2\": 0.23451959052844218, \"f0_5\": 0.550604850954345, \"p4\": 0.49502429244955354, \"phi\": 0.44358457943917007}, {\"truth_threshold\": 23.0799994841218, \"match_probability\": 0.9999998872211124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59779.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19666667763298581, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8033333223670142, \"precision\": 0.999765858879802, \"recall\": 0.19666667763298581, \"specificity\": 0.9999999890517038, \"npv\": 0.9998090809662398, \"accuracy\": 0.9998090789456816, \"f1\": 0.3286781726111603, \"f2\": 0.2343103876729822, \"f0_5\": 0.5503164050057721, \"p4\": 0.4947329100799753, \"phi\": 0.4433768955652405}, {\"truth_threshold\": 23.099999483674765, \"match_probability\": 0.9999998887737725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59719.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244242.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19646928388839358, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8035307161116064, \"precision\": 0.9997656236920965, \"recall\": 0.19646928388839358, \"specificity\": 0.9999999890517038, \"npv\": 0.999809034062887, \"accuracy\": 0.9998090320355633, \"f1\": 0.3284024482119584, \"f2\": 0.23408622137275914, \"f0_5\": 0.5500070916368419, \"p4\": 0.49442048980971415, \"phi\": 0.4431542691416482}, {\"truth_threshold\": 23.11999948322773, \"match_probability\": 0.9999998903050566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59635.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244326.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19619293264596446, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8038070673540355, \"precision\": 0.9997652936344281, \"recall\": 0.19619293264596446, \"specificity\": 0.9999999890517038, \"npv\": 0.9998089683982005, \"accuracy\": 0.9998089663613976, \"f1\": 0.32801628118038556, \"f2\": 0.2337723531214989, \"f0_5\": 0.549573593189287, \"p4\": 0.4939827101297121, \"phi\": 0.4428424041597328}, {\"truth_threshold\": 23.139999482780695, \"match_probability\": 0.9999998918152592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59555.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19592974098650814, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8040702590134918, \"precision\": 0.9997649784283772, \"recall\": 0.19592974098650814, \"specificity\": 0.9999999890517038, \"npv\": 0.9998089058604119, \"accuracy\": 0.9998089038145731, \"f1\": 0.327648337138613, \"f2\": 0.23347339254029872, \"f0_5\": 0.5491602380508892, \"p4\": 0.49356535208245006, \"phi\": 0.44254518560475764}, {\"truth_threshold\": 23.15999948233366, \"match_probability\": 0.9999998933046703, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59466.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.195636940265363, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8043630597346371, \"precision\": 0.9997646267652993, \"recall\": 0.195636940265363, \"specificity\": 0.9999999890517038, \"npv\": 0.9998088362871312, \"accuracy\": 0.9998088342312309, \"f1\": 0.3272388090501622, \"f2\": 0.23314075481995164, \"f0_5\": 0.5486998067841463, \"p4\": 0.4931005532392074, \"phi\": 0.4422142952669035}, {\"truth_threshold\": 23.179999481886625, \"match_probability\": 0.9999998947735762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59401.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244560.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19542309704205474, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8045769029579453, \"precision\": 0.9997643692670201, \"recall\": 0.19542309704205474, \"specificity\": 0.9999999890517038, \"npv\": 0.9998087854751908, \"accuracy\": 0.999808783411936, \"f1\": 0.3269395887455418, \"f2\": 0.2328977878219248, \"f0_5\": 0.5483631543090094, \"p4\": 0.49276076815561043, \"phi\": 0.44197247728359396}, {\"truth_threshold\": 23.19999948143959, \"match_probability\": 0.9999998962222593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59322.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244639.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19516319527834164, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8048368047216584, \"precision\": 0.9997640555480652, \"recall\": 0.19516319527834164, \"specificity\": 0.9999999890517038, \"npv\": 0.9998087237191471, \"accuracy\": 0.9998087216469469, \"f1\": 0.3265757768437394, \"f2\": 0.23260245612384134, \"f0_5\": 0.5479535566824618, \"p4\": 0.49234742841670476, \"phi\": 0.4416783972206733}, {\"truth_threshold\": 23.219999480992556, \"match_probability\": 0.999999897650998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59244.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244717.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19490658341037173, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8050934165896283, \"precision\": 0.9997637449795809, \"recall\": 0.19490658341037173, \"specificity\": 0.9999999890517038, \"npv\": 0.9998086627448329, \"accuracy\": 0.999808660663793, \"f1\": 0.3262164148901902, \"f2\": 0.232310826898554, \"f0_5\": 0.5475486743821084, \"p4\": 0.4919389217897963, \"phi\": 0.44138784749608806}, {\"truth_threshold\": 23.23999948054552, \"match_probability\": 0.9999998990600667, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59135.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1945479847743625, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8054520152256375, \"precision\": 0.9997633096079392, \"recall\": 0.1945479847743625, \"specificity\": 0.9999999890517038, \"npv\": 0.99980857753715, \"accuracy\": 0.9998085754437447, \"f1\": 0.3257139709729834, \"f2\": 0.23190323397853949, \"f0_5\": 0.5469820943952257, \"p4\": 0.4913673946827071, \"phi\": 0.4409815022623677}, {\"truth_threshold\": 23.259999480098486, \"match_probability\": 0.9999999004497364, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59072.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19434072134254066, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8056592786574593, \"precision\": 0.9997630572386014, \"recall\": 0.19434072134254066, \"specificity\": 0.9999999890517038, \"npv\": 0.9998085282886793, \"accuracy\": 0.9998085261881204, \"f1\": 0.32542343002421176, \"f2\": 0.23166762096742566, \"f0_5\": 0.5466542045696412, \"p4\": 0.4910367082732176, \"phi\": 0.44074647136565154}, {\"truth_threshold\": 23.27999947965145, \"match_probability\": 0.9999999018202742, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58982.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244979.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1940446307256523, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8059553692743477, \"precision\": 0.9997626957759849, \"recall\": 0.1940446307256523, \"specificity\": 0.9999999890517038, \"npv\": 0.9998084579337296, \"accuracy\": 0.999808455822943, \"f1\": 0.32500819656322927, \"f2\": 0.23133099055567757, \"f0_5\": 0.546185259609775, \"p4\": 0.4905638482404118, \"phi\": 0.4404104954040205}, {\"truth_threshold\": 23.299999479204416, \"match_probability\": 0.9999999031719433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58925.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245036.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19385710666828967, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8061428933317103, \"precision\": 0.9997624662786949, \"recall\": 0.19385710666828967, \"specificity\": 0.9999999890517038, \"npv\": 0.9998084133755999, \"accuracy\": 0.9998084112583305, \"f1\": 0.32474510884541197, \"f2\": 0.2311177667100989, \"f0_5\": 0.5458879375672806, \"p4\": 0.49026409550326816, \"phi\": 0.4401975780215752}, {\"truth_threshold\": 23.31999947875738, \"match_probability\": 0.9999999045050036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58813.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245148.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19348863834505084, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8065113616549492, \"precision\": 0.9997620140411716, \"recall\": 0.19348863834505084, \"specificity\": 0.9999999890517038, \"npv\": 0.9998083258227952, \"accuracy\": 0.9998083236927763, \"f1\": 0.32422792374609966, \"f2\": 0.23069874500949658, \"f0_5\": 0.545302993496752, \"p4\": 0.4896744860861232, \"phi\": 0.4397789138269212}, {\"truth_threshold\": 23.339999478310347, \"match_probability\": 0.9999999058197113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58746.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245215.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19326821533025618, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8067317846697438, \"precision\": 0.9997617426820966, \"recall\": 0.19326821533025618, \"specificity\": 0.9999999890517038, \"npv\": 0.999808273447464, \"accuracy\": 0.9998082713098108, \"f1\": 0.3239183835509937, \"f2\": 0.2304480450398712, \"f0_5\": 0.5449526067669633, \"p4\": 0.4893213788870637, \"phi\": 0.4395282723231886}, {\"truth_threshold\": 23.35999947786331, \"match_probability\": 0.999999907116319, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58661.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245300.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19298857419208384, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8070114258079162, \"precision\": 0.9997613975287601, \"recall\": 0.19298857419208384, \"specificity\": 0.9999999890517038, \"npv\": 0.9998082070011562, \"accuracy\": 0.9998082048538098, \"f1\": 0.32352551870194907, \"f2\": 0.2301299549084792, \"f0_5\": 0.5445075845476097, \"p4\": 0.4888729814564804, \"phi\": 0.4392100885002411}, {\"truth_threshold\": 23.379999477416277, \"match_probability\": 0.999999908395076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58608.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245353.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19281420971769406, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.807185790282306, \"precision\": 0.9997611818088772, \"recall\": 0.19281420971769406, \"specificity\": 0.9999999890517038, \"npv\": 0.9998081655699336, \"accuracy\": 0.9998081634165386, \"f1\": 0.32328046268026905, \"f2\": 0.22993159487973786, \"f0_5\": 0.5442298156371356, \"p4\": 0.4885931512235759, \"phi\": 0.4390115748238256}, {\"truth_threshold\": 23.399999476969242, \"match_probability\": 0.9999999096562279, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58466.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1923470445221591, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8076529554778409, \"precision\": 0.9997606019151847, \"recall\": 0.1923470445221591, \"specificity\": 0.9999999890517038, \"npv\": 0.9998080545655423, \"accuracy\": 0.9998080523959252, \"f1\": 0.32262354424582207, \"f2\": 0.2294000583838961, \"f0_5\": 0.5434845253875857, \"p4\": 0.4878425024577135, \"phi\": 0.438479265105523}, {\"truth_threshold\": 23.419999476522207, \"match_probability\": 0.9999999109000172, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58375.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245586.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19204766400952752, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8079523359904724, \"precision\": 0.9997602288102211, \"recall\": 0.19204766400952752, \"specificity\": 0.9999999890517038, \"npv\": 0.9998079834289385, \"accuracy\": 0.9998079812489123, \"f1\": 0.32220229060300815, \"f2\": 0.2290593635543892, \"f0_5\": 0.5430060816681147, \"p4\": 0.4873607510512076, \"phi\": 0.43813779708573586}, {\"truth_threshold\": 23.439999476075172, \"match_probability\": 0.9999999121266828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58316.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245645.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1918535601606785, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8081464398393214, \"precision\": 0.9997599862849306, \"recall\": 0.1918535601606785, \"specificity\": 0.9999999890517038, \"npv\": 0.9998079373074095, \"accuracy\": 0.9998079351206294, \"f1\": 0.3219290570287421, \"f2\": 0.22883844749618185, \"f0_5\": 0.5426955354832946, \"p4\": 0.48704811325099373, \"phi\": 0.43791626347972273}, {\"truth_threshold\": 23.459999475628138, \"match_probability\": 0.9999999133364607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58237.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245724.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1915936583969654, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8084063416030346, \"precision\": 0.9997596607783558, \"recall\": 0.1915936583969654, \"specificity\": 0.9999999890517038, \"npv\": 0.9998078755514705, \"accuracy\": 0.9998078733556401, \"f1\": 0.3215630625158747, \"f2\": 0.22854261259953143, \"f0_5\": 0.5422792919464025, \"p4\": 0.486629134486886, \"phi\": 0.437619458155955}, {\"truth_threshold\": 23.479999475181103, \"match_probability\": 0.999999914529583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58180.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245781.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19140613433960277, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8085938656603973, \"precision\": 0.999759425370313, \"recall\": 0.19140613433960277, \"specificity\": 0.9999999890517038, \"npv\": 0.9998078309933928, \"accuracy\": 0.9998078287910277, \"f1\": 0.3212988913586724, \"f2\": 0.22832913931923537, \"f0_5\": 0.5419786599395979, \"p4\": 0.48632657559949344, \"phi\": 0.43740518242181514}, {\"truth_threshold\": 23.499999474734068, \"match_probability\": 0.9999999157062794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58086.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1910968841397416, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8089031158602584, \"precision\": 0.9997590361445783, \"recall\": 0.1910968841397416, \"specificity\": 0.9999999890517038, \"npv\": 0.9998077575116592, \"accuracy\": 0.999807755298509, \"f1\": 0.3208630589872977, \"f2\": 0.22797705393643677, \"f0_5\": 0.5414823225402294, \"p4\": 0.48582714620672157, \"phi\": 0.43705158598694704}, {\"truth_threshold\": 23.519999474287033, \"match_probability\": 0.9999999168667758, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58003.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245958.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19082382279305568, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8091761772069443, \"precision\": 0.9997586914180326, \"recall\": 0.19082382279305568, \"specificity\": 0.9999999890517038, \"npv\": 0.9998076926288607, \"accuracy\": 0.9998076904061787, \"f1\": 0.32047804010188463, \"f2\": 0.22766612683801452, \"f0_5\": 0.5410434883187291, \"p4\": 0.48538567078038136, \"phi\": 0.4367391299113363}, {\"truth_threshold\": 23.53999947384, \"match_probability\": 0.9999999180112954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57879.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1904158757208984, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8095841242791016, \"precision\": 0.9997581745634188, \"recall\": 0.1904158757208984, \"specificity\": 0.9999999890517038, \"npv\": 0.9998075956955391, \"accuracy\": 0.9998075934586007, \"f1\": 0.3199025021141123, \"f2\": 0.22720153375461338, \"f0_5\": 0.5403868669157643, \"p4\": 0.4847252595658486, \"phi\": 0.43627191124452624}, {\"truth_threshold\": 23.559999473392963, \"match_probability\": 0.999999919140058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57800.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1901559739571853, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8098440260428147, \"precision\": 0.9997578441208012, \"recall\": 0.1901559739571853, \"specificity\": 0.9999999890517038, \"npv\": 0.9998075339396424, \"accuracy\": 0.9998075316936116, \"f1\": 0.3195356229700781, \"f2\": 0.22690549582383968, \"f0_5\": 0.5399679008701144, \"p4\": 0.48430397695365474, \"phi\": 0.4359739866728611}, {\"truth_threshold\": 23.57999947294593, \"match_probability\": 0.9999999202532805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57697.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246264.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1898171146956353, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8101828853043647, \"precision\": 0.9997574119318674, \"recall\": 0.1898171146956353, \"specificity\": 0.9999999890517038, \"npv\": 0.999807453422472, \"accuracy\": 0.999807451164575, \"f1\": 0.31905704616337455, \"f2\": 0.22651946716082147, \"f0_5\": 0.5394209104252952, \"p4\": 0.483754081115098, \"phi\": 0.43558524739614374}, {\"truth_threshold\": 23.599999472498894, \"match_probability\": 0.9999999213511771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57625.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246336.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1895802422021246, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8104197577978753, \"precision\": 0.9997571089019588, \"recall\": 0.1895802422021246, \"specificity\": 0.9999999890517038, \"npv\": 0.9998073971386325, \"accuracy\": 0.9998073948724331, \"f1\": 0.3187223451327434, \"f2\": 0.2262495848001112, \"f0_5\": 0.5390380474334773, \"p4\": 0.4833692646992422, \"phi\": 0.43531330120764067}, {\"truth_threshold\": 23.61999947205186, \"match_probability\": 0.9999999224339586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57536.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18928744148097948, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8107125585190206, \"precision\": 0.9997567332754127, \"recall\": 0.18928744148097948, \"specificity\": 0.9999999890517038, \"npv\": 0.9998073275655618, \"accuracy\": 0.9998073252890909, \"f1\": 0.31830843321503355, \"f2\": 0.22591593803646004, \"f0_5\": 0.538564215657826, \"p4\": 0.482893106770095, \"phi\": 0.434976910570438}, {\"truth_threshold\": 23.639999471604824, \"match_probability\": 0.9999999235018331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57481.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246480.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18910649721510325, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8108935027848967, \"precision\": 0.9997565005652665, \"recall\": 0.18910649721510325, \"specificity\": 0.9999999890517038, \"npv\": 0.9998072845709725, \"accuracy\": 0.9998072822881491, \"f1\": 0.31805254304811653, \"f2\": 0.22570972851691498, \"f0_5\": 0.538271082385507, \"p4\": 0.4825985850488487, \"phi\": 0.4347688986193285}, {\"truth_threshold\": 23.65999947115779, \"match_probability\": 0.9999999245550059, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57400.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246561.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18884001565990374, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8111599843400963, \"precision\": 0.9997561570348695, \"recall\": 0.18884001565990374, \"specificity\": 0.9999999890517038, \"npv\": 0.9998072212516748, \"accuracy\": 0.9998072189594893, \"f1\": 0.31767554479418886, \"f2\": 0.2254060056956249, \"f0_5\": 0.5378389369154281, \"p4\": 0.48216446322738904, \"phi\": 0.43446237243883556}, {\"truth_threshold\": 23.679999470710754, \"match_probability\": 0.9999999255936793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57306.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18853076546004258, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8114692345399575, \"precision\": 0.9997557571528263, \"recall\": 0.18853076546004258, \"specificity\": 0.9999999890517038, \"npv\": 0.9998071477700308, \"accuracy\": 0.9998071454669706, \"f1\": 0.3172378287261162, \"f2\": 0.2250534887885614, \"f0_5\": 0.5373367764294193, \"p4\": 0.4816601117499345, \"phi\": 0.4341063794129952}, {\"truth_threshold\": 23.69999947026372, \"match_probability\": 0.999999926618053, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57246.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246715.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18833337171545034, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8116666282845496, \"precision\": 0.9997555012224939, \"recall\": 0.18833337171545034, \"specificity\": 0.9999999890517038, \"npv\": 0.9998071008668594, \"accuracy\": 0.9998070985568522, \"f1\": 0.3169583163769548, \"f2\": 0.22482845077856956, \"f0_5\": 0.5370158780189905, \"p4\": 0.48133787262755223, \"phi\": 0.4338789971278278}, {\"truth_threshold\": 23.719999469816685, \"match_probability\": 0.9999999276283239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57178.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18810965880491248, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8118903411950875, \"precision\": 0.9997552105189537, \"recall\": 0.18810965880491248, \"specificity\": 0.9999999890517038, \"npv\": 0.9998070477099371, \"accuracy\": 0.9998070453920515, \"f1\": 0.3166414234410347, \"f2\": 0.2245733820567525, \"f0_5\": 0.5366518436203023, \"p4\": 0.4809723733651763, \"phi\": 0.4336211530889618}, {\"truth_threshold\": 23.73999946936965, \"match_probability\": 0.999999928624686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57111.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18788923579011782, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8121107642098822, \"precision\": 0.9997549234135668, \"recall\": 0.18788923579011782, \"specificity\": 0.9999999890517038, \"npv\": 0.9998069953347398, \"accuracy\": 0.9998069930090859, \"f1\": 0.31632907396022, \"f2\": 0.2243220376929839, \"f0_5\": 0.5362927989092159, \"p4\": 0.48061194223670434, \"phi\": 0.43336695085691906}, {\"truth_threshold\": 23.759999468922615, \"match_probability\": 0.999999929607331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57026.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1876095946519455, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8123904053480545, \"precision\": 0.9997545582047686, \"recall\": 0.1876095946519455, \"specificity\": 0.9999999890517038, \"npv\": 0.999806928888602, \"accuracy\": 0.9998069265530849, \"f1\": 0.3159326428458647, \"f2\": 0.22400312990028942, \"f0_5\": 0.5358367739668234, \"p4\": 0.48015423993958434, \"phi\": 0.4330442407881531}, {\"truth_threshold\": 23.77999946847558, \"match_probability\": 0.9999999305764475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56982.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246979.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1874648392392445, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8125351607607555, \"precision\": 0.99975436872763, \"recall\": 0.1874648392392445, \"specificity\": 0.9999999890517038, \"npv\": 0.9998068944929576, \"accuracy\": 0.9998068921523314, \"f1\": 0.31572735810636726, \"f2\": 0.22383803148863957, \"f0_5\": 0.5356004850125483, \"p4\": 0.4799171186247867, \"phi\": 0.43287709638641186}, {\"truth_threshold\": 23.799999468028545, \"match_probability\": 0.999999931532222, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56878.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18712269008195132, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8128773099180487, \"precision\": 0.999753919707516, \"recall\": 0.18712269008195132, \"specificity\": 0.9999999890517038, \"npv\": 0.9998068131941712, \"accuracy\": 0.9998068108414597, \"f1\": 0.3152419406240214, \"f2\": 0.22344775350111884, \"f0_5\": 0.5350413618071639, \"p4\": 0.4793561257386589, \"phi\": 0.4324817710578836}, {\"truth_threshold\": 23.81999946758151, \"match_probability\": 0.9999999324748381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56820.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1869318761288455, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8130681238711546, \"precision\": 0.9997536685786677, \"recall\": 0.1869318761288455, \"specificity\": 0.9999999890517038, \"npv\": 0.9998067678544691, \"accuracy\": 0.9998067654950119, \"f1\": 0.31497110547540846, \"f2\": 0.22323007076416815, \"f0_5\": 0.5347291627846572, \"p4\": 0.4790429438325096, \"phi\": 0.4322611441514611}, {\"truth_threshold\": 23.839999467134476, \"match_probability\": 0.9999999334044769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56747.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247214.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1866917137395916, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8133082862604084, \"precision\": 0.9997533517732246, \"recall\": 0.1866917137395916, \"specificity\": 0.9999999890517038, \"npv\": 0.9998067107889879, \"accuracy\": 0.9998067084210346, \"f1\": 0.3146301029601743, \"f2\": 0.22295606256458209, \"f0_5\": 0.5343358348791443, \"p4\": 0.47864843993574235, \"phi\": 0.4319832984293644}, {\"truth_threshold\": 23.85999946668744, \"match_probability\": 0.9999999343213171, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56680.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247281.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18647129072479693, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.813528709275203, \"precision\": 0.9997530602885667, \"recall\": 0.18647129072479693, \"specificity\": 0.9999999890517038, \"npv\": 0.9998066584138259, \"accuracy\": 0.9998066560380692, \"f1\": 0.31431700655751343, \"f2\": 0.2227045479191977, \"f0_5\": 0.5339744543907812, \"p4\": 0.47828604019641885, \"phi\": 0.4317281319991486}, {\"truth_threshold\": 23.879999466240406, \"match_probability\": 0.9999999352255348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56617.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247344.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1862640272929751, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8137359727070249, \"precision\": 0.9997527855768042, \"recall\": 0.1862640272929751, \"specificity\": 0.9999999890517038, \"npv\": 0.9998066091655443, \"accuracy\": 0.9998066067824449, \"f1\": 0.3140224963393531, \"f2\": 0.2224680249120808, \"f0_5\": 0.5336343157676466, \"p4\": 0.47794499578309074, \"phi\": 0.431488061758105}, {\"truth_threshold\": 23.89999946579337, \"match_probability\": 0.9999999361173039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56513.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18592187813568187, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8140781218643182, \"precision\": 0.9997523307445999, \"recall\": 0.18592187813568187, \"specificity\": 0.9999999890517038, \"npv\": 0.9998065278668044, \"accuracy\": 0.9998065254715731, \"f1\": 0.3135360955149686, \"f2\": 0.22207752298661318, \"f0_5\": 0.5330721094800865, \"p4\": 0.47738140615479097, \"phi\": 0.43109146286690064}, {\"truth_threshold\": 23.919999465346336, \"match_probability\": 0.9999999369967958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56453.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247508.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18572448439108966, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8142755156089103, \"precision\": 0.9997520675792941, \"recall\": 0.18572448439108966, \"specificity\": 0.9999999890517038, \"npv\": 0.9998064809636911, \"accuracy\": 0.9998064785614548, \"f1\": 0.31325535197043514, \"f2\": 0.22185220437455935, \"f0_5\": 0.5327473581098807, \"p4\": 0.4770559203209359, \"phi\": 0.43086248978460506}, {\"truth_threshold\": 23.9399994648993, \"match_probability\": 0.9999999378641794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56354.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247607.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18539878471251245, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8146012152874875, \"precision\": 0.9997516321317059, \"recall\": 0.18539878471251245, \"specificity\": 0.9999999890517038, \"npv\": 0.9998064035735639, \"accuracy\": 0.9998064011597595, \"f1\": 0.3127919207169004, \"f2\": 0.22148038220045088, \"f0_5\": 0.5322108746526945, \"p4\": 0.47651832714207804, \"phi\": 0.43048441798272535}, {\"truth_threshold\": 23.959999464452267, \"match_probability\": 0.9999999387196216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56311.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247650.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1852573191955547, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8147426808044453, \"precision\": 0.9997514425210831, \"recall\": 0.1852573191955547, \"specificity\": 0.9999999890517038, \"npv\": 0.999806369959674, \"accuracy\": 0.9998063675408413, \"f1\": 0.31259055306062405, \"f2\": 0.22131886565385575, \"f0_5\": 0.5319776065117211, \"p4\": 0.4762846167346018, \"phi\": 0.43032010152641387}, {\"truth_threshold\": 23.979999464005232, \"match_probability\": 0.9999999395632866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56254.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247707.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18506979513819208, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8149302048618079, \"precision\": 0.9997511907300775, \"recall\": 0.18506979513819208, \"specificity\": 0.9999999890517038, \"npv\": 0.9998063254017304, \"accuracy\": 0.999806322976229, \"f1\": 0.3123235497419697, \"f2\": 0.22110474549410744, \"f0_5\": 0.5316681568068533, \"p4\": 0.4759746179645912, \"phi\": 0.4301021899454851}, {\"truth_threshold\": 23.999999463558197, \"match_probability\": 0.9999999403953366, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56190.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18485924181062702, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8151407581893729, \"precision\": 0.9997509074087254, \"recall\": 0.18485924181062702, \"specificity\": 0.9999999890517038, \"npv\": 0.9998062753717634, \"accuracy\": 0.9998062729387693, \"f1\": 0.3120236558244138, \"f2\": 0.22086430700728274, \"f0_5\": 0.5313203864767189, \"p4\": 0.4756262817893407, \"phi\": 0.42985738566612935}, {\"truth_threshold\": 24.019999463111162, \"match_probability\": 0.9999999412159316, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56112.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1846026299426571, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8153973700573429, \"precision\": 0.9997505612372163, \"recall\": 0.1846026299426571, \"specificity\": 0.9999999890517038, \"npv\": 0.9998062143977479, \"accuracy\": 0.9998062119556155, \"f1\": 0.3116580159794716, \"f2\": 0.2205712398877332, \"f0_5\": 0.5308960858334989, \"p4\": 0.4752013641658989, \"phi\": 0.4295588418549585}, {\"truth_threshold\": 24.039999462664127, \"match_probability\": 0.9999999420252291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56000.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18423416161941827, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8157658383805817, \"precision\": 0.9997500624843789, \"recall\": 0.18423416161941827, \"specificity\": 0.9999999890517038, \"npv\": 0.9998061268453283, \"accuracy\": 0.9998061243900612, \"f1\": 0.31113271754982985, \"f2\": 0.22015036269772253, \"f0_5\": 0.5302859567021516, \"p4\": 0.47459048917842717, \"phi\": 0.4291298003975278}, {\"truth_threshold\": 24.059999462217093, \"match_probability\": 0.9999999428233849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55954.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248007.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1840828264152309, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8159171735847691, \"precision\": 0.9997498570611778, \"recall\": 0.1840828264152309, \"specificity\": 0.9999999890517038, \"npv\": 0.9998060908863033, \"accuracy\": 0.9998060884256372, \"f1\": 0.31091687527262324, \"f2\": 0.21997748094844208, \"f0_5\": 0.5300350679097366, \"p4\": 0.47433934204795253, \"phi\": 0.42895346264471773}, {\"truth_threshold\": 24.079999461770058, \"match_probability\": 0.9999999436105522, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55860.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248101.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18377357621536974, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8162264237846303, \"precision\": 0.9997494362315209, \"recall\": 0.18377357621536974, \"specificity\": 0.9999999890517038, \"npv\": 0.9998060174048254, \"accuracy\": 0.9998060149331185, \"f1\": 0.3104756346658885, \"f2\": 0.21962416196043463, \"f0_5\": 0.5295218377991002, \"p4\": 0.4738256712403499, \"phi\": 0.4285928947111682}, {\"truth_threshold\": 24.099999461323023, \"match_probability\": 0.9999999443868823, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55758.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248203.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18343800684956293, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8165619931504371, \"precision\": 0.999748977981783, \"recall\": 0.18343800684956293, \"specificity\": 0.9999999890517038, \"npv\": 0.999805937669617, \"accuracy\": 0.9998059351859173, \"f1\": 0.30999658079742476, \"f2\": 0.219240714177865, \"f0_5\": 0.5289641001121338, \"p4\": 0.4732675882860006, \"phi\": 0.428201296728948}, {\"truth_threshold\": 24.119999460875988, \"match_probability\": 0.9999999451525244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55644.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1830629587348377, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8169370412651623, \"precision\": 0.9997484638326926, \"recall\": 0.1830629587348377, \"specificity\": 0.9999999890517038, \"npv\": 0.9998058485538109, \"accuracy\": 0.9998058460566924, \"f1\": 0.30946084606208235, \"f2\": 0.21881208208874228, \"f0_5\": 0.5283397234676496, \"p4\": 0.4726429902012082, \"phi\": 0.42776320423596853}, {\"truth_threshold\": 24.139999460428953, \"match_probability\": 0.9999999459076259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55554.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248407.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18276686811794934, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8172331318820507, \"precision\": 0.9997480564353585, \"recall\": 0.18276686811794934, \"specificity\": 0.9999999890517038, \"npv\": 0.9998057781992383, \"accuracy\": 0.9998057756915149, \"f1\": 0.30903765760202934, \"f2\": 0.21847363403837622, \"f0_5\": 0.5278460301805474, \"p4\": 0.4721492452319939, \"phi\": 0.4274170246118426}, {\"truth_threshold\": 24.15999945998192, \"match_probability\": 0.9999999466523315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55439.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1823885301074809, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8176114698925191, \"precision\": 0.9997475339476674, \"recall\": 0.1823885301074809, \"specificity\": 0.9999999890517038, \"npv\": 0.9998056883017433, \"accuracy\": 0.9998056857804547, \"f1\": 0.3084966083680658, \"f2\": 0.21804110290514334, \"f0_5\": 0.5272142160209824, \"p4\": 0.4715175238563522, \"phi\": 0.4269742756031814}, {\"truth_threshold\": 24.179999459534883, \"match_probability\": 0.9999999473867845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55394.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248567.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1822404847990367, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8177595152009632, \"precision\": 0.9997473289055732, \"recall\": 0.1822404847990367, \"specificity\": 0.9999999890517038, \"npv\": 0.9998056531244671, \"accuracy\": 0.999805650597866, \"f1\": 0.3082847991896908, \"f2\": 0.21787183029013918, \"f0_5\": 0.5269666833462394, \"p4\": 0.47127007616368416, \"phi\": 0.4268009009878908}, {\"truth_threshold\": 24.19999945908785, \"match_probability\": 0.9999999481111261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55329.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18202664157572845, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8179733584242715, \"precision\": 0.9997831625738602, \"recall\": 0.18202664157572845, \"specificity\": 0.9999999906157462, \"npv\": 0.9998056023131542, \"accuracy\": 0.9998056013422417, \"f1\": 0.30798047325091427, \"f2\": 0.2176276466446662, \"f0_5\": 0.5266168562318565, \"p4\": 0.47091440483351554, \"phi\": 0.42655805753592213}, {\"truth_threshold\": 24.219999458640814, \"match_probability\": 0.9999999488254956, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55258.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248703.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.181793058977961, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8182069410220391, \"precision\": 0.9997828840238827, \"recall\": 0.181793058977961, \"specificity\": 0.9999999906157462, \"npv\": 0.9998055468112402, \"accuracy\": 0.999805545831935, \"f1\": 0.3076460550453608, \"f2\": 0.2173605199848322, \"f0_5\": 0.5262255709554111, \"p4\": 0.4705233731235748, \"phi\": 0.42628421174153924}, {\"truth_threshold\": 24.23999945819378, \"match_probability\": 0.99999994953003, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55175.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248786.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18151999763127508, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.818480002368725, \"precision\": 0.9997825574863646, \"recall\": 0.18151999763127508, \"specificity\": 0.9999999906157462, \"npv\": 0.9998054819287289, \"accuracy\": 0.9998054809396046, \"f1\": 0.307254947820954, \"f2\": 0.21704820732145794, \"f0_5\": 0.5257676159547483, \"p4\": 0.47006580172355156, \"phi\": 0.4259638589909838}, {\"truth_threshold\": 24.259999457746744, \"match_probability\": 0.999999950224865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55071.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18117784847398186, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8188221515260181, \"precision\": 0.9997821469418877, \"recall\": 0.18117784847398186, \"specificity\": 0.9999999906157462, \"npv\": 0.9998054006301723, \"accuracy\": 0.9998053996287328, \"f1\": 0.3067646305188222, \"f2\": 0.21665681821221833, \"f0_5\": 0.5251929741575798, \"p4\": 0.46949177370407486, \"phi\": 0.4255621127991854}, {\"truth_threshold\": 24.27999945729971, \"match_probability\": 0.9999999509101339, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55021.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18101335368682167, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8189866463131783, \"precision\": 0.9997819490124107, \"recall\": 0.18101335368682167, \"specificity\": 0.9999999906157462, \"npv\": 0.9998053615443325, \"accuracy\": 0.9998053605369676, \"f1\": 0.3065287999242327, \"f2\": 0.21646862756978055, \"f0_5\": 0.5249163793448872, \"p4\": 0.46921552685810203, \"phi\": 0.42536883055330416}, {\"truth_threshold\": 24.299999456852674, \"match_probability\": 0.9999999515859685, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54907.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249054.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18063830557209642, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8193616944279036, \"precision\": 0.9998179070233261, \"recall\": 0.18063830557209642, \"specificity\": 0.9999999921797885, \"npv\": 0.9998052724289337, \"accuracy\": 0.9998052729714133, \"f1\": 0.3059925657187122, \"f2\": 0.2160398375461633, \"f0_5\": 0.524292963147572, \"p4\": 0.46858702246732975, \"phi\": 0.4249355592670296}, {\"truth_threshold\": 24.31999945640564, \"match_probability\": 0.9999999522524988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54797.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.180276417040344, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.819723582959656, \"precision\": 0.9998175415549109, \"recall\": 0.180276417040344, \"specificity\": 0.9999999921797885, \"npv\": 0.9998051864401124, \"accuracy\": 0.9998051869695297, \"f1\": 0.3054731748650939, \"f2\": 0.21562569108275995, \"f0_5\": 0.5236826462330056, \"p4\": 0.46797776734748675, \"phi\": 0.42450959468282456}, {\"truth_threshold\": 24.339999455958605, \"match_probability\": 0.9999999529098527, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54714.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18000335569365808, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8199966443063419, \"precision\": 0.9998172648198231, \"recall\": 0.18000335569365808, \"specificity\": 0.9999999921797885, \"npv\": 0.999805121557648, \"accuracy\": 0.9998051220771993, \"f1\": 0.30508105998299345, \"f2\": 0.21531315128352044, \"f0_5\": 0.5232214544320913, \"p4\": 0.46751748805548915, \"phi\": 0.4241879019458107}, {\"truth_threshold\": 24.35999945551157, \"match_probability\": 0.9999999535581566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54620.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249341.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1796941054937969, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8203058945062031, \"precision\": 0.9998169503935567, \"recall\": 0.1796941054937969, \"specificity\": 0.9999999921797885, \"npv\": 0.9998050480763128, \"accuracy\": 0.9998050485846806, \"f1\": 0.30463675887013336, \"f2\": 0.21495914123390167, \"f0_5\": 0.522698433053068, \"p4\": 0.46699561622378527, \"phi\": 0.4238232804244115}, {\"truth_threshold\": 24.379999455064535, \"match_probability\": 0.9999999541975352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54552.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17947039258325903, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.820529607416741, \"precision\": 0.9998167222609142, \"recall\": 0.17947039258325903, \"specificity\": 0.9999999921797885, \"npv\": 0.9998049949196091, \"accuracy\": 0.9998049954198798, \"f1\": 0.30431520432440873, \"f2\": 0.21470301620111995, \"f0_5\": 0.5223196076666622, \"p4\": 0.4666176995604352, \"phi\": 0.4235593160348227}, {\"truth_threshold\": 24.3999994546175, \"match_probability\": 0.9999999548281112, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54464.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249497.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1791808817578571, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8208191182421429, \"precision\": 0.999816426184969, \"recall\": 0.1791808817578571, \"specificity\": 0.9999999921797885, \"npv\": 0.999804926128589, \"accuracy\": 0.9998049266183728, \"f1\": 0.30389889380222357, \"f2\": 0.21437151957226458, \"f0_5\": 0.5218287768488302, \"p4\": 0.46612814119904383, \"phi\": 0.4232174707101238}, {\"truth_threshold\": 24.419999454170465, \"match_probability\": 0.9999999554500059, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54369.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249592.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1788683416622527, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8211316583377473, \"precision\": 0.9998161054818956, \"recall\": 0.1788683416622527, \"specificity\": 0.9999999921797885, \"npv\": 0.9998048518655666, \"accuracy\": 0.9998048523440188, \"f1\": 0.3034492381537088, \"f2\": 0.21401360233596778, \"f0_5\": 0.5212981588833256, \"p4\": 0.46559901949581367, \"phi\": 0.4228481229878249}, {\"truth_threshold\": 24.43999945372343, \"match_probability\": 0.9999999560633388, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54237.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249724.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1784340754241498, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8215659245758502, \"precision\": 0.9998156580087378, \"recall\": 0.1784340754241498, \"specificity\": 0.9999999921797885, \"npv\": 0.9998047486790695, \"accuracy\": 0.9998047491417584, \"f1\": 0.3028240575308201, \"f2\": 0.21351619687093287, \"f0_5\": 0.5205595941253367, \"p4\": 0.4648627459739474, \"phi\": 0.42233438792644923}, {\"truth_threshold\": 24.459999453276396, \"match_probability\": 0.9999999566682277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54139.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17811166564131584, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8218883343586841, \"precision\": 0.9998153243827218, \"recall\": 0.17811166564131584, \"specificity\": 0.9999999921797885, \"npv\": 0.9998046720709265, \"accuracy\": 0.9998046725218985, \"f1\": 0.30235961017564433, \"f2\": 0.21314684411646365, \"f0_5\": 0.5200102966629975, \"p4\": 0.4643153099465227, \"phi\": 0.4219525740642966}, {\"truth_threshold\": 24.47999945282936, \"match_probability\": 0.9999999572647891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54060.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1778517638776027, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8221482361223973, \"precision\": 0.9998150545589051, \"recall\": 0.1778517638776027, \"specificity\": 0.9999999921797885, \"npv\": 0.9998046103153911, \"accuracy\": 0.9998046107569094, \"f1\": 0.30198502364320406, \"f2\": 0.21284905907014176, \"f0_5\": 0.5195668930361121, \"p4\": 0.46387350677971184, \"phi\": 0.4216445336861306}, {\"truth_threshold\": 24.499999452382326, \"match_probability\": 0.9999999578531372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53979.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1775852823224032, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8224147176775968, \"precision\": 0.9998147770842208, \"recall\": 0.1775852823224032, \"specificity\": 0.9999999921797885, \"npv\": 0.9998045469964324, \"accuracy\": 0.9998045474282496, \"f1\": 0.3016007822321553, \"f2\": 0.2125436966908247, \"f0_5\": 0.5191117043681972, \"p4\": 0.4634200520301607, \"phi\": 0.42132846101890403}, {\"truth_threshold\": 24.51999945193529, \"match_probability\": 0.9999999584333855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53897.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250064.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1773155108714605, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8226844891285395, \"precision\": 0.9998144953345577, \"recall\": 0.1773155108714605, \"specificity\": 0.9999999921797885, \"npv\": 0.9998044828957663, \"accuracy\": 0.9998044833177545, \"f1\": 0.30121161992690043, \"f2\": 0.21223452472177615, \"f0_5\": 0.5186503178473755, \"p4\": 0.46296051701078245, \"phi\": 0.4210082445564284}, {\"truth_threshold\": 24.539999451488256, \"match_probability\": 0.9999999590056454, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53816.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250145.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17704902931626096, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.822950970683739, \"precision\": 0.9998142161780552, \"recall\": 0.17704902931626096, \"specificity\": 0.9999999921797885, \"npv\": 0.9998044195768238, \"accuracy\": 0.9998044199890948, \"f1\": 0.30082702837162895, \"f2\": 0.21192908393519577, \"f0_5\": 0.5181939857298297, \"p4\": 0.4625061091437985, \"phi\": 0.4206916939156479}, {\"truth_threshold\": 24.55999945104122, \"match_probability\": 0.9999999595700267, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53741.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250220.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17680228713552068, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8231977128644793, \"precision\": 0.9998139569496381, \"recall\": 0.17680228713552068, \"specificity\": 0.9999999921797885, \"npv\": 0.9998043609481804, \"accuracy\": 0.9998043613514468, \"f1\": 0.30047076978127657, \"f2\": 0.21164623364143684, \"f0_5\": 0.5177709479444664, \"p4\": 0.46208493782988425, \"phi\": 0.42039837898078253}, {\"truth_threshold\": 24.579999450594187, \"match_probability\": 0.999999960126638, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53649.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17649961672714592, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8235003832728541, \"precision\": 0.9998136379731266, \"recall\": 0.17649961672714592, \"specificity\": 0.9999999921797885, \"npv\": 0.9998042890303872, \"accuracy\": 0.9998042894225987, \"f1\": 0.3000335551702925, \"f2\": 0.2112992249722923, \"f0_5\": 0.517251353170188, \"p4\": 0.46156774428147246, \"phi\": 0.4200382996495447}, {\"truth_threshold\": 24.599999450147152, \"match_probability\": 0.9999999606755864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53588.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250373.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17629893308681047, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8237010669131896, \"precision\": 0.9998134258740998, \"recall\": 0.17629893308681047, \"specificity\": 0.9999999921797885, \"npv\": 0.9998042413457692, \"accuracy\": 0.9998042417306451, \"f1\": 0.299743538828557, \"f2\": 0.21106911540661172, \"f0_5\": 0.5169064324890567, \"p4\": 0.46122448377970565, \"phi\": 0.4197993811433834}, {\"truth_threshold\": 24.619999449700117, \"match_probability\": 0.9999999612169772, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53515.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250446.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1760587706975566, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8239412293024434, \"precision\": 0.9998131714152265, \"recall\": 0.1760587706975566, \"specificity\": 0.9999999921797885, \"npv\": 0.9998041842805765, \"accuracy\": 0.9998041846566678, \"f1\": 0.2993963399965313, \"f2\": 0.21079370931541577, \"f0_5\": 0.5164932314920444, \"p4\": 0.4608133411170811, \"phi\": 0.4195132834542025}, {\"truth_threshold\": 24.639999449253082, \"match_probability\": 0.9999999617509145, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53441.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250520.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1758153184125595, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8241846815874405, \"precision\": 0.9998129127612205, \"recall\": 0.1758153184125595, \"specificity\": 0.9999999921797885, \"npv\": 0.9998041264336756, \"accuracy\": 0.9998041268008551, \"f1\": 0.29904424026053966, \"f2\": 0.21051449820569687, \"f0_5\": 0.51607389452744, \"p4\": 0.4603961704954028, \"phi\": 0.41922306737517906}, {\"truth_threshold\": 24.659999448806047, \"match_probability\": 0.999999962277501, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53372.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17558831560627844, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8244116843937216, \"precision\": 0.9998126709377693, \"recall\": 0.17558831560627844, \"specificity\": 0.9999999921797885, \"npv\": 0.999804072495355, \"accuracy\": 0.999804072854219, \"f1\": 0.29871579966586725, \"f2\": 0.21025412337913027, \"f0_5\": 0.5156824589508183, \"p4\": 0.4600068275006022, \"phi\": 0.4189522793995055}, {\"truth_threshold\": 24.679999448359013, \"match_probability\": 0.9999999627968377, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53299.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17534815321702454, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8246518467829754, \"precision\": 0.9998124144140764, \"recall\": 0.17534815321702454, \"specificity\": 0.9999999921797885, \"npv\": 0.9998040154301816, \"accuracy\": 0.9998040157802417, \"f1\": 0.29836818092758977, \"f2\": 0.20997862353869076, \"f0_5\": 0.5152678766504832, \"p4\": 0.4595945356076025, \"phi\": 0.4186656029355339}, {\"truth_threshold\": 24.699999447911978, \"match_probability\": 0.9999999633090246, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53248.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17518036853412117, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8248196314658789, \"precision\": 0.9998122347816291, \"recall\": 0.17518036853412117, \"specificity\": 0.9999999921797885, \"npv\": 0.9998039755627356, \"accuracy\": 0.999803975906641, \"f1\": 0.2981252396988962, \"f2\": 0.20978613224153772, \"f0_5\": 0.5149779590826181, \"p4\": 0.45930626499395244, \"phi\": 0.4184652056068666}, {\"truth_threshold\": 24.719999447464943, \"match_probability\": 0.9999999638141601, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53188.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250773.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17498297478952893, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.825017025210471, \"precision\": 0.9998120230083838, \"recall\": 0.17498297478952893, \"specificity\": 0.9999999921797885, \"npv\": 0.999803928659862, \"accuracy\": 0.9998039289965227, \"f1\": 0.29783933766193765, \"f2\": 0.20955965208401298, \"f0_5\": 0.5146365865316699, \"p4\": 0.45896687945669506, \"phi\": 0.4182293211298886}, {\"truth_threshold\": 24.739999447017908, \"match_probability\": 0.9999999643123412, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53129.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250832.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17478887094067988, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8252111290593201, \"precision\": 0.9998118142983496, \"recall\": 0.17478887094067988, \"specificity\": 0.9999999921797885, \"npv\": 0.9998038825387072, \"accuracy\": 0.9998038828682397, \"f1\": 0.29755810697283674, \"f2\": 0.20933692571137674, \"f0_5\": 0.5143005941721183, \"p4\": 0.45863289321724443, \"phi\": 0.41799723827738855}, {\"truth_threshold\": 24.759999446570873, \"match_probability\": 0.9999999648036637, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53066.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17458160750885804, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8254183924911419, \"precision\": 0.999811590926219, \"recall\": 0.17458160750885804, \"specificity\": 0.9999999921797885, \"npv\": 0.9998038332906992, \"accuracy\": 0.9998038336126155, \"f1\": 0.29725770718440947, \"f2\": 0.20909907637991362, \"f0_5\": 0.5139414835404298, \"p4\": 0.4582759820291775, \"phi\": 0.4177492786747029}, {\"truth_threshold\": 24.77999944612384, \"match_probability\": 0.999999965288222, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52955.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251006.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17421642908136242, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8257835709186376, \"precision\": 0.9998111960728783, \"recall\": 0.17421642908136242, \"specificity\": 0.9999999921797885, \"npv\": 0.9998037465204113, \"accuracy\": 0.9998037468288965, \"f1\": 0.2967281733468562, \"f2\": 0.20867995104070036, \"f0_5\": 0.51330791107768, \"p4\": 0.4576464292734983, \"phi\": 0.41731203905204284}, {\"truth_threshold\": 24.799999445676804, \"match_probability\": 0.9999999657661093, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52878.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1739631071091357, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8260368928908642, \"precision\": 0.9998109211919528, \"recall\": 0.1739631071091357, \"specificity\": 0.9999999921797885, \"npv\": 0.9998036863284185, \"accuracy\": 0.999803686627578, \"f1\": 0.2963606455391496, \"f2\": 0.20838916335364757, \"f0_5\": 0.5128677647314422, \"p4\": 0.45720918005517486, \"phi\": 0.4170084594090693}, {\"truth_threshold\": 24.81999944522977, \"match_probability\": 0.9999999662374174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52829.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251132.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1738019022177187, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8261980977822813, \"precision\": 0.9998107458506028, \"recall\": 0.1738019022177187, \"specificity\": 0.9999999921797885, \"npv\": 0.9998036480244269, \"accuracy\": 0.999803648317648, \"f1\": 0.2961266816143498, \"f2\": 0.20820409826568181, \"f0_5\": 0.5125873976600811, \"p4\": 0.45693070311751194, \"phi\": 0.41681515726098073}, {\"truth_threshold\": 24.839999444782734, \"match_probability\": 0.9999999667022368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52757.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251204.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17356502972420804, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8264349702757919, \"precision\": 0.9998104876153656, \"recall\": 0.17356502972420804, \"specificity\": 0.9999999921797885, \"npv\": 0.999803591741016, \"accuracy\": 0.999803592025506, \"f1\": 0.29578278127873336, \"f2\": 0.2079321399546433, \"f0_5\": 0.5121750425704183, \"p4\": 0.4565211911739764, \"phi\": 0.4165309587282003}, {\"truth_threshold\": 24.8599994443357, \"match_probability\": 0.999999967160657, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52683.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251278.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17332157743921095, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.826678422560789, \"precision\": 0.9998102214715427, \"recall\": 0.17332157743921095, \"specificity\": 0.9999999921797885, \"npv\": 0.9998035338941836, \"accuracy\": 0.9998035341696934, \"f1\": 0.29542918346632874, \"f2\": 0.20765259507606007, \"f0_5\": 0.5117507523317915, \"p4\": 0.45609990488959523, \"phi\": 0.41623866362068074}, {\"truth_threshold\": 24.879999443888664, \"match_probability\": 0.9999999676127659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52621.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251340.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1731176039031323, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8268823960968676, \"precision\": 0.999809997909977, \"recall\": 0.1731176039031323, \"specificity\": 0.9999999921797885, \"npv\": 0.9998034854279237, \"accuracy\": 0.9998034856959044, \"f1\": 0.29513281285054066, \"f2\": 0.20741835668814915, \"f0_5\": 0.5113948900356667, \"p4\": 0.4557466234718868, \"phi\": 0.41599360962343185}, {\"truth_threshold\": 24.89999944344163, \"match_probability\": 0.9999999680586504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52550.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17288402130536484, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8271159786946352, \"precision\": 0.9998097412480974, \"recall\": 0.17288402130536484, \"specificity\": 0.9999999921797885, \"npv\": 0.9998034299262449, \"accuracy\": 0.9998034301855977, \"f1\": 0.29479329408365845, \"f2\": 0.2071500878269069, \"f0_5\": 0.5109869486834915, \"p4\": 0.4553417095815193, \"phi\": 0.41571280587112286}, {\"truth_threshold\": 24.919999442994595, \"match_probability\": 0.9999999684983965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52464.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251497.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1726010902714493, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8273989097285507, \"precision\": 0.9998094294317186, \"recall\": 0.1726010902714493, \"specificity\": 0.9999999921797885, \"npv\": 0.9998033626988675, \"accuracy\": 0.9998033629477614, \"f1\": 0.29438186485614487, \"f2\": 0.20682510222199796, \"f0_5\": 0.510492218652271, \"p4\": 0.45485074979486667, \"phi\": 0.4153724231985596}, {\"truth_threshold\": 24.93999944254756, \"match_probability\": 0.9999999689320883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52378.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17231815923753377, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8276818407624662, \"precision\": 0.9998091165915859, \"recall\": 0.17231815923753377, \"specificity\": 0.9999999921797885, \"npv\": 0.999803295471499, \"accuracy\": 0.9998032957099251, \"f1\": 0.29397023704289893, \"f2\": 0.2065000725419324, \"f0_5\": 0.5099968257862995, \"p4\": 0.4543592405943695, \"phi\": 0.4150317614117279}, {\"truth_threshold\": 24.959999442100525, \"match_probability\": 0.9999999693598094, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52308.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17208786653550948, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8279121334644906, \"precision\": 0.9998088611949998, \"recall\": 0.17208786653550948, \"specificity\": 0.9999999921797885, \"npv\": 0.9998032407515548, \"accuracy\": 0.9998032409814537, \"f1\": 0.2936350444455048, \"f2\": 0.2062354809559031, \"f0_5\": 0.5095931087829504, \"p4\": 0.4539587687295526, \"phi\": 0.4147542720333098}, {\"truth_threshold\": 24.97999944165349, \"match_probability\": 0.999999969781642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52221.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17180164560585076, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8281983543941492, \"precision\": 0.9998085428193985, \"recall\": 0.17180164560585076, \"specificity\": 0.9999999921797885, \"npv\": 0.9998031727424894, \"accuracy\": 0.9998031729617821, \"f1\": 0.2932182643068907, \"f2\": 0.2059065906984997, \"f0_5\": 0.509090731840471, \"p4\": 0.45346053047718565, \"phi\": 0.4144091334457348}, {\"truth_threshold\": 24.999999441206455, \"match_probability\": 0.999999970197667, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52159.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1715976720697721, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8284023279302279, \"precision\": 0.9998083152830225, \"recall\": 0.1715976720697721, \"specificity\": 0.9999999921797885, \"npv\": 0.9998031242762646, \"accuracy\": 0.9998031244879931, \"f1\": 0.292921124308539, \"f2\": 0.20567218159435274, \"f0_5\": 0.5087322998535025, \"p4\": 0.45310511943714316, \"phi\": 0.41416299712252724}, {\"truth_threshold\": 25.01999944075942, \"match_probability\": 0.9999999706079644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52109.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17143317728261193, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8285668227173881, \"precision\": 0.9998081313916231, \"recall\": 0.17143317728261193, \"specificity\": 0.9999999921797885, \"npv\": 0.9998030851906029, \"accuracy\": 0.9998030853962279, \"f1\": 0.2926814199056392, \"f2\": 0.20548312529624288, \"f0_5\": 0.5084429890893905, \"p4\": 0.45281828840574834, \"phi\": 0.4139643935036647}, {\"truth_threshold\": 25.039999440312386, \"match_probability\": 0.9999999710126133, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52034.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251927.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17118643510187162, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8288135648981284, \"precision\": 0.9998078548920144, \"recall\": 0.17118643510187162, \"specificity\": 0.9999999921797885, \"npv\": 0.999803026562116, \"accuracy\": 0.9998030267585799, \"f1\": 0.29232173705425485, \"f2\": 0.20519951289072852, \"f0_5\": 0.5080085992615258, \"p4\": 0.4523876911666086, \"phi\": 0.41366630932190224}, {\"truth_threshold\": 25.05999943986535, \"match_probability\": 0.9999999714116912, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51969.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17097259187856337, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8290274081214366, \"precision\": 0.9998076146135939, \"recall\": 0.17097259187856337, \"specificity\": 0.9999999921797885, \"npv\": 0.9998029757507663, \"accuracy\": 0.999802975939285, \"f1\": 0.29200988930718663, \"f2\": 0.20495368833031108, \"f0_5\": 0.5076317162130747, \"p4\": 0.4520141660656591, \"phi\": 0.41340779587072285}, {\"truth_threshold\": 25.079999439418316, \"match_probability\": 0.9999999718052749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51906.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252055.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17076532844674153, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8292346715532585, \"precision\": 0.9998073811541721, \"recall\": 0.17076532844674153, \"specificity\": 0.9999999921797885, \"npv\": 0.9998029265028475, \"accuracy\": 0.9998029266836608, \"f1\": 0.2917075281628203, \"f2\": 0.20471540354641257, \"f0_5\": 0.5072660640117274, \"p4\": 0.4516518316194032, \"phi\": 0.41315708234112997}, {\"truth_threshold\": 25.09999943897128, \"match_probability\": 0.99999997219344, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51819.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252142.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17047910751708278, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8295208924829173, \"precision\": 0.9998070578247699, \"recall\": 0.17047910751708278, \"specificity\": 0.9999999921797885, \"npv\": 0.999802858493825, \"accuracy\": 0.9998028586639892, \"f1\": 0.29128980578431096, \"f2\": 0.20438630467005292, \"f0_5\": 0.506760523160635, \"p4\": 0.4511509748999955, \"phi\": 0.4128106086113327}, {\"truth_threshold\": 25.119999438524246, \"match_probability\": 0.999999972576261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51740.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17021920575336968, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8297807942466303, \"precision\": 0.9998067632850242, \"recall\": 0.17021920575336968, \"specificity\": 0.9999999921797885, \"npv\": 0.9998027967385137, \"accuracy\": 0.9998027968990001, \"f1\": 0.29091031764550435, \"f2\": 0.2040874286246227, \"f0_5\": 0.5063008722779234, \"p4\": 0.4506956807272622, \"phi\": 0.41249574246714804}, {\"truth_threshold\": 25.13999943807721, \"match_probability\": 0.9999999729538117, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51659.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16995272419817015, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8300472758018298, \"precision\": 0.9998064603534034, \"recall\": 0.16995272419817015, \"specificity\": 0.9999999921797885, \"npv\": 0.9998027334197847, \"accuracy\": 0.9998027335703403, \"f1\": 0.2905210471557518, \"f2\": 0.20378094741434605, \"f0_5\": 0.5058289939820264, \"p4\": 0.45022837188133075, \"phi\": 0.4121726553255741}, {\"truth_threshold\": 25.159999437630177, \"match_probability\": 0.9999999733261646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51595.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252366.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1697421708706051, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8302578291293949, \"precision\": 0.9998062203274877, \"recall\": 0.1697421708706051, \"specificity\": 0.9999999921797885, \"npv\": 0.9998026833901773, \"accuracy\": 0.9998026835328807, \"f1\": 0.29021334998284426, \"f2\": 0.20353876171743399, \"f0_5\": 0.5054557281716991, \"p4\": 0.4498587900856125, \"phi\": 0.4119171974092234}, {\"truth_threshold\": 25.17999943718314, \"match_probability\": 0.9999999736933911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51497.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252464.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16941976108777113, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8305802389122289, \"precision\": 0.999805851631817, \"recall\": 0.16941976108777113, \"specificity\": 0.9999999921797885, \"npv\": 0.9998026067823507, \"accuracy\": 0.9998026069130208, \"f1\": 0.2897419739610879, \"f2\": 0.20316786746528784, \"f0_5\": 0.5048834386624025, \"p4\": 0.4492922680401727, \"phi\": 0.41152572020311673}, {\"truth_threshold\": 25.199999436736107, \"match_probability\": 0.999999974055562, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51437.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1692223673431789, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8307776326568211, \"precision\": 0.9998056252065232, \"recall\": 0.1692223673431789, \"specificity\": 0.9999999921797885, \"npv\": 0.9998025598796055, \"accuracy\": 0.9998025600029025, \"f1\": 0.28945324809796064, \"f2\": 0.20294076104067654, \"f0_5\": 0.5045326229183382, \"p4\": 0.4489450590583168, \"phi\": 0.41128585640494103}, {\"truth_threshold\": 25.219999436289072, \"match_probability\": 0.9999999744127467, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51374.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252587.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16901510391135705, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8309848960886429, \"precision\": 0.999805386890861, \"recall\": 0.16901510391135705, \"specificity\": 0.9999999921797885, \"npv\": 0.9998025106317279, \"accuracy\": 0.9998025107472782, \"f1\": 0.28914998100437606, \"f2\": 0.20270227614920125, \"f0_5\": 0.5041639106805339, \"p4\": 0.4485801959588962, \"phi\": 0.41103384879258825}, {\"truth_threshold\": 25.239999435842037, \"match_probability\": 0.999999974765014, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51323.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16884731922845364, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8311526807715464, \"precision\": 0.9998051935402178, \"recall\": 0.16884731922845364, \"specificity\": 0.9999999921797885, \"npv\": 0.9998024707644018, \"accuracy\": 0.9998024708736776, \"f1\": 0.2889044002994703, \"f2\": 0.2025091995830101, \"f0_5\": 0.5038651620972603, \"p4\": 0.4482846100048985, \"phi\": 0.4108297294268122}, {\"truth_threshold\": 25.259999435395002, \"match_probability\": 0.9999999751124314, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51270.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252691.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16867295475406385, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8313270452459361, \"precision\": 0.999804992199688, \"recall\": 0.16867295475406385, \"specificity\": 0.9999999921797885, \"npv\": 0.9998024293336546, \"accuracy\": 0.9998024294364064, \"f1\": 0.2886491142632748, \"f2\": 0.20230853491844525, \"f0_5\": 0.5035544441847172, \"p4\": 0.44797722308629295, \"phi\": 0.4106174978821268}, {\"truth_threshold\": 25.279999434947968, \"match_probability\": 0.999999975455066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51200.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16844266205203956, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8315573379479604, \"precision\": 0.9998047256395235, \"recall\": 0.16844266205203956, \"specificity\": 0.9999999921797885, \"npv\": 0.9998023746138051, \"accuracy\": 0.999802374707935, \"f1\": 0.2883118272606716, \"f2\": 0.20204348038836545, \"f0_5\": 0.5031436652050605, \"p4\": 0.4475709129626971, \"phi\": 0.4103370238665428}, {\"truth_threshold\": 25.299999434500933, \"match_probability\": 0.9999999757929833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51127.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252834.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1682024996627857, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8317975003372143, \"precision\": 0.9998044468779944, \"recall\": 0.1682024996627857, \"specificity\": 0.9999999921797885, \"npv\": 0.9998023175488255, \"accuracy\": 0.9998023176339577, \"f1\": 0.2879599434522301, \"f2\": 0.20176703518048023, \"f0_5\": 0.5027147995414044, \"p4\": 0.4471467920878742, \"phi\": 0.41004432521287765}, {\"truth_threshold\": 25.319999434053898, \"match_probability\": 0.9999999761262485, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51085.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16806432404157112, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8319356759584289, \"precision\": 0.9998042861336726, \"recall\": 0.16806432404157112, \"specificity\": 0.9999999921797885, \"npv\": 0.9998022847169225, \"accuracy\": 0.9998022847968748, \"f1\": 0.2877574241809743, \"f2\": 0.20160797007590736, \"f0_5\": 0.5024678316327033, \"p4\": 0.4469025932146638, \"phi\": 0.40987582853881893}, {\"truth_threshold\": 25.339999433606863, \"match_probability\": 0.9999999764549254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51022.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16785706060974928, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8321429393902507, \"precision\": 0.9998040445210848, \"recall\": 0.16785706060974928, \"specificity\": 0.9999999921797885, \"npv\": 0.9998022354690719, \"accuracy\": 0.9998022355412506, \"f1\": 0.2874535554222196, \"f2\": 0.20136935264382624, \"f0_5\": 0.5020970735442019, \"p4\": 0.44653604244131023, \"phi\": 0.4096229535915452}, {\"truth_threshold\": 25.359999433159828, \"match_probability\": 0.9999999767790774, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50945.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16760373863752256, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8323962613624775, \"precision\": 0.9998037484054558, \"recall\": 0.16760373863752256, \"specificity\": 0.9999999921797885, \"npv\": 0.9998021752772611, \"accuracy\": 0.999802175339932, \"f1\": 0.2870820137722729, \"f2\": 0.20107767688480965, \"f0_5\": 0.5016434250198413, \"p4\": 0.4460876240266938, \"phi\": 0.4093136720857339}, {\"truth_threshold\": 25.379999432712793, \"match_probability\": 0.9999999770987668, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50866.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253095.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16734383687380947, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8326561631261905, \"precision\": 0.999803443666955, \"recall\": 0.16734383687380947, \"specificity\": 0.9999999921797885, \"npv\": 0.9998021135220342, \"accuracy\": 0.9998021135749429, \"f1\": 0.2867006541031516, \"f2\": 0.2007783882783883, \"f0_5\": 0.5011774211029332, \"p4\": 0.4456270867913117, \"phi\": 0.40899611426425647}, {\"truth_threshold\": 25.39999943226576, \"match_probability\": 0.9999999774140548, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50782.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16706748563138035, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8329325143686197, \"precision\": 0.9998031186013545, \"recall\": 0.16706748563138035, \"specificity\": 0.9999999921797885, \"npv\": 0.9998020478582569, \"accuracy\": 0.9998020479007772, \"f1\": 0.2862949714308265, \"f2\": 0.20046011640281816, \"f0_5\": 0.5006812862210601, \"p4\": 0.4451368768658895, \"phi\": 0.4086581872022398}, {\"truth_threshold\": 25.419999431818724, \"match_probability\": 0.9999999777250022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50748.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253213.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1669556291761114, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8330443708238886, \"precision\": 0.999802986721305, \"recall\": 0.1669556291761114, \"specificity\": 0.9999999921797885, \"npv\": 0.9998020212800638, \"accuracy\": 0.9998020213183768, \"f1\": 0.286130711915629, \"f2\": 0.20033128007061413, \"f0_5\": 0.5004802827652453, \"p4\": 0.44493830459840417, \"phi\": 0.40852132774353145}, {\"truth_threshold\": 25.43999943137169, \"match_probability\": 0.9999999780316686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50637.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253324.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16659045074861578, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8334095492513842, \"precision\": 0.9998025549390882, \"recall\": 0.16659045074861578, \"specificity\": 0.9999999921797885, \"npv\": 0.9998019345100904, \"accuracy\": 0.9998019345346578, \"f1\": 0.285594233632631, \"f2\": 0.19991061918323935, \"f0_5\": 0.4998233142302127, \"p4\": 0.44428940595678823, \"phi\": 0.4080742023830471}, {\"truth_threshold\": 25.459999430924654, \"match_probability\": 0.999999978334113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50585.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253376.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16641937616996919, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8335806238300308, \"precision\": 0.9998023520110683, \"recall\": 0.16641937616996919, \"specificity\": 0.9999999921797885, \"npv\": 0.999801893861099, \"accuracy\": 0.9998018938792219, \"f1\": 0.2853427949322533, \"f2\": 0.19971352745769833, \"f0_5\": 0.49951514888188, \"p4\": 0.44398509121664503, \"phi\": 0.4078645696769725}, {\"truth_threshold\": 25.47999943047762, \"match_probability\": 0.9999999786323938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50527.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253434.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16622856221686336, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8337714377831367, \"precision\": 0.999802125175614, \"recall\": 0.16622856221686336, \"specificity\": 0.9999999921797885, \"npv\": 0.9998018485218432, \"accuracy\": 0.9998018485327742, \"f1\": 0.2850622570508155, \"f2\": 0.19949367528413645, \"f0_5\": 0.49917112716825823, \"p4\": 0.44364541735428775, \"phi\": 0.40763062141708284}, {\"truth_threshold\": 25.499999430030584, \"match_probability\": 0.9999999789265679, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50449.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253512.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16597195034889345, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8340280496511066, \"precision\": 0.9998018192988367, \"recall\": 0.16597195034889345, \"specificity\": 0.9999999921797885, \"npv\": 0.9998017875483678, \"accuracy\": 0.9998017875496203, \"f1\": 0.28468483719880366, \"f2\": 0.19919798026222793, \"f0_5\": 0.4987079796835489, \"p4\": 0.4431882052388198, \"phi\": 0.4073157895136246}, {\"truth_threshold\": 25.51999942958355, \"match_probability\": 0.999999979216692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50378.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16573836775112596, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8342616322488741, \"precision\": 0.9998015400492181, \"recall\": 0.16573836775112596, \"specificity\": 0.9999999921797885, \"npv\": 0.9998017320468774, \"accuracy\": 0.9998017320393137, \"f1\": 0.28434114390050486, \"f2\": 0.1989287903006716, \"f0_5\": 0.49828589967023595, \"p4\": 0.4427716162067878, \"phi\": 0.40702900007098075}, {\"truth_threshold\": 25.539999429136515, \"match_probability\": 0.9999999795028219, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50306.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1655014952576153, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8344985047423847, \"precision\": 0.9998012560616901, \"recall\": 0.1655014952576153, \"specificity\": 0.9999999921797885, \"npv\": 0.9998016757636822, \"accuracy\": 0.9998016757471716, \"f1\": 0.2839924691696046, \"f2\": 0.19865577810071397, \"f0_5\": 0.49785739027166115, \"p4\": 0.4423487613057648, \"phi\": 0.4067379648666803}, {\"truth_threshold\": 25.55999942868948, \"match_probability\": 0.9999999797850126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50230.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253731.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1652514631811318, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8347485368188682, \"precision\": 0.9998009554140127, \"recall\": 0.1652514631811318, \"specificity\": 0.9999999921797885, \"npv\": 0.9998016163536497, \"accuracy\": 0.9998016163276884, \"f1\": 0.2836242698354889, \"f2\": 0.19836756486931356, \"f0_5\": 0.49740454447329385, \"p4\": 0.4419019785800106, \"phi\": 0.40643053498368575}, {\"truth_threshold\": 25.579999428242445, \"match_probability\": 0.9999999800633184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50162.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253799.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16502775027059394, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8349722497294061, \"precision\": 0.9998006856413936, \"recall\": 0.16502775027059394, \"specificity\": 0.9999999921797885, \"npv\": 0.9998015631973108, \"accuracy\": 0.9998015631628876, \"f1\": 0.28329469436624094, \"f2\": 0.19810966054141496, \"f0_5\": 0.49699890418885206, \"p4\": 0.4415018456113093, \"phi\": 0.40615526892332293}, {\"truth_threshold\": 25.59999942779541, \"match_probability\": 0.9999999803377925, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50087.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253874.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16478100808985363, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8352189919101464, \"precision\": 0.9998003872487374, \"recall\": 0.16478100808985363, \"specificity\": 0.9999999921797885, \"npv\": 0.9998015045690024, \"accuracy\": 0.9998015045252396, \"f1\": 0.28293104519598483, \"f2\": 0.19782517510689676, \"f0_5\": 0.4965509994071566, \"p4\": 0.44106010567101683, \"phi\": 0.4058514501700761}, {\"truth_threshold\": 25.619999427348375, \"match_probability\": 0.9999999806084879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50011.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253950.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16453097601337013, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8354690239866298, \"precision\": 0.9998000839647349, \"recall\": 0.16453097601337013, \"specificity\": 0.9999999921797885, \"npv\": 0.9998014451589903, \"accuracy\": 0.9998014451057564, \"f1\": 0.28256239017803164, \"f2\": 0.19753686214564745, \"f0_5\": 0.496096578678491, \"p4\": 0.4406120292197138, \"phi\": 0.40554334835389466}, {\"truth_threshold\": 25.63999942690134, \"match_probability\": 0.9999999808754566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49943.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16430726310283228, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8356927368971677, \"precision\": 0.9997998118231137, \"recall\": 0.16430726310283228, \"specificity\": 0.9999999921797885, \"npv\": 0.9998013920026696, \"accuracy\": 0.9998013919409556, \"f1\": 0.282232406742881, \"f2\": 0.1972788685705528, \"f0_5\": 0.49568952683053674, \"p4\": 0.44021073705488717, \"phi\": 0.40526747979305966}, {\"truth_threshold\": 25.659999426454306, \"match_probability\": 0.9999999811387498, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49845.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1639848533199983, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8360151466800018, \"precision\": 0.999799418313108, \"recall\": 0.1639848533199983, \"specificity\": 0.9999999921797885, \"npv\": 0.9998013153950409, \"accuracy\": 0.9998013153210957, \"f1\": 0.2817566192597282, \"f2\": 0.19690700553607138, \"f0_5\": 0.49510211946815635, \"p4\": 0.4396317691478072, \"phi\": 0.4048695739106661}, {\"truth_threshold\": 25.67999942600727, \"match_probability\": 0.9999999813984182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49770.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254191.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16373811113925799, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.836261888860742, \"precision\": 0.9997991161108879, \"recall\": 0.16373811113925799, \"specificity\": 0.9999999921797885, \"npv\": 0.9998012567667616, \"accuracy\": 0.9998012566834478, \"f1\": 0.28139231810844656, \"f2\": 0.19662237757817488, \"f0_5\": 0.49465195465541334, \"p4\": 0.4391881741289149, \"phi\": 0.4045647897827961}, {\"truth_threshold\": 25.699999425560236, \"match_probability\": 0.9999999816545116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49714.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16355387697763857, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8364461230223614, \"precision\": 0.999798889872094, \"recall\": 0.16355387697763857, \"specificity\": 0.9999999921797885, \"npv\": 0.9998012129909841, \"accuracy\": 0.9998012129006707, \"f1\": 0.2811202058328739, \"f2\": 0.19640983337126097, \"f0_5\": 0.4943154813396254, \"p4\": 0.4388566692352579, \"phi\": 0.40433706784490897}, {\"truth_threshold\": 25.7199994251132, \"match_probability\": 0.9999999819070794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49657.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254304.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16336635292027596, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8366336470797241, \"precision\": 0.9997986590694022, \"recall\": 0.16336635292027596, \"specificity\": 0.9999999921797885, \"npv\": 0.9998011684335004, \"accuracy\": 0.9998011683360583, \"f1\": 0.280843145904736, \"f2\": 0.19619347441468307, \"f0_5\": 0.49397269158763224, \"p4\": 0.43851899206612627, \"phi\": 0.4041051476804076}, {\"truth_threshold\": 25.739999424666166, \"match_probability\": 0.99999998215617, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49570.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16308013199061722, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8369198680093828, \"precision\": 0.9997983057684551, \"recall\": 0.16308013199061722, \"specificity\": 0.9999999921797885, \"npv\": 0.999801100424717, \"accuracy\": 0.9998011003163866, \"f1\": 0.2804200927190906, \"f2\": 0.19586320474402255, \"f0_5\": 0.49344888618124116, \"p4\": 0.438003098209549, \"phi\": 0.4037509074697496}, {\"truth_threshold\": 25.75999942421913, \"match_probability\": 0.9999999824018313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49508.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254453.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16287615845453857, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8371238415454614, \"precision\": 0.9997980532331677, \"recall\": 0.16287615845453857, \"specificity\": 0.9999999921797885, \"npv\": 0.9998010519586931, \"accuracy\": 0.9998010518425977, \"f1\": 0.28011847945705404, \"f2\": 0.19562781243628305, \"f0_5\": 0.4930751564140206, \"p4\": 0.43763508652571526, \"phi\": 0.4034982706668866}, {\"truth_threshold\": 25.779999423772097, \"match_probability\": 0.9999999826441105, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49454.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254507.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16269850408440556, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8373014959155944, \"precision\": 0.9997978327672651, \"recall\": 0.16269850408440556, \"specificity\": 0.9999999921797885, \"npv\": 0.9998010097463536, \"accuracy\": 0.9998010096234912, \"f1\": 0.2798556978142463, \"f2\": 0.19542277453394746, \"f0_5\": 0.4927493488662202, \"p4\": 0.4373143136221553, \"phi\": 0.4032781032295142}, {\"truth_threshold\": 25.799999423325062, \"match_probability\": 0.9999999828830541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49347.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16234648523988274, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8376535147601173, \"precision\": 0.9997973944931823, \"recall\": 0.16234648523988274, \"specificity\": 0.9999999921797885, \"npv\": 0.9998009261033949, \"accuracy\": 0.9998009259671135, \"f1\": 0.27933476358408005, \"f2\": 0.19501644402747073, \"f0_5\": 0.4921029380381301, \"p4\": 0.4366780288655197, \"phi\": 0.40284149014652587}, {\"truth_threshold\": 25.819999422878027, \"match_probability\": 0.9999999831187082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49273.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254688.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16210303295488565, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8378969670451143, \"precision\": 0.9997970902745369, \"recall\": 0.16210303295488565, \"specificity\": 0.9999999921797885, \"npv\": 0.999800868256871, \"accuracy\": 0.9998008681113009, \"f1\": 0.2789743067115082, \"f2\": 0.19473539020193228, \"f0_5\": 0.4916552416417711, \"p4\": 0.43623745257031354, \"phi\": 0.4025392564662306}, {\"truth_threshold\": 25.839999422430992, \"match_probability\": 0.9999999833511178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49209.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254752.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16189247962732062, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8381075203726794, \"precision\": 0.9997968264288182, \"recall\": 0.16189247962732062, \"specificity\": 0.9999999921797885, \"npv\": 0.9998008182274503, \"accuracy\": 0.9998008180738412, \"f1\": 0.2786624384166714, \"f2\": 0.1944922901072911, \"f0_5\": 0.4912676180074555, \"p4\": 0.43585606429246454, \"phi\": 0.40227768208784287}, {\"truth_threshold\": 25.859999421983957, \"match_probability\": 0.9999999835803279, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49150.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16169837577847157, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8383016242215284, \"precision\": 0.9997965825874695, \"recall\": 0.16169837577847157, \"specificity\": 0.9999999921797885, \"npv\": 0.9998007721065825, \"accuracy\": 0.9998007719455582, \"f1\": 0.2783748346883929, \"f2\": 0.19426816041688405, \"f0_5\": 0.4909099262686251, \"p4\": 0.43550418457197687, \"phi\": 0.4020363924689184}, {\"truth_threshold\": 25.879999421536922, \"match_probability\": 0.9999999838063824, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49062.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16140886495306964, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8385911350469304, \"precision\": 0.9997962178024128, \"recall\": 0.16140886495306964, \"specificity\": 0.9999999921797885, \"npv\": 0.9998007033161436, \"accuracy\": 0.9998007031440513, \"f1\": 0.2779456877968915, \"f2\": 0.19393382643590562, \"f0_5\": 0.49037579285515814, \"p4\": 0.4349788339943908, \"phi\": 0.40167623359027593}, {\"truth_threshold\": 25.899999421089888, \"match_probability\": 0.9999999840293248, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48986.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254975.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16115883287658614, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8388411671234138, \"precision\": 0.9997959017062618, \"recall\": 0.16115883287658614, \"specificity\": 0.9999999921797885, \"npv\": 0.9998006439062266, \"accuracy\": 0.9998006437245681, \"f1\": 0.27757488872582214, \"f2\": 0.19364504601372506, \"f0_5\": 0.4899138905279581, \"p4\": 0.4345246270891665, \"phi\": 0.4013649272436736}, {\"truth_threshold\": 25.919999420642853, \"match_probability\": 0.9999999842491977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48916.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255045.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16092854017456187, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8390714598254382, \"precision\": 0.999795609696276, \"recall\": 0.16092854017456187, \"specificity\": 0.9999999921797885, \"npv\": 0.9998005891865726, \"accuracy\": 0.9998005889960967, \"f1\": 0.2772332219662385, \"f2\": 0.19337903334203058, \"f0_5\": 0.4894879569311439, \"p4\": 0.4341058720755629, \"phi\": 0.40107798397967953}, {\"truth_threshold\": 25.939999420195818, \"match_probability\": 0.9999999844660437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48867.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255094.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16076733528314488, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8392326647168551, \"precision\": 0.9997954047916198, \"recall\": 0.16076733528314488, \"specificity\": 0.9999999921797885, \"npv\": 0.9998005508828182, \"accuracy\": 0.9998005506861667, \"f1\": 0.27699397457189984, \"f2\": 0.1931928069510983, \"f0_5\": 0.4891895192694642, \"p4\": 0.43381251130958237, \"phi\": 0.4008770015061181}, {\"truth_threshold\": 25.959999419748783, \"match_probability\": 0.9999999846799043, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48825.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1606291596619303, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8393708403380696, \"precision\": 0.9997952288317805, \"recall\": 0.1606291596619303, \"specificity\": 0.9999999921797885, \"npv\": 0.9998005180510311, \"accuracy\": 0.9998005178490839, \"f1\": 0.2767888524813206, \"f2\": 0.19303317284465069, \"f0_5\": 0.48893352907364496, \"p4\": 0.43356090682588166, \"phi\": 0.4007046505923977}, {\"truth_threshold\": 25.97999941930175, \"match_probability\": 0.9999999848908205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48759.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255202.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16041202654287887, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8395879734571211, \"precision\": 0.999794951711128, \"recall\": 0.16041202654287887, \"specificity\": 0.9999999921797885, \"npv\": 0.9998004664582273, \"accuracy\": 0.9998004662479537, \"f1\": 0.2764664190740793, \"f2\": 0.19278229782550077, \"f0_5\": 0.48853091053368786, \"p4\": 0.4331652438320064, \"phi\": 0.40043366358795945}, {\"truth_threshold\": 25.999999418854713, \"match_probability\": 0.999999985098833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48702.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255259.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16022450248551623, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8397754975144838, \"precision\": 0.9997947117753325, \"recall\": 0.16022450248551623, \"specificity\": 0.9999999921797885, \"npv\": 0.99980042190081, \"accuracy\": 0.9998004216833413, \"f1\": 0.2761878567398128, \"f2\": 0.19256561196182692, \"f0_5\": 0.4881828515523978, \"p4\": 0.43282325472560157, \"phi\": 0.4001994817127549}, {\"truth_threshold\": 26.01999941840768, \"match_probability\": 0.9999999853039818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48635.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255326.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16000407947072157, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8399959205292784, \"precision\": 0.9997944290266214, \"recall\": 0.16000407947072157, \"specificity\": 0.9999999921797885, \"npv\": 0.9998003695263071, \"accuracy\": 0.9998003693003757, \"f1\": 0.2758603086731366, \"f2\": 0.19231088605752997, \"f0_5\": 0.4877733225552161, \"p4\": 0.4324209351248709, \"phi\": 0.39992403999902276}, {\"truth_threshold\": 26.039999417960644, \"match_probability\": 0.9999999855063062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48572.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15979681603889972, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8402031839611003, \"precision\": 0.9997941624469968, \"recall\": 0.15979681603889972, \"specificity\": 0.9999999921797885, \"npv\": 0.9998003202786452, \"accuracy\": 0.9998003200447515, \"f1\": 0.27555220214271736, \"f2\": 0.19207134304419554, \"f0_5\": 0.48738784119256096, \"p4\": 0.4320423065116855, \"phi\": 0.39966486942508256}, {\"truth_threshold\": 26.05999941751361, \"match_probability\": 0.9999999857058451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48526.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255435.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15964548083471236, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8403545191652877, \"precision\": 0.9997939673644305, \"recall\": 0.15964548083471236, \"specificity\": 0.9999999921797885, \"npv\": 0.999800284320038, \"accuracy\": 0.9998002840803274, \"f1\": 0.27532716590495804, \"f2\": 0.19189642354355493, \"f0_5\": 0.48710613224119415, \"p4\": 0.43176564642647114, \"phi\": 0.39947552757677535}, {\"truth_threshold\": 26.079999417066574, \"match_probability\": 0.9999999859026371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48449.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255512.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15939215886248564, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8406078411375143, \"precision\": 0.9997936399843166, \"recall\": 0.15939215886248564, \"specificity\": 0.9999999921797885, \"npv\": 0.999800224128462, \"accuracy\": 0.9998002238790089, \"f1\": 0.2749503433403326, \"f2\": 0.19160359502429403, \"f0_5\": 0.48663410988816724, \"p4\": 0.43130216117357745, \"phi\": 0.39915838481684746}, {\"truth_threshold\": 26.09999941661954, \"match_probability\": 0.9999999860967196, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48390.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255571.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15919805501363662, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8408019449863634, \"precision\": 0.9997933884297521, \"recall\": 0.15919805501363662, \"specificity\": 0.9999999921797885, \"npv\": 0.9998001780076491, \"accuracy\": 0.9998001777507258, \"f1\": 0.2746614977253442, \"f2\": 0.19137919578815482, \"f0_5\": 0.48627203498666494, \"p4\": 0.4309467005105643, \"phi\": 0.39891520873983416}, {\"truth_threshold\": 26.119999416172504, \"match_probability\": 0.9999999862881301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48315.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255646.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15895131283289632, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8410486871671037, \"precision\": 0.9997930677703052, \"recall\": 0.15895131283289632, \"specificity\": 0.9999999921797885, \"npv\": 0.9998001193795032, \"accuracy\": 0.999800119113078, \"f1\": 0.27429418143213186, \"f2\": 0.19109391228546183, \"f0_5\": 0.48581127415984765, \"p4\": 0.4304944390965075, \"phi\": 0.3986058724846524}, {\"truth_threshold\": 26.13999941572547, \"match_probability\": 0.9999999864769055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48261.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255700.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1587736584627633, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8412263415372366, \"precision\": 0.9997928362785109, \"recall\": 0.1587736584627633, \"specificity\": 0.9999999921797885, \"npv\": 0.9998000771672424, \"accuracy\": 0.9998000768939714, \"f1\": 0.27402961684344407, \"f2\": 0.19088848720250925, \"f0_5\": 0.4854791819654156, \"p4\": 0.43016853005665456, \"phi\": 0.39838300167578256}, {\"truth_threshold\": 26.159999415278435, \"match_probability\": 0.9999999866630819, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48179.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15850388701182058, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8414961129881794, \"precision\": 0.9997924837618544, \"recall\": 0.15850388701182058, \"specificity\": 0.9999999921797885, \"npv\": 0.9998000130671494, \"accuracy\": 0.9998000127834763, \"f1\": 0.273627715462161, \"f2\": 0.19057651184739638, \"f0_5\": 0.48497434152646274, \"p4\": 0.4296731809369616, \"phi\": 0.39804432963958086}, {\"truth_threshold\": 26.1799994148314, \"match_probability\": 0.9999999868466952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48113.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15828675389276914, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8417132461072309, \"precision\": 0.9997921991563286, \"recall\": 0.15828675389276914, \"specificity\": 0.9999999921797885, \"npv\": 0.9997999614743976, \"accuracy\": 0.9997999611823462, \"f1\": 0.2733040978857318, \"f2\": 0.1903253803303409, \"f0_5\": 0.4845675220010756, \"p4\": 0.42927409043585074, \"phi\": 0.3977715305371602}, {\"truth_threshold\": 26.199999414384365, \"match_probability\": 0.9999999870277806, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48015.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255946.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15796434410993515, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8420356558900648, \"precision\": 0.9997917751171265, \"recall\": 0.15796434410993515, \"specificity\": 0.9999999921797885, \"npv\": 0.9997998848669882, \"accuracy\": 0.9997998845624863, \"f1\": 0.2728233509287301, \"f2\": 0.18995243969113887, \"f0_5\": 0.4839626578182925, \"p4\": 0.428680850734333, \"phi\": 0.39736611975624425}, {\"truth_threshold\": 26.21999941393733, \"match_probability\": 0.999999987206373, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47921.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15765509391007398, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.842344906089926, \"precision\": 0.9997913667563789, \"recall\": 0.15765509391007398, \"specificity\": 0.9999999921797885, \"npv\": 0.9997998113864228, \"accuracy\": 0.9997998110699675, \"f1\": 0.27236197469678197, \"f2\": 0.18959466677217068, \"f0_5\": 0.48338158306182355, \"p4\": 0.42811109284841137, \"phi\": 0.39697686739251}, {\"truth_threshold\": 26.239999413490295, \"match_probability\": 0.9999999873825066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47856.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256105.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15744125068676573, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8425587493132343, \"precision\": 0.9997910834412735, \"recall\": 0.15744125068676573, \"specificity\": 0.9999999921797885, \"npv\": 0.9997997605753999, \"accuracy\": 0.9997997602506726, \"f1\": 0.2720427937594329, \"f2\": 0.18934723947741175, \"f0_5\": 0.4829792602311147, \"p4\": 0.4277166914086099, \"phi\": 0.39670748019165586}, {\"truth_threshold\": 26.25999941304326, \"match_probability\": 0.9999999875562154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47783.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15720108829751187, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8427989117024881, \"precision\": 0.9997907643378737, \"recall\": 0.15720108829751187, \"specificity\": 0.9999999921797885, \"npv\": 0.9997997035107187, \"accuracy\": 0.9997997031766953, \"f1\": 0.2716841883816531, \"f2\": 0.18906932924566153, \"f0_5\": 0.4825269170101771, \"p4\": 0.42727333829801273, \"phi\": 0.3964047194227244}, {\"truth_threshold\": 26.279999412596226, \"match_probability\": 0.9999999877275326, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47694.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1569082875763667, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8430917124236333, \"precision\": 0.9997903739728324, \"recall\": 0.1569082875763667, \"specificity\": 0.9999999921797885, \"npv\": 0.999799633938719, \"accuracy\": 0.9997996335933531, \"f1\": 0.27124678316010975, \"f2\": 0.18873046374178107, \"f0_5\": 0.4819747077976543, \"p4\": 0.42673222427757285, \"phi\": 0.39603528706776003}, {\"truth_threshold\": 26.29999941214919, \"match_probability\": 0.9999999878964914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47624.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15667799487434242, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8433220051256576, \"precision\": 0.9997900659193013, \"recall\": 0.15667799487434242, \"specificity\": 0.9999999921797885, \"npv\": 0.9997995792191754, \"accuracy\": 0.9997995788648817, \"f1\": 0.2709026010039961, \"f2\": 0.1884639067716256, \"f0_5\": 0.48153982733970074, \"p4\": 0.4263061746556067, \"phi\": 0.395744480037877}, {\"truth_threshold\": 26.319999411702156, \"match_probability\": 0.999999988063124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47531.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15637203457022447, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8436279654297756, \"precision\": 0.9997896552449465, \"recall\": 0.15637203457022447, \"specificity\": 0.9999999921797885, \"npv\": 0.9997995065203625, \"accuracy\": 0.9997995061541982, \"f1\": 0.2704451183777048, \"f2\": 0.18810972110639274, \"f0_5\": 0.48096129521882114, \"p4\": 0.42573951746488214, \"phi\": 0.3953577913012313}, {\"truth_threshold\": 26.33999941125512, \"match_probability\": 0.9999999882274624, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47459.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256502.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1561351620767138, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8438648379232863, \"precision\": 0.9997893361983611, \"recall\": 0.1561351620767138, \"specificity\": 0.9999999921797885, \"npv\": 0.9997994502374179, \"accuracy\": 0.9997994498620563, \"f1\": 0.27009077198873177, \"f2\": 0.18783547703538236, \"f0_5\": 0.4805128007824444, \"p4\": 0.4253003285954595, \"phi\": 0.39505815946923595}, {\"truth_threshold\": 26.359999410808086, \"match_probability\": 0.9999999883895384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47397.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256564.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15593118854063515, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8440688114593649, \"precision\": 0.9997890606872403, \"recall\": 0.15593118854063515, \"specificity\": 0.9999999921797885, \"npv\": 0.999799401771554, \"accuracy\": 0.9997994013882673, \"f1\": 0.2697855240090162, \"f2\": 0.18759929736845646, \"f0_5\": 0.4801261778524238, \"p4\": 0.4249217974186339, \"phi\": 0.39479996097481146}, {\"truth_threshold\": 26.37999941036105, \"match_probability\": 0.9999999885493831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47332.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1557173453173269, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8442826546826732, \"precision\": 0.9997887710700858, \"recall\": 0.1557173453173269, \"specificity\": 0.9999999921797885, \"npv\": 0.9997993509605727, \"accuracy\": 0.9997993505689724, \"f1\": 0.269465390275631, \"f2\": 0.18735166475879245, \"f0_5\": 0.4797204299767498, \"p4\": 0.4245246111761975, \"phi\": 0.3945290875922278}, {\"truth_threshold\": 26.399999409914017, \"match_probability\": 0.9999999887070271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47254.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256707.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15546073344935699, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.844539266550643, \"precision\": 0.9997884224779959, \"recall\": 0.15546073344935699, \"specificity\": 0.9999999921797885, \"npv\": 0.999799289987402, \"accuracy\": 0.9997992895858185, \"f1\": 0.2690810733860061, \"f2\": 0.18705447198497674, \"f0_5\": 0.4792329676258628, \"p4\": 0.42404752894746534, \"phi\": 0.394203793880587}, {\"truth_threshold\": 26.419999409466982, \"match_probability\": 0.9999999888625007, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47190.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15525018012179195, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8447498198782081, \"precision\": 0.9997881355932203, \"recall\": 0.15525018012179195, \"specificity\": 0.9999999921797885, \"npv\": 0.9997992399581392, \"accuracy\": 0.999799239548359, \"f1\": 0.26876560893721113, \"f2\": 0.18681059408856698, \"f0_5\": 0.4788325374776007, \"p4\": 0.4236557025732686, \"phi\": 0.39393668562959855}, {\"truth_threshold\": 26.439999409019947, \"match_probability\": 0.999999989015834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47127.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256834.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15504291668997008, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8449570833100299, \"precision\": 0.9997878524301504, \"recall\": 0.15504291668997008, \"specificity\": 0.9999999921797885, \"npv\": 0.9997991907105885, \"accuracy\": 0.9997991902927347, \"f1\": 0.2684549612928584, \"f2\": 0.18657050264414113, \"f0_5\": 0.4784379574789496, \"p4\": 0.42326966851007874, \"phi\": 0.3936735739633295}, {\"truth_threshold\": 26.459999408572912, \"match_probability\": 0.9999999891670562, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47041.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256920.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15475998565605456, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8452400143439455, \"precision\": 0.9997874646660008, \"recall\": 0.15475998565605456, \"specificity\": 0.9999999921797885, \"npv\": 0.9997991234837812, \"accuracy\": 0.9997991230548984, \"f1\": 0.26803072259637845, \"f2\": 0.18624272009945403, \"f0_5\": 0.47789867219326854, \"p4\": 0.4227421721442993, \"phi\": 0.3933141215708715}, {\"truth_threshold\": 26.479999408125877, \"match_probability\": 0.9999999893161966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46974.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256987.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1545395626412599, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8454604373587401, \"precision\": 0.9997871615869232, \"recall\": 0.1545395626412599, \"specificity\": 0.9999999921797885, \"npv\": 0.9997990711094144, \"accuracy\": 0.999799070671933, \"f1\": 0.26770006696205956, \"f2\": 0.1859873236893702, \"f0_5\": 0.477478008607493, \"p4\": 0.4223307916793182, \"phi\": 0.39303385529257007}, {\"truth_threshold\": 26.499999407678843, \"match_probability\": 0.9999999894632836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46900.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1542961103562628, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8457038896437372, \"precision\": 0.9997868258367086, \"recall\": 0.1542961103562628, \"specificity\": 0.9999999921797885, \"npv\": 0.999799013263105, \"accuracy\": 0.9997990128161203, \"f1\": 0.2673347184577808, \"f2\": 0.1857052125750542, \"f0_5\": 0.47701286205683063, \"p4\": 0.4218759989417116, \"phi\": 0.39272407504930196}, {\"truth_threshold\": 26.519999407231808, \"match_probability\": 0.9999999896083457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46820.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1540329186968065, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8459670813031935, \"precision\": 0.9997864616698697, \"recall\": 0.1540329186968065, \"specificity\": 0.9999999921797885, \"npv\": 0.999798950726562, \"accuracy\": 0.9997989502692959, \"f1\": 0.26693957370628096, \"f2\": 0.18540019038960176, \"f0_5\": 0.47650937040105357, \"p4\": 0.42138382000507907, \"phi\": 0.3923889024185113}, {\"truth_threshold\": 26.539999406784773, \"match_probability\": 0.9999999897514107, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46767.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257194.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1538585542224167, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8461414457775833, \"precision\": 0.9997862197233683, \"recall\": 0.1538585542224167, \"specificity\": 0.9999999921797885, \"npv\": 0.9997989092961066, \"accuracy\": 0.9997989088320246, \"f1\": 0.2666776910400356, \"f2\": 0.18519809190564707, \"f0_5\": 0.47617544581311383, \"p4\": 0.4210574586132759, \"phi\": 0.3921666928184967}, {\"truth_threshold\": 26.559999406337738, \"match_probability\": 0.999999989892506, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46717.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257244.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1536940594352565, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8463059405647435, \"precision\": 0.9997859909688189, \"recall\": 0.1536940594352565, \"specificity\": 0.9999999921797885, \"npv\": 0.9997988702107744, \"accuracy\": 0.9997988697402593, \"f1\": 0.2664305593576056, \"f2\": 0.18500741740464496, \"f0_5\": 0.47586015820921673, \"p4\": 0.42074935628978405, \"phi\": 0.391956945655711}, {\"truth_threshold\": 26.579999405890703, \"match_probability\": 0.999999990031659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46629.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15340454860985456, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8465954513901455, \"precision\": 0.9997855871695362, \"recall\": 0.15340454860985456, \"specificity\": 0.9999999921797885, \"npv\": 0.9997988014205972, \"accuracy\": 0.9997988009387525, \"f1\": 0.26599543639475187, \"f2\": 0.18467179360038907, \"f0_5\": 0.47530462756642483, \"p4\": 0.42020659040971753, \"phi\": 0.3915875178196638}, {\"truth_threshold\": 26.59999940544367, \"match_probability\": 0.999999990168896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46525.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257436.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15306239945256134, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8469376005474386, \"precision\": 0.9997851079832384, \"recall\": 0.15306239945256134, \"specificity\": 0.9999999921797885, \"npv\": 0.9997987201231272, \"accuracy\": 0.9997987196278807, \"f1\": 0.26548091846982563, \"f2\": 0.18427508695882933, \"f0_5\": 0.4746470625442511, \"p4\": 0.41956430680693535, \"phi\": 0.3911504715157327}, {\"truth_threshold\": 26.619999404996634, \"match_probability\": 0.9999999903042437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46458.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257503.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15284197643776667, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8471580235622334, \"precision\": 0.9997847981406559, \"recall\": 0.15284197643776667, \"specificity\": 0.9999999921797885, \"npv\": 0.9997986677488025, \"accuracy\": 0.9997986672449152, \"f1\": 0.2651492884435934, \"f2\": 0.18401948171292043, \"f0_5\": 0.4742228473785964, \"p4\": 0.4191500491510617, \"phi\": 0.3908686540567095}, {\"truth_threshold\": 26.6399994045496, \"match_probability\": 0.999999990437728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46391.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257570.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15262155342297204, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.847378446577028, \"precision\": 0.9997844874032887, \"recall\": 0.15262155342297204, \"specificity\": 0.9999999921797885, \"npv\": 0.9997986153744834, \"accuracy\": 0.9997986148619497, \"f1\": 0.2648175315816213, \"f2\": 0.18376384933194428, \"f0_5\": 0.4737981677611757, \"p4\": 0.41873541569345074, \"phi\": 0.3905866332893979}, {\"truth_threshold\": 26.659999404102564, \"match_probability\": 0.9999999905693747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46329.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1524175798868934, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8475824201131066, \"precision\": 0.9997841990547919, \"recall\": 0.1524175798868934, \"specificity\": 0.9999999921797885, \"npv\": 0.9997985669087004, \"accuracy\": 0.9997985663881608, \"f1\": 0.2645104196403083, \"f2\": 0.18352726981745118, \"f0_5\": 0.47340476623538524, \"p4\": 0.41835138980592, \"phi\": 0.39032547734916534}, {\"truth_threshold\": 26.67999940365553, \"match_probability\": 0.9999999906992089, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46212.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257749.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15203266208493854, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8479673379150615, \"precision\": 0.9997836528060231, \"recall\": 0.15203266208493854, \"specificity\": 0.9999999921797885, \"npv\": 0.9997984754490905, \"accuracy\": 0.99979847491343, \"f1\": 0.26393057344302834, \"f2\": 0.18308075805861182, \"f0_5\": 0.47266129213724484, \"p4\": 0.41762581653132747, \"phi\": 0.38983217429325884}, {\"truth_threshold\": 26.699999403208494, \"match_probability\": 0.9999999908272557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46126.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257835.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.151749731051023, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.848250268948977, \"precision\": 0.9997832495231489, \"recall\": 0.151749731051023, \"specificity\": 0.9999999921797885, \"npv\": 0.9997984082223794, \"accuracy\": 0.9997984076755937, \"f1\": 0.26350411457396095, \"f2\": 0.1827525000396203, \"f0_5\": 0.4721138985271389, \"p4\": 0.4170917549012977, \"phi\": 0.38946917709811085}, {\"truth_threshold\": 26.71999940276146, \"match_probability\": 0.9999999909535395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46018.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15139442231075698, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.848605577689243, \"precision\": 0.9997827409402972, \"recall\": 0.15139442231075698, \"specificity\": 0.9999999921797885, \"npv\": 0.9997983237981503, \"accuracy\": 0.9997983232373807, \"f1\": 0.2629682647168911, \"f2\": 0.18234020566269796, \"f0_5\": 0.47142538103931175, \"p4\": 0.41642018977422135, \"phi\": 0.38901284044606205}, {\"truth_threshold\": 26.739999402314425, \"match_probability\": 0.9999999910780848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45931.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15110820138109823, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8488917986189017, \"precision\": 0.9997823295095883, \"recall\": 0.15110820138109823, \"specificity\": 0.9999999921797885, \"npv\": 0.9997982557897539, \"accuracy\": 0.999798255217709, \"f1\": 0.26253636732570834, \"f2\": 0.1820080283091018, \"f0_5\": 0.4708698549387462, \"p4\": 0.41587849035370694, \"phi\": 0.38864484630973484}, {\"truth_threshold\": 26.75999940186739, \"match_probability\": 0.9999999912009154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45879.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15093712680245164, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8490628731975484, \"precision\": 0.9997820828520997, \"recall\": 0.15093712680245164, \"specificity\": 0.9999999921797885, \"npv\": 0.9997982151410616, \"accuracy\": 0.9997982145622731, \"f1\": 0.2622781191939403, \"f2\": 0.18180946365039197, \"f0_5\": 0.47053743766884026, \"p4\": 0.4155544102497711, \"phi\": 0.3884247293498405}, {\"truth_threshold\": 26.779999401420355, \"match_probability\": 0.999999991322055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45786.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258175.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15063116649833366, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8493688335016664, \"precision\": 0.9997816403179317, \"recall\": 0.15063116649833366, \"specificity\": 0.9999999921797885, \"npv\": 0.9997981424424471, \"accuracy\": 0.9997981418515898, \"f1\": 0.26181606086511494, \"f2\": 0.1814542975809264, \"f0_5\": 0.4699422143304355, \"p4\": 0.4149742341459697, \"phi\": 0.388030747323484}, {\"truth_threshold\": 26.79999940097332, \"match_probability\": 0.9999999914415268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45709.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258252.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15037784452610697, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8496221554738931, \"precision\": 0.9997812725562676, \"recall\": 0.15037784452610697, \"specificity\": 0.9999999921797885, \"npv\": 0.9997980822511292, \"accuracy\": 0.9997980816502712, \"f1\": 0.2614333104552734, \"f2\": 0.1811601957254612, \"f0_5\": 0.46944870665130217, \"p4\": 0.4144933178803985, \"phi\": 0.3877042442272345}, {\"truth_threshold\": 26.819999400526285, \"match_probability\": 0.9999999915593538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45619.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258342.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15008175390921863, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8499182460907814, \"precision\": 0.9997808411317364, \"recall\": 0.15008175390921863, \"specificity\": 0.9999999921797885, \"npv\": 0.9997980118976498, \"accuracy\": 0.9997980112850937, \"f1\": 0.26098572613633114, \"f2\": 0.18081639480194978, \"f0_5\": 0.46887108743064937, \"p4\": 0.4139305691119895, \"phi\": 0.38732226842294687}, {\"truth_threshold\": 26.83999940007925, \"match_probability\": 0.9999999916755588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45562.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.149894229851856, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.850105770148144, \"precision\": 0.9997805670148336, \"recall\": 0.149894229851856, \"specificity\": 0.9999999921797885, \"npv\": 0.9997979673404513, \"accuracy\": 0.9997979667204813, \"f1\": 0.26070213685117, \"f2\": 0.18059862884250716, \"f0_5\": 0.46850481954718676, \"p4\": 0.41357380486752027, \"phi\": 0.38708015548038216}, {\"truth_threshold\": 26.859999399632215, \"match_probability\": 0.9999999917901637, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45439.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1494895726754419, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8505104273245581, \"precision\": 0.9997799731567251, \"recall\": 0.1494895726754419, \"specificity\": 0.9999999921797885, \"npv\": 0.9997978711907208, \"accuracy\": 0.9997978705547387, \"f1\": 0.2600898657737329, \"f2\": 0.18012864576272128, \"f0_5\": 0.46771328050856703, \"p4\": 0.4128030009558797, \"phi\": 0.38655718463175526}, {\"truth_threshold\": 26.87999939918518, \"match_probability\": 0.999999991903191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45367.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258594.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14925270018193124, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8507472998180687, \"precision\": 0.9997796240386099, \"recall\": 0.14925270018193124, \"specificity\": 0.9999999921797885, \"npv\": 0.9997978149079603, \"accuracy\": 0.9997978142625966, \"f1\": 0.2597312631319811, \"f2\": 0.17985349118037203, \"f0_5\": 0.4672491961381674, \"p4\": 0.4123511988598287, \"phi\": 0.3862507268430807}, {\"truth_threshold\": 26.899999398738146, \"match_probability\": 0.9999999920146622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45305.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258656.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1490487266458526, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8509512733541474, \"precision\": 0.9997793225201368, \"recall\": 0.1490487266458526, \"specificity\": 0.9999999921797885, \"npv\": 0.9997977664422549, \"accuracy\": 0.9997977657888076, \"f1\": 0.2594223479426013, \"f2\": 0.17961652733715575, \"f0_5\": 0.46684912648051097, \"p4\": 0.411961791504637, \"phi\": 0.3859866376926905}, {\"truth_threshold\": 26.91999939829111, \"match_probability\": 0.9999999921245987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45240.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258721.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14883488342254433, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8511651165774556, \"precision\": 0.9997790055248619, \"recall\": 0.14883488342254433, \"specificity\": 0.9999999921797885, \"npv\": 0.9997977156314398, \"accuracy\": 0.9997977149695128, \"f1\": 0.2590983674626515, \"f2\": 0.179368072483098, \"f0_5\": 0.466429259260023, \"p4\": 0.4115531880962897, \"phi\": 0.3857095759094994}, {\"truth_threshold\": 26.939999397844076, \"match_probability\": 0.9999999922330216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45151.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14854208270139918, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8514579172986008, \"precision\": 0.9997785700050928, \"recall\": 0.14854208270139918, \"specificity\": 0.9999999921797885, \"npv\": 0.9997976460597168, \"accuracy\": 0.9997976453861706, \"f1\": 0.25865456774422696, \"f2\": 0.1790278389062692, \"f0_5\": 0.46585363337150876, \"p4\": 0.41099312751069583, \"phi\": 0.38532989130893175}, {\"truth_threshold\": 26.95999939739704, \"match_probability\": 0.999999992339952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45070.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14827560114619967, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8517243988538004, \"precision\": 0.9997781721384206, \"recall\": 0.14827560114619967, \"specificity\": 0.9999999921797885, \"npv\": 0.9997975827416402, \"accuracy\": 0.9997975820575108, \"f1\": 0.2582504634126077, \"f2\": 0.17871814637519787, \"f0_5\": 0.46532901352727035, \"p4\": 0.41048281752772575, \"phi\": 0.3849840102252476}, {\"truth_threshold\": 26.979999396950006, \"match_probability\": 0.99999999244541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45005.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14806175792289142, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8519382420771086, \"precision\": 0.9997778518271687, \"recall\": 0.14806175792289142, \"specificity\": 0.9999999921797885, \"npv\": 0.9997975319308438, \"accuracy\": 0.9997975312382159, \"f1\": 0.25792604649030304, \"f2\": 0.17846959890043215, \"f0_5\": 0.46490751434338595, \"p4\": 0.4100729009211291, \"phi\": 0.38470622646217884}, {\"truth_threshold\": 26.99999939650297, \"match_probability\": 0.9999999925494163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44928.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14780843595066473, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8521915640493353, \"precision\": 0.9997774711825181, \"recall\": 0.14780843595066473, \"specificity\": 0.9999999921797885, \"npv\": 0.9997974717395993, \"accuracy\": 0.9997974710368974, \"f1\": 0.2575415808013207, \"f2\": 0.1781751325764486, \"f0_5\": 0.46440761360558847, \"p4\": 0.4095868359171387, \"phi\": 0.38437689981567}, {\"truth_threshold\": 27.019999396055937, \"match_probability\": 0.9999999926519907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44878.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14764394116350452, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8523560588364955, \"precision\": 0.9997772233113527, \"recall\": 0.14764394116350452, \"specificity\": 0.9999999921797885, \"npv\": 0.9997974326543795, \"accuracy\": 0.9997974319451322, \"f1\": 0.25729183686924717, \"f2\": 0.17798390141600276, \"f0_5\": 0.46408266168644896, \"p4\": 0.409270935112973, \"phi\": 0.38416290018304683}, {\"truth_threshold\": 27.039999395608902, \"match_probability\": 0.999999992753153, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44806.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259155.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14740706866999384, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8525929313300061, \"precision\": 0.9997768654052124, \"recall\": 0.14740706866999384, \"specificity\": 0.9999999921797885, \"npv\": 0.9997973763716683, \"accuracy\": 0.9997973756529901, \"f1\": 0.2569320798103086, \"f2\": 0.17770850189583234, \"f0_5\": 0.46361425836825493, \"p4\": 0.4088156581657975, \"phi\": 0.38385453114621393}, {\"truth_threshold\": 27.059999395161867, \"match_probability\": 0.9999999928529224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44737.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259224.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14718006586371277, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8528199341362872, \"precision\": 0.999776521331039, \"recall\": 0.14718006586371277, \"specificity\": 0.9999999921797885, \"npv\": 0.9997973224340762, \"accuracy\": 0.999797321706354, \"f1\": 0.25658717322229485, \"f2\": 0.17744454783510274, \"f0_5\": 0.46316484763401516, \"p4\": 0.40837892989366614, \"phi\": 0.3835587782128253}, {\"truth_threshold\": 27.079999394714832, \"match_probability\": 0.9999999929513184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44688.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259273.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1470188609722958, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8529811390277042, \"precision\": 0.9997762763434606, \"recall\": 0.1470188609722958, \"specificity\": 0.9999999921797885, \"npv\": 0.9997972841305721, \"accuracy\": 0.999797283396424, \"f1\": 0.2563421566631006, \"f2\": 0.17725708465088827, \"f0_5\": 0.4628453888427415, \"p4\": 0.4080685388805235, \"phi\": 0.38334861223439676}, {\"truth_threshold\": 27.099999394267797, \"match_probability\": 0.9999999930483596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44622.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259339.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14680172785324433, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8531982721467557, \"precision\": 0.999775945509948, \"recall\": 0.14680172785324433, \"specificity\": 0.9999999921797885, \"npv\": 0.999797232538102, \"accuracy\": 0.9997972317952939, \"f1\": 0.2560120254853081, \"f2\": 0.17700456018202648, \"f0_5\": 0.46241468717421536, \"p4\": 0.40765013175289705, \"phi\": 0.3830653493026206}, {\"truth_threshold\": 27.119999393820763, \"match_probability\": 0.999999993144065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44556.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259405.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14658459473419289, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8534154052658072, \"precision\": 0.99977561369654, \"recall\": 0.14658459473419289, \"specificity\": 0.9999999921797885, \"npv\": 0.9997971809456372, \"accuracy\": 0.9997971801941636, \"f1\": 0.25568176927469033, \"f2\": 0.17675200926682588, \"f0_5\": 0.4619835139198507, \"p4\": 0.40723134602030786, \"phi\": 0.3827818767824275}, {\"truth_threshold\": 27.139999393373728, \"match_probability\": 0.9999999932384526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44492.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259469.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14637404140662783, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8536259585933722, \"precision\": 0.9997752909981574, \"recall\": 0.14637404140662783, \"specificity\": 0.9999999921797885, \"npv\": 0.9997971309165855, \"accuracy\": 0.9997971301567041, \"f1\": 0.25536140135394575, \"f2\": 0.17650708614935898, \"f0_5\": 0.4615649554224442, \"p4\": 0.4068248887089422, \"phi\": 0.38250679374019503}, {\"truth_threshold\": 27.159999392926693, \"match_probability\": 0.9999999933315408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44420.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259541.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14613716891311715, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8538628310868829, \"precision\": 0.9997749268512266, \"recall\": 0.14613716891311715, \"specificity\": 0.9999999921797885, \"npv\": 0.9997970746339083, \"accuracy\": 0.9997970738645621, \"f1\": 0.2550008467497725, \"f2\": 0.17623151790801048, \"f0_5\": 0.46109354531318447, \"p4\": 0.4063671975315255, \"phi\": 0.3821970886924589}, {\"truth_threshold\": 27.179999392479658, \"match_probability\": 0.9999999934233474, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44323.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14581804902602635, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8541819509739736, \"precision\": 0.9997744343942435, \"recall\": 0.14581804902602635, \"specificity\": 0.9999999921797885, \"npv\": 0.999796998808645, \"accuracy\": 0.9997969980265374, \"f1\": 0.2545148638793663, \"f2\": 0.17586021646165578, \"f0_5\": 0.4604575591167958, \"p4\": 0.4057498703122092, \"phi\": 0.38177944999035013}, {\"truth_threshold\": 27.199999392032623, \"match_probability\": 0.9999999935138901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44260.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1456107855942045, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8543892144057955, \"precision\": 0.9997741133950757, \"recall\": 0.1456107855942045, \"specificity\": 0.9999999921797885, \"npv\": 0.9997969495613152, \"accuracy\": 0.9997969487709132, \"f1\": 0.2541990804954183, \"f2\": 0.17561903129399403, \"f0_5\": 0.4600439463580028, \"p4\": 0.4053484851734596, \"phi\": 0.3815079552479306}, {\"truth_threshold\": 27.21999939158559, \"match_probability\": 0.9999999936031864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44205.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259756.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1454298413283283, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8545701586716717, \"precision\": 0.9997738324098157, \"recall\": 0.1454298413283283, \"specificity\": 0.9999999921797885, \"npv\": 0.9997969065676184, \"accuracy\": 0.9997969057699714, \"f1\": 0.25392330315702405, \"f2\": 0.1754084530962439, \"f0_5\": 0.4596825013882505, \"p4\": 0.4049977854408726, \"phi\": 0.3812707779899654}, {\"truth_threshold\": 27.239999391138554, \"match_probability\": 0.9999999936912531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44160.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259801.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14528179601988414, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8547182039801159, \"precision\": 0.9997736019923025, \"recall\": 0.14528179601988414, \"specificity\": 0.9999999921797885, \"npv\": 0.9997968713909603, \"accuracy\": 0.9997968705873826, \"f1\": 0.2536976023393493, \"f2\": 0.17523614816978225, \"f0_5\": 0.4593865275746347, \"p4\": 0.4047106520631541, \"phi\": 0.3810766140879202}, {\"truth_threshold\": 27.25999939069152, \"match_probability\": 0.9999999937781076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44109.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14511401133698074, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8548859886630192, \"precision\": 0.9997733402842313, \"recall\": 0.14511401133698074, \"specificity\": 0.9999999921797885, \"npv\": 0.9997968315240839, \"accuracy\": 0.999796830713782, \"f1\": 0.25344173753160193, \"f2\": 0.17504085437429512, \"f0_5\": 0.4590508224803668, \"p4\": 0.40438501942288513, \"phi\": 0.38085644201857666}, {\"truth_threshold\": 27.279999390244484, \"match_probability\": 0.9999999938637661, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44011.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259950.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14479160155414675, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8552083984458533, \"precision\": 0.9997728356920561, \"recall\": 0.14479160155414675, \"specificity\": 0.9999999921797885, \"npv\": 0.9997967549171541, \"accuracy\": 0.9997967540939221, \"f1\": 0.25294986522291385, \"f2\": 0.17466553956177844, \"f0_5\": 0.45840494120342884, \"p4\": 0.4037586524387069, \"phi\": 0.3804330086523576}, {\"truth_threshold\": 27.29999938979745, \"match_probability\": 0.9999999939482456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43944.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260017.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14457117853935209, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8554288214606479, \"precision\": 0.999772489420758, \"recall\": 0.14457117853935209, \"specificity\": 0.9999999921797885, \"npv\": 0.9997967025430354, \"accuracy\": 0.9997967017109566, \"f1\": 0.2526134256930572, \"f2\": 0.17440891317496932, \"f0_5\": 0.45796276186645046, \"p4\": 0.40332993554124796, \"phi\": 0.3801432470753505}, {\"truth_threshold\": 27.319999389350414, \"match_probability\": 0.9999999940315618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43901.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260060.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14442971302239432, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8555702869776057, \"precision\": 0.9997722666302293, \"recall\": 0.14442971302239432, \"specificity\": 0.9999999921797885, \"npv\": 0.9997966689297979, \"accuracy\": 0.9997966680920384, \"f1\": 0.25239743353877286, \"f2\": 0.17424419827664903, \"f0_5\": 0.4576787147757008, \"p4\": 0.4030545804626334, \"phi\": 0.3799571642859158}, {\"truth_threshold\": 27.33999938890338, \"match_probability\": 0.9999999941137311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43842.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1442356091735453, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8557643908264547, \"precision\": 0.9997719602298641, \"recall\": 0.1442356091735453, \"specificity\": 0.9999999921797885, \"npv\": 0.9997966228093129, \"accuracy\": 0.9997966219637554, \"f1\": 0.2521009852995719, \"f2\": 0.17401817581384715, \"f0_5\": 0.4572886440299644, \"p4\": 0.4026765022067355, \"phi\": 0.379701693001961}, {\"truth_threshold\": 27.359999388456345, \"match_probability\": 0.999999994194769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43750.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260211.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14393293876517052, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8560670612348295, \"precision\": 0.9997714808043876, \"recall\": 0.14393293876517052, \"specificity\": 0.9999999921797885, \"npv\": 0.999796550892633, \"accuracy\": 0.9997965500349073, \"f1\": 0.2516385262897553, \"f2\": 0.1736656917570919, \"f0_5\": 0.4566796311489955, \"p4\": 0.4020863428107786, \"phi\": 0.379302987703809}, {\"truth_threshold\": 27.37999938800931, \"match_probability\": 0.9999999942746914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43701.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14377173387375355, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8562282661262465, \"precision\": 0.9997712246345314, \"recall\": 0.14377173387375355, \"specificity\": 0.9999999921797885, \"npv\": 0.9997965125891881, \"accuracy\": 0.9997965117249773, \"f1\": 0.2513921167077015, \"f2\": 0.17347793466740238, \"f0_5\": 0.4563548835120769, \"p4\": 0.40177171317764, \"phi\": 0.3790904626709666}, {\"truth_threshold\": 27.399999387562275, \"match_probability\": 0.9999999943535134, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43615.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260346.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.143488802839838, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.856511197160162, \"precision\": 0.9997707736389685, \"recall\": 0.143488802839838, \"specificity\": 0.9999999921797885, \"npv\": 0.999796445362741, \"accuracy\": 0.999796444487141, \"f1\": 0.25095947477746516, \"f2\": 0.17314836649413365, \"f0_5\": 0.4557842749983802, \"p4\": 0.40121899171484676, \"phi\": 0.3787171712448148}, {\"truth_threshold\": 27.41999938711524, \"match_probability\": 0.9999999944312503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43559.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260402.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14330456867821859, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8566954313217814, \"precision\": 0.9997704790103055, \"recall\": 0.14330456867821859, \"specificity\": 0.9999999921797885, \"npv\": 0.9997964015873849, \"accuracy\": 0.9997964007043638, \"f1\": 0.2506776393404886, \"f2\": 0.17293373976606563, \"f0_5\": 0.45541227466716294, \"p4\": 0.40085872730702193, \"phi\": 0.37847389985606666}, {\"truth_threshold\": 27.439999386668205, \"match_probability\": 0.9999999945079169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43500.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14311046482936957, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8568895351706305, \"precision\": 0.9997701677775224, \"recall\": 0.14311046482936957, \"specificity\": 0.9999999921797885, \"npv\": 0.9997963554669246, \"accuracy\": 0.9997963545760808, \"f1\": 0.2503806073024799, \"f2\": 0.17270759452862341, \"f0_5\": 0.4550199685774716, \"p4\": 0.40047886161393603, \"phi\": 0.3782174268229427}, {\"truth_threshold\": 27.45999938622117, \"match_probability\": 0.9999999945835281, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43421.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260540.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14285056306565644, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8571494369343435, \"precision\": 0.9997697497179434, \"recall\": 0.14285056306565644, \"specificity\": 0.9999999921797885, \"npv\": 0.9997962937124166, \"accuracy\": 0.9997962928110917, \"f1\": 0.24998272844509947, \"f2\": 0.17240475670524708, \"f0_5\": 0.4544940703601746, \"p4\": 0.39996974294668824, \"phi\": 0.37787374122650996}, {\"truth_threshold\": 27.479999385774136, \"match_probability\": 0.9999999946580982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43353.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14262685015511858, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8573731498448814, \"precision\": 0.9997693886493093, \"recall\": 0.14262685015511858, \"specificity\": 0.9999999921797885, \"npv\": 0.9997962405566437, \"accuracy\": 0.9997962396462909, \"f1\": 0.2496401054922781, \"f2\": 0.17214405574301922, \"f0_5\": 0.4540408409490316, \"p4\": 0.3995310689453645, \"phi\": 0.37757766009147}, {\"truth_threshold\": 27.4999993853271, \"match_probability\": 0.9999999947316417, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43298.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260663.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14244590588924236, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8575540941107577, \"precision\": 0.9997690957790708, \"recall\": 0.14244590588924236, \"specificity\": 0.9999999921797885, \"npv\": 0.999796197563008, \"accuracy\": 0.999796196645349, \"f1\": 0.2493628858320207, \"f2\": 0.17193317407270925, \"f0_5\": 0.45367388037963674, \"p4\": 0.399175957321278, \"phi\": 0.3773380127799831}, {\"truth_threshold\": 27.519999384880066, \"match_probability\": 0.9999999948041728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43248.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14228141110208217, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8577185888979179, \"precision\": 0.9997688288871422, \"recall\": 0.14228141110208217, \"specificity\": 0.9999999921797885, \"npv\": 0.9997961584778878, \"accuracy\": 0.9997961575535838, \"f1\": 0.24911079174814743, \"f2\": 0.17174144747605832, \"f0_5\": 0.45333998612138965, \"p4\": 0.39885289410221064, \"phi\": 0.37712001945497636}, {\"truth_threshold\": 27.53999938443303, \"match_probability\": 0.9999999948757052, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43192.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260769.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14209717694046275, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8579028230595372, \"precision\": 0.9997685292347577, \"recall\": 0.14209717694046275, \"specificity\": 0.9999999921797885, \"npv\": 0.9997961147025568, \"accuracy\": 0.9997961137708067, \"f1\": 0.24882836016510976, \"f2\": 0.17152669560921524, \"f0_5\": 0.4529656919808125, \"p4\": 0.3984907978941887, \"phi\": 0.37687571725462}, {\"truth_threshold\": 27.559999383985996, \"match_probability\": 0.9999999949462529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43111.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14183069538526324, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8581693046147367, \"precision\": 0.9997680944319474, \"recall\": 0.14183069538526324, \"specificity\": 0.9999999921797885, \"npv\": 0.9997960513846742, \"accuracy\": 0.9997960504421469, \"f1\": 0.24841968180429985, \"f2\": 0.17121603857136616, \"f0_5\": 0.4524236795432841, \"p4\": 0.39796655479633236, \"phi\": 0.3765220711545939}, {\"truth_threshold\": 27.57999938353896, \"match_probability\": 0.9999999950158294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43010.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14149841591519965, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8585015840848004, \"precision\": 0.999767549976755, \"recall\": 0.14149841591519965, \"specificity\": 0.9999999921797885, \"npv\": 0.9997959724327576, \"accuracy\": 0.999795971476781, \"f1\": 0.24790982791564956, \"f2\": 0.1708286200892233, \"f0_5\": 0.45174680332156264, \"p4\": 0.39731204466508185, \"phi\": 0.37608063923946555}, {\"truth_threshold\": 27.599999383091927, \"match_probability\": 0.9999999950844479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42941.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261020.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14127141310891858, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8587285868910814, \"precision\": 0.9997671765500221, \"recall\": 0.14127141310891858, \"specificity\": 0.9999999921797885, \"npv\": 0.9997959184953169, \"accuracy\": 0.999795917530145, \"f1\": 0.24756134120468593, \"f2\": 0.17056391231296597, \"f0_5\": 0.451283722005612, \"p4\": 0.39686437716365996, \"phi\": 0.3757787688411688}, {\"truth_threshold\": 27.61999938264489, \"match_probability\": 0.9999999951521218, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42882.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261079.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14107730926006956, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8589226907399304, \"precision\": 0.9997668562902173, \"recall\": 0.14107730926006956, \"specificity\": 0.9999999921797885, \"npv\": 0.9997958723749012, \"accuracy\": 0.9997958714018619, \"f1\": 0.24726324984935982, \"f2\": 0.1703375449657434, \"f0_5\": 0.45088732758675076, \"p4\": 0.3964812492323877, \"phi\": 0.37552045534156453}, {\"truth_threshold\": 27.639999382197857, \"match_probability\": 0.999999995218864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42783.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14075160958149235, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8592483904185076, \"precision\": 0.9997663169209917, \"recall\": 0.14075160958149235, \"specificity\": 0.9999999921797885, \"npv\": 0.9997957949864166, \"accuracy\": 0.9997957940001666, \"f1\": 0.24676283474740018, \"f2\": 0.1699576605486729, \"f0_5\": 0.45022130645524516, \"p4\": 0.39583766868109777, \"phi\": 0.3750866144117334}, {\"truth_threshold\": 27.659999381750822, \"match_probability\": 0.9999999952846872, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42696.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1404653886518336, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8595346113481663, \"precision\": 0.9997658408654522, \"recall\": 0.1404653886518336, \"specificity\": 0.9999999921797885, \"npv\": 0.9997957269783642, \"accuracy\": 0.999795725980495, \"f1\": 0.24632284007419222, \"f2\": 0.1696237733900123, \"f0_5\": 0.4496350979917226, \"p4\": 0.3952713674491838, \"phi\": 0.3747049456463511}, {\"truth_threshold\": 27.679999381303787, \"match_probability\": 0.9999999953496044, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42646.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261315.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14030089386467343, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8596991061353265, \"precision\": 0.9997655663915979, \"recall\": 0.14030089386467343, \"specificity\": 0.9999999921797885, \"npv\": 0.9997956878932808, \"accuracy\": 0.9997956868887298, \"f1\": 0.24606986962555213, \"f2\": 0.16943186332936036, \"f0_5\": 0.44929780755818244, \"p4\": 0.39494559725985956, \"phi\": 0.3744854197854467}, {\"truth_threshold\": 27.699999380856752, \"match_probability\": 0.9999999954136277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42577.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14007389105839235, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8599261089416076, \"precision\": 0.9997651865592787, \"recall\": 0.14007389105839235, \"specificity\": 0.9999999921797885, \"npv\": 0.9997956339558708, \"accuracy\": 0.9997956329420936, \"f1\": 0.24572065053037387, \"f2\": 0.16916700240219765, \"f0_5\": 0.4488318796396442, \"p4\": 0.3944956626205617, \"phi\": 0.3741822626238439}, {\"truth_threshold\": 27.719999380409718, \"match_probability\": 0.9999999954767697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42490.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1397876701287336, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8602123298712664, \"precision\": 0.9997647058823529, \"recall\": 0.1397876701287336, \"specificity\": 0.9999999921797885, \"npv\": 0.9997955659478404, \"accuracy\": 0.999795564922422, \"f1\": 0.24528013254017048, \"f2\": 0.16883300591889022, \"f0_5\": 0.4482436318600054, \"p4\": 0.3939277383336019, \"phi\": 0.3737996705932385}, {\"truth_threshold\": 27.739999379962683, \"match_probability\": 0.9999999955390423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42424.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261537.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13957053700968217, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8604294629903179, \"precision\": 0.999764339916105, \"recall\": 0.13957053700968217, \"specificity\": 0.9999999921797885, \"npv\": 0.9997955143555475, \"accuracy\": 0.9997955133212919, \"f1\": 0.24494579887123083, \"f2\": 0.1685795984671114, \"f0_5\": 0.44779679837533276, \"p4\": 0.3934964406395042, \"phi\": 0.3735091669788637}, {\"truth_threshold\": 27.759999379515648, \"match_probability\": 0.9999999956004576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42348.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261613.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13932050493319867, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8606794950668013, \"precision\": 0.9997639170876812, \"recall\": 0.13932050493319867, \"specificity\": 0.9999999921797885, \"npv\": 0.9997954549462472, \"accuracy\": 0.9997954539018087, \"f1\": 0.2445606507295297, \"f2\": 0.16828776301420598, \"f0_5\": 0.4472816454827173, \"p4\": 0.39299930393227667, \"phi\": 0.37317436756255407}, {\"truth_threshold\": 27.779999379068613, \"match_probability\": 0.9999999956610274, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42255.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261706.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1390145446290807, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8609854553709193, \"precision\": 0.9997633976103159, \"recall\": 0.1390145446290807, \"specificity\": 0.9999999921797885, \"npv\": 0.9997953822480342, \"accuracy\": 0.9997953811911252, \"f1\": 0.24408912097878263, \"f2\": 0.16793060060773748, \"f0_5\": 0.4466503601320026, \"p4\": 0.3923902495300919, \"phi\": 0.37276426974060556}, {\"truth_threshold\": 27.799999378621578, \"match_probability\": 0.9999999957207634, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42192.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261769.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13880728119725885, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8611927188027412, \"precision\": 0.9997630444054784, \"recall\": 0.13880728119725885, \"specificity\": 0.9999999921797885, \"npv\": 0.9997953330008635, \"accuracy\": 0.999795331935501, \"f1\": 0.24376955364958128, \"f2\": 0.16768862187869124, \"f0_5\": 0.44622215077553734, \"p4\": 0.3919772158044927, \"phi\": 0.37248620504518015}, {\"truth_threshold\": 27.819999378174543, \"match_probability\": 0.9999999957796768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42104.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13851777037185692, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8614822296281431, \"precision\": 0.9997625492710263, \"recall\": 0.13851777037185692, \"specificity\": 0.9999999921797885, \"npv\": 0.999795264211173, \"accuracy\": 0.999795263133994, \"f1\": 0.24332297912302248, \"f2\": 0.16735057927212196, \"f0_5\": 0.445623252338506, \"p4\": 0.39139967239808293, \"phi\": 0.3720974494195965}, {\"truth_threshold\": 27.83999937772751, \"match_probability\": 0.9999999958377793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42014.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261947.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13822167975496857, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8617783202450314, \"precision\": 0.9997620407386255, \"recall\": 0.13822167975496857, \"specificity\": 0.9999999921797885, \"npv\": 0.9997951938580903, \"accuracy\": 0.9997951927688166, \"f1\": 0.242866020203188, \"f2\": 0.16700480495568693, \"f0_5\": 0.44500981872951784, \"p4\": 0.39080826948243685, \"phi\": 0.3716994379339848}, {\"truth_threshold\": 27.859999377280474, \"match_probability\": 0.9999999958950818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41937.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262024.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13796835778274186, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8620316422172581, \"precision\": 0.9997616039287672, \"recall\": 0.13796835778274186, \"specificity\": 0.9999999921797885, \"npv\": 0.9997951336671274, \"accuracy\": 0.999795132567498, \"f1\": 0.24247487771314916, \"f2\": 0.16670893654033142, \"f0_5\": 0.44448424903921363, \"p4\": 0.3903017015972184, \"phi\": 0.3713585784387315}, {\"truth_threshold\": 27.87999937683344, \"match_probability\": 0.9999999959515954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41879.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13777754382963603, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.862222456170364, \"precision\": 0.9997612738427749, \"recall\": 0.13777754382963603, \"specificity\": 0.9999999921797885, \"npv\": 0.9997950883284847, \"accuracy\": 0.9997950872210503, \"f1\": 0.2421801358970652, \"f2\": 0.1664860506959744, \"f0_5\": 0.4440879119946895, \"p4\": 0.38991977126029026, \"phi\": 0.37110162042559197}, {\"truth_threshold\": 27.899999376386404, \"match_probability\": 0.999999996007331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41799.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262162.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13751435217017974, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8624856478298203, \"precision\": 0.9997608170489608, \"recall\": 0.13751435217017974, \"specificity\": 0.9999999921797885, \"npv\": 0.9997950257924327, \"accuracy\": 0.9997950246742258, \"f1\": 0.24177343320704514, \"f2\": 0.1661785882115337, \"f0_5\": 0.4435405997915946, \"p4\": 0.38939246283923135, \"phi\": 0.3707469033849293}, {\"truth_threshold\": 27.91999937593937, \"match_probability\": 0.9999999960622993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41706.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13720839186606176, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8627916081339382, \"precision\": 0.9997602838239524, \"recall\": 0.13720839186606176, \"specificity\": 0.9999999921797885, \"npv\": 0.999794953094282, \"accuracy\": 0.9997949519635424, \"f1\": 0.2413004047130703, \"f2\": 0.16582111390311396, \"f0_5\": 0.4429034142197207, \"p4\": 0.38877872534056596, \"phi\": 0.37033411782081055}, {\"truth_threshold\": 27.939999375492334, \"match_probability\": 0.9999999961165108, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41645.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262316.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13700770822572633, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8629922917742737, \"precision\": 0.9997599327811787, \"recall\": 0.13700770822572633, \"specificity\": 0.9999999921797885, \"npv\": 0.9997949054105546, \"accuracy\": 0.9997949042715887, \"f1\": 0.24099000046294153, \"f2\": 0.16558661279253503, \"f0_5\": 0.4424849282057712, \"p4\": 0.38837573270634035, \"phi\": 0.3700631159813902}, {\"truth_threshold\": 27.9599993750453, \"match_probability\": 0.9999999961699759, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41583.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13680373468964768, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8631962653103523, \"precision\": 0.9997595749284736, \"recall\": 0.13680373468964768, \"specificity\": 0.9999999921797885, \"npv\": 0.9997948569451313, \"accuracy\": 0.9997948557977997, \"f1\": 0.24067439531882137, \"f2\": 0.1653482440869801, \"f0_5\": 0.4420591368243351, \"p4\": 0.3879657810850416, \"phi\": 0.36978746799908063}, {\"truth_threshold\": 27.979999374598265, \"match_probability\": 0.999999996222705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41514.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262447.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1365767318833666, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8634232681166334, \"precision\": 0.9997591754166265, \"recall\": 0.1365767318833666, \"specificity\": 0.9999999921797885, \"npv\": 0.9997948030078109, \"accuracy\": 0.9997948018511637, \"f1\": 0.24032302415444953, \"f2\": 0.16508293514706912, \"f0_5\": 0.441584743977858, \"p4\": 0.3875091261680099, \"phi\": 0.3694804567193011}, {\"truth_threshold\": 27.99999937415123, \"match_probability\": 0.9999999962747081, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41455.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262506.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1363826280345176, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8636173719654824, \"precision\": 0.9997588327505125, \"recall\": 0.1363826280345176, \"specificity\": 0.9999999921797885, \"npv\": 0.9997947568874981, \"accuracy\": 0.9997947557228806, \"f1\": 0.24002246501421434, \"f2\": 0.16485605368290532, \"f0_5\": 0.44117866166050473, \"p4\": 0.3871183030590039, \"phi\": 0.36921773738465913}, {\"truth_threshold\": 28.019999373704195, \"match_probability\": 0.9999999963259953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41401.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262560.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13620497366438458, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8637950263356154, \"precision\": 0.999758518268093, \"recall\": 0.13620497366438458, \"specificity\": 0.9999999921797885, \"npv\": 0.99979471467569, \"accuracy\": 0.9997947135037741, \"f1\": 0.23974728698331074, \"f2\": 0.16464838079784927, \"f0_5\": 0.4408066353637632, \"p4\": 0.3867603173407657, \"phi\": 0.3689771184674474}, {\"truth_threshold\": 28.03999937325716, \"match_probability\": 0.9999999963765764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41369.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262592.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13609969700060204, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8639003029993979, \"precision\": 0.9997583315208197, \"recall\": 0.13609969700060204, \"specificity\": 0.9999999921797885, \"npv\": 0.999794689661287, \"accuracy\": 0.9997946884850443, \"f1\": 0.23958417791162331, \"f2\": 0.16452530696622636, \"f0_5\": 0.44058601379833306, \"p4\": 0.3865480497977008, \"phi\": 0.36883445541625454}, {\"truth_threshold\": 28.059999372810125, \"match_probability\": 0.9999999964264611, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41311.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262650.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13590888304749624, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8640911169525037, \"precision\": 0.9997579923041553, \"recall\": 0.13590888304749624, \"specificity\": 0.9999999921797885, \"npv\": 0.9997946443226846, \"accuracy\": 0.9997946431385966, \"f1\": 0.23928846565995332, \"f2\": 0.16430221967681252, \"f0_5\": 0.44018583042973286, \"p4\": 0.3861630721093352, \"phi\": 0.36857573790799175}, {\"truth_threshold\": 28.07999937236309, \"match_probability\": 0.9999999964756591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41257.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262704.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1357312286773632, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8642687713226368, \"precision\": 0.9997576756245911, \"recall\": 0.1357312286773632, \"specificity\": 0.9999999921797885, \"npv\": 0.9997946021108861, \"accuracy\": 0.9997946009194901, \"f1\": 0.23901305803700743, \"f2\": 0.16409449921287778, \"f0_5\": 0.4398128900345181, \"p4\": 0.38580436304791876, \"phi\": 0.3683346996518019}, {\"truth_threshold\": 28.099999371916056, \"match_probability\": 0.9999999965241797, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41171.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13544829764344768, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8645517023565523, \"precision\": 0.9997571695684904, \"recall\": 0.13544829764344768, \"specificity\": 0.9999999921797885, \"npv\": 0.9997945348846959, \"accuracy\": 0.9997945336816538, \"f1\": 0.2385742679824536, \"f2\": 0.16376364829657325, \"f0_5\": 0.4392182382623724, \"p4\": 0.3852325243650218, \"phi\": 0.367950497972329}, {\"truth_threshold\": 28.11999937146902, \"match_probability\": 0.9999999965720324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41076.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13513575754784332, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8648642424521567, \"precision\": 0.999756608090347, \"recall\": 0.13513575754784332, \"specificity\": 0.9999999921797885, \"npv\": 0.9997944606232172, \"accuracy\": 0.9997944594072997, \"f1\": 0.23808930377600732, \"f2\": 0.163398120818184, \"f0_5\": 0.438560339949392, \"p4\": 0.3846000391680158, \"phi\": 0.36752562231994534}, {\"truth_threshold\": 28.139999371021986, \"match_probability\": 0.9999999966192262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41018.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1349449435947375, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8650550564052625, \"precision\": 0.9997562640148191, \"recall\": 0.1349449435947375, \"specificity\": 0.9999999921797885, \"npv\": 0.9997944152846356, \"accuracy\": 0.999794414060852, \"f1\": 0.23779308905501334, \"f2\": 0.16317492950753934, \"f0_5\": 0.43815815054489365, \"p4\": 0.3842134752382371, \"phi\": 0.36726598293532264}, {\"truth_threshold\": 28.15999937057495, \"match_probability\": 0.9999999966657703, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40936.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13467517214379476, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8653248278562052, \"precision\": 0.9997557758999658, \"recall\": 0.13467517214379476, \"specificity\": 0.9999999921797885, \"npv\": 0.9997943511852686, \"accuracy\": 0.999794349950357, \"f1\": 0.23737413273723063, \"f2\": 0.16285934802154695, \"f0_5\": 0.43758885717645296, \"p4\": 0.3836664159674322, \"phi\": 0.3668985930946894}, {\"truth_threshold\": 28.179999370127916, \"match_probability\": 0.9999999967116737, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40875.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13447448850345933, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8655255114965407, \"precision\": 0.9997554115201174, \"recall\": 0.13447448850345933, \"specificity\": 0.9999999921797885, \"npv\": 0.9997943035015986, \"accuracy\": 0.9997943022584033, \"f1\": 0.23706234087099748, \"f2\": 0.16262455947145327, \"f0_5\": 0.4371648402891117, \"p4\": 0.38325904798003735, \"phi\": 0.3666250521236016}, {\"truth_threshold\": 28.19999936968088, \"match_probability\": 0.9999999967569451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40778.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263183.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13415536861636854, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8658446313836314, \"precision\": 0.9997548298519172, \"recall\": 0.13415536861636854, \"specificity\": 0.9999999921797885, \"npv\": 0.9997942276767555, \"accuracy\": 0.9997942264203786, \"f1\": 0.23656631346283818, \"f2\": 0.16225116024420833, \"f0_5\": 0.4364896716640299, \"p4\": 0.38261054582595555, \"phi\": 0.36618965638889606}, {\"truth_threshold\": 28.219999369233847, \"match_probability\": 0.9999999968015931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40701.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13390204664414185, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8660979533558582, \"precision\": 0.999754366141829, \"recall\": 0.13390204664414185, \"specificity\": 0.9999999921797885, \"npv\": 0.9997941674859089, \"accuracy\": 0.9997941662190601, \"f1\": 0.23617236096926933, \"f2\": 0.16195470950336435, \"f0_5\": 0.4359529139576483, \"p4\": 0.38209512475156, \"phi\": 0.3658436640919506}, {\"truth_threshold\": 28.239999368786812, \"match_probability\": 0.9999999968456266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40624.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13364872467191516, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8663512753280849, \"precision\": 0.9997539006743121, \"recall\": 0.13364872467191516, \"specificity\": 0.9999999921797885, \"npv\": 0.9997941072950696, \"accuracy\": 0.9997941060177415, \"f1\": 0.23577823241776577, \"f2\": 0.16165822242808867, \"f0_5\": 0.43541544747340283, \"p4\": 0.3815791444801593, \"phi\": 0.36549734430879843}, {\"truth_threshold\": 28.259999368339777, \"match_probability\": 0.9999999968890537, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40560.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1334381713443501, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8665618286556499, \"precision\": 0.9997535124476213, \"recall\": 0.1334381713443501, \"specificity\": 0.9999999921797885, \"npv\": 0.9997940572663254, \"accuracy\": 0.999794055980282, \"f1\": 0.23545051098449776, \"f2\": 0.16141176395678494, \"f0_5\": 0.43496818169144286, \"p4\": 0.3811498515553314, \"phi\": 0.36520924421165046}, {\"truth_threshold\": 28.279999367892742, \"match_probability\": 0.999999996931883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40487.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263474.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1331980089550962, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8668019910449037, \"precision\": 0.9997530681285034, \"recall\": 0.1331980089550962, \"specificity\": 0.9999999921797885, \"npv\": 0.9997940002022954, \"accuracy\": 0.9997939989063047, \"f1\": 0.2350765550517044, \"f2\": 0.16113061660807057, \"f0_5\": 0.4344574191596076, \"p4\": 0.38065971625040224, \"phi\": 0.364880352364849}, {\"truth_threshold\": 28.299999367445707, \"match_probability\": 0.9999999969741227, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40379.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263582.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1328427002148302, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8671572997851698, \"precision\": 0.9997524078338161, \"recall\": 0.1328427002148302, \"specificity\": 0.9999999921797885, \"npv\": 0.9997939157788107, \"accuracy\": 0.9997939144680916, \"f1\": 0.23452301437490924, \"f2\": 0.16071461265545484, \"f0_5\": 0.4337005952521605, \"p4\": 0.3799336583173796, \"phi\": 0.3643932282601368}, {\"truth_threshold\": 28.319999366998672, \"match_probability\": 0.9999999970157809, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40306.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1326025378255763, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8673974621744237, \"precision\": 0.9997519595197937, \"recall\": 0.1326025378255763, \"specificity\": 0.9999999921797885, \"npv\": 0.9997938587147968, \"accuracy\": 0.9997938573941143, \"f1\": 0.23414866517368282, \"f2\": 0.16043338428225704, \"f0_5\": 0.43318824224837443, \"p4\": 0.3794422697381052, \"phi\": 0.36406359932598203}, {\"truth_threshold\": 28.339999366551638, \"match_probability\": 0.9999999970568655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40248.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1324117238724705, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8675882761275295, \"precision\": 0.9997516021660291, \"recall\": 0.1324117238724705, \"specificity\": 0.9999999921797885, \"npv\": 0.9997938133762697, \"accuracy\": 0.9997938120476666, \"f1\": 0.23385112384848017, \"f2\": 0.16020991925814942, \"f0_5\": 0.432780708526795, \"p4\": 0.3790514901418027, \"phi\": 0.36380148947485647}, {\"truth_threshold\": 28.359999366104603, \"match_probability\": 0.9999999970973845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40172.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263789.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.132161691795987, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.867838308204013, \"precision\": 0.9997511323478174, \"recall\": 0.132161691795987, \"specificity\": 0.9999999921797885, \"npv\": 0.9997937539671716, \"accuracy\": 0.9997937526281834, \"f1\": 0.2334610903025777, \"f2\": 0.15991707178036124, \"f0_5\": 0.43224608286402305, \"p4\": 0.37853894917729464, \"phi\": 0.3634577491054002}, {\"truth_threshold\": 28.379999365657568, \"match_probability\": 0.9999999971373457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40092.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263869.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13189850013653068, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8681014998634693, \"precision\": 0.9997506358785098, \"recall\": 0.13189850013653068, \"specificity\": 0.9999999921797885, \"npv\": 0.9997936914312865, \"accuracy\": 0.9997936900813589, \"f1\": 0.23305034252447954, \"f2\": 0.1596087729886476, \"f0_5\": 0.4316825627895058, \"p4\": 0.3779988372004792, \"phi\": 0.3630955656235581}, {\"truth_threshold\": 28.399999365210533, \"match_probability\": 0.9999999971767567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40024.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1316747872259928, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8683252127740072, \"precision\": 0.9997502123195284, \"recall\": 0.1316747872259928, \"specificity\": 0.9999999921797885, \"npv\": 0.9997936382757903, \"accuracy\": 0.9997936369165581, \"f1\": 0.23270105670140553, \"f2\": 0.15934668813372, \"f0_5\": 0.43120295972609174, \"p4\": 0.37753926130666393, \"phi\": 0.36278742540714365}, {\"truth_threshold\": 28.4199993647635, \"match_probability\": 0.999999997215625, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39946.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264015.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13141817535802292, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8685818246419771, \"precision\": 0.9997497246971668, \"recall\": 0.13141817535802292, \"specificity\": 0.9999999921797885, \"npv\": 0.9997935773033163, \"accuracy\": 0.9997935759334042, \"f1\": 0.23230023523117496, \"f2\": 0.1590460264373308, \"f0_5\": 0.430652134070744, \"p4\": 0.37701155589706314, \"phi\": 0.36243364789102667}, {\"truth_threshold\": 28.439999364316463, \"match_probability\": 0.9999999972539584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39879.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13119775234322825, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8688022476567717, \"precision\": 0.9997493043194866, \"recall\": 0.13119775234322825, \"specificity\": 0.9999999921797885, \"npv\": 0.9997935249295306, \"accuracy\": 0.9997935235504388, \"f1\": 0.2319557946779119, \"f2\": 0.1587877359279401, \"f0_5\": 0.43017839690885123, \"p4\": 0.3765578049942237, \"phi\": 0.36212948616706964}, {\"truth_threshold\": 28.45999936386943, \"match_probability\": 0.9999999972917639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39796.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264165.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13092469099654233, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8690753090034576, \"precision\": 0.999748781590715, \"recall\": 0.13092469099654233, \"specificity\": 0.9999999921797885, \"npv\": 0.9997934600485796, \"accuracy\": 0.9997934586581084, \"f1\": 0.23152891347918794, \"f2\": 0.1584677258790268, \"f0_5\": 0.4295907682675389, \"p4\": 0.3759950981706018, \"phi\": 0.36175233421221226}, {\"truth_threshold\": 28.479999363422394, \"match_probability\": 0.9999999973290491, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39722.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13068123871154524, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8693187612884548, \"precision\": 0.9997483137018021, \"recall\": 0.13068123871154524, \"specificity\": 0.9999999921797885, \"npv\": 0.9997934022029196, \"accuracy\": 0.9997934008022957, \"f1\": 0.23114814674724246, \"f2\": 0.1581823800391215, \"f0_5\": 0.4290661476077418, \"p4\": 0.3754928492968214, \"phi\": 0.36141574642185254}, {\"truth_threshold\": 28.49999936297536, \"match_probability\": 0.9999999973658208, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39680.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264281.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13054306309033067, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8694569369096693, \"precision\": 0.999748047367095, \"recall\": 0.13054306309033067, \"specificity\": 0.9999999921797885, \"npv\": 0.999793369371602, \"accuracy\": 0.9997933679652129, \"f1\": 0.23093196295078436, \"f2\": 0.15802041203185258, \"f0_5\": 0.4287680913552659, \"p4\": 0.3752075546079319, \"phi\": 0.3612245706068358}, {\"truth_threshold\": 28.519999362528324, \"match_probability\": 0.9999999974020863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39564.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13016143518411902, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.869838564815881, \"precision\": 0.9997473088391368, \"recall\": 0.13016143518411902, \"specificity\": 0.9999999921797885, \"npv\": 0.999793278694641, \"accuracy\": 0.9997932772723175, \"f1\": 0.23033460928289695, \"f2\": 0.1575730155215235, \"f0_5\": 0.4279437628851483, \"p4\": 0.3744187141635696, \"phi\": 0.3606960348847146}, {\"truth_threshold\": 28.53999936208129, \"match_probability\": 0.9999999974378526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39506.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1299706212310132, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8700293787689868, \"precision\": 0.9997469379491851, \"recall\": 0.1299706212310132, \"specificity\": 0.9999999921797885, \"npv\": 0.9997932333561665, \"accuracy\": 0.9997932319258698, \"f1\": 0.23003578114400672, \"f2\": 0.15734928626051492, \"f0_5\": 0.4275309777609437, \"p4\": 0.3740238066092133, \"phi\": 0.3604314764186035}, {\"truth_threshold\": 28.559999361634254, \"match_probability\": 0.9999999974731264, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39443.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12976335779919135, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8702366422008087, \"precision\": 0.9997465338504042, \"recall\": 0.12976335779919135, \"specificity\": 0.9999999921797885, \"npv\": 0.9997931841092076, \"accuracy\": 0.9997931826702455, \"f1\": 0.22971107759147852, \"f2\": 0.15710624656953692, \"f0_5\": 0.4270821377603281, \"p4\": 0.37359448657363065, \"phi\": 0.3601438910206362}, {\"truth_threshold\": 28.57999936118722, \"match_probability\": 0.9999999975079147, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39354.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264607.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1294705570780462, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8705294429219538, \"precision\": 0.9997459607763439, \"recall\": 0.1294705570780462, \"specificity\": 0.9999999921797885, \"npv\": 0.9997931145381153, \"accuracy\": 0.9997931130869032, \"f1\": 0.22925216631471637, \"f2\": 0.15676286320673546, \"f0_5\": 0.4264472266951586, \"p4\": 0.37298733151098457, \"phi\": 0.359737227828357}, {\"truth_threshold\": 28.599999360740185, \"match_probability\": 0.9999999975422239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39291.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12926329364622435, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8707367063537756, \"precision\": 0.9997455535482558, \"recall\": 0.12926329364622435, \"specificity\": 0.9999999921797885, \"npv\": 0.9997930652911681, \"accuracy\": 0.999793063831279, \"f1\": 0.22892717516066444, \"f2\": 0.15651976464870593, \"f0_5\": 0.4259972027365477, \"p4\": 0.37255708299573326, \"phi\": 0.35944908705013917}, {\"truth_threshold\": 28.61999936029315, \"match_probability\": 0.9999999975760608, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39224.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264737.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1290428706314297, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8709571293685703, \"precision\": 0.9997451190294132, \"recall\": 0.1290428706314297, \"specificity\": 0.9999999921797885, \"npv\": 0.9997930129174358, \"accuracy\": 0.9997930114483136, \"f1\": 0.2285814187269628, \"f2\": 0.15626120448290864, \"f0_5\": 0.42551806585853236, \"p4\": 0.3720990938767575, \"phi\": 0.35914239799193654}, {\"truth_threshold\": 28.639999359846115, \"match_probability\": 0.9999999976094319, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39169.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12886192636555346, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8711380736344465, \"precision\": 0.9997447612241251, \"recall\": 0.12886192636555346, \"specificity\": 0.9999999921797885, \"npv\": 0.9997929699240777, \"accuracy\": 0.9997929684473718, \"f1\": 0.22829748790581103, \"f2\": 0.15604893296776234, \"f0_5\": 0.4251243278913425, \"p4\": 0.37172280617694464, \"phi\": 0.35889044246707885}, {\"truth_threshold\": 28.65999935939908, \"match_probability\": 0.9999999976423436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39088.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12859544481035395, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.871404555189646, \"precision\": 0.9997442324415571, \"recall\": 0.12859544481035395, \"specificity\": 0.9999999921797885, \"npv\": 0.9997929066065934, \"accuracy\": 0.999792905118712, \"f1\": 0.22787916947230652, \"f2\": 0.15573628103928308, \"f0_5\": 0.42454377401689575, \"p4\": 0.3711681002479534, \"phi\": 0.35851905832713227}, {\"truth_threshold\": 28.679999358952045, \"match_probability\": 0.9999999976748021, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39035.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264926.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12842108033596417, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8715789196640359, \"precision\": 0.9997438852605968, \"recall\": 0.12842108033596417, \"specificity\": 0.9999999921797885, \"npv\": 0.9997928651766389, \"accuracy\": 0.9997928636814407, \"f1\": 0.22760534801140506, \"f2\": 0.15553168447567872, \"f0_5\": 0.4241634629385341, \"p4\": 0.3708047979950435, \"phi\": 0.35827584555766523}, {\"truth_threshold\": 28.69999935850501, \"match_probability\": 0.9999999977068138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38954.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265007.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12815459878076463, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8718454012192354, \"precision\": 0.9997433528385176, \"recall\": 0.12815459878076463, \"specificity\": 0.9999999921797885, \"npv\": 0.9997928018591677, \"accuracy\": 0.999792800352781, \"f1\": 0.2271867026317708, \"f2\": 0.15521896577006203, \"f0_5\": 0.42358155527090124, \"p4\": 0.370249032075088, \"phi\": 0.35790382375097085}, {\"truth_threshold\": 28.719999358057976, \"match_probability\": 0.9999999977383848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38887.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265074.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12793417576596997, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.87206582423403, \"precision\": 0.9997429107643263, \"recall\": 0.12793417576596997, \"specificity\": 0.9999999921797885, \"npv\": 0.9997927494854633, \"accuracy\": 0.9997927479698155, \"f1\": 0.22684026623266776, \"f2\": 0.1549602667004585, \"f0_5\": 0.4230996041771389, \"p4\": 0.3697888392033789, \"phi\": 0.35759580957579906}, {\"truth_threshold\": 28.73999935761094, \"match_probability\": 0.9999999977695211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38799.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265162.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12764466494056803, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.872355335059432, \"precision\": 0.9998453807499034, \"recall\": 0.12764466494056803, \"specificity\": 0.9999999953078731, \"npv\": 0.9997926806967766, \"accuracy\": 0.9997926822956498, \"f1\": 0.22638768139197002, \"f2\": 0.15462093382292577, \"f0_5\": 0.42248045977512133, \"p4\": 0.36918725118078327, \"phi\": 0.35720926741165576}, {\"truth_threshold\": 28.759999357163906, \"match_probability\": 0.9999999978002287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38749.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12748017015340785, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8725198298465922, \"precision\": 0.9998451812669333, \"recall\": 0.12748017015340785, \"specificity\": 0.9999999953078731, \"npv\": 0.9997926416119316, \"accuracy\": 0.9997926432038845, \"f1\": 0.22612892307333185, \"f2\": 0.154427829131061, \"f0_5\": 0.42211986988568156, \"p4\": 0.36884310301346024, \"phi\": 0.35697898406202055}, {\"truth_threshold\": 28.77999935671687, \"match_probability\": 0.9999999978305136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38652.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265309.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12716105026631705, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8728389497336829, \"precision\": 0.9998447927983859, \"recall\": 0.12716105026631705, \"specificity\": 0.9999999953078731, \"npv\": 0.9997925657873408, \"accuracy\": 0.9997925673658599, \"f1\": 0.22562671655687513, \"f2\": 0.15405316213126802, \"f0_5\": 0.421419428556476, \"p4\": 0.3681747543922753, \"phi\": 0.3565318102396792}, {\"truth_threshold\": 28.799999356269836, \"match_probability\": 0.9999999978603816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38551.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12682877079625346, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8731712292037466, \"precision\": 0.9998443862333688, \"recall\": 0.12682877079625346, \"specificity\": 0.9999999953078731, \"npv\": 0.999792486835975, \"accuracy\": 0.999792488400494, \"f1\": 0.22510349821031303, \"f2\": 0.1536629833681574, \"f0_5\": 0.4206888423772723, \"p4\": 0.3674778598715135, \"phi\": 0.35606559952285793}, {\"truth_threshold\": 28.8199993558228, \"match_probability\": 0.9999999978898384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38475.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265486.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12657873871976996, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.87342126128023, \"precision\": 0.9998440788960786, \"recall\": 0.12657873871976996, \"specificity\": 0.9999999953078731, \"npv\": 0.9997924274270348, \"accuracy\": 0.9997924289810107, \"f1\": 0.22470958585687503, \"f2\": 0.15336934207641562, \"f0_5\": 0.4201382443189884, \"p4\": 0.3669528000297499, \"phi\": 0.35571438466583793}, {\"truth_threshold\": 28.839999355375767, \"match_probability\": 0.9999999979188896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38397.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265564.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12632212685180005, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8736778731481999, \"precision\": 0.9998437622060776, \"recall\": 0.12632212685180005, \"specificity\": 0.9999999953078731, \"npv\": 0.9997923664547087, \"accuracy\": 0.9997923679978569, \"f1\": 0.2243051255389001, \"f2\": 0.1530679363793575, \"f0_5\": 0.419572396098546, \"p4\": 0.3664133288524378, \"phi\": 0.35535356640944327}, {\"truth_threshold\": 28.859999354928732, \"match_probability\": 0.9999999979475409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38329.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1260984139412622, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8739015860587378, \"precision\": 0.9998434850658667, \"recall\": 0.1260984139412622, \"specificity\": 0.9999999953078731, \"npv\": 0.9997923132993535, \"accuracy\": 0.9997923148330561, \"f1\": 0.22395236871012222, \"f2\": 0.15280514184976784, \"f0_5\": 0.41907846254436354, \"p4\": 0.36594252894478446, \"phi\": 0.3550387077521881}, {\"truth_threshold\": 28.879999354481697, \"match_probability\": 0.9999999979757976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38245.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265716.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1258220626988331, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8741779373011669, \"precision\": 0.9998431413557816, \"recall\": 0.1258220626988331, \"specificity\": 0.9999999953078731, \"npv\": 0.9997922476368638, \"accuracy\": 0.9997922491588904, \"f1\": 0.2235164167241359, \"f2\": 0.15248047396728318, \"f0_5\": 0.4184674975107503, \"p4\": 0.36536031918827355, \"phi\": 0.3546493788227873}, {\"truth_threshold\": 28.899999354034662, \"match_probability\": 0.9999999980036655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38149.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1255062327074855, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8744937672925145, \"precision\": 0.9998427466911283, \"recall\": 0.1255062327074855, \"specificity\": 0.9999999953078731, \"npv\": 0.999792172594029, \"accuracy\": 0.999792174102701, \"f1\": 0.22301792374516247, \"f2\": 0.15210937169806354, \"f0_5\": 0.41776815066767997, \"p4\": 0.364694077851924, \"phi\": 0.35420390753338327}, {\"truth_threshold\": 28.919999353587627, \"match_probability\": 0.9999999980311496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38098.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265863.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1253384480245821, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.874661551975418, \"precision\": 0.9998425362166702, \"recall\": 0.1253384480245821, \"specificity\": 0.9999999953078731, \"npv\": 0.9997921327275275, \"accuracy\": 0.9997921342291005, \"f1\": 0.22275298554368322, \"f2\": 0.1519122005059221, \"f0_5\": 0.4173961439774572, \"p4\": 0.3643397639491245, \"phi\": 0.3539670229083776}, {\"truth_threshold\": 28.939999353140593, \"match_probability\": 0.9999999980582553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38041.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265920.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12515092396721947, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8748490760327805, \"precision\": 0.999842300312771, \"recall\": 0.12515092396721947, \"specificity\": 0.9999999953078731, \"npv\": 0.9997920881708532, \"accuracy\": 0.9997920896644881, \"f1\": 0.2224567846366167, \"f2\": 0.15169181372224538, \"f0_5\": 0.41697997803349346, \"p4\": 0.36394345916988186, \"phi\": 0.35370208178313084}, {\"truth_threshold\": 28.959999352693558, \"match_probability\": 0.999999998084988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37981.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265980.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12495353022262724, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8750464697773728, \"precision\": 0.9998420512280517, \"recall\": 0.12495353022262724, \"specificity\": 0.9999999953078731, \"npv\": 0.999792041269095, \"accuracy\": 0.9997920427543697, \"f1\": 0.22214488752675846, \"f2\": 0.15145980598661224, \"f0_5\": 0.4165414589314973, \"p4\": 0.36352594586241743, \"phi\": 0.35342298184753174}, {\"truth_threshold\": 28.979999352246523, \"match_probability\": 0.9999999981113524, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37925.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266036.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12476929606100783, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8752307039389922, \"precision\": 0.9998418180380164, \"recall\": 0.12476929606100783, \"specificity\": 0.9999999953078731, \"npv\": 0.9997919974941247, \"accuracy\": 0.9997919989715927, \"f1\": 0.2218536847893487, \"f2\": 0.15124324539889533, \"f0_5\": 0.4161317576834875, \"p4\": 0.36313594214452094, \"phi\": 0.35316228959547175}, {\"truth_threshold\": 28.999999351799488, \"match_probability\": 0.999999998137354, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37840.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266121.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1244896549228355, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8755103450771645, \"precision\": 0.9998414627701738, \"recall\": 0.1244896549228355, \"specificity\": 0.9999999953078731, \"npv\": 0.9997919310499808, \"accuracy\": 0.9997919325155916, \"f1\": 0.22141149830167317, \"f2\": 0.15091450039483445, \"f0_5\": 0.41550911945887187, \"p4\": 0.36254337241235596, \"phi\": 0.35276622791249057}, {\"truth_threshold\": 29.019999351352453, \"match_probability\": 0.9999999981629976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37773.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266188.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12426923190804083, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8757307680919592, \"precision\": 0.9998411816088303, \"recall\": 0.12426923190804083, \"specificity\": 0.9999999953078731, \"npv\": 0.9997918786763675, \"accuracy\": 0.9997918801326261, \"f1\": 0.22106279627787206, \"f2\": 0.15065534056091823, \"f0_5\": 0.41501767832696446, \"p4\": 0.36207577760294724, \"phi\": 0.3524537244818398}, {\"truth_threshold\": 29.03999935090542, \"match_probability\": 0.9999999981882882, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37701.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12403235941453016, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8759676405854698, \"precision\": 0.9998408783514997, \"recall\": 0.12403235941453016, \"specificity\": 0.9999999953078731, \"npv\": 0.9997918223942819, \"accuracy\": 0.9997918238404842, \"f1\": 0.2206879192666565, \"f2\": 0.15037680955940363, \"f0_5\": 0.41448891683835803, \"p4\": 0.36157278523923597, \"phi\": 0.3521175907719107}, {\"truth_threshold\": 29.059999350458384, \"match_probability\": 0.9999999982132305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37620.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266341.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12376587785933064, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8762341221406693, \"precision\": 0.999840535799713, \"recall\": 0.12376587785933064, \"specificity\": 0.9999999953078731, \"npv\": 0.9997917590769432, \"accuracy\": 0.9997917605118244, \"f1\": 0.22026599372926955, \"f2\": 0.150063423935156, \"f0_5\": 0.4138932591068619, \"p4\": 0.36100629569439413, \"phi\": 0.35173905643466014}, {\"truth_threshold\": 29.07999935001135, \"match_probability\": 0.9999999982378295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37545.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12351913567859034, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8764808643214097, \"precision\": 0.9998402173044659, \"recall\": 0.12351913567859034, \"specificity\": 0.9999999953078731, \"npv\": 0.9997917004497847, \"accuracy\": 0.9997917018741764, \"f1\": 0.2198751434795849, \"f2\": 0.14977321594549203, \"f0_5\": 0.41334096638886747, \"p4\": 0.3604811790813438, \"phi\": 0.3513881981332568}, {\"truth_threshold\": 29.099999349564314, \"match_probability\": 0.9999999982620899, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37486.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12332503182974132, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8766749681702587, \"precision\": 0.9998399658593833, \"recall\": 0.12332503182974132, \"specificity\": 0.9999999953078731, \"npv\": 0.9997916543297584, \"accuracy\": 0.9997916557458933, \"f1\": 0.21956755395325273, \"f2\": 0.14954489458533066, \"f0_5\": 0.41290598309427246, \"p4\": 0.36006768855258664, \"phi\": 0.3511119432423844}, {\"truth_threshold\": 29.11999934911728, \"match_probability\": 0.9999999982860162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37442.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266519.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12318027641704034, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8768197235829597, \"precision\": 0.999839777825251, \"recall\": 0.12318027641704034, \"specificity\": 0.9999999953078731, \"npv\": 0.9997916199351651, \"accuracy\": 0.9997916213451399, \"f1\": 0.2193380959494331, \"f2\": 0.14937460703491284, \"f0_5\": 0.4125812942283577, \"p4\": 0.359759093838866, \"phi\": 0.35090578108786274}, {\"truth_threshold\": 29.139999348670244, \"match_probability\": 0.9999999983096131, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37386.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12299604225542092, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8770039577445791, \"precision\": 0.9998395378690629, \"recall\": 0.12299604225542092, \"specificity\": 0.9999999953078731, \"npv\": 0.9997915761602317, \"accuracy\": 0.9997915775623628, \"f1\": 0.21904597293710618, \"f2\": 0.14915786013169108, \"f0_5\": 0.4121676893870072, \"p4\": 0.3593660537696013, \"phi\": 0.3506432176024293}, {\"truth_threshold\": 29.15999934822321, \"match_probability\": 0.9999999983328851, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37332.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12281838788528791, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8771816121147121, \"precision\": 0.9998393058010606, \"recall\": 0.12281838788528791, \"specificity\": 0.9999999953078731, \"npv\": 0.9997915339486925, \"accuracy\": 0.9997915353432563, \"f1\": 0.21876419210135395, \"f2\": 0.14894883584347685, \"f0_5\": 0.4117684690269196, \"p4\": 0.35898675015924275, \"phi\": 0.35038984506986853}, {\"truth_threshold\": 29.179999347776175, \"match_probability\": 0.9999999983558368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37259.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266702.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12257822549603403, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.877421774503966, \"precision\": 0.9998389910103314, \"recall\": 0.12257822549603403, \"specificity\": 0.9999999953078731, \"npv\": 0.9997914768849505, \"accuracy\": 0.9997914782692789, \"f1\": 0.21838312438090884, \"f2\": 0.14866623733450163, \"f0_5\": 0.4112281770602246, \"p4\": 0.35847351794771354, \"phi\": 0.3500470314343215}, {\"truth_threshold\": 29.19999934732914, \"match_probability\": 0.9999999983784725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37213.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12242689029184665, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8775731097081534, \"precision\": 0.9998387920148312, \"recall\": 0.12242689029184665, \"specificity\": 0.9999999953078731, \"npv\": 0.9997914409269796, \"accuracy\": 0.999791442304855, \"f1\": 0.21814291576294037, \"f2\": 0.1484881446503488, \"f0_5\": 0.4108873612359414, \"p4\": 0.35814983353898866, \"phi\": 0.3498308393643823}, {\"truth_threshold\": 29.219999346882105, \"match_probability\": 0.9999999984007966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37144.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266817.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12219988748556558, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8778001125144345, \"precision\": 0.9998384925975774, \"recall\": 0.12219988748556558, \"specificity\": 0.9999999953078731, \"npv\": 0.9997913869900279, \"accuracy\": 0.9997913883582188, \"f1\": 0.21778248136237177, \"f2\": 0.14822098110605478, \"f0_5\": 0.4103756178725078, \"p4\": 0.3576639036717831, \"phi\": 0.349506300547536}, {\"truth_threshold\": 29.23999934643507, \"match_probability\": 0.9999999984228133, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37083.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266878.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12199920384523015, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8780007961547699, \"precision\": 0.9998382269675645, \"recall\": 0.12199920384523015, \"specificity\": 0.9999999953078731, \"npv\": 0.9997913393066408, \"accuracy\": 0.9997913406662652, \"f1\": 0.2174637149978009, \"f2\": 0.14798476853909986, \"f0_5\": 0.4099226869651152, \"p4\": 0.35723390998680066, \"phi\": 0.34921913827168316}, {\"truth_threshold\": 29.259999345988035, \"match_probability\": 0.9999999984445268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37024.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12180509999638112, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8781949000036189, \"precision\": 0.9998379692141507, \"recall\": 0.12180509999638112, \"specificity\": 0.9999999953078731, \"npv\": 0.9997912931866476, \"accuracy\": 0.9997912945379821, \"f1\": 0.21715529148863166, \"f2\": 0.14775627876386613, \"f0_5\": 0.4094841411163044, \"p4\": 0.356817653702353, \"phi\": 0.3489411663527973}, {\"truth_threshold\": 29.279999345541, \"match_probability\": 0.9999999984659415, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36965.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266996.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12161099614753208, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8783890038524679, \"precision\": 0.9998377106380677, \"recall\": 0.12161099614753208, \"specificity\": 0.9999999953078731, \"npv\": 0.9997912470666588, \"accuracy\": 0.9997912484096991, \"f1\": 0.21684676123097862, \"f2\": 0.14752776746766283, \"f0_5\": 0.4090451371598668, \"p4\": 0.3564010422181715, \"phi\": 0.348662972846279}, {\"truth_threshold\": 29.299999345093966, \"match_probability\": 0.9999999984870613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36894.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12137741354976461, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8786225864502354, \"precision\": 0.9998373983739838, \"recall\": 0.12137741354976461, \"specificity\": 0.9999999953078731, \"npv\": 0.9997911915663388, \"accuracy\": 0.9997911928993924, \"f1\": 0.21647533745427022, \"f2\": 0.1472527507615283, \"f0_5\": 0.4085162359016833, \"p4\": 0.3558992246382452, \"phi\": 0.34832790308410605}, {\"truth_threshold\": 29.31999934464693, \"match_probability\": 0.9999999985078905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36832.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267129.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12117344001368596, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.878826559986314, \"precision\": 0.9998371247081818, \"recall\": 0.12117344001368596, \"specificity\": 0.9999999953078731, \"npv\": 0.9997911431012757, \"accuracy\": 0.9997911444256035, \"f1\": 0.21615086898729163, \"f2\": 0.14701256983017238, \"f0_5\": 0.40805383403535905, \"p4\": 0.35546059586747153, \"phi\": 0.34803504314222644}, {\"truth_threshold\": 29.339999344199896, \"match_probability\": 0.9999999985284327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36772.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12097604626909374, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8790239537309062, \"precision\": 0.9998368589917885, \"recall\": 0.12097604626909374, \"specificity\": 0.9999999953078731, \"npv\": 0.9997910961996063, \"accuracy\": 0.9997910975154851, \"f1\": 0.21583675481820397, \"f2\": 0.14678011403280478, \"f0_5\": 0.4076058642392695, \"p4\": 0.3550357413931379, \"phi\": 0.3477513954950181}, {\"truth_threshold\": 29.35999934375286, \"match_probability\": 0.9999999985486923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36699.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267262.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12073588387983984, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8792641161201602, \"precision\": 0.9998365345320801, \"recall\": 0.12073588387983984, \"specificity\": 0.9999999953078731, \"npv\": 0.9997910391359144, \"accuracy\": 0.9997910404415078, \"f1\": 0.215454433374625, \"f2\": 0.1464972627817355, \"f0_5\": 0.4070601910905739, \"p4\": 0.3545183370010618, \"phi\": 0.34740597860008915}, {\"truth_threshold\": 29.379999343305826, \"match_probability\": 0.9999999985686728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36623.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267338.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12048585180335634, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8795141481966436, \"precision\": 0.9998361953643288, \"recall\": 0.12048585180335634, \"specificity\": 0.9999999953078731, \"npv\": 0.9997909797271461, \"accuracy\": 0.9997909810220246, \"f1\": 0.21505622596083268, \"f2\": 0.14620275247450443, \"f0_5\": 0.4064913414003379, \"p4\": 0.3539790875628286, \"phi\": 0.34704600125387075}, {\"truth_threshold\": 29.39999934285879, \"match_probability\": 0.9999999985883783, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36535.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267426.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12019634097795441, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8798036590220456, \"precision\": 0.9998358008812019, \"recall\": 0.12019634097795441, \"specificity\": 0.9999999953078731, \"npv\": 0.9997909109380548, \"accuracy\": 0.9997909122205176, \"f1\": 0.21459492161573207, \"f2\": 0.14586169588425285, \"f0_5\": 0.40583171341294083, \"p4\": 0.35335395065368813, \"phi\": 0.34662871839206194}, {\"truth_threshold\": 29.419999342411757, \"match_probability\": 0.9999999986078125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36451.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11991998973552528, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8800800102644747, \"precision\": 0.9998354225525962, \"recall\": 0.11991998973552528, \"specificity\": 0.9999999953078731, \"npv\": 0.9997908452757494, \"accuracy\": 0.999790846546352, \"f1\": 0.21415436316528502, \"f2\": 0.14553609715236193, \"f0_5\": 0.40520110540720206, \"p4\": 0.3527564840735953, \"phi\": 0.34622993384016254}, {\"truth_threshold\": 29.43999934196472, \"match_probability\": 0.9999999986269792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36382.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11969298692924421, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8803070130707558, \"precision\": 0.9998351104759811, \"recall\": 0.11969298692924421, \"specificity\": 0.9999999953078731, \"npv\": 0.999790791338862, \"accuracy\": 0.9997907925997158, \"f1\": 0.21379231318440778, \"f2\": 0.14526860837288938, \"f0_5\": 0.4046824007314583, \"p4\": 0.3522651626488508, \"phi\": 0.34590201692052386}, {\"truth_threshold\": 29.459999341517687, \"match_probability\": 0.999999998645882, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36329.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11951862245485441, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8804813775451455, \"precision\": 0.9998348699600935, \"recall\": 0.11951862245485441, \"specificity\": 0.9999999953078731, \"npv\": 0.9997907499090829, \"accuracy\": 0.9997907511624446, \"f1\": 0.21351411712156476, \"f2\": 0.14506312595882856, \"f0_5\": 0.4042835426584851, \"p4\": 0.3518874363388229, \"phi\": 0.3456499274800642}, {\"truth_threshold\": 29.479999341070652, \"match_probability\": 0.9999999986645245, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36274.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267687.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1193376781889782, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8806623218110218, \"precision\": 0.9998346196251379, \"recall\": 0.1193376781889782, \"specificity\": 0.9999999953078731, \"npv\": 0.9997907069159195, \"accuracy\": 0.9997907081615028, \"f1\": 0.2132253314562325, \"f2\": 0.14484987109902853, \"f0_5\": 0.40386923517138335, \"p4\": 0.3514951485298198, \"phi\": 0.3453881307137523}, {\"truth_threshold\": 29.499999340623617, \"match_probability\": 0.9999999986829103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36167.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267794.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11898565934445537, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8810143406555446, \"precision\": 0.9998341304287729, \"recall\": 0.11898565934445537, \"specificity\": 0.9999999953078731, \"npv\": 0.999790623274685, \"accuracy\": 0.9997906245051251, \"f1\": 0.2126632444859967, \"f2\": 0.1444349397811691, \"f0_5\": 0.4030620546391086, \"p4\": 0.3507310711701536, \"phi\": 0.3448782476847134}, {\"truth_threshold\": 29.519999340176582, \"match_probability\": 0.9999999987010432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36083.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267878.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11870930810202625, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8812906918979737, \"precision\": 0.9998337443542353, \"recall\": 0.11870930810202625, \"specificity\": 0.9999999953078731, \"npv\": 0.9997905576124173, \"accuracy\": 0.9997905588309595, \"f1\": 0.21222173209822084, \"f2\": 0.1441091496110415, \"f0_5\": 0.4024273003254394, \"p4\": 0.3501304009124973, \"phi\": 0.344477436936105}, {\"truth_threshold\": 29.539999339729548, \"match_probability\": 0.9999999987189263, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36019.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1184987547744612, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8815012452255389, \"precision\": 0.9998334489937544, \"recall\": 0.1184987547744612, \"specificity\": 0.9999999953078731, \"npv\": 0.9997905075840285, \"accuracy\": 0.9997905087934998, \"f1\": 0.21188519527274652, \"f2\": 0.14386089918354078, \"f0_5\": 0.40194303900584966, \"p4\": 0.3496722541976797, \"phi\": 0.3441717440564011}, {\"truth_threshold\": 29.559999339282513, \"match_probability\": 0.9999999987365632, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35940.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268021.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11823885301074809, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8817611469892519, \"precision\": 0.99983308295777, \"recall\": 0.11823885301074809, \"specificity\": 0.9999999953078731, \"npv\": 0.9997904458302432, \"accuracy\": 0.9997904470285107, \"f1\": 0.21146960786332733, \"f2\": 0.1435544300561596, \"f0_5\": 0.4013445152933031, \"p4\": 0.34910614016502856, \"phi\": 0.343794029610886}, {\"truth_threshold\": 29.579999338835478, \"match_probability\": 0.9999999987539573, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35894.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11808751780656071, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8819124821934393, \"precision\": 0.99983286908078, \"recall\": 0.11808751780656071, \"specificity\": 0.9999999953078731, \"npv\": 0.9997904098723464, \"accuracy\": 0.9997904110640866, \"f1\": 0.211227531255425, \"f2\": 0.1433759618580157, \"f0_5\": 0.4009956184743532, \"p4\": 0.34877620384854197, \"phi\": 0.34357390334958593}, {\"truth_threshold\": 29.599999338388443, \"match_probability\": 0.9999999987711119, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35826.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268135.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11786380489602284, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8821361951039771, \"precision\": 0.9998325519089082, \"recall\": 0.11786380489602284, \"specificity\": 0.9999999953078731, \"npv\": 0.9997903567171993, \"accuracy\": 0.9997903578992858, \"f1\": 0.21086955881963432, \"f2\": 0.14311211527583817, \"f0_5\": 0.4004793321543789, \"p4\": 0.34828806647944177, \"phi\": 0.3432482407552075}, {\"truth_threshold\": 29.619999337941408, \"match_probability\": 0.9999999987880304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35765.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268196.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11766312125568741, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8823368787443125, \"precision\": 0.9998322663610187, \"recall\": 0.11766312125568741, \"specificity\": 0.9999999953078731, \"npv\": 0.9997903090339104, \"accuracy\": 0.9997903102073322, \"f1\": 0.21054831455382478, \"f2\": 0.14287540497677, \"f0_5\": 0.4000156583789104, \"p4\": 0.34784976647800775, \"phi\": 0.34295583915171945}, {\"truth_threshold\": 29.639999337494373, \"match_probability\": 0.9999999988047159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35714.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.117495336572784, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.882504663427216, \"precision\": 0.9998320268756999, \"recall\": 0.117495336572784, \"specificity\": 0.9999999953078731, \"npv\": 0.9997902691675575, \"accuracy\": 0.9997902703337316, \"f1\": 0.21027964472549246, \"f2\": 0.14267748193460342, \"f0_5\": 0.399627608030597, \"p4\": 0.34748301942879334, \"phi\": 0.3427111807760392}, {\"truth_threshold\": 29.65999933704734, \"match_probability\": 0.9999999988211717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35667.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268294.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11734071147285342, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8826592885271466, \"precision\": 0.9998318055672357, \"recall\": 0.11734071147285342, \"specificity\": 0.9999999953078731, \"npv\": 0.9997902324279804, \"accuracy\": 0.9997902335874722, \"f1\": 0.21003197559726058, \"f2\": 0.1424950679854928, \"f0_5\": 0.39926967914689926, \"p4\": 0.3471447950594371, \"phi\": 0.3424855565596145}, {\"truth_threshold\": 29.679999336600304, \"match_probability\": 0.9999999988374011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35582.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11706107033468109, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.882938929665319, \"precision\": 0.9998314038439924, \"recall\": 0.11706107033468109, \"specificity\": 0.9999999953078731, \"npv\": 0.9997901659840709, \"accuracy\": 0.9997901671314713, \"f1\": 0.2095838892177565, \"f2\": 0.14216513562063302, \"f0_5\": 0.39862159515855466, \"p4\": 0.34653252290166425, \"phi\": 0.34207713487363633}, {\"truth_threshold\": 29.69999933615327, \"match_probability\": 0.9999999988534068, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35504.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268457.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11680445846671118, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8831955415332888, \"precision\": 0.9998310335116869, \"recall\": 0.11680445846671118, \"specificity\": 0.9999999953078731, \"npv\": 0.9997901050120207, \"accuracy\": 0.9997901061483174, \"f1\": 0.20917250663532377, \"f2\": 0.14186233471903234, \"f0_5\": 0.3980260133945888, \"p4\": 0.3459700038101869, \"phi\": 0.3417019184417754}, {\"truth_threshold\": 29.719999335706234, \"match_probability\": 0.9999999988691923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35418.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11652152743279566, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8834784725672044, \"precision\": 0.9998306233062331, \"recall\": 0.11652152743279566, \"specificity\": 0.9999999953078731, \"npv\": 0.9997900377864354, \"accuracy\": 0.9997900389104811, \"f1\": 0.20871871178749798, \"f2\": 0.1415284335569998, \"f0_5\": 0.3973683797180343, \"p4\": 0.3453490465754613, \"phi\": 0.3412877401746973}, {\"truth_threshold\": 29.7399993352592, \"match_probability\": 0.9999999988847605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35340.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268621.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11626491556482575, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8837350844351742, \"precision\": 0.9998302495331862, \"recall\": 0.11626491556482575, \"specificity\": 0.9999999953078731, \"npv\": 0.9997899768144007, \"accuracy\": 0.9997899779273273, \"f1\": 0.20830693148093024, \"f2\": 0.14122555327328384, \"f0_5\": 0.39677104267478025, \"p4\": 0.34478517693007044, \"phi\": 0.34091165501174825}, {\"truth_threshold\": 29.759999334812164, \"match_probability\": 0.9999999989001144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35262.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268699.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11600830369685584, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8839916963031441, \"precision\": 0.9998298741068391, \"recall\": 0.11600830369685584, \"specificity\": 0.9999999953078731, \"npv\": 0.9997899158423735, \"accuracy\": 0.9997899169441734, \"f1\": 0.2078949618104584, \"f2\": 0.140922635223705, \"f0_5\": 0.3961728680794458, \"p4\": 0.34422066324061223, \"phi\": 0.3405351545486495}, {\"truth_threshold\": 29.77999933436513, \"match_probability\": 0.9999999989152568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35149.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1156365454778738, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8843634545221262, \"precision\": 0.9998293272649694, \"recall\": 0.1156365454778738, \"specificity\": 0.9999999953078731, \"npv\": 0.9997898275111166, \"accuracy\": 0.9997898285967839, \"f1\": 0.2072977978037014, \"f2\": 0.140483725406655, \"f0_5\": 0.39530479260247287, \"p4\": 0.34340169750078287, \"phi\": 0.33998897211744783}, {\"truth_threshold\": 29.799999333918095, \"match_probability\": 0.9999999989301908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35070.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1153766437141607, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8846233562858393, \"precision\": 0.9998289428669176, \"recall\": 0.1153766437141607, \"specificity\": 0.9999999953078731, \"npv\": 0.9997897657574152, \"accuracy\": 0.9997897668317948, \"f1\": 0.20688007503605801, \"f2\": 0.14017682985322802, \"f0_5\": 0.3946968588567634, \"p4\": 0.34282834022416714, \"phi\": 0.3396066060968502}, {\"truth_threshold\": 29.81999933347106, \"match_probability\": 0.9999999989449192, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35011.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268950.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11518253986531167, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8848174601346883, \"precision\": 0.999828654653454, \"recall\": 0.11518253986531167, \"specificity\": 0.9999999953078731, \"npv\": 0.9997897196375672, \"accuracy\": 0.9997897207035117, \"f1\": 0.20656797786287015, \"f2\": 0.1399476040903026, \"f0_5\": 0.3942422679599756, \"p4\": 0.3423997032368932, \"phi\": 0.3393207605740287}, {\"truth_threshold\": 29.839999333024025, \"match_probability\": 0.9999999989594448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34927.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269034.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11490618862288254, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8850938113771175, \"precision\": 0.999828242635903, \"recall\": 0.11490618862288254, \"specificity\": 0.9999999953078731, \"npv\": 0.9997896539754182, \"accuracy\": 0.999789655029346, \"f1\": 0.2061234486299551, \"f2\": 0.1396212114549596, \"f0_5\": 0.39359421942649536, \"p4\": 0.34178879988870664, \"phi\": 0.33891337814918954}, {\"truth_threshold\": 29.85999933257699, \"match_probability\": 0.9999999989737705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34855.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11466931612937185, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8853306838706282, \"precision\": 0.9998278878976506, \"recall\": 0.11466931612937185, \"specificity\": 0.9999999953078731, \"npv\": 0.999789597693583, \"accuracy\": 0.999789598737204, \"f1\": 0.2057422481420923, \"f2\": 0.1393414114439456, \"f0_5\": 0.3930379675465996, \"p4\": 0.34126456857501525, \"phi\": 0.33856380310567297}, {\"truth_threshold\": 29.879999332129955, \"match_probability\": 0.9999999989878988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34772.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11439625478268593, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8856037452173141, \"precision\": 0.9998274771407212, \"recall\": 0.11439625478268593, \"specificity\": 0.9999999953078731, \"npv\": 0.999789532813142, \"accuracy\": 0.9997895338448737, \"f1\": 0.2053026076123505, \"f2\": 0.13901882423306164, \"f0_5\": 0.3923958354492375, \"p4\": 0.34065955807272336, \"phi\": 0.3381603724055481}, {\"truth_threshold\": 29.89999933168292, \"match_probability\": 0.9999999990018327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34708.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269253.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11418570145512089, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8858142985448791, \"precision\": 0.9998271590712681, \"recall\": 0.11418570145512089, \"specificity\": 0.9999999953078731, \"npv\": 0.9997894827848559, \"accuracy\": 0.9997894838074141, \"f1\": 0.20496346054477005, \"f2\": 0.13877005304831924, \"f0_5\": 0.39190003997136513, \"p4\": 0.3401925398003999, \"phi\": 0.3378489644001084}, {\"truth_threshold\": 29.919999331235886, \"match_probability\": 0.9999999990155748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34604.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11384355229782768, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8861564477021723, \"precision\": 0.9998266396995088, \"recall\": 0.11384355229782768, \"specificity\": 0.9999999953078731, \"npv\": 0.9997894014889016, \"accuracy\": 0.9997894024965422, \"f1\": 0.20441207309545117, \"f2\": 0.13836574556121217, \"f0_5\": 0.3910931485236245, \"p4\": 0.33943269710010715, \"phi\": 0.3373423133442571}, {\"truth_threshold\": 29.93999933078885, \"match_probability\": 0.9999999990291276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34542.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269419.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11363957876174904, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.886360421238251, \"precision\": 0.9998263285863147, \"recall\": 0.11363957876174904, \"specificity\": 0.9999999953078731, \"npv\": 0.9997893530240121, \"accuracy\": 0.9997893540227533, \"f1\": 0.20408320015125153, \"f2\": 0.13812468409906653, \"f0_5\": 0.3906113946982153, \"p4\": 0.33897916047657495, \"phi\": 0.33703990904863557}, {\"truth_threshold\": 29.959999330341816, \"match_probability\": 0.9999999990424939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34467.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269494.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11339283658100875, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8866071634189913, \"precision\": 0.9998259507440606, \"recall\": 0.11339283658100875, \"specificity\": 0.9999999953078731, \"npv\": 0.9997892943971359, \"accuracy\": 0.9997892953851054, \"f1\": 0.20368520893290865, \"f2\": 0.13783304553965114, \"f0_5\": 0.3900279052082933, \"p4\": 0.3384299739224026, \"phi\": 0.33667373441636206}, {\"truth_threshold\": 29.97999932989478, \"match_probability\": 0.9999999990556762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34393.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269568.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11314938429601167, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8868506157039884, \"precision\": 0.9998255763248932, \"recall\": 0.11314938429601167, \"specificity\": 0.9999999953078731, \"npv\": 0.9997892365519581, \"accuracy\": 0.9997892375292927, \"f1\": 0.20329235134176615, \"f2\": 0.13754526120122249, \"f0_5\": 0.3894514185031604, \"p4\": 0.3378875149318184, \"phi\": 0.3363120514044495}, {\"truth_threshold\": 29.999999329447746, \"match_probability\": 0.999999999068677, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34304.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269657.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11285658357486651, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8871434164251335, \"precision\": 0.9998251238705916, \"recall\": 0.11285658357486651, \"specificity\": 0.9999999953078731, \"npv\": 0.9997891669814153, \"accuracy\": 0.9997891679459505, \"f1\": 0.20281963277963527, \"f2\": 0.1371990970712408, \"f0_5\": 0.388757051774588, \"p4\": 0.3372343139178511, \"phi\": 0.3358765384301996}, {\"truth_threshold\": 30.01999932900071, \"match_probability\": 0.9999999990814988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34225.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1125966818111534, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8874033181888465, \"precision\": 0.9998247202827846, \"recall\": 0.1125966818111534, \"specificity\": 0.9999999953078731, \"npv\": 0.9997891052277955, \"accuracy\": 0.9997891061809614, \"f1\": 0.2023998202204665, \"f2\": 0.13689178649281042, \"f0_5\": 0.3881397643376391, \"p4\": 0.33665378762865633, \"phi\": 0.33548948590787414}, {\"truth_threshold\": 30.039999328553677, \"match_probability\": 0.999999999094144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34165.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269796.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11239928806656117, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8876007119334388, \"precision\": 0.9998244125135348, \"recall\": 0.11239928806656117, \"specificity\": 0.9999999953078731, \"npv\": 0.9997890583263173, \"accuracy\": 0.999789059270843, \"f1\": 0.2020808441673666, \"f2\": 0.1366583600996788, \"f0_5\": 0.3876703468778722, \"p4\": 0.3362124292348418, \"phi\": 0.3351952233756178}, {\"truth_threshold\": 30.05999932810664, \"match_probability\": 0.9999999991066153, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34075.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269886.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11210319744967281, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8878968025503272, \"precision\": 0.9998239488277926, \"recall\": 0.11210319744967281, \"specificity\": 0.9999999953078731, \"npv\": 0.9997889879741081, \"accuracy\": 0.9997889889056656, \"f1\": 0.2016021677779684, \"f2\": 0.13630817849070945, \"f0_5\": 0.3869652611376722, \"p4\": 0.335549658182129, \"phi\": 0.33475334462442646}, {\"truth_threshold\": 30.079999327659607, \"match_probability\": 0.9999999991189148, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34006.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11187619464339175, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8881238053566083, \"precision\": 0.999823591673527, \"recall\": 0.11187619464339175, \"specificity\": 0.9999999953078731, \"npv\": 0.9997889340374211, \"accuracy\": 0.9997889349590294, \"f1\": 0.2012350098972403, \"f2\": 0.13603967177018791, \"f0_5\": 0.3864239140563034, \"p4\": 0.33504093668359897, \"phi\": 0.33441417554299585}, {\"truth_threshold\": 30.099999327212572, \"match_probability\": 0.9999999991310449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33918.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1115866838179898, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8884133161820101, \"precision\": 0.9998231340643792, \"recall\": 0.1115866838179898, \"specificity\": 0.9999999953078731, \"npv\": 0.9997888652486114, \"accuracy\": 0.9997888661575225, \"f1\": 0.20076653299199432, \"f2\": 0.1356971853976098, \"f0_5\": 0.3857325142099409, \"p4\": 0.33439137923506146, \"phi\": 0.333981112366704}, {\"truth_threshold\": 30.119999326765537, \"match_probability\": 0.9999999991430081, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33838.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270123.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1113234921585335, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8886765078414665, \"precision\": 0.9998227159910176, \"recall\": 0.1113234921585335, \"specificity\": 0.9999999953078731, \"npv\": 0.999788802713338, \"accuracy\": 0.9997888036106981, \"f1\": 0.20034043309009636, \"f2\": 0.13538579229375652, \"f0_5\": 0.38510300748628046, \"p4\": 0.3338001384589385, \"phi\": 0.33358693075982454}, {\"truth_threshold\": 30.139999326318502, \"match_probability\": 0.9999999991548065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33782.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11113925799691408, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.888860742003086, \"precision\": 0.9998224221617142, \"recall\": 0.11113925799691408, \"specificity\": 0.9999999953078731, \"npv\": 0.9997887589386514, \"accuracy\": 0.9997887598279209, \"f1\": 0.2000420430556419, \"f2\": 0.13516779339837648, \"f0_5\": 0.38466180686975787, \"p4\": 0.33338585328997417, \"phi\": 0.33331072629396585}, {\"truth_threshold\": 30.159999325871468, \"match_probability\": 0.9999999991664426, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33743.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270218.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11101095206292913, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8889890479370709, \"precision\": 0.9998222169545764, \"recall\": 0.11101095206292913, \"specificity\": 0.9999999953078731, \"npv\": 0.999788728452711, \"accuracy\": 0.999788729336344, \"f1\": 0.1998341772526724, \"f2\": 0.13501596119696574, \"f0_5\": 0.38435427615916823, \"p4\": 0.3330971303206365, \"phi\": 0.33311823434313265}, {\"truth_threshold\": 30.179999325424433, \"match_probability\": 0.9999999991779184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33672.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11077736946516165, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8892226305348383, \"precision\": 0.9998218421521468, \"recall\": 0.11077736946516165, \"specificity\": 0.9999999953078731, \"npv\": 0.9997886729526707, \"accuracy\": 0.9997886738260373, \"f1\": 0.19945563160653834, \"f2\": 0.1347395243941283, \"f0_5\": 0.38379385100063146, \"p4\": 0.3325710781354333, \"phi\": 0.33276751443421804}, {\"truth_threshold\": 30.199999324977398, \"match_probability\": 0.9999999991892362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33621.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270340.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11060958478225826, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8893904152177418, \"precision\": 0.9998215719511108, \"recall\": 0.11060958478225826, \"specificity\": 0.9999999953078731, \"npv\": 0.9997886330864484, \"accuracy\": 0.9997886339524368, \"f1\": 0.1991836202708627, \"f2\": 0.13454093772484516, \"f0_5\": 0.38339084405054863, \"p4\": 0.3321928680287627, \"phi\": 0.33251536059709264}, {\"truth_threshold\": 30.219999324530363, \"match_probability\": 0.9999999992003983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33541.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270420.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11034639312280194, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8896536068771981, \"precision\": 0.9998211464512475, \"recall\": 0.11034639312280194, \"specificity\": 0.9999999953078731, \"npv\": 0.9997885705512041, \"accuracy\": 0.9997885714056123, \"f1\": 0.19875677020989133, \"f2\": 0.134229396562005, \"f0_5\": 0.3827579202508736, \"p4\": 0.33159902097871535, \"phi\": 0.33211943952654993}, {\"truth_threshold\": 30.23999932408333, \"match_probability\": 0.9999999992114066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33473.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270488.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11012268021226407, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8898773197877359, \"precision\": 0.9998207831775142, \"recall\": 0.11012268021226407, \"specificity\": 0.9999999953078731, \"npv\": 0.9997885173962526, \"accuracy\": 0.9997885182408115, \"f1\": 0.19839378852536746, \"f2\": 0.133964555203098, \"f0_5\": 0.3822192076770417, \"p4\": 0.3310936967504174, \"phi\": 0.3317825351853171}, {\"truth_threshold\": 30.259999323636293, \"match_probability\": 0.9999999992222635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33424.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270537.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10996147532084709, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8900385246791529, \"precision\": 0.9998205204905773, \"recall\": 0.10996147532084709, \"specificity\": 0.9999999953078731, \"npv\": 0.9997884790934234, \"accuracy\": 0.9997884799308815, \"f1\": 0.1981321374903302, \"f2\": 0.13377369576249887, \"f0_5\": 0.38183060265353075, \"p4\": 0.33072924987213714, \"phi\": 0.3315395536703885}, {\"truth_threshold\": 30.27999932318926, \"match_probability\": 0.9999999992329708, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33328.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10964564532949951, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8903543546705005, \"precision\": 0.999820003599928, \"recall\": 0.10964564532949951, \"specificity\": 0.9999999953078731, \"npv\": 0.9997884040511542, \"accuracy\": 0.9997884048746921, \"f1\": 0.19761929468269615, \"f2\": 0.13339972365827768, \"f0_5\": 0.38106824423675445, \"p4\": 0.3300144625729972, \"phi\": 0.33106299135271344}, {\"truth_threshold\": 30.299999322742224, \"match_probability\": 0.9999999992435307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33253.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270708.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10939890314875922, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8906010968512408, \"precision\": 0.9998195977028774, \"recall\": 0.10939890314875922, \"specificity\": 0.9999999953078731, \"npv\": 0.9997883454243893, \"accuracy\": 0.9997883462370443, \"f1\": 0.19721843307039916, \"f2\": 0.13310751795488443, \"f0_5\": 0.38047171948548847, \"p4\": 0.32945532539853567, \"phi\": 0.33069019922976695}, {\"truth_threshold\": 30.31999932229519, \"match_probability\": 0.9999999992539452, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33187.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270774.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10918177002970776, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8908182299702923, \"precision\": 0.9998192389961739, \"recall\": 0.10918177002970776, \"specificity\": 0.9999999953078731, \"npv\": 0.9997882938328418, \"accuracy\": 0.999788294635914, \"f1\": 0.19686552732579177, \"f2\": 0.13285034790802835, \"f0_5\": 0.3799460997909478, \"p4\": 0.3289627688841671, \"phi\": 0.33036179421812045}, {\"truth_threshold\": 30.339999321848154, \"match_probability\": 0.9999999992642163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33109.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10892515816173785, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8910748418382621, \"precision\": 0.9998188132266345, \"recall\": 0.10892515816173785, \"specificity\": 0.9999999953078731, \"npv\": 0.9997882328610199, \"accuracy\": 0.9997882336527601, \"f1\": 0.1964482787264593, \"f2\": 0.13254638462911913, \"f0_5\": 0.3793240930202717, \"p4\": 0.32838003307298086, \"phi\": 0.32997325786251563}, {\"truth_threshold\": 30.35999932140112, \"match_probability\": 0.9999999992743461, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33061.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270900.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10876724316606406, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8912327568339359, \"precision\": 0.9998185502162277, \"recall\": 0.10876724316606406, \"specificity\": 0.9999999953078731, \"npv\": 0.9997881953399025, \"accuracy\": 0.9997881961246655, \"f1\": 0.1961914143631983, \"f2\": 0.13235931143211965, \"f0_5\": 0.37894087738320925, \"p4\": 0.3280210901733688, \"phi\": 0.32973393103237014}, {\"truth_threshold\": 30.379999320954084, \"match_probability\": 0.9999999992843364, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32971.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270990.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10847115254917572, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8915288474508243, \"precision\": 0.9998180550080359, \"recall\": 0.10847115254917572, \"specificity\": 0.9999999953078731, \"npv\": 0.9997881249878148, \"accuracy\": 0.9997881257594881, \"f1\": 0.19570959642426797, \"f2\": 0.1320085104270348, \"f0_5\": 0.3782214380926379, \"p4\": 0.3273473806195258, \"phi\": 0.3292847244394274}, {\"truth_threshold\": 30.39999932050705, \"match_probability\": 0.9999999992941891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32904.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10825072953438106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8917492704656189, \"precision\": 1.0, \"recall\": 0.10825072953438106, \"specificity\": 1.0, \"npv\": 0.9997880726155945, \"accuracy\": 0.9997880780675343, \"f1\": 0.19535422201772223, \"f2\": 0.1317479587554895, \"f0_5\": 0.3777058935618731, \"p4\": 0.32685012480699804, \"phi\": 0.328979920725279}, {\"truth_threshold\": 30.419999320060015, \"match_probability\": 0.9999999993039063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32837.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271124.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1080303065195864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8919696934804136, \"precision\": 1.0, \"recall\": 0.1080303065195864, \"specificity\": 1.0, \"npv\": 0.9997880202423859, \"accuracy\": 0.9997880256845689, \"f1\": 0.1949952196865777, \"f2\": 0.1314867448131268, \"f0_5\": 0.3771688616591892, \"p4\": 0.32634749221185344, \"phi\": 0.32864480260821927}, {\"truth_threshold\": 30.43999931961298, \"match_probability\": 0.9999999993134896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32772.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10781646329627814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8921835367037219, \"precision\": 1.0, \"recall\": 0.10781646329627814, \"specificity\": 1.0, \"npv\": 0.9997879694325618, \"accuracy\": 0.999787974865274, \"f1\": 0.19464679731419254, \"f2\": 0.13123330151143345, \"f0_5\": 0.37664722824325536, \"p4\": 0.32585938353885563, \"phi\": 0.3283193611567649}, {\"truth_threshold\": 30.459999319165945, \"match_probability\": 0.9999999993229409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32700.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271261.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10757959080276747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8924204091972325, \"precision\": 1.0, \"recall\": 0.10757959080276747, \"specificity\": 1.0, \"npv\": 0.9997879131509165, \"accuracy\": 0.999787918573132, \"f1\": 0.19426069547705258, \"f2\": 0.13095253351103364, \"f0_5\": 0.3760686906139235, \"p4\": 0.32531815660289287, \"phi\": 0.32795849521902676}, {\"truth_threshold\": 30.47999931871891, \"match_probability\": 0.9999999993322622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32619.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271342.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10731310924756794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.892686890752432, \"precision\": 1.0, \"recall\": 0.10731310924756794, \"specificity\": 1.0, \"npv\": 0.9997878498340732, \"accuracy\": 0.9997878552444722, \"f1\": 0.19382613346009864, \"f2\": 0.1306366308012332, \"f0_5\": 0.37541691890884066, \"p4\": 0.32470858074753994, \"phi\": 0.3275520458700189}, {\"truth_threshold\": 30.499999318271875, \"match_probability\": 0.9999999993414552, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32562.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10712558519020532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8928744148097947, \"precision\": 1.0, \"recall\": 0.10712558519020532, \"specificity\": 1.0, \"npv\": 0.9997878052777809, \"accuracy\": 0.9997878106798598, \"f1\": 0.19352020515685406, \"f2\": 0.13041430432086998, \"f0_5\": 0.3749576816694265, \"p4\": 0.3242791777916628, \"phi\": 0.32726572339066207}, {\"truth_threshold\": 30.51999931782484, \"match_probability\": 0.9999999993505215, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32497.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271464.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10691174196689707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8930882580331029, \"precision\": 1.0, \"recall\": 0.10691174196689707, \"specificity\": 1.0, \"npv\": 0.9997877544679786, \"accuracy\": 0.9997877598605649, \"f1\": 0.1931712130488798, \"f2\": 0.1301607493465327, \"f0_5\": 0.37443340116004414, \"p4\": 0.3237890613115933, \"phi\": 0.326938909319989}, {\"truth_threshold\": 30.539999317377806, \"match_probability\": 0.9999999993594632, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32402.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271559.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1065992018712927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8934007981287073, \"precision\": 1.0, \"recall\": 0.1065992018712927, \"specificity\": 1.0, \"npv\": 0.9997876802075077, \"accuracy\": 0.9997876855862109, \"f1\": 0.19266090503414465, \"f2\": 0.12979012149848668, \"f0_5\": 0.37366601394472393, \"p4\": 0.3230718801078885, \"phi\": 0.32646066953137176}, {\"truth_threshold\": 30.55999931693077, \"match_probability\": 0.9999999993682815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32346.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271615.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10641496770967328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8935850322903267, \"precision\": 1.0, \"recall\": 0.10641496770967328, \"specificity\": 1.0, \"npv\": 0.9997876364329196, \"accuracy\": 0.9997876418034337, \"f1\": 0.19235995682516271, \"f2\": 0.12957161970533332, \"f0_5\": 0.3732130288799917, \"p4\": 0.322648643062925, \"phi\": 0.3261784313033891}, {\"truth_threshold\": 30.579999316483736, \"match_probability\": 0.9999999993769786, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32277.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271684.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10618796490339222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8938120350966078, \"precision\": 1.0, \"recall\": 0.10618796490339222, \"specificity\": 1.0, \"npv\": 0.9997875824963787, \"accuracy\": 0.9997875878567977, \"f1\": 0.19198900778615147, \"f2\": 0.12930236731855324, \"f0_5\": 0.3726542421646435, \"p4\": 0.32212666661506906, \"phi\": 0.32583033732446215}, {\"truth_threshold\": 30.5999993160367, \"match_probability\": 0.999999999385556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32222.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10600702063751599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.893992979362484, \"precision\": 1.0, \"recall\": 0.10600702063751599, \"specificity\": 1.0, \"npv\": 0.9997875395034879, \"accuracy\": 0.9997875448558559, \"f1\": 0.19169321470746586, \"f2\": 0.1290877245273888, \"f0_5\": 0.3722083220707452, \"p4\": 0.32171021208095263, \"phi\": 0.32555260455612633}, {\"truth_threshold\": 30.619999315589666, \"match_probability\": 0.9999999993940152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32152.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271809.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10577672793549173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8942232720645082, \"precision\": 1.0, \"recall\": 0.10577672793549173, \"specificity\": 1.0, \"npv\": 0.9997874847852686, \"accuracy\": 0.9997874901273844, \"f1\": 0.1913166107826832, \"f2\": 0.1288145154311392, \"f0_5\": 0.37164013140100194, \"p4\": 0.32117968263201446, \"phi\": 0.32519878347164977}, {\"truth_threshold\": 30.63999931514263, \"match_probability\": 0.999999999402358, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32117.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1056615815844796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8943384184155204, \"precision\": 1.0, \"recall\": 0.1056615815844796, \"specificity\": 1.0, \"npv\": 0.9997874574261613, \"accuracy\": 0.9997874627631488, \"f1\": 0.19112824998958575, \"f2\": 0.12867789938948412, \"f0_5\": 0.3713557601363461, \"p4\": 0.32091420916721464, \"phi\": 0.3250217285043782}, {\"truth_threshold\": 30.659999314695597, \"match_probability\": 0.9999999994105859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32057.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10546418783988736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8945358121601127, \"precision\": 1.0, \"recall\": 0.10546418783988736, \"specificity\": 1.0, \"npv\": 0.9997874105248378, \"accuracy\": 0.9997874158530304, \"f1\": 0.19080525448041474, \"f2\": 0.12844368263187544, \"f0_5\": 0.3708678379135054, \"p4\": 0.3204587876379198, \"phi\": 0.3247179811213818}, {\"truth_threshold\": 30.679999314248562, \"match_probability\": 0.9999999994187005, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31987.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271974.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10523389513786308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8947661048621369, \"precision\": 1.0, \"recall\": 0.10523389513786308, \"specificity\": 1.0, \"npv\": 0.9997873558066327, \"accuracy\": 0.999787361124559, \"f1\": 0.19042828056723066, \"f2\": 0.12817040128030158, \"f0_5\": 0.37029790997640705, \"p4\": 0.31992694435950225, \"phi\": 0.3243632497079726}, {\"truth_threshold\": 30.699999313801527, \"match_probability\": 0.9999999994267035, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31891.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272070.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10491806514651551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8950819348534845, \"precision\": 1.0, \"recall\": 0.10491806514651551, \"specificity\": 1.0, \"npv\": 0.9997872807645325, \"accuracy\": 0.9997872860683696, \"f1\": 0.1899110322403916, \"f2\": 0.12779556556480343, \"f0_5\": 0.3695150918255026, \"p4\": 0.31919665034443395, \"phi\": 0.3238761291850803}, {\"truth_threshold\": 30.719999313354492, \"match_probability\": 0.9999999994345962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31811.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1046548734870592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8953451265129408, \"precision\": 1.0, \"recall\": 0.1046548734870592, \"specificity\": 1.0, \"npv\": 0.9997872182294577, \"accuracy\": 0.9997872235215451, \"f1\": 0.189479766031712, \"f2\": 0.1274831584051681, \"f0_5\": 0.36886167832005656, \"p4\": 0.3185872674283162, \"phi\": 0.32346963510936033}, {\"truth_threshold\": 30.739999312907457, \"match_probability\": 0.9999999994423803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31771.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272190.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10452327765733103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.895476722342669, \"precision\": 1.0, \"recall\": 0.10452327765733103, \"specificity\": 1.0, \"npv\": 0.9997871869619231, \"accuracy\": 0.999787192248133, \"f1\": 0.18926405585407408, \"f2\": 0.12732693980114057, \"f0_5\": 0.3685346077555708, \"p4\": 0.3182823012397666, \"phi\": 0.3232661964094963}, {\"truth_threshold\": 30.759999312460423, \"match_probability\": 0.9999999994500571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31690.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272271.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10425679610213152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8957432038978684, \"precision\": 1.0, \"recall\": 0.10425679610213152, \"specificity\": 1.0, \"npv\": 0.9997871236451719, \"accuracy\": 0.9997871289194732, \"f1\": 0.18882708527607545, \"f2\": 0.12701056644548364, \"f0_5\": 0.36787154561769686, \"p4\": 0.31766418289485576, \"phi\": 0.3228538404532479}, {\"truth_threshold\": 30.779999312013388, \"match_probability\": 0.9999999994576284, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31610.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272351.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1039936044426752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8960063955573248, \"precision\": 1.0, \"recall\": 0.1039936044426752, \"specificity\": 1.0, \"npv\": 0.9997870611101166, \"accuracy\": 0.9997870663726487, \"f1\": 0.18839530233542232, \"f2\": 0.12669805860576822, \"f0_5\": 0.36721568955462464, \"p4\": 0.3170529562165689, \"phi\": 0.32244605775228546}, {\"truth_threshold\": 30.799999311566353, \"match_probability\": 0.9999999994650954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31546.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10378305111511016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8962169488848898, \"precision\": 1.0, \"recall\": 0.10378305111511016, \"specificity\": 1.0, \"npv\": 0.9997870110820781, \"accuracy\": 0.9997870163351892, \"f1\": 0.188049727725502, \"f2\": 0.12644802347301165, \"f0_5\": 0.36669030210742887, \"p4\": 0.3165634448993314, \"phi\": 0.3221194599451491}, {\"truth_threshold\": 30.819999311119318, \"match_probability\": 0.9999999994724595, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31502.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10363829570240919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8963617042975908, \"precision\": 1.0, \"recall\": 0.10363829570240919, \"specificity\": 1.0, \"npv\": 0.9997869766878045, \"accuracy\": 0.9997869819344357, \"f1\": 0.18781206869311967, \"f2\": 0.12627610943555356, \"f0_5\": 0.3663287353274306, \"p4\": 0.3162266322137517, \"phi\": 0.3218947317515283}, {\"truth_threshold\": 30.839999310672283, \"match_probability\": 0.9999999994797224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31443.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10344419185356016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8965558081464399, \"precision\": 1.0, \"recall\": 0.10344419185356016, \"specificity\": 1.0, \"npv\": 0.9997869305682141, \"accuracy\": 0.9997869358061526, \"f1\": 0.18749329167213272, \"f2\": 0.12604556930361657, \"f0_5\": 0.36584344232348925, \"p4\": 0.31577464662329685, \"phi\": 0.321593145229155}, {\"truth_threshold\": 30.85999931022525, \"match_probability\": 0.9999999994868852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31370.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272591.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10320402946430628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8967959705356937, \"precision\": 1.0, \"recall\": 0.10320402946430628, \"specificity\": 1.0, \"npv\": 0.999786873504998, \"accuracy\": 0.9997868787321754, \"f1\": 0.1870987173867015, \"f2\": 0.12576029454448073, \"f0_5\": 0.3652422567942977, \"p4\": 0.315214853868198, \"phi\": 0.32121960393356513}, {\"truth_threshold\": 30.879999309778214, \"match_probability\": 0.9999999994939494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31312.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272649.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10301321551120045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8969867844887995, \"precision\": 1.0, \"recall\": 0.10301321551120045, \"specificity\": 1.0, \"npv\": 0.9997868281671048, \"accuracy\": 0.9997868333857276, \"f1\": 0.1867850975175454, \"f2\": 0.12553361407875196, \"f0_5\": 0.36476401939381514, \"p4\": 0.31476964771312854, \"phi\": 0.3209225077728851}, {\"truth_threshold\": 30.89999930933118, \"match_probability\": 0.9999999995009163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31208.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10267106635390724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8973289336460928, \"precision\": 1.0, \"recall\": 0.10267106635390724, \"specificity\": 1.0, \"npv\": 0.9997867468715826, \"accuracy\": 0.9997867520748558, \"f1\": 0.18622247284205878, \"f2\": 0.12512709975205524, \"f0_5\": 0.3639051943478555, \"p4\": 0.31397037115975285, \"phi\": 0.32038909380284675}, {\"truth_threshold\": 30.919999308884144, \"match_probability\": 0.9999999995077874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31149.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10247696250505821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8975230374949418, \"precision\": 1.0, \"recall\": 0.10247696250505821, \"specificity\": 1.0, \"npv\": 0.9997867007520135, \"accuracy\": 0.9997867059465728, \"f1\": 0.18590313628360836, \"f2\": 0.12489645090229055, \"f0_5\": 0.36341723504691326, \"p4\": 0.3135163774622458, \"phi\": 0.3200860888042777}, {\"truth_threshold\": 30.93999930843711, \"match_probability\": 0.9999999995145639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31075.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272886.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10223351022006112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8977664897799389, \"precision\": 1.0, \"recall\": 0.10223351022006112, \"specificity\": 1.0, \"npv\": 0.999786642907136, \"accuracy\": 0.9997866480907601, \"f1\": 0.18550245346768707, \"f2\": 0.12460713165811091, \"f0_5\": 0.36280445802909905, \"p4\": 0.3129463896014236, \"phi\": 0.31970564270204443}, {\"truth_threshold\": 30.959999307990074, \"match_probability\": 0.999999999521247, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30989.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272972.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10195057918614558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8980494208138544, \"precision\": 1.0, \"recall\": 0.10195057918614558, \"specificity\": 1.0, \"npv\": 0.9997865756820167, \"accuracy\": 0.9997865808529239, \"f1\": 0.18503657262277953, \"f2\": 0.12427085263222902, \"f0_5\": 0.3620912466669938, \"p4\": 0.3122831701939381, \"phi\": 0.3192629331026619}, {\"truth_threshold\": 30.97999930754304, \"match_probability\": 0.9999999995278381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30918.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10171699658837811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8982830034116219, \"precision\": 1.0, \"recall\": 0.10171699658837811, \"specificity\": 1.0, \"npv\": 0.9997865201822157, \"accuracy\": 0.9997865253426171, \"f1\": 0.18465176974369846, \"f2\": 0.12399319196446475, \"f0_5\": 0.36150156793325117, \"p4\": 0.3117349784978314, \"phi\": 0.31889697719244825}, {\"truth_threshold\": 30.999999307096004, \"match_probability\": 0.9999999995343385, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30873.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273088.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10156895127993394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8984310487200661, \"precision\": 1.0, \"recall\": 0.10156895127993394, \"specificity\": 1.0, \"npv\": 0.9997864850062886, \"accuracy\": 0.9997864901600284, \"f1\": 0.18440779610194902, \"f2\": 0.12381719347694786, \"f0_5\": 0.3611274221961245, \"p4\": 0.3113872281613793, \"phi\": 0.31866481573267563}, {\"truth_threshold\": 31.01999930664897, \"match_probability\": 0.9999999995407494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30795.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273166.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10131233941196403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.898687660588036, \"precision\": 1.0, \"recall\": 0.10131233941196403, \"specificity\": 1.0, \"npv\": 0.9997864240346875, \"accuracy\": 0.9997864291768745, \"f1\": 0.18398475307388068, \"f2\": 0.12351209933268573, \"f0_5\": 0.36047815592509264, \"p4\": 0.3107838997121415, \"phi\": 0.3182620013939397}, {\"truth_threshold\": 31.039999306201935, \"match_probability\": 0.9999999995470721, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30738.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10112481535460141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8988751846453986, \"precision\": 1.0, \"recall\": 0.10112481535460141, \"specificity\": 1.0, \"npv\": 0.9997863794785223, \"accuracy\": 0.9997863846122621, \"f1\": 0.18367548155208113, \"f2\": 0.12328912177458042, \"f0_5\": 0.3600030919648734, \"p4\": 0.3103425551141075, \"phi\": 0.3179673143875185}, {\"truth_threshold\": 31.0599993057549, \"match_probability\": 0.9999999995533077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30667.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273294.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10089123275683394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.899108767243166, \"precision\": 1.0, \"recall\": 0.10089123275683394, \"specificity\": 1.0, \"npv\": 0.999786323978743, \"accuracy\": 0.9997863291019554, \"f1\": 0.1832901012467576, \"f2\": 0.12301134927810504, \"f0_5\": 0.3594106354701626, \"p4\": 0.30979227693193534, \"phi\": 0.31759986574247595}, {\"truth_threshold\": 31.079999305307865, \"match_probability\": 0.9999999995594574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30610.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273351.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10070370869947132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8992962913005287, \"precision\": 1.0, \"recall\": 0.10070370869947132, \"specificity\": 1.0, \"npv\": 0.9997862794225867, \"accuracy\": 0.999786284537343, \"f1\": 0.18298059305797573, \"f2\": 0.12278832592297831, \"f0_5\": 0.3589344302663455, \"p4\": 0.3093500756794691, \"phi\": 0.31730456385734573}, {\"truth_threshold\": 31.09999930486083, \"match_probability\": 0.9999999995655224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30549.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273412.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10050302505913587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8994969749408641, \"precision\": 1.0, \"recall\": 0.10050302505913587, \"specificity\": 1.0, \"npv\": 0.999786231739687, \"accuracy\": 0.9997862368453894, \"f1\": 0.1826492481540163, \"f2\": 0.12254962921004851, \"f0_5\": 0.35842424270867307, \"p4\": 0.30887641928402876, \"phi\": 0.3169882343278892}, {\"truth_threshold\": 31.119999304413795, \"match_probability\": 0.999999999571504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30483.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273478.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10028589194008442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8997141080599156, \"precision\": 1.0, \"recall\": 0.10028589194008442, \"specificity\": 1.0, \"npv\": 0.9997861801483579, \"accuracy\": 0.9997861852442592, \"f1\": 0.18229060769515973, \"f2\": 0.12229134087603012, \"f0_5\": 0.35787157807242664, \"p4\": 0.3083634447716188, \"phi\": 0.3166456202532225}, {\"truth_threshold\": 31.13999930396676, \"match_probability\": 0.9999999995774033, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30418.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10007204871677616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8999279512832238, \"precision\": 1.0, \"recall\": 0.10007204871677616, \"specificity\": 1.0, \"npv\": 0.9997861293387208, \"accuracy\": 0.9997861344249643, \"f1\": 0.18193726280657577, \"f2\": 0.12203693926317259, \"f0_5\": 0.3573266170621169, \"p4\": 0.3078577402112084, \"phi\": 0.31630783461928597}, {\"truth_threshold\": 31.159999303519726, \"match_probability\": 0.9999999995832213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30356.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273605.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09986807518069753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9001319248193025, \"precision\": 1.0, \"recall\": 0.09986807518069753, \"specificity\": 1.0, \"npv\": 0.9997860808741488, \"accuracy\": 0.9997860859511754, \"f1\": 0.18160009811047598, \"f2\": 0.1217942545337827, \"f0_5\": 0.3568061873361778, \"p4\": 0.307374910610507, \"phi\": 0.3159853026476934}, {\"truth_threshold\": 31.17999930307269, \"match_probability\": 0.9999999995889592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30271.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0995884340425252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9004115659574748, \"precision\": 1.0, \"recall\": 0.0995884340425252, \"specificity\": 1.0, \"npv\": 0.9997860144307915, \"accuracy\": 0.9997860194951743, \"f1\": 0.18113765288781444, \"f2\": 0.12146150234930163, \"f0_5\": 0.35609170793680667, \"p4\": 0.30671222732193154, \"phi\": 0.3155425859607226}, {\"truth_threshold\": 31.199999302625656, \"match_probability\": 0.9999999995946182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30207.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09937788071496015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9006221192850399, \"precision\": 1.0, \"recall\": 0.09937788071496015, \"specificity\": 1.0, \"npv\": 0.9997859644028577, \"accuracy\": 0.9997859694577148, \"f1\": 0.1807893035838261, \"f2\": 0.12121092956869342, \"f0_5\": 0.3555529921914174, \"p4\": 0.30621270052043226, \"phi\": 0.3152088360292563}, {\"truth_threshold\": 31.21999930217862, \"match_probability\": 0.9999999996001991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30118.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.099085079993815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.900914920006185, \"precision\": 1.0, \"recall\": 0.099085079993815, \"specificity\": 1.0, \"npv\": 0.9997858948327706, \"accuracy\": 0.9997858998743726, \"f1\": 0.18030465847898253, \"f2\": 0.12086243400681562, \"f0_5\": 0.35480276038856545, \"p4\": 0.3055172374239159, \"phi\": 0.314744126817631}, {\"truth_threshold\": 31.239999301731586, \"match_probability\": 0.9999999996057033, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30018.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09875609041949461, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9012439095805054, \"precision\": 1.0, \"recall\": 0.09875609041949461, \"specificity\": 1.0, \"npv\": 0.999785816664145, \"accuracy\": 0.9997858216908421, \"f1\": 0.17975980525721677, \"f2\": 0.1204708065580297, \"f0_5\": 0.35395830041529786, \"p4\": 0.3047346936858518, \"phi\": 0.31422116178038134}, {\"truth_threshold\": 31.25999930128455, \"match_probability\": 0.9999999996111317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29964.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273997.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09857843604936159, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9014215639506384, \"precision\": 1.0, \"recall\": 0.09857843604936159, \"specificity\": 1.0, \"npv\": 0.9997857744530922, \"accuracy\": 0.9997857794717355, \"f1\": 0.1794654488283297, \"f2\": 0.12025930159382506, \"f0_5\": 0.3535016292409224, \"p4\": 0.3043116243588511, \"phi\": 0.31393839846375216}, {\"truth_threshold\": 31.279999300837517, \"match_probability\": 0.9999999996164853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29865.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274096.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09825273637078441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9017472636292156, \"precision\": 1.0, \"recall\": 0.09825273637078441, \"specificity\": 1.0, \"npv\": 0.9997856970661715, \"accuracy\": 0.9997857020700402, \"f1\": 0.17892554803999688, \"f2\": 0.11987149486758143, \"f0_5\": 0.35266318864676055, \"p4\": 0.3035350926203807, \"phi\": 0.31341933654630094}, {\"truth_threshold\": 31.299999300390482, \"match_probability\": 0.9999999996217653, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29744.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274217.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09785465898585674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9021453410141432, \"precision\": 1.0, \"recall\": 0.09785465898585674, \"specificity\": 1.0, \"npv\": 0.9997856024821734, \"accuracy\": 0.9997856074679683, \"f1\": 0.17826523426379587, \"f2\": 0.11939742515181585, \"f0_5\": 0.3516362957130731, \"p4\": 0.302584405097309, \"phi\": 0.31278375787413004}, {\"truth_threshold\": 31.319999299943447, \"match_probability\": 0.9999999996269726, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29665.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274296.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09759475722214363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9024052427778564, \"precision\": 1.0, \"recall\": 0.09759475722214363, \"specificity\": 1.0, \"npv\": 0.9997855407289943, \"accuracy\": 0.9997855457029791, \"f1\": 0.17783386186927877, \"f2\": 0.11908785885930973, \"f0_5\": 0.3509645758256215, \"p4\": 0.3019627605143712, \"phi\": 0.3123680955565978}, {\"truth_threshold\": 31.339999299496412, \"match_probability\": 0.9999999996321082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29592.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274369.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09735459483288975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9026454051671102, \"precision\": 1.0, \"recall\": 0.09735459483288975, \"specificity\": 1.0, \"npv\": 0.9997854836659368, \"accuracy\": 0.9997854886290017, \"f1\": 0.17743507028867975, \"f2\": 0.11880176901904232, \"f0_5\": 0.3503429790518766, \"p4\": 0.30138766245720733, \"phi\": 0.3119835102727418}, {\"truth_threshold\": 31.359999299049377, \"match_probability\": 0.999999999637173, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29516.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274445.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09710456275640625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9028954372435938, \"precision\": 1.0, \"recall\": 0.09710456275640625, \"specificity\": 1.0, \"npv\": 0.999785424257829, \"accuracy\": 0.9997854292095185, \"f1\": 0.17701970450735732, \"f2\": 0.11850388642641485, \"f0_5\": 0.3496949232865352, \"p4\": 0.30078824835495216, \"phi\": 0.3115826158064416}, {\"truth_threshold\": 31.379999298602343, \"match_probability\": 0.9999999996421682, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29462.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274499.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09692690838627324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9030730916137267, \"precision\": 1.0, \"recall\": 0.09692690838627324, \"specificity\": 1.0, \"npv\": 0.9997853820468094, \"accuracy\": 0.9997853869904121, \"f1\": 0.17672446111995874, \"f2\": 0.11829221091041077, \"f0_5\": 0.34923389496193774, \"p4\": 0.3003619254934662, \"phi\": 0.31129745603134357}, {\"truth_threshold\": 31.399999298155308, \"match_probability\": 0.9999999996470945, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29410.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274551.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09675583380762663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9032441661923734, \"precision\": 1.0, \"recall\": 0.09675583380762663, \"specificity\": 1.0, \"npv\": 0.9997853413991643, \"accuracy\": 0.9997853463349762, \"f1\": 0.17644006227296316, \"f2\": 0.1180883578771881, \"f0_5\": 0.3487894952810833, \"p4\": 0.2999510594826545, \"phi\": 0.3110226106502851}, {\"truth_threshold\": 31.419999297708273, \"match_probability\": 0.9999999996519531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29288.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274673.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09635446652695576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9036455334730442, \"precision\": 1.0, \"recall\": 0.09635446652695576, \"specificity\": 1.0, \"npv\": 0.9997852460335482, \"accuracy\": 0.9997852509510688, \"f1\": 0.17577247043502006, \"f2\": 0.11761002046369382, \"f0_5\": 0.34774514204025997, \"p4\": 0.29898582035528637, \"phi\": 0.31037682584736215}, {\"truth_threshold\": 31.439999297261238, \"match_probability\": 0.9999999996567448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29197.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274764.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0960550860143242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9039449139856758, \"precision\": 1.0, \"recall\": 0.0960550860143242, \"specificity\": 1.0, \"npv\": 0.9997851749001907, \"accuracy\": 0.999785179804056, \"f1\": 0.17527419422616297, \"f2\": 0.1172531667631829, \"f0_5\": 0.3469645798326318, \"p4\": 0.2982646718900638, \"phi\": 0.30989425772492785}, {\"truth_threshold\": 31.459999296814203, \"match_probability\": 0.9999999996614705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29113.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09577873477189508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.904221265228105, \"precision\": 1.0, \"recall\": 0.09577873477189508, \"specificity\": 1.0, \"npv\": 0.999785109238639, \"accuracy\": 0.9997851141298904, \"f1\": 0.17481400529612037, \"f2\": 0.11692371704404249, \"f0_5\": 0.34624286118649994, \"p4\": 0.2975981032250188, \"phi\": 0.30944814235451107}, {\"truth_threshold\": 31.47999929636717, \"match_probability\": 0.9999999996661311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29052.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274909.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09557805113155964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9044219488684404, \"precision\": 1.0, \"recall\": 0.09557805113155964, \"specificity\": 1.0, \"npv\": 0.9997850615558508, \"accuracy\": 0.9997850664379366, \"f1\": 0.1744796749676439, \"f2\": 0.11668444592961982, \"f0_5\": 0.34571803250596783, \"p4\": 0.29711350902164024, \"phi\": 0.3091237741325546}, {\"truth_threshold\": 31.499999295920134, \"match_probability\": 0.9999999996707276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29022.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09547935425926353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9045206457407364, \"precision\": 1.0, \"recall\": 0.09547935425926353, \"specificity\": 1.0, \"npv\": 0.999785038105301, \"accuracy\": 0.9997850429828775, \"f1\": 0.17431520528075006, \"f2\": 0.1165667630090307, \"f0_5\": 0.34545969636875695, \"p4\": 0.29687501760784646, \"phi\": 0.3089641238661332}, {\"truth_threshold\": 31.5199992954731, \"match_probability\": 0.9999999996752608, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28973.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274988.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09531814936784654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9046818506321535, \"precision\": 1.0, \"recall\": 0.09531814936784654, \"specificity\": 1.0, \"npv\": 0.9997849998027385, \"accuracy\": 0.9997850046729475, \"f1\": 0.17404650771624405, \"f2\": 0.11637453537347257, \"f0_5\": 0.3450374297670851, \"p4\": 0.29648524543782, \"phi\": 0.3087031842189676}, {\"truth_threshold\": 31.539999295026064, \"match_probability\": 0.9999999996797315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28926.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275035.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09516352426791595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.904836475732084, \"precision\": 1.0, \"recall\": 0.09516352426791595, \"specificity\": 1.0, \"npv\": 0.9997849630635487, \"accuracy\": 0.9997849679266881, \"f1\": 0.1737887030734153, \"f2\": 0.11619013954385148, \"f0_5\": 0.34463202792703707, \"p4\": 0.2961111067639836, \"phi\": 0.3084526877743092}, {\"truth_threshold\": 31.55999929457903, \"match_probability\": 0.9999999996841408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28789.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275172.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09471280855109701, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.905287191448903, \"precision\": 1.0, \"recall\": 0.09471280855109701, \"specificity\": 1.0, \"npv\": 0.9997848559727343, \"accuracy\": 0.9997848608152513, \"f1\": 0.17303681442524418, \"f2\": 0.11565256585676259, \"f0_5\": 0.3434482495341396, \"p4\": 0.29501898998701925, \"phi\": 0.30772135391622024}, {\"truth_threshold\": 31.579999294131994, \"match_probability\": 0.9999999996884893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28689.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275272.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09438381897677663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9056161810232234, \"precision\": 1.0, \"recall\": 0.09438381897677663, \"specificity\": 1.0, \"npv\": 0.9997847778042711, \"accuracy\": 0.9997847826317207, \"f1\": 0.17248759957913723, \"f2\": 0.11526010158027147, \"f0_5\": 0.34258222140491074, \"p4\": 0.2942203712103495, \"phi\": 0.30718643440753557}, {\"truth_threshold\": 31.59999929368496, \"match_probability\": 0.999999999692778, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28612.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09413049700454992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9058695029954501, \"precision\": 1.0, \"recall\": 0.09413049700454992, \"specificity\": 1.0, \"npv\": 0.9997847176145628, \"accuracy\": 0.9997847224304022, \"f1\": 0.17206447907677414, \"f2\": 0.11495786110557545, \"f0_5\": 0.3419142513664859, \"p4\": 0.293604597024089, \"phi\": 0.30677391083110767}, {\"truth_threshold\": 31.619999293237925, \"match_probability\": 0.9999999996970076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28546.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09391336388549847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9060866361145016, \"precision\": 1.0, \"recall\": 0.09391336388549847, \"specificity\": 1.0, \"npv\": 0.99978466602339, \"accuracy\": 0.999784670829272, \"f1\": 0.17170164838634977, \"f2\": 0.11469876807110312, \"f0_5\": 0.3413409224072989, \"p4\": 0.2930762093714111, \"phi\": 0.3064198772067442}, {\"truth_threshold\": 31.63999929279089, \"match_probability\": 0.9999999997011789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28467.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275494.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09365346212178537, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9063465378782146, \"precision\": 1.0, \"recall\": 0.09365346212178537, \"specificity\": 1.0, \"npv\": 0.9997846042703266, \"accuracy\": 0.9997846090642828, \"f1\": 0.1712671616109353, \"f2\": 0.11438860542099202, \"f0_5\": 0.34065371240387815, \"p4\": 0.2924430387387581, \"phi\": 0.30599557115418385}, {\"truth_threshold\": 31.659999292343855, \"match_probability\": 0.999999999705293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28400.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275561.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0934330391069907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9065669608930093, \"precision\": 1.0, \"recall\": 0.0934330391069907, \"specificity\": 1.0, \"npv\": 0.9997845518974813, \"accuracy\": 0.9997845566813174, \"f1\": 0.17089851095646, \"f2\": 0.11412552521852627, \"f0_5\": 0.34007007359403774, \"p4\": 0.29190544151562053, \"phi\": 0.30563525506067285}, {\"truth_threshold\": 31.67999929189682, \"match_probability\": 0.9999999997093503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28340.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275621.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09323564536239846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9067643546376015, \"precision\": 1.0, \"recall\": 0.09323564536239846, \"specificity\": 1.0, \"npv\": 0.9997845049964305, \"accuracy\": 0.999784509771199, \"f1\": 0.17056824986984692, \"f2\": 0.1138899069590993, \"f0_5\": 0.3395467757433726, \"p4\": 0.29142353959553885, \"phi\": 0.3053122230548071}, {\"truth_threshold\": 31.699999291449785, \"match_probability\": 0.9999999997133517, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28274.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275687.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.093018512243347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.906981487756653, \"precision\": 1.0, \"recall\": 0.093018512243347, \"specificity\": 1.0, \"npv\": 0.9997844534052795, \"accuracy\": 0.9997844581700688, \"f1\": 0.17020482489803904, \"f2\": 0.11363070062486035, \"f0_5\": 0.33897045248011665, \"p4\": 0.2908929320733159, \"phi\": 0.3049564926670475}, {\"truth_threshold\": 31.71999929100275, \"match_probability\": 0.9999999997172981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28172.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275789.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09268294287754021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9073170571224598, \"precision\": 1.0, \"recall\": 0.09268294287754021, \"specificity\": 1.0, \"npv\": 0.9997843736735115, \"accuracy\": 0.9997843784228676, \"f1\": 0.1696428840253754, \"f2\": 0.1132300549189078, \"f0_5\": 0.3380783345213837, \"p4\": 0.29007183833885797, \"phi\": 0.3044059099213407}, {\"truth_threshold\": 31.739999290555716, \"match_probability\": 0.9999999997211901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28076.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09236711288619263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9076328871138074, \"precision\": 1.0, \"recall\": 0.09236711288619263, \"specificity\": 1.0, \"npv\": 0.9997842986318589, \"accuracy\": 0.9997843033666783, \"f1\": 0.1691136831136289, \"f2\": 0.11285291658627565, \"f0_5\": 0.33723709656108486, \"p4\": 0.289297861673089, \"phi\": 0.3038868032237857}, {\"truth_threshold\": 31.75999929010868, \"match_probability\": 0.9999999997250286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28037.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09223880695220768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9077611930477923, \"precision\": 1.0, \"recall\": 0.09223880695220768, \"specificity\": 1.0, \"npv\": 0.9997842681461908, \"accuracy\": 0.9997842728751014, \"f1\": 0.1688986078229387, \"f2\": 0.11269968751030042, \"f0_5\": 0.3368949001343398, \"p4\": 0.2889831054959999, \"phi\": 0.30367566267877105}, {\"truth_threshold\": 31.779999289661646, \"match_probability\": 0.9999999997288141, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27964.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275997.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0919986445629538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9080013554370462, \"precision\": 1.0, \"recall\": 0.0919986445629538, \"specificity\": 1.0, \"npv\": 0.9997842110832786, \"accuracy\": 0.9997842158011241, \"f1\": 0.1684958951570385, \"f2\": 0.11241284828526589, \"f0_5\": 0.3362536885216333, \"p4\": 0.2883934360846654, \"phi\": 0.30328005584789736}, {\"truth_threshold\": 31.79999928921461, \"match_probability\": 0.9999999997325477, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27901.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276060.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09179138113113196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9082086188688681, \"precision\": 1.0, \"recall\": 0.09179138113113196, \"specificity\": 1.0, \"npv\": 0.999784161837209, \"accuracy\": 0.9997841665454997, \"f1\": 0.16814820618208773, \"f2\": 0.11216527503628156, \"f0_5\": 0.335699589715207, \"p4\": 0.2878840076955253, \"phi\": 0.30293822645560686}, {\"truth_threshold\": 31.819999288767576, \"match_probability\": 0.9999999997362298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27831.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276130.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09156108842910768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9084389115708923, \"precision\": 1.0, \"recall\": 0.09156108842910768, \"specificity\": 1.0, \"npv\": 0.9997841071193594, \"accuracy\": 0.9997841118170284, \"f1\": 0.16776173024063268, \"f2\": 0.1118901642310089, \"f0_5\": 0.33508313567790793, \"p4\": 0.28731739322968486, \"phi\": 0.30255796311115685}, {\"truth_threshold\": 31.83999928832054, \"match_probability\": 0.9999999997398612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27743.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276218.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09127157760370574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9087284223962943, \"precision\": 1.0, \"recall\": 0.09127157760370574, \"specificity\": 1.0, \"npv\": 0.9997840383312142, \"accuracy\": 0.9997840430155215, \"f1\": 0.16727564334466874, \"f2\": 0.11154426670590799, \"f0_5\": 0.33430698450111224, \"p4\": 0.28660420584621177, \"phi\": 0.3020792386800088}, {\"truth_threshold\": 31.859999287873507, \"match_probability\": 0.9999999997434426, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27674.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276287.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09104457479742467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9089554252025753, \"precision\": 1.0, \"recall\": 0.09104457479742467, \"specificity\": 1.0, \"npv\": 0.9997839843950616, \"accuracy\": 0.9997839890688854, \"f1\": 0.16689432659399642, \"f2\": 0.11127301735881588, \"f0_5\": 0.3336974897324777, \"p4\": 0.28604432146386416, \"phi\": 0.30170334394653875}, {\"truth_threshold\": 31.87999928742647, \"match_probability\": 0.9999999997469747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27566.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09068926605715864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9093107339428413, \"precision\": 1.0, \"recall\": 0.09068926605715864, \"specificity\": 1.0, \"npv\": 0.999783899973269, \"accuracy\": 0.9997839046306723, \"f1\": 0.16629716433352337, \"f2\": 0.11084839272645386, \"f0_5\": 0.3327418673426278, \"p4\": 0.2851667771616013, \"phi\": 0.3011140450134126}, {\"truth_threshold\": 31.899999286979437, \"match_probability\": 0.9999999997504582, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27503.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276458.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0904820026253368, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9095179973746632, \"precision\": 1.0, \"recall\": 0.0904820026253368, \"specificity\": 1.0, \"npv\": 0.99978385072723, \"accuracy\": 0.9997838553750481, \"f1\": 0.1659486399729684, \"f2\": 0.11060066095788224, \"f0_5\": 0.33218349989008944, \"p4\": 0.2846541967944088, \"phi\": 0.3007697541413873}, {\"truth_threshold\": 31.919999286532402, \"match_probability\": 0.9999999997538936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27399.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276562.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0901398534680436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9098601465319563, \"precision\": 1.0, \"recall\": 0.0901398534680436, \"specificity\": 1.0, \"npv\": 0.999783769432192, \"accuracy\": 0.9997837740641763, \"f1\": 0.16537300820859488, \"f2\": 0.11019165199401887, \"f0_5\": 0.33126026158425564, \"p4\": 0.2838069345236609, \"phi\": 0.300200537102028}, {\"truth_threshold\": 31.939999286085367, \"match_probability\": 0.9999999997572819, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27291.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08978454472777758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9102154552722225, \"precision\": 1.0, \"recall\": 0.08978454472777758, \"specificity\": 1.0, \"npv\": 0.9997836850104358, \"accuracy\": 0.9997836896259633, \"f1\": 0.16477485418955962, \"f2\": 0.10976683948243755, \"f0_5\": 0.3302995461422088, \"p4\": 0.28292563486009986, \"phi\": 0.2996082825706288}, {\"truth_threshold\": 31.959999285638332, \"match_probability\": 0.9999999997606235, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27220.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276741.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0895509621300101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9104490378699899, \"precision\": 1.0, \"recall\": 0.0895509621300101, \"specificity\": 1.0, \"npv\": 0.9997836295109557, \"accuracy\": 0.9997836341156566, \"f1\": 0.1643814107693376, \"f2\": 0.1094875243752534, \"f0_5\": 0.3296668693274166, \"p4\": 0.2823454550893139, \"phi\": 0.29921829146049816}, {\"truth_threshold\": 31.979999285191298, \"match_probability\": 0.9999999997639191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27170.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276791.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0893864673428499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9106135326571501, \"precision\": 1.0, \"recall\": 0.0893864673428499, \"specificity\": 1.0, \"npv\": 0.9997835904268184, \"accuracy\": 0.9997835950238912, \"f1\": 0.16410423669182286, \"f2\": 0.10929080444789842, \"f0_5\": 0.32922079967817064, \"p4\": 0.28193649301093215, \"phi\": 0.29894334455813537}, {\"truth_threshold\": 31.999999284744263, \"match_probability\": 0.9999999997671692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27088.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08911669589190718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9108833041080928, \"precision\": 1.0, \"recall\": 0.08911669589190718, \"specificity\": 1.0, \"npv\": 0.99978352632884, \"accuracy\": 0.9997835309133962, \"f1\": 0.16364948995465928, \"f2\": 0.10896814950455858, \"f0_5\": 0.32848830863931044, \"p4\": 0.28126510571653685, \"phi\": 0.29849188342999516}, {\"truth_threshold\": 32.01999928429723, \"match_probability\": 0.9999999997703747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26998.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08882060527501884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9111793947249812, \"precision\": 1.0, \"recall\": 0.08882060527501884, \"specificity\": 1.0, \"npv\": 0.9997834559774097, \"accuracy\": 0.9997834605482188, \"f1\": 0.16315011829259818, \"f2\": 0.1086139670207476, \"f0_5\": 0.32768301238248054, \"p4\": 0.2805272294447906, \"phi\": 0.2979955900745239}, {\"truth_threshold\": 32.03999928385019, \"match_probability\": 0.999999999773536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26905.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277056.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08851464497090088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9114853550290991, \"precision\": 1.0, \"recall\": 0.08851464497090088, \"specificity\": 1.0, \"npv\": 0.9997833832809422, \"accuracy\": 0.9997833878375353, \"f1\": 0.16263381550234837, \"f2\": 0.10824792456079224, \"f0_5\": 0.32684939295059784, \"p4\": 0.27976366907136424, \"phi\": 0.297481883849956}, {\"truth_threshold\": 32.05999928340316, \"match_probability\": 0.9999999997766538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26825.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08825145331144456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9117485466885554, \"precision\": 1.0, \"recall\": 0.08825145331144456, \"specificity\": 1.0, \"npv\": 0.9997833207463549, \"accuracy\": 0.9997833252907108, \"f1\": 0.16218945179058364, \"f2\": 0.10793300549060128, \"f0_5\": 0.32613109436586496, \"p4\": 0.2791059561724034, \"phi\": 0.29703927526912655}, {\"truth_threshold\": 32.07999928295612, \"match_probability\": 0.9999999997797286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26783.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08811327769023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.91188672230977, \"precision\": 1.0, \"recall\": 0.08811327769023, \"specificity\": 1.0, \"npv\": 0.9997832879156997, \"accuracy\": 0.999783292453628, \"f1\": 0.16195607478896065, \"f2\": 0.10776765674655388, \"f0_5\": 0.3257535399532466, \"p4\": 0.27876032803898065, \"phi\": 0.2968066415668073}, {\"truth_threshold\": 32.09999928250909, \"match_probability\": 0.9999999997827612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26705.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277256.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0878566658222601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.91214333417774, \"precision\": 1.0, \"recall\": 0.0878566658222601, \"specificity\": 1.0, \"npv\": 0.9997832269444886, \"accuracy\": 0.9997832314704741, \"f1\": 0.16152250306956265, \"f2\": 0.10746055085151572, \"f0_5\": 0.3250515481485268, \"p4\": 0.27811784555068175, \"phi\": 0.2963741231355443}, {\"truth_threshold\": 32.119999282062054, \"match_probability\": 0.999999999785752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26634.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277327.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08762308322449261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9123769167755074, \"precision\": 1.0, \"recall\": 0.08762308322449261, \"specificity\": 1.0, \"npv\": 0.9997831714450593, \"accuracy\": 0.9997831759601674, \"f1\": 0.16112766375777007, \"f2\": 0.10718097221842157, \"f0_5\": 0.3244116278559892, \"p4\": 0.2775323407045703, \"phi\": 0.2959798710013531}, {\"truth_threshold\": 32.13999928161502, \"match_probability\": 0.9999999997887016, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26557.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277404.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08736976125226592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9126302387477341, \"precision\": 1.0, \"recall\": 0.08736976125226592, \"specificity\": 1.0, \"npv\": 0.9997831112555444, \"accuracy\": 0.9997831157588489, \"f1\": 0.1606992660006414, \"f2\": 0.10687773110292087, \"f0_5\": 0.3237166281884692, \"p4\": 0.2768966216404637, \"phi\": 0.2955517073786659}, {\"truth_threshold\": 32.159999281167984, \"match_probability\": 0.9999999997916106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26501.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277460.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0871855270906465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9128144729093535, \"precision\": 1.0, \"recall\": 0.0871855270906465, \"specificity\": 1.0, \"npv\": 0.9997830674813564, \"accuracy\": 0.9997830719760717, \"f1\": 0.1603875786020783, \"f2\": 0.10665716849989335, \"f0_5\": 0.32321051797104633, \"p4\": 0.2764337994100615, \"phi\": 0.2952399256785326}, {\"truth_threshold\": 32.17999928072095, \"match_probability\": 0.9999999997944796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26443.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08699471313754067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9130052868624593, \"precision\": 1.0, \"recall\": 0.08699471313754067, \"specificity\": 1.0, \"npv\": 0.9997830221438084, \"accuracy\": 0.999783026629624, \"f1\": 0.16006464812774665, \"f2\": 0.10642870769797962, \"f0_5\": 0.32268574901216157, \"p4\": 0.27595402008310155, \"phi\": 0.29491666146758155}, {\"truth_threshold\": 32.199999280273914, \"match_probability\": 0.999999999797309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26407.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277554.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08687627689078534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9131237231092146, \"precision\": 1.0, \"recall\": 0.08687627689078534, \"specificity\": 1.0, \"npv\": 0.9997829940032635, \"accuracy\": 0.999782998483553, \"f1\": 0.1598641514916699, \"f2\": 0.10628689371149631, \"f0_5\": 0.32235973134044127, \"p4\": 0.27565600684956204, \"phi\": 0.2947158363877413}, {\"truth_threshold\": 32.21999927982688, \"match_probability\": 0.9999999998000996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26343.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277618.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08666572356322028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9133342764367797, \"precision\": 1.0, \"recall\": 0.08666572356322028, \"specificity\": 1.0, \"npv\": 0.999782943975632, \"accuracy\": 0.9997829484460935, \"f1\": 0.15950760511528775, \"f2\": 0.10603475966179005, \"f0_5\": 0.321779577996399, \"p4\": 0.27512579052931746, \"phi\": 0.29435847574991736}, {\"truth_threshold\": 32.239999279379845, \"match_probability\": 0.9999999998028516, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26264.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08640582179950718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9135941782004928, \"precision\": 1.0, \"recall\": 0.08640582179950718, \"specificity\": 1.0, \"npv\": 0.9997828822227812, \"accuracy\": 0.9997828866811043, \"f1\": 0.15906730259671437, \"f2\": 0.10572349586348369, \"f0_5\": 0.32106244972702846, \"p4\": 0.2744705711627466, \"phi\": 0.29391675957580116}, {\"truth_threshold\": 32.25999927893281, \"match_probability\": 0.9999999998055659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26169.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0860932817039028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9139067182960972, \"precision\": 1.0, \"recall\": 0.0860932817039028, \"specificity\": 1.0, \"npv\": 0.9997828079630342, \"accuracy\": 0.9997828124067503, \"f1\": 0.1585375458152849, \"f2\": 0.10534913885764481, \"f0_5\": 0.3201986114815839, \"p4\": 0.2736815737226445, \"phi\": 0.2933847012519236}, {\"truth_threshold\": 32.279999278485775, \"match_probability\": 0.9999999998082427, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26123.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08594194649971543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9140580535002846, \"precision\": 1.0, \"recall\": 0.08594194649971543, \"specificity\": 1.0, \"npv\": 0.9997827720056869, \"accuracy\": 0.9997827764423262, \"f1\": 0.15828092243186584, \"f2\": 0.10516785067558156, \"f0_5\": 0.3197797543413808, \"p4\": 0.27329911015898867, \"phi\": 0.29312672601291395}, {\"truth_threshold\": 32.29999927803874, \"match_probability\": 0.9999999998108826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26044.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08568204473600231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9143179552639977, \"precision\": 1.0, \"recall\": 0.08568204473600231, \"specificity\": 1.0, \"npv\": 0.9997827102528574, \"accuracy\": 0.999782714677337, \"f1\": 0.15784003272677688, \"f2\": 0.10485647659048158, \"f0_5\": 0.3190595314808508, \"p4\": 0.2726416258869777, \"phi\": 0.2926831510459168}, {\"truth_threshold\": 32.319999277591705, \"match_probability\": 0.9999999998134863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25970.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277991.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08543859245100523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9145614075489947, \"precision\": 1.0, \"recall\": 0.08543859245100523, \"specificity\": 1.0, \"npv\": 0.9997826524084418, \"accuracy\": 0.9997826568215245, \"f1\": 0.1574268559183587, \"f2\": 0.10456477379059988, \"f0_5\": 0.31838387999244805, \"p4\": 0.2720250142493057, \"phi\": 0.2922670398432055}, {\"truth_threshold\": 32.33999927714467, \"match_probability\": 0.999999999816054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25905.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278056.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08522474922769697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.914775250772303, \"precision\": 1.0, \"recall\": 0.08522474922769697, \"specificity\": 1.0, \"npv\": 0.9997826015991633, \"accuracy\": 0.9997826060022296, \"f1\": 0.15706377741264635, \"f2\": 0.10430851967668184, \"f0_5\": 0.3177895927435283, \"p4\": 0.27148280414886866, \"phi\": 0.2919010474518774}, {\"truth_threshold\": 32.359999276697636, \"match_probability\": 0.9999999998185866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25833.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278128.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0849878767341863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9150121232658137, \"precision\": 1.0, \"recall\": 0.0849878767341863, \"specificity\": 1.0, \"npv\": 0.9997825453181224, \"accuracy\": 0.9997825497100875, \"f1\": 0.156661431075156, \"f2\": 0.10402463764731086, \"f0_5\": 0.31713041962420174, \"p4\": 0.27088155505178824, \"phi\": 0.2914951041140959}, {\"truth_threshold\": 32.3799992762506, \"match_probability\": 0.9999999998210841, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25745.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278216.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08469836590878435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9153016340912157, \"precision\": 1.0, \"recall\": 0.08469836590878435, \"specificity\": 1.0, \"npv\": 0.9997824765301921, \"accuracy\": 0.9997824809085807, \"f1\": 0.15616943580037973, \"f2\": 0.10367762600989539, \"f0_5\": 0.3163234965265235, \"p4\": 0.27014576967294784, \"phi\": 0.2909981821701723}, {\"truth_threshold\": 32.399999275803566, \"match_probability\": 0.9999999998235473, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25656.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278305.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0844055651876392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9155944348123608, \"precision\": 1.0, \"recall\": 0.0844055651876392, \"specificity\": 1.0, \"npv\": 0.9997824069605904, \"accuracy\": 0.9997824113252384, \"f1\": 0.15567158247299137, \"f2\": 0.1033266210229561, \"f0_5\": 0.31550598275883274, \"p4\": 0.26940058574132064, \"phi\": 0.29049474887537463}, {\"truth_threshold\": 32.41999927535653, \"match_probability\": 0.9999999998259765, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25587.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278374.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08417856238135814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9158214376186419, \"precision\": 1.0, \"recall\": 0.08417856238135814, \"specificity\": 1.0, \"npv\": 0.9997823530246137, \"accuracy\": 0.9997823573786023, \"f1\": 0.1552854212436428, \"f2\": 0.10305445892683524, \"f0_5\": 0.3148711940911966, \"p4\": 0.26882213957053475, \"phi\": 0.29010384549651086}, {\"truth_threshold\": 32.439999274909496, \"match_probability\": 0.9999999998283724, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25556.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278405.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08407657561331881, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9159234243866812, \"precision\": 1.0, \"recall\": 0.08407657561331881, \"specificity\": 1.0, \"npv\": 0.9997823287925102, \"accuracy\": 0.9997823331417078, \"f1\": 0.15511187586679898, \"f2\": 0.10293217335266634, \"f0_5\": 0.31458571833031745, \"p4\": 0.26856205311813836, \"phi\": 0.2899280506670292}, {\"truth_threshold\": 32.45999927446246, \"match_probability\": 0.9999999998307353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25466.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08378048499643047, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9162195150035696, \"precision\": 1.0, \"recall\": 0.08378048499643047, \"specificity\": 1.0, \"npv\": 0.9997822584412485, \"accuracy\": 0.9997822627765304, \"f1\": 0.15460784938696584, \"f2\": 0.1025771161112051, \"f0_5\": 0.313755929279862, \"p4\": 0.2678062427580782, \"phi\": 0.28941707362046626}, {\"truth_threshold\": 32.47999927401543, \"match_probability\": 0.9999999998330655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25429.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278532.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08365875885393192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9163412411460681, \"precision\": 1.0, \"recall\": 0.08365875885393192, \"specificity\": 1.0, \"npv\": 0.9997822295190659, \"accuracy\": 0.999782233848624, \"f1\": 0.15440055860833662, \"f2\": 0.10243113319954596, \"f0_5\": 0.3134143666020011, \"p4\": 0.2674952093712187, \"phi\": 0.2892067434306848}, {\"truth_threshold\": 32.49999927356839, \"match_probability\": 0.9999999998353638, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25324.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278637.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08331331980089551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9166866801991045, \"precision\": 1.0, \"recall\": 0.08331331980089551, \"specificity\": 1.0, \"npv\": 0.9997821474426112, \"accuracy\": 0.9997821517559169, \"f1\": 0.15381204731463627, \"f2\": 0.10201680997254199, \"f0_5\": 0.31244370856024695, \"p4\": 0.26661155732902037, \"phi\": 0.28860902581366427}, {\"truth_threshold\": 32.51999927312136, \"match_probability\": 0.9999999998376304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25239.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08303367866272318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9169663213372768, \"precision\": 1.0, \"recall\": 0.08303367866272318, \"specificity\": 1.0, \"npv\": 0.9997820809997767, \"accuracy\": 0.999782085299916, \"f1\": 0.15333535844471446, \"f2\": 0.10168135410766242, \"f0_5\": 0.3116564629294399, \"p4\": 0.265895145998995, \"phi\": 0.28812425105583206}, {\"truth_threshold\": 32.53999927267432, \"match_probability\": 0.9999999998398658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25195.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278766.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0828889232500222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9171110767499778, \"precision\": 1.0, \"recall\": 0.0828889232500222, \"specificity\": 1.0, \"npv\": 0.9997820466058422, \"accuracy\": 0.9997820508991625, \"f1\": 0.15308850514649588, \"f2\": 0.10150768831599974, \"f0_5\": 0.3112484280070465, \"p4\": 0.26552391963329997, \"phi\": 0.28787298818725904}, {\"truth_threshold\": 32.55999927222729, \"match_probability\": 0.9999999998420704, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25102.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278859.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08258296294590424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9174170370540957, \"precision\": 1.0, \"recall\": 0.08258296294590424, \"specificity\": 1.0, \"npv\": 0.9997819739095797, \"accuracy\": 0.999781978188479, \"f1\": 0.15256652981344, \"f2\": 0.10114058145962838, \"f0_5\": 0.31038482178406357, \"p4\": 0.2647384317630499, \"phi\": 0.2873411869282888}, {\"truth_threshold\": 32.57999927178025, \"match_probability\": 0.9999999998442447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24967.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278994.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08213882702057172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9178611729794283, \"precision\": 1.0, \"recall\": 0.08213882702057172, \"specificity\": 1.0, \"npv\": 0.9997818683827657, \"accuracy\": 0.9997818726407127, \"f1\": 0.15180829847261407, \"f2\": 0.10060758648980385, \"f0_5\": 0.3091283686907082, \"p4\": 0.2635961487768332, \"phi\": 0.2865674614212088}, {\"truth_threshold\": 32.59999927133322, \"match_probability\": 0.999999999846389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24895.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279066.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08190195452706103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9180980454729389, \"precision\": 1.0, \"recall\": 0.08190195452706103, \"specificity\": 1.0, \"npv\": 0.9997818121018074, \"accuracy\": 0.9997818163485708, \"f1\": 0.1514036538789014, \"f2\": 0.10032327508041579, \"f0_5\": 0.3084568854218035, \"p4\": 0.2629859319905578, \"phi\": 0.2861539524657049}, {\"truth_threshold\": 32.61999927088618, \"match_probability\": 0.9999999998485037, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24810.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279151.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0816223133888887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9183776866111113, \"precision\": 1.0, \"recall\": 0.0816223133888887, \"specificity\": 1.0, \"npv\": 0.9997817456590175, \"accuracy\": 0.9997817498925697, \"f1\": 0.1509257203342144, \"f2\": 0.09998758719191653, \"f0_5\": 0.3076629274232951, \"p4\": 0.2622646404268354, \"phi\": 0.2856650117964581}, {\"truth_threshold\": 32.63999927043915, \"match_probability\": 0.9999999998505895, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24723.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279238.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08133609245922997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.91866390754077, \"precision\": 1.0, \"recall\": 0.08133609245922997, \"specificity\": 1.0, \"npv\": 0.999781677652877, \"accuracy\": 0.9997816818728982, \"f1\": 0.15043628530746858, \"f2\": 0.09964395312788427, \"f0_5\": 0.30684890021918665, \"p4\": 0.2615253698113246, \"phi\": 0.28516369855333695}, {\"truth_threshold\": 32.65999926999211, \"match_probability\": 0.9999999998526464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24655.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279306.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0811123795486921, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9188876204513079, \"precision\": 1.0, \"recall\": 0.0811123795486921, \"specificity\": 1.0, \"npv\": 0.9997816244986586, \"accuracy\": 0.9997816287080974, \"f1\": 0.15005355795213868, \"f2\": 0.09937533202364532, \"f0_5\": 0.30621166920445825, \"p4\": 0.26094683811864794, \"phi\": 0.284771253099998}, {\"truth_threshold\": 32.67999926954508, \"match_probability\": 0.9999999998546751, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24589.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279372.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08089524642964065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9191047535703594, \"precision\": 1.0, \"recall\": 0.08089524642964065, \"specificity\": 1.0, \"npv\": 0.999781572907805, \"accuracy\": 0.9997815771069672, \"f1\": 0.14968193577842034, \"f2\": 0.09911458337532136, \"f0_5\": 0.3055923562762697, \"p4\": 0.26038472443971467, \"phi\": 0.2843898323009995}, {\"truth_threshold\": 32.69999926909804, \"match_probability\": 0.9999999998566759, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24522.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279439.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08067482341484598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.919325176585154, \"precision\": 1.0, \"recall\": 0.08067482341484598, \"specificity\": 1.0, \"npv\": 0.9997815205352772, \"accuracy\": 0.9997815247240017, \"f1\": 0.14930453021921986, \"f2\": 0.09884985560713531, \"f0_5\": 0.30496282791401047, \"p4\": 0.2598134907732644, \"phi\": 0.28400210848268315}, {\"truth_threshold\": 32.71999926865101, \"match_probability\": 0.9999999998586491, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24471.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279490.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08050703873194258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9194929612680575, \"precision\": 1.0, \"recall\": 0.08050703873194258, \"specificity\": 1.0, \"npv\": 0.9997814806696256, \"accuracy\": 0.9997814848504011, \"f1\": 0.14901714814634384, \"f2\": 0.09864832723945127, \"f0_5\": 0.3044830718311787, \"p4\": 0.2593782632110759, \"phi\": 0.28370662027479804}, {\"truth_threshold\": 32.739999268203974, \"match_probability\": 0.9999999998605951, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24405.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279556.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08028990561289112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9197100943871088, \"precision\": 1.0, \"recall\": 0.08028990561289112, \"specificity\": 1.0, \"npv\": 0.9997814290787869, \"accuracy\": 0.9997814332492709, \"f1\": 0.14864510942058556, \"f2\": 0.09838750121951317, \"f0_5\": 0.3038614874707718, \"p4\": 0.25881450337194845, \"phi\": 0.28332376634207235}, {\"truth_threshold\": 32.75999926775694, \"match_probability\": 0.9999999998625143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24350.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08010896134701491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.919891038652985, \"precision\": 1.0, \"recall\": 0.08010896134701491, \"specificity\": 1.0, \"npv\": 0.9997813860864253, \"accuracy\": 0.9997813902483291, \"f1\": 0.14833496288580036, \"f2\": 0.09817012499657311, \"f0_5\": 0.3033428758648698, \"p4\": 0.25834425114536697, \"phi\": 0.28300432578577744}, {\"truth_threshold\": 32.779999267309904, \"match_probability\": 0.9999999998644071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24276.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279685.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07986550906201782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9201344909379822, \"precision\": 1.0, \"recall\": 0.07986550906201782, \"specificity\": 1.0, \"npv\": 0.9997813282421629, \"accuracy\": 0.9997813323925165, \"f1\": 0.14791751082297241, \"f2\": 0.09787762474599232, \"f0_5\": 0.3026442097914303, \"p4\": 0.25771089827135785, \"phi\": 0.2825739632923753}, {\"truth_threshold\": 32.79999926686287, \"match_probability\": 0.9999999998662739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24207.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07963850625573675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9203614937442632, \"precision\": 1.0, \"recall\": 0.07963850625573675, \"specificity\": 1.0, \"npv\": 0.9997812743063026, \"accuracy\": 0.9997812784458804, \"f1\": 0.14752809536578826, \"f2\": 0.09760485657444734, \"f0_5\": 0.30199182113281553, \"p4\": 0.25711966671934106, \"phi\": 0.2821720880388614}, {\"truth_threshold\": 32.819999266415834, \"match_probability\": 0.9999999998681149, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24117.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0793424156388484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9206575843611516, \"precision\": 1.0, \"recall\": 0.0793424156388484, \"specificity\": 1.0, \"npv\": 0.9997812039551892, \"accuracy\": 0.9997812080807029, \"f1\": 0.14701991599558642, \"f2\": 0.09724902638066843, \"f0_5\": 0.30113952785637405, \"p4\": 0.2563475175757097, \"phi\": 0.28164704122735057}, {\"truth_threshold\": 32.8399992659688, \"match_probability\": 0.9999999998699306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24069.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07918450064317462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9208154993568254, \"precision\": 1.0, \"recall\": 0.07918450064317462, \"specificity\": 1.0, \"npv\": 0.9997811664345995, \"accuracy\": 0.9997811705526082, \"f1\": 0.14674877297808128, \"f2\": 0.09705922915559398, \"f0_5\": 0.3006843445258684, \"p4\": 0.25593525144902013, \"phi\": 0.28136661567530435}, {\"truth_threshold\": 32.859999265521765, \"match_probability\": 0.9999999998717213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24018.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07901671596027122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9209832840397287, \"precision\": 1.0, \"recall\": 0.07901671596027122, \"specificity\": 1.0, \"npv\": 0.999781126568976, \"accuracy\": 0.9997811306790076, \"f1\": 0.1464605965625848, \"f2\": 0.09685755350192199, \"f0_5\": 0.3002002334807378, \"p4\": 0.2554968726883873, \"phi\": 0.2810683569890797}, {\"truth_threshold\": 32.87999926507473, \"match_probability\": 0.9999999998734873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23963.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.078835771694395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.921164228305605, \"precision\": 1.0, \"recall\": 0.078835771694395, \"specificity\": 1.0, \"npv\": 0.9997810835766405, \"accuracy\": 0.9997810876780658, \"f1\": 0.14614971761749673, \"f2\": 0.09664004155485491, \"f0_5\": 0.2996775992776623, \"p4\": 0.255023711266841, \"phi\": 0.28074635037560663}, {\"truth_threshold\": 32.899999264627695, \"match_probability\": 0.999999999875229, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23922.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280039.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07870088596892365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9212991140310763, \"precision\": 1.0, \"recall\": 0.07870088596892365, \"specificity\": 1.0, \"npv\": 0.9997810515278109, \"accuracy\": 0.9997810556228183, \"f1\": 0.14591790364245782, \"f2\": 0.09647788372967157, \"f0_5\": 0.2992876248908417, \"p4\": 0.2546707205571635, \"phi\": 0.280506068615602}, {\"truth_threshold\": 32.91999926418066, \"match_probability\": 0.9999999998769469, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23850.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280111.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07846401347541296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.921535986524587, \"precision\": 1.0, \"recall\": 0.07846401347541296, \"specificity\": 1.0, \"npv\": 0.9997809952469445, \"accuracy\": 0.9997809993306762, \"f1\": 0.14551067535866705, \"f2\": 0.09619309281161319, \"f0_5\": 0.29860201672171294, \"p4\": 0.2540502747930986, \"phi\": 0.28008361159396317}, {\"truth_threshold\": 32.939999263733625, \"match_probability\": 0.999999999878641, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23807.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280154.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0783225479584552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9216774520415448, \"precision\": 1.0, \"recall\": 0.0783225479584552, \"specificity\": 1.0, \"npv\": 0.9997809616347635, \"accuracy\": 0.9997809657117581, \"f1\": 0.1452673842473945, \"f2\": 0.09602299356835109, \"f0_5\": 0.29819208445122486, \"p4\": 0.25367939022615055, \"phi\": 0.27983100670867267}, {\"truth_threshold\": 32.95999926328659, \"match_probability\": 0.9999999998803117, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23758.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280203.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0781613430670382, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9218386569329617, \"precision\": 1.0, \"recall\": 0.0781613430670382, \"specificity\": 1.0, \"npv\": 0.9997809233325134, \"accuracy\": 0.9997809274018281, \"f1\": 0.14499006771044706, \"f2\": 0.09582914516110816, \"f0_5\": 0.297724521482833, \"p4\": 0.25325644344498754, \"phi\": 0.27954287639013947}, {\"truth_threshold\": 32.979999262839556, \"match_probability\": 0.9999999998819595, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23668.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280293.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07786525245014986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9221347475498501, \"precision\": 1.0, \"recall\": 0.07786525245014986, \"specificity\": 1.0, \"npv\": 0.9997808529814495, \"accuracy\": 0.9997808570366506, \"f1\": 0.1444804947059021, \"f2\": 0.09547305713861584, \"f0_5\": 0.2968645345468137, \"p4\": 0.25247873845130653, \"phi\": 0.27901288234098925}, {\"truth_threshold\": 32.99999926239252, \"match_probability\": 0.9999999998835846, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23588.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280373.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07760206079069354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9223979392093065, \"precision\": 1.0, \"recall\": 0.07760206079069354, \"specificity\": 1.0, \"npv\": 0.9997807904471787, \"accuracy\": 0.9997807944898262, \"f1\": 0.14402730583821047, \"f2\": 0.09515649103783023, \"f0_5\": 0.29609879667497674, \"p4\": 0.25178650423192434, \"phi\": 0.27854092998633}, {\"truth_threshold\": 33.019999261945486, \"match_probability\": 0.9999999998851874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23544.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280417.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07745730537799257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9225426946220074, \"precision\": 1.0, \"recall\": 0.07745730537799257, \"specificity\": 1.0, \"npv\": 0.999780756053333, \"accuracy\": 0.9997807600890727, \"f1\": 0.14377795758843376, \"f2\": 0.09498236226266513, \"f0_5\": 0.295677116168555, \"p4\": 0.2514053973006912, \"phi\": 0.27828101504174396}, {\"truth_threshold\": 33.03999926149845, \"match_probability\": 0.999999999886768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23477.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280484.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07723688236319791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9227631176368021, \"precision\": 1.0, \"recall\": 0.07723688236319791, \"specificity\": 1.0, \"npv\": 0.999780703680891, \"accuracy\": 0.9997807077061073, \"f1\": 0.14339813949511052, \"f2\": 0.09471718787949207, \"f0_5\": 0.2950342952077191, \"p4\": 0.25082455919638197, \"phi\": 0.2778847685627915}, {\"truth_threshold\": 33.059999261051416, \"match_probability\": 0.9999999998883269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23403.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280558.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07699343007820082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9230065699217992, \"precision\": 1.0, \"recall\": 0.07699343007820082, \"specificity\": 1.0, \"npv\": 0.9997806458367074, \"accuracy\": 0.9997806498502946, \"f1\": 0.14297845822998254, \"f2\": 0.09442427538658556, \"f0_5\": 0.29432330666317885, \"p4\": 0.25018231123805446, \"phi\": 0.2774464655546489}, {\"truth_threshold\": 33.07999926060438, \"match_probability\": 0.9999999998898643, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23341.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280620.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07678945654212219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9232105434578778, \"precision\": 1.0, \"recall\": 0.07678945654212219, \"specificity\": 1.0, \"npv\": 0.9997805973726671, \"accuracy\": 0.9997806013765056, \"f1\": 0.14262668727963776, \"f2\": 0.09417883528286737, \"f0_5\": 0.29372679796136664, \"p4\": 0.24964362452749164, \"phi\": 0.2770787049442908}, {\"truth_threshold\": 33.09999926015735, \"match_probability\": 0.9999999998913806, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23242.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.076463756863545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.923536243136455, \"precision\": 1.0, \"recall\": 0.076463756863545, \"specificity\": 1.0, \"npv\": 0.9997805199865477, \"accuracy\": 0.9997805239748104, \"f1\": 0.14206471212061014, \"f2\": 0.09378687193624978, \"f0_5\": 0.29277276288706544, \"p4\": 0.24878235165846255, \"phi\": 0.2764904602281243}, {\"truth_threshold\": 33.11999925971031, \"match_probability\": 0.999999999892876, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23165.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280796.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07621043489131829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9237895651086817, \"precision\": 1.0, \"recall\": 0.07621043489131829, \"specificity\": 1.0, \"npv\": 0.9997804597973521, \"accuracy\": 0.9997804637734918, \"f1\": 0.1416273851665719, \"f2\": 0.0934819682504324, \"f0_5\": 0.2920294185128876, \"p4\": 0.2481115256277591, \"phi\": 0.2760320699429658}, {\"truth_threshold\": 33.13999925926328, \"match_probability\": 0.9999999998943508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23099.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07599330177226683, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9240066982277332, \"precision\": 1.0, \"recall\": 0.07599330177226683, \"specificity\": 1.0, \"npv\": 0.9997804082066187, \"accuracy\": 0.9997804121723617, \"f1\": 0.14125236959579282, \"f2\": 0.09322059206920738, \"f0_5\": 0.29139134668997896, \"p4\": 0.24753587099389818, \"phi\": 0.2756385572935066}, {\"truth_threshold\": 33.15999925881624, \"match_probability\": 0.9999999998958053, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23067.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07588802510848432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9241119748915156, \"precision\": 1.0, \"recall\": 0.07588802510848432, \"specificity\": 1.0, \"npv\": 0.9997803831929317, \"accuracy\": 0.9997803871536319, \"f1\": 0.1410704893770564, \"f2\": 0.09309385419937348, \"f0_5\": 0.29108167246718436, \"p4\": 0.24725654581039183, \"phi\": 0.2754475609307791}, {\"truth_threshold\": 33.17999925836921, \"match_probability\": 0.9999999998972398, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23000.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07566760209368965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9243323979063104, \"precision\": 1.0, \"recall\": 0.07566760209368965, \"specificity\": 1.0, \"npv\": 0.9997803308205286, \"accuracy\": 0.9997803347706664, \"f1\": 0.140689562363707, \"f2\": 0.09282847557884609, \"f0_5\": 0.2904326436189423, \"p4\": 0.24667124296259177, \"phi\": 0.27504723276852866}, {\"truth_threshold\": 33.19999925792217, \"match_probability\": 0.9999999998986545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22946.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281015.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07548994772355665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9245100522764433, \"precision\": 1.0, \"recall\": 0.07548994772355665, \"specificity\": 1.0, \"npv\": 0.9997802886099391, \"accuracy\": 0.9997802925515599, \"f1\": 0.14038243292434852, \"f2\": 0.09261456744080918, \"f0_5\": 0.2899089059874414, \"p4\": 0.2461990469806463, \"phi\": 0.27472415569477443}, {\"truth_threshold\": 33.21999925747514, \"match_probability\": 0.9999999999000497, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22911.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281050.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0753748013725445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9246251986274555, \"precision\": 1.0, \"recall\": 0.0753748013725445, \"specificity\": 1.0, \"npv\": 0.9997802612512255, \"accuracy\": 0.9997802651873242, \"f1\": 0.14018331334589687, \"f2\": 0.09247591331619247, \"f0_5\": 0.2895691409360347, \"p4\": 0.24589277476121651, \"phi\": 0.2745145508128882}, {\"truth_threshold\": 33.2399992570281, \"match_probability\": 0.9999999999014259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22859.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0752037267938979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9247962732061021, \"precision\": 1.0, \"recall\": 0.0752037267938979, \"specificity\": 1.0, \"npv\": 0.9997802206039968, \"accuracy\": 0.9997802245318883, \"f1\": 0.1398873997919344, \"f2\": 0.09226989843408791, \"f0_5\": 0.28906390286218664, \"p4\": 0.24543742293869655, \"phi\": 0.2742028420061432}, {\"truth_threshold\": 33.25999925658107, \"match_probability\": 0.9999999999027829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22806.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281155.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07502936231950809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9249706376804919, \"precision\": 1.0, \"recall\": 0.07502936231950809, \"specificity\": 1.0, \"npv\": 0.999780179175094, \"accuracy\": 0.9997801830946171, \"f1\": 0.1395856986782631, \"f2\": 0.09205990392766318, \"f0_5\": 0.2885484013816314, \"p4\": 0.24497292173689272, \"phi\": 0.27388477377026793}, {\"truth_threshold\": 33.27999925613403, \"match_probability\": 0.9999999999041214, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22759.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281202.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0748747372195775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9251252627804225, \"precision\": 1.0, \"recall\": 0.0748747372195775, \"specificity\": 1.0, \"npv\": 0.9997801424362585, \"accuracy\": 0.9997801463483578, \"f1\": 0.13931807051909892, \"f2\": 0.09187366734942512, \"f0_5\": 0.2880907956262959, \"p4\": 0.24456067358327158, \"phi\": 0.2736024039409497}, {\"truth_threshold\": 33.299999255687, \"match_probability\": 0.9999999999054413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22708.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281253.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07470695253667411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9252930474633259, \"precision\": 1.0, \"recall\": 0.07470695253667411, \"specificity\": 1.0, \"npv\": 0.9997801025707166, \"accuracy\": 0.9997801064747571, \"f1\": 0.13902757837444019, \"f2\": 0.09167156485961026, \"f0_5\": 0.28759375166226353, \"p4\": 0.24411298700721792, \"phi\": 0.273295672614591}, {\"truth_threshold\": 33.31999925523996, \"match_probability\": 0.9999999999067432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22637.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281324.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07447336993890663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9255266300610934, \"precision\": 1.0, \"recall\": 0.07447336993890663, \"specificity\": 1.0, \"npv\": 0.9997800470716343, \"accuracy\": 0.9997800509644504, \"f1\": 0.1386230166749337, \"f2\": 0.09139017877545154, \"f0_5\": 0.2869009325516021, \"p4\": 0.24348912363073733, \"phi\": 0.2728680804035227}, {\"truth_threshold\": 33.33999925479293, \"match_probability\": 0.999999999908027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22524.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281437.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07410161171992459, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9258983882800754, \"precision\": 1.0, \"recall\": 0.07410161171992459, \"specificity\": 1.0, \"npv\": 0.9997799587421214, \"accuracy\": 0.9997799626170608, \"f1\": 0.13797877390998056, \"f2\": 0.0909422724101398, \"f0_5\": 0.2857962172985127, \"p4\": 0.24249473904284455, \"phi\": 0.27218616112519556}, {\"truth_threshold\": 33.359999254345894, \"match_probability\": 0.9999999999092932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22477.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281484.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.073946986619994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.926053013380006, \"precision\": 1.0, \"recall\": 0.073946986619994, \"specificity\": 1.0, \"npv\": 0.9997799220033021, \"accuracy\": 0.9997799258708014, \"f1\": 0.13771068319252047, \"f2\": 0.09075595100139625, \"f0_5\": 0.28533598734604654, \"p4\": 0.24208061088527408, \"phi\": 0.2719020274203869}, {\"truth_threshold\": 33.37999925389886, \"match_probability\": 0.999999999910542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22423.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281538.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.073769332249861, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.926230667750139, \"precision\": 1.0, \"recall\": 0.073769332249861, \"specificity\": 1.0, \"npv\": 0.9997798797927472, \"accuracy\": 0.999779883651695, \"f1\": 0.13740256875337026, \"f2\": 0.09054186213474154, \"f0_5\": 0.2848066698335844, \"p4\": 0.2416044156914787, \"phi\": 0.2715752089737891}, {\"truth_threshold\": 33.399999253451824, \"match_probability\": 0.9999999999117737, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22352.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281609.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07353574965209353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9264642503479065, \"precision\": 1.0, \"recall\": 0.07353574965209353, \"specificity\": 1.0, \"npv\": 0.9997798242936895, \"accuracy\": 0.9997798281413883, \"f1\": 0.13699730013821085, \"f2\": 0.0902603465041076, \"f0_5\": 0.2841098307187399, \"p4\": 0.2409776743361081, \"phi\": 0.2711449038180043}, {\"truth_threshold\": 33.41999925300479, \"match_probability\": 0.9999999999129883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22280.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281681.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07329887715858284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9267011228414171, \"precision\": 1.0, \"recall\": 0.07329887715858284, \"specificity\": 1.0, \"npv\": 0.9997797680129613, \"accuracy\": 0.9997797718492463, \"f1\": 0.13658614337253747, \"f2\": 0.08997483289234358, \"f0_5\": 0.2834021486665598, \"p4\": 0.24034137027871347, \"phi\": 0.27070783956364936}, {\"truth_threshold\": 33.439999252557755, \"match_probability\": 0.9999999999141862, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22226.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281735.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07312122278844983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9268787772115502, \"precision\": 1.0, \"recall\": 0.07312122278844983, \"specificity\": 1.0, \"npv\": 0.9997797258024193, \"accuracy\": 0.9997797296301397, \"f1\": 0.13627765668159675, \"f2\": 0.08976067589070084, \"f0_5\": 0.2828707062222392, \"p4\": 0.2398636555067073, \"phi\": 0.2703795777601814}, {\"truth_threshold\": 33.45999925211072, \"match_probability\": 0.9999999999153676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22138.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281823.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07283171196304788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9271682880369521, \"precision\": 1.0, \"recall\": 0.07283171196304788, \"specificity\": 1.0, \"npv\": 0.9997796570148769, \"accuracy\": 0.9997796608286329, \"f1\": 0.1357747187203886, \"f2\": 0.08941163926454504, \"f0_5\": 0.2820033986135491, \"p4\": 0.2390842618999027, \"phi\": 0.2698437770381639}, {\"truth_threshold\": 33.479999251663685, \"match_probability\": 0.9999999999165328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22076.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07262773842696925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9273722615730308, \"precision\": 1.0, \"recall\": 0.07262773842696925, \"specificity\": 1.0, \"npv\": 0.9997796085509324, \"accuracy\": 0.9997796123548439, \"f1\": 0.1354202130433049, \"f2\": 0.08916569729869459, \"f0_5\": 0.2813914063197073, \"p4\": 0.23853447613969983, \"phi\": 0.26946564139877804}, {\"truth_threshold\": 33.49999925121665, \"match_probability\": 0.9999999999176818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21977.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281984.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07230203874839207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.927697961251608, \"precision\": 1.0, \"recall\": 0.07230203874839207, \"specificity\": 1.0, \"npv\": 0.9997795311649661, \"accuracy\": 0.9997795349531486, \"f1\": 0.13485386791352957, \"f2\": 0.08877293243530365, \"f0_5\": 0.28041258685938414, \"p4\": 0.23765544604248942, \"phi\": 0.26886074165288365}, {\"truth_threshold\": 33.519999250769615, \"match_probability\": 0.9999999999188152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21944.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282017.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07219347218886633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9278065278111337, \"precision\": 1.0, \"recall\": 0.07219347218886633, \"specificity\": 1.0, \"npv\": 0.9997795053696467, \"accuracy\": 0.9997795091525835, \"f1\": 0.13466500974210277, \"f2\": 0.0886419968524497, \"f0_5\": 0.28008587394093487, \"p4\": 0.2373621222196493, \"phi\": 0.2686588057665375}, {\"truth_threshold\": 33.53999925032258, \"match_probability\": 0.9999999999199329, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21848.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282113.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07187764219751876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9281223578024812, \"precision\": 1.0, \"recall\": 0.07187764219751876, \"specificity\": 1.0, \"npv\": 0.9997794303287251, \"accuracy\": 0.9997794340963942, \"f1\": 0.13411538662222344, \"f2\": 0.08826105363854658, \"f0_5\": 0.2791341832054437, \"p4\": 0.23650792280324442, \"phi\": 0.2680704910459323}, {\"truth_threshold\": 33.559999249875546, \"match_probability\": 0.9999999999210352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21802.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282159.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07172630699333138, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9282736930066686, \"precision\": 1.0, \"recall\": 0.07172630699333138, \"specificity\": 1.0, \"npv\": 0.9997793943716207, \"accuracy\": 0.9997793981319701, \"f1\": 0.13385191074492805, \"f2\": 0.08807849740555862, \"f0_5\": 0.2786775025628309, \"p4\": 0.23609814683342686, \"phi\": 0.26778813223573933}, {\"truth_threshold\": 33.57999924942851, \"match_probability\": 0.9999999999221223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21733.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282228.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0714993041870503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9285006958129497, \"precision\": 1.0, \"recall\": 0.0714993041870503, \"specificity\": 1.0, \"npv\": 0.999779340435969, \"accuracy\": 0.999779344185334, \"f1\": 0.13345655738208256, \"f2\": 0.08780463761042748, \"f0_5\": 0.27799167547129267, \"p4\": 0.23548290841441089, \"phi\": 0.26736403494441785}, {\"truth_threshold\": 33.599999248981476, \"match_probability\": 0.9999999999231944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21643.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07120321357016196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.928796786429838, \"precision\": 1.0, \"recall\": 0.07120321357016196, \"specificity\": 1.0, \"npv\": 0.9997792700851279, \"accuracy\": 0.9997792738201565, \"f1\": 0.13294062726502132, \"f2\": 0.0874473832856426, \"f0_5\": 0.27709566157021304, \"p4\": 0.23467938580230613, \"phi\": 0.26680985156266623}, {\"truth_threshold\": 33.61999924853444, \"match_probability\": 0.9999999999242519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21557.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282404.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07092028253624642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9290797174637536, \"precision\": 1.0, \"recall\": 0.07092028253624642, \"specificity\": 1.0, \"npv\": 0.999779202861, \"accuracy\": 0.9997792065823202, \"f1\": 0.1324473608218286, \"f2\": 0.08710595837565996, \"f0_5\": 0.2762379257231752, \"p4\": 0.2339104755008646, \"phi\": 0.2662792210082592}, {\"truth_threshold\": 33.639999248087406, \"match_probability\": 0.9999999999252948, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21509.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282452.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07076236754057263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9292376324594274, \"precision\": 1.0, \"recall\": 0.07076236754057263, \"specificity\": 1.0, \"npv\": 0.9997791653405604, \"accuracy\": 0.9997791690542256, \"f1\": 0.132171935969521, \"f2\": 0.08691537499808058, \"f0_5\": 0.27575853147588314, \"p4\": 0.2334808480512896, \"phi\": 0.26598259483890235}, {\"truth_threshold\": 33.65999924764037, \"match_probability\": 0.9999999999263233, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21473.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282488.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0706439312938173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9293560687061827, \"precision\": 1.0, \"recall\": 0.0706439312938173, \"specificity\": 1.0, \"npv\": 0.9997791372002327, \"accuracy\": 0.9997791409081546, \"f1\": 0.13196531401144318, \"f2\": 0.08677242776103457, \"f0_5\": 0.2753986759111768, \"p4\": 0.23315840703000987, \"phi\": 0.265759907957098}, {\"truth_threshold\": 33.67999924719334, \"match_probability\": 0.9999999999273376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21437.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07052549504706196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.929474504952938, \"precision\": 1.0, \"recall\": 0.07052549504706196, \"specificity\": 1.0, \"npv\": 0.9997791090599064, \"accuracy\": 0.9997791127620835, \"f1\": 0.1317586463346425, \"f2\": 0.08662947220558628, \"f0_5\": 0.27503855440854585, \"p4\": 0.23283577688050155, \"phi\": 0.26553703433638115}, {\"truth_threshold\": 33.6999992467463, \"match_probability\": 0.9999999999283379, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21387.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07036100025990176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9296389997400982, \"precision\": 1.0, \"recall\": 0.07036100025990176, \"specificity\": 1.0, \"npv\": 0.9997790699761226, \"accuracy\": 0.9997790736703183, \"f1\": 0.1314715320210974, \"f2\": 0.0864309090218399, \"f0_5\": 0.2745379439242739, \"p4\": 0.23238736538426433, \"phi\": 0.26522717696803677}, {\"truth_threshold\": 33.71999924629927, \"match_probability\": 0.9999999999293245, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21340.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282621.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07020637515997118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9297936248400288, \"precision\": 1.0, \"recall\": 0.07020637515997118, \"specificity\": 1.0, \"npv\": 0.9997790332373687, \"accuracy\": 0.9997790369240589, \"f1\": 0.13120156408987368, \"f2\": 0.08624424499508561, \"f0_5\": 0.274066901091901, \"p4\": 0.23196552523333241, \"phi\": 0.2649355806314735}, {\"truth_threshold\": 33.73999924585223, \"match_probability\": 0.9999999999302975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21270.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282691.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06997608245794691, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.930023917542053, \"precision\": 1.0, \"recall\": 0.06997608245794691, \"specificity\": 1.0, \"npv\": 0.9997789785200805, \"accuracy\": 0.9997789821955875, \"f1\": 0.1307993395463532, \"f2\": 0.08596620844966592, \"f0_5\": 0.27336450399829326, \"p4\": 0.23133665301673914, \"phi\": 0.26450069232545137}, {\"truth_threshold\": 33.7599992454052, \"match_probability\": 0.9999999999312571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21157.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06960432423896487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9303956757610351, \"precision\": 1.0, \"recall\": 0.06960432423896487, \"specificity\": 1.0, \"npv\": 0.9997788901907566, \"accuracy\": 0.999778893848198, \"f1\": 0.13014966873565906, \"f2\": 0.08551731162707225, \"f0_5\": 0.27222849849069325, \"p4\": 0.23031995667306276, \"phi\": 0.26379714562540263}, {\"truth_threshold\": 33.77999924495816, \"match_probability\": 0.9999999999322036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21090.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282871.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06938390122417021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9306160987758298, \"precision\": 1.0, \"recall\": 0.06938390122417021, \"specificity\": 1.0, \"npv\": 0.9997788378185098, \"accuracy\": 0.9997788414652324, \"f1\": 0.12976425237885747, \"f2\": 0.08525111283221255, \"f0_5\": 0.2715536888296023, \"p4\": 0.22971625024870604, \"phi\": 0.2633791110342944}, {\"truth_threshold\": 33.79999924451113, \"match_probability\": 0.9999999999331369, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21030.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282931.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06918650747957797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.930813492520422, \"precision\": 1.0, \"recall\": 0.06918650747957797, \"specificity\": 1.0, \"npv\": 0.9997787909179952, \"accuracy\": 0.9997787945551141, \"f1\": 0.12941896852528223, \"f2\": 0.08501270137459434, \"f0_5\": 0.27094859062927584, \"p4\": 0.22917505642420682, \"phi\": 0.2630041877913188}, {\"truth_threshold\": 33.81999924406409, \"match_probability\": 0.9999999999340574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20977.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282984.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06901214300518817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9309878569948118, \"precision\": 1.0, \"recall\": 0.06901214300518817, \"specificity\": 1.0, \"npv\": 0.9997787494892107, \"accuracy\": 0.9997787531178429, \"f1\": 0.12911386172131298, \"f2\": 0.08480208534622229, \"f0_5\": 0.2704134643397642, \"p4\": 0.22869656014588735, \"phi\": 0.26267256048795357}, {\"truth_threshold\": 33.83999924361706, \"match_probability\": 0.9999999999349652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20938.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283023.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06888383707120321, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9311161629287967, \"precision\": 1.0, \"recall\": 0.06888383707120321, \"specificity\": 1.0, \"npv\": 0.9997787190038812, \"accuracy\": 0.999778722626266, \"f1\": 0.128889285593369, \"f2\": 0.08464709221188536, \"f0_5\": 0.27001931841336246, \"p4\": 0.228344194140131, \"phi\": 0.26242826522141166}, {\"truth_threshold\": 33.85999924317002, \"match_probability\": 0.9999999999358606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20900.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06875882103296146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9312411789670385, \"precision\": 1.0, \"recall\": 0.06875882103296146, \"specificity\": 1.0, \"npv\": 0.9997786893002283, \"accuracy\": 0.9997786929165243, \"f1\": 0.12867041596251935, \"f2\": 0.08449606385800133, \"f0_5\": 0.26963497359125405, \"p4\": 0.22800064684768, \"phi\": 0.2621900150085109}, {\"truth_threshold\": 33.87999924272299, \"match_probability\": 0.9999999999367437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20843.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06857129697559884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9314287030244012, \"precision\": 1.0, \"recall\": 0.06857129697559884, \"specificity\": 1.0, \"npv\": 0.9997786447447524, \"accuracy\": 0.9997786483519119, \"f1\": 0.12834201549242005, \"f2\": 0.08426950392459855, \"f0_5\": 0.2690578907554998, \"p4\": 0.22748492515130214, \"phi\": 0.2618322332308498}, {\"truth_threshold\": 33.89999924227595, \"match_probability\": 0.9999999999376146, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20805.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06844628093735709, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.931553719062643, \"precision\": 1.0, \"recall\": 0.06844628093735709, \"specificity\": 1.0, \"npv\": 0.9997786150411041, \"accuracy\": 0.9997786186421703, \"f1\": 0.1281230178035878, \"f2\": 0.0841184523660311, \"f0_5\": 0.26867279127849764, \"p4\": 0.22714084322426162, \"phi\": 0.2615934402087812}, {\"truth_threshold\": 33.91999924182892, \"match_probability\": 0.9999999999384734, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20710.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06813374084175272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9318662591582473, \"precision\": 1.0, \"recall\": 0.06813374084175272, \"specificity\": 1.0, \"npv\": 0.9997785407819909, \"accuracy\": 0.9997785443678163, \"f1\": 0.12757529930298672, \"f2\": 0.08374078285299308, \"f0_5\": 0.2677087184366121, \"p4\": 0.22627970082924337, \"phi\": 0.2609955018707906}, {\"truth_threshold\": 33.939999241381884, \"match_probability\": 0.9999999999393204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20662.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283299.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06797582584607893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.932024174153921, \"precision\": 1.0, \"recall\": 0.06797582584607893, \"specificity\": 1.0, \"npv\": 0.999778503261601, \"accuracy\": 0.9997785068397216, \"f1\": 0.12729843541585162, \"f2\": 0.08354993829386999, \"f0_5\": 0.26722088725301274, \"p4\": 0.2258440872058794, \"phi\": 0.2606928641569693}, {\"truth_threshold\": 33.95999924093485, \"match_probability\": 0.9999999999401559, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20619.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283342.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06783436032912117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9321656396708788, \"precision\": 1.0, \"recall\": 0.06783436032912117, \"specificity\": 1.0, \"npv\": 0.9997784696495875, \"accuracy\": 0.9997784732208035, \"f1\": 0.12705034198040543, \"f2\": 0.08337896079381267, \"f0_5\": 0.2667834601759148, \"p4\": 0.2254535587638184, \"phi\": 0.26042145257161026}, {\"truth_threshold\": 33.979999240487814, \"match_probability\": 0.9999999999409798, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20548.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06760077773135369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9323992222686464, \"precision\": 1.0, \"recall\": 0.06760077773135369, \"specificity\": 1.0, \"npv\": 0.9997784141506865, \"accuracy\": 0.9997784177104967, \"f1\": 0.12664055542373248, \"f2\": 0.08309662307747058, \"f0_5\": 0.266060343956929, \"p4\": 0.224808129508336, \"phi\": 0.2599726877108552}, {\"truth_threshold\": 33.99999924004078, \"match_probability\": 0.9999999999417923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20482.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283479.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06738364461230223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9326163553876977, \"precision\": 1.0, \"recall\": 0.06738364461230223, \"specificity\": 1.0, \"npv\": 0.9997783625601642, \"accuracy\": 0.9997783661093665, \"f1\": 0.126259466223651, \"f2\": 0.08283413921570848, \"f0_5\": 0.26538719683639594, \"p4\": 0.2242074781463436, \"phi\": 0.2595548301878113}, {\"truth_threshold\": 34.019999239593744, \"match_probability\": 0.9999999999425937, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20386.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06706781462095467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9329321853790453, \"precision\": 1.0, \"recall\": 0.06706781462095467, \"specificity\": 1.0, \"npv\": 0.999778287519414, \"accuracy\": 0.9997782910531772, \"f1\": 0.1257048778006271, \"f2\": 0.08245229447594703, \"f0_5\": 0.2644064279321928, \"p4\": 0.22333264045541112, \"phi\": 0.25894583381357494}, {\"truth_threshold\": 34.03999923914671, \"match_probability\": 0.999999999943384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20291.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0667552745253503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9332447254746498, \"precision\": 1.0, \"recall\": 0.0667552745253503, \"specificity\": 1.0, \"npv\": 0.9997782132603495, \"accuracy\": 0.9997782167788232, \"f1\": 0.12515574306403662, \"f2\": 0.08207436889983699, \"f0_5\": 0.2634339500162285, \"p4\": 0.22246555590155284, \"phi\": 0.25834176799476083}, {\"truth_threshold\": 34.059999238699675, \"match_probability\": 0.9999999999441634, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20223.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06653156161481243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9334684383851876, \"precision\": 1.0, \"recall\": 0.06653156161481243, \"specificity\": 1.0, \"npv\": 0.9997781601064996, \"accuracy\": 0.9997781636140224, \"f1\": 0.12476248056659181, \"f2\": 0.08180381807782264, \"f0_5\": 0.26273668127830624, \"p4\": 0.22184407351879853, \"phi\": 0.2579085152922822}, {\"truth_threshold\": 34.07999923825264, \"match_probability\": 0.9999999999449322, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20179.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06638680620211146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9336131937978885, \"precision\": 1.0, \"recall\": 0.06638680620211146, \"specificity\": 1.0, \"npv\": 0.999778125712835, \"accuracy\": 0.9997781292132689, \"f1\": 0.12450792867279571, \"f2\": 0.08162873991827013, \"f0_5\": 0.2622849819458923, \"p4\": 0.22144156714582058, \"phi\": 0.25762778708207734}, {\"truth_threshold\": 34.099999237805605, \"match_probability\": 0.9999999999456903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20103.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283858.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06613677412562796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9338632258743721, \"precision\": 1.0, \"recall\": 0.06613677412562796, \"specificity\": 1.0, \"npv\": 0.9997780663056016, \"accuracy\": 0.9997780697937857, \"f1\": 0.1240680853164807, \"f2\": 0.08132630282690115, \"f0_5\": 0.2615037996945675, \"p4\": 0.22074564174211114, \"phi\": 0.25714217107858967}, {\"truth_threshold\": 34.11999923735857, \"match_probability\": 0.999999999946438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20026.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06588345215340126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9341165478465987, \"precision\": 1.0, \"recall\": 0.06588345215340126, \"specificity\": 1.0, \"npv\": 0.9997780061167014, \"accuracy\": 0.9997780095924671, \"f1\": 0.12362224410238683, \"f2\": 0.08101984836592846, \"f0_5\": 0.26071107755197687, \"p4\": 0.2200396703747153, \"phi\": 0.2566492283838247}, {\"truth_threshold\": 34.139999236911535, \"match_probability\": 0.9999999999471754, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19952.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284009.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06563999986840417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9343600001315958, \"precision\": 1.0, \"recall\": 0.06563999986840417, \"specificity\": 1.0, \"npv\": 0.9997779482728301, \"accuracy\": 0.9997779517366545, \"f1\": 0.12319357358303001, \"f2\": 0.08072529770285711, \"f0_5\": 0.259948041660478, \"p4\": 0.2193603595633676, \"phi\": 0.256174597478091}, {\"truth_threshold\": 34.1599992364645, \"match_probability\": 0.9999999999479027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19900.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06546892528975756, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9345310747102424, \"precision\": 1.0, \"recall\": 0.06546892528975756, \"specificity\": 1.0, \"npv\": 0.9997779076257894, \"accuracy\": 0.9997779110812186, \"f1\": 0.12289222845603515, \"f2\": 0.08051829505140223, \"f0_5\": 0.2594111497258585, \"p4\": 0.21888250981983842, \"phi\": 0.25584054631880176}, {\"truth_threshold\": 34.179999236017466, \"match_probability\": 0.9999999999486199, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19815.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284146.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06518928415158523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9348107158484148, \"precision\": 1.0, \"recall\": 0.06518928415158523, \"specificity\": 1.0, \"npv\": 0.9997778411835184, \"accuracy\": 0.9997778446252177, \"f1\": 0.12239943664755881, \"f2\": 0.08017988781694627, \"f0_5\": 0.25853228293856545, \"p4\": 0.2181005258343608, \"phi\": 0.25529355999979875}, {\"truth_threshold\": 34.19999923557043, \"match_probability\": 0.9999999999493273, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19749.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06497215103253377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9350278489674663, \"precision\": 1.0, \"recall\": 0.06497215103253377, \"specificity\": 1.0, \"npv\": 0.9997777895930553, \"accuracy\": 0.9997777930240874, \"f1\": 0.12201661981403107, \"f2\": 0.07991709244063377, \"f0_5\": 0.2578487924231702, \"p4\": 0.21749258093481771, \"phi\": 0.25486803162502114}, {\"truth_threshold\": 34.219999235123396, \"match_probability\": 0.9999999999500249, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19701.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06481423603686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.93518576396314, \"precision\": 1.0, \"recall\": 0.06481423603686, \"specificity\": 1.0, \"npv\": 0.9997777520727219, \"accuracy\": 0.9997777554959928, \"f1\": 0.12173810950930292, \"f2\": 0.07972595089616323, \"f0_5\": 0.25735111622013507, \"p4\": 0.2170500226787065, \"phi\": 0.2545581096866542}, {\"truth_threshold\": 34.23999923467636, \"match_probability\": 0.9999999999507129, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19640.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06461355239652455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9353864476034754, \"precision\": 1.0, \"recall\": 0.06461355239652455, \"specificity\": 1.0, \"npv\": 0.9997777043906355, \"accuracy\": 0.9997777078040392, \"f1\": 0.1213840501110936, \"f2\": 0.0794830204195279, \"f0_5\": 0.2567179318259651, \"p4\": 0.21648709806219796, \"phi\": 0.25416370529153326}, {\"truth_threshold\": 34.259999234229326, \"match_probability\": 0.9999999999513914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19601.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284360.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0644852464625396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9355147535374604, \"precision\": 1.0, \"recall\": 0.0644852464625396, \"specificity\": 1.0, \"npv\": 0.9997776739053695, \"accuracy\": 0.9997776773124623, \"f1\": 0.12115761430575903, \"f2\": 0.07932769164147331, \"f0_5\": 0.256312685522995, \"p4\": 0.21612689778970365, \"phi\": 0.2539112240715883}, {\"truth_threshold\": 34.27999923378229, \"match_probability\": 0.9999999999520607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19523.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284438.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06422863459456969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9357713654054303, \"precision\": 1.0, \"recall\": 0.06422863459456969, \"specificity\": 1.0, \"npv\": 0.9997776129348432, \"accuracy\": 0.9997776163293084, \"f1\": 0.12070457889725612, \"f2\": 0.07901700466339152, \"f0_5\": 0.2555012000952747, \"p4\": 0.2154057997204448, \"phi\": 0.25340550699821657}, {\"truth_threshold\": 34.29999923333526, \"match_probability\": 0.9999999999527207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19441.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284520.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06395886314362698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.936041136856373, \"precision\": 1.0, \"recall\": 0.06395886314362698, \"specificity\": 1.0, \"npv\": 0.9997775488376313, \"accuracy\": 0.9997775522188133, \"f1\": 0.12022807527473547, \"f2\": 0.07869034271443433, \"f0_5\": 0.2546466697229681, \"p4\": 0.2146467178141527, \"phi\": 0.25287276527964986}, {\"truth_threshold\": 34.31999923288822, \"match_probability\": 0.9999999999533715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19397.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284564.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06381410773092601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.936185892269074, \"precision\": 1.0, \"recall\": 0.06381410773092601, \"specificity\": 1.0, \"npv\": 0.9997775144440086, \"accuracy\": 0.9997775178180598, \"f1\": 0.11997229077369355, \"f2\": 0.07851504281350764, \"f0_5\": 0.2541875355458932, \"p4\": 0.21423898041353376, \"phi\": 0.2525864406766274}, {\"truth_threshold\": 34.33999923244119, \"match_probability\": 0.9999999999540136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19368.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284593.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0637187007543731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9362812992456269, \"precision\": 1.0, \"recall\": 0.0637187007543731, \"specificity\": 1.0, \"npv\": 0.999777491775486, \"accuracy\": 0.9997774951448359, \"f1\": 0.11980366747183209, \"f2\": 0.07839949741420905, \"f0_5\": 0.2538846927245414, \"p4\": 0.21397008184249136, \"phi\": 0.2523975491548995}, {\"truth_threshold\": 34.35999923199415, \"match_probability\": 0.9999999999546466, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19314.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284647.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06354104638424009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9364589536157599, \"precision\": 1.0, \"recall\": 0.06354104638424009, \"specificity\": 1.0, \"npv\": 0.9997774495651363, \"accuracy\": 0.9997774529257295, \"f1\": 0.1194895986389297, \"f2\": 0.07818432945420747, \"f0_5\": 0.253320287395368, \"p4\": 0.213469029639086, \"phi\": 0.25204544291999326}, {\"truth_threshold\": 34.37999923154712, \"match_probability\": 0.999999999955271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19253.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284708.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06334036274390464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9366596372560954, \"precision\": 1.0, \"recall\": 0.06334036274390464, \"specificity\": 1.0, \"npv\": 0.9997774018830787, \"accuracy\": 0.9997774052337758, \"f1\": 0.11913469094779311, \"f2\": 0.07794124671989326, \"f0_5\": 0.2526819485895326, \"p4\": 0.21290248635572376, \"phi\": 0.2516471007153326}, {\"truth_threshold\": 34.39999923110008, \"match_probability\": 0.9999999999558868, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19196.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284765.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06315283868654202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.936847161313458, \"precision\": 1.0, \"recall\": 0.06315283868654202, \"specificity\": 1.0, \"npv\": 0.9997773573277176, \"accuracy\": 0.9997773606691633, \"f1\": 0.11880293479639928, \"f2\": 0.07771408213499158, \"f0_5\": 0.25208472862414477, \"p4\": 0.21237257508556776, \"phi\": 0.2512743086146585}, {\"truth_threshold\": 34.41999923065305, \"match_probability\": 0.9999999999564941, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19124.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284837.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06291596619303134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9370840338069687, \"precision\": 1.0, \"recall\": 0.06291596619303134, \"specificity\": 1.0, \"npv\": 0.999777301047267, \"accuracy\": 0.9997773043770214, \"f1\": 0.11838370707398982, \"f2\": 0.07742710742302635, \"f0_5\": 0.2513293223675737, \"p4\": 0.2117024965350799, \"phi\": 0.2508026213444548}, {\"truth_threshold\": 34.43999923020601, \"match_probability\": 0.9999999999570931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19067.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06272844213566872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9372715578643313, \"precision\": 1.0, \"recall\": 0.06272844213566872, \"specificity\": 1.0, \"npv\": 0.999777256491915, \"accuracy\": 0.999777259812409, \"f1\": 0.11805168592196343, \"f2\": 0.07719989537707575, \"f0_5\": 0.2507304808418085, \"p4\": 0.21117144922329673, \"phi\": 0.25042857221653186}, {\"truth_threshold\": 34.45999922975898, \"match_probability\": 0.9999999999576838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19022.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06258039682722455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9374196031727755, \"precision\": 1.0, \"recall\": 0.06258039682722455, \"specificity\": 1.0, \"npv\": 0.9997772213166397, \"accuracy\": 0.9997772246298202, \"f1\": 0.11778948118012403, \"f2\": 0.07702050262943509, \"f0_5\": 0.25025720367636806, \"p4\": 0.21075184598025246, \"phi\": 0.2501328751860003}, {\"truth_threshold\": 34.47999922931194, \"match_probability\": 0.9999999999582664, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18991.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284970.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.062478410059185224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9375215899408148, \"precision\": 1.0, \"recall\": 0.062478410059185224, \"specificity\": 1.0, \"npv\": 0.999777197084785, \"accuracy\": 0.9997772003929257, \"f1\": 0.11760880873937922, \"f2\": 0.07689691335279612, \"f0_5\": 0.24993090741593735, \"p4\": 0.21046260336133643, \"phi\": 0.2499289692838468}, {\"truth_threshold\": 34.49999922886491, \"match_probability\": 0.9999999999588409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18936.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06229746579330901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.937702534206691, \"precision\": 1.0, \"recall\": 0.06229746579330901, \"specificity\": 1.0, \"npv\": 0.9997771540927873, \"accuracy\": 0.9997771573919839, \"f1\": 0.11728817548630059, \"f2\": 0.07667762678371856, \"f0_5\": 0.2493514702203026, \"p4\": 0.20994906396432716, \"phi\": 0.2495667907755903}, {\"truth_threshold\": 34.51999922841787, \"match_probability\": 0.9999999999594076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18889.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285072.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06214284069337843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9378571593066216, \"precision\": 1.0, \"recall\": 0.06214284069337843, \"specificity\": 1.0, \"npv\": 0.9997771173541742, \"accuracy\": 0.9997771206457245, \"f1\": 0.11701409323215116, \"f2\": 0.07649022096275065, \"f0_5\": 0.24885578248141718, \"p4\": 0.20950984882081558, \"phi\": 0.24925687579809222}, {\"truth_threshold\": 34.53999922797084, \"match_probability\": 0.9999999999599665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18836.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06196847621898862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9380315237810114, \"precision\": 1.0, \"recall\": 0.06196847621898862, \"specificity\": 1.0, \"npv\": 0.9997770759255286, \"accuracy\": 0.9997770792084534, \"f1\": 0.1167049260061277, \"f2\": 0.07627887387825186, \"f0_5\": 0.24829622599227535, \"p4\": 0.20901415143696425, \"phi\": 0.24890693432241112}, {\"truth_threshold\": 34.559999227523804, \"match_probability\": 0.9999999999605176, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18741.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285220.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06165593612338425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9383440638766157, \"precision\": 1.0, \"recall\": 0.06165593612338425, \"specificity\": 1.0, \"npv\": 0.999777001666644, \"accuracy\": 0.9997770049340993, \"f1\": 0.11615050418032737, \"f2\": 0.07589999878501683, \"f0_5\": 0.24729168041169097, \"p4\": 0.20812454192706856, \"phi\": 0.24827844641125665}, {\"truth_threshold\": 34.57999922707677, \"match_probability\": 0.9999999999610611, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18697.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285264.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06151118071068328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9384888192893167, \"precision\": 1.0, \"recall\": 0.06151118071068328, \"specificity\": 1.0, \"npv\": 0.9997769672730591, \"accuracy\": 0.9997769705333458, \"f1\": 0.11589360871263071, \"f2\": 0.0757245000368558, \"f0_5\": 0.2468257341933576, \"p4\": 0.20771203503570884, \"phi\": 0.2479868176018879}, {\"truth_threshold\": 34.599999226629734, \"match_probability\": 0.9999999999615973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18652.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285309.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0613631354022391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9386368645977609, \"precision\": 1.0, \"recall\": 0.0613631354022391, \"specificity\": 1.0, \"npv\": 0.9997769320978043, \"accuracy\": 0.9997769353507571, \"f1\": 0.11563080223053628, \"f2\": 0.07554499974078491, \"f0_5\": 0.2463487501617935, \"p4\": 0.20728984000339767, \"phi\": 0.24768820572718592}, {\"truth_threshold\": 34.6199992261827, \"match_probability\": 0.999999999962126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18610.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285351.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06122495978102454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9387750402189755, \"precision\": 1.0, \"recall\": 0.06122495978102454, \"specificity\": 1.0, \"npv\": 0.9997768992675686, \"accuracy\": 0.9997769025136742, \"f1\": 0.11538545002495575, \"f2\": 0.07537745432393593, \"f0_5\": 0.24590315564705167, \"p4\": 0.20689550544039262, \"phi\": 0.24740917615895797}, {\"truth_threshold\": 34.639999225735664, \"match_probability\": 0.9999999999626473, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18566.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.061080204368323565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9389197956316764, \"precision\": 1.0, \"recall\": 0.061080204368323565, \"specificity\": 1.0, \"npv\": 0.9997768648739908, \"accuracy\": 0.9997768681129208, \"f1\": 0.11512834584391385, \"f2\": 0.0752019183253538, \"f0_5\": 0.24543591777381188, \"p4\": 0.20648209668097461, \"phi\": 0.24711652156265307}, {\"truth_threshold\": 34.65999922528863, \"match_probability\": 0.9999999999631616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18498.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285463.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.060856491457785704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9391435085422143, \"precision\": 1.0, \"recall\": 0.060856491457785704, \"specificity\": 1.0, \"npv\": 0.9997768117202842, \"accuracy\": 0.99977681494812, \"f1\": 0.11473086500919497, \"f2\": 0.07493061080316477, \"f0_5\": 0.24471296695620884, \"p4\": 0.2058425949884069, \"phi\": 0.24666355426399683}, {\"truth_threshold\": 34.679999224841595, \"match_probability\": 0.9999999999636687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18411.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285550.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06057027052812696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9394297294718731, \"precision\": 1.0, \"recall\": 0.06057027052812696, \"specificity\": 1.0, \"npv\": 0.9997767437148148, \"accuracy\": 0.9997767469284484, \"f1\": 0.1142220788405941, \"f2\": 0.07458345317620751, \"f0_5\": 0.2437864964711802, \"p4\": 0.20502334974884934, \"phi\": 0.24608280686495795}, {\"truth_threshold\": 34.69999922439456, \"match_probability\": 0.999999999964169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18341.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285620.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06033997782610269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9396600221738973, \"precision\": 1.0, \"recall\": 0.06033997782610269, \"specificity\": 1.0, \"npv\": 0.9997766889977773, \"accuracy\": 0.999776692199977, \"f1\": 0.11381251124721535, \"f2\": 0.07430409541519302, \"f0_5\": 0.24303981978400582, \"p4\": 0.20436332202148433, \"phi\": 0.2456145420067392}, {\"truth_threshold\": 34.719999223947525, \"match_probability\": 0.9999999999646623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18298.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285663.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06019851230914492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.939801487690855, \"precision\": 1.0, \"recall\": 0.06019851230914492, \"specificity\": 1.0, \"npv\": 0.9997766553858858, \"accuracy\": 0.9997766585810588, \"f1\": 0.11356083150509373, \"f2\": 0.07413247422095674, \"f0_5\": 0.24258059726424025, \"p4\": 0.2039574933845719, \"phi\": 0.24532645046069326}, {\"truth_threshold\": 34.73999922350049, \"match_probability\": 0.9999999999651488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18266.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0600932356453624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9399067643546376, \"precision\": 1.0, \"recall\": 0.0600932356453624, \"specificity\": 1.0, \"npv\": 0.9997766303723866, \"accuracy\": 0.999776633562329, \"f1\": 0.11337349135857641, \"f2\": 0.07400474836116716, \"f0_5\": 0.24223857834361118, \"p4\": 0.20365529195528267, \"phi\": 0.245111837008526}, {\"truth_threshold\": 34.759999223053455, \"match_probability\": 0.9999999999656286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18221.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059945190336918225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9400548096630817, \"precision\": 1.0, \"recall\": 0.059945190336918225, \"specificity\": 1.0, \"npv\": 0.9997765951971554, \"accuracy\": 0.9997765983797403, \"f1\": 0.11310998131490896, \"f2\": 0.07382512266371706, \"f0_5\": 0.24175722113866444, \"p4\": 0.20323004744505774, \"phi\": 0.24480971854378972}, {\"truth_threshold\": 34.77999922260642, \"match_probability\": 0.9999999999661018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18161.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285800.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059747796592325986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.940252203407674, \"precision\": 1.0, \"recall\": 0.059747796592325986, \"specificity\": 1.0, \"npv\": 0.9997765482968511, \"accuracy\": 0.999776551469622, \"f1\": 0.11275852006382675, \"f2\": 0.07358560135493779, \"f0_5\": 0.2411146957687763, \"p4\": 0.20266255646620623, \"phi\": 0.2444063130228392}, {\"truth_threshold\": 34.799999222159386, \"match_probability\": 0.9999999999665684, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18111.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05958330180516579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9404166981948342, \"precision\": 1.0, \"recall\": 0.05958330180516579, \"specificity\": 1.0, \"npv\": 0.9997765092132676, \"accuracy\": 0.9997765123778567, \"f1\": 0.11246553565662336, \"f2\": 0.07338598247099773, \"f0_5\": 0.24057863205855395, \"p4\": 0.20218921172998808, \"phi\": 0.24406963245387417}, {\"truth_threshold\": 34.81999922171235, \"match_probability\": 0.9999999999670287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18063.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285898.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059425386809492005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.940574613190508, \"precision\": 1.0, \"recall\": 0.059425386809492005, \"specificity\": 1.0, \"npv\": 0.9997764716930302, \"accuracy\": 0.999776474849762, \"f1\": 0.11218418502968723, \"f2\": 0.0731943331223504, \"f0_5\": 0.2400634746805666, \"p4\": 0.2017344277442907, \"phi\": 0.24374598161485136}, {\"truth_threshold\": 34.839999221265316, \"match_probability\": 0.9999999999674827, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18018.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05927734150104783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9407226584989522, \"precision\": 1.0, \"recall\": 0.05927734150104783, \"specificity\": 1.0, \"npv\": 0.9997764365178102, \"accuracy\": 0.9997764396671732, \"f1\": 0.11192034263104116, \"f2\": 0.0730146483156139, \"f0_5\": 0.2395800368584672, \"p4\": 0.20130773547904554, \"phi\": 0.2434421681881898}, {\"truth_threshold\": 34.85999922081828, \"match_probability\": 0.9999999999679303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17984.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285977.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0591654850457789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9408345149542211, \"precision\": 1.0, \"recall\": 0.0591654850457789, \"specificity\": 1.0, \"npv\": 0.9997764099409789, \"accuracy\": 0.9997764130847728, \"f1\": 0.11172094612433801, \"f2\": 0.07287887776902453, \"f0_5\": 0.23921446566479648, \"p4\": 0.2009851322787288, \"phi\": 0.24321236858244996}, {\"truth_threshold\": 34.879999220371246, \"match_probability\": 0.9999999999683719, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17889.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286072.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05885294495017453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9411470550498254, \"precision\": 1.0, \"recall\": 0.05885294495017453, \"specificity\": 1.0, \"npv\": 0.9997763356821934, \"accuracy\": 0.9997763388104188, \"f1\": 0.11116358552120553, \"f2\": 0.07249947922281401, \"f0_5\": 0.23819161316265308, \"p4\": 0.20008276550927762, \"phi\": 0.24256912756241536}, {\"truth_threshold\": 34.89999921992421, \"match_probability\": 0.9999999999688073, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17826.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286135.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.058645681518352685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9413543184816473, \"precision\": 1.0, \"recall\": 0.058645681518352685, \"specificity\": 1.0, \"npv\": 0.9997762864368994, \"accuracy\": 0.9997762895547946, \"f1\": 0.11079378595157667, \"f2\": 0.07224784585829273, \"f0_5\": 0.23751215807496037, \"p4\": 0.19948356026598885, \"phi\": 0.24214161493634204}, {\"truth_threshold\": 34.91999921947718, \"match_probability\": 0.9999999999692367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17760.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286201.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05842854839930123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9415714516006988, \"precision\": 1.0, \"recall\": 0.05842854839930123, \"specificity\": 1.0, \"npv\": 0.9997762348465968, \"accuracy\": 0.9997762379536643, \"f1\": 0.11040622153978136, \"f2\": 0.07198420238585478, \"f0_5\": 0.23679936853501724, \"p4\": 0.19885514137248886, \"phi\": 0.24169293354627797}, {\"truth_threshold\": 34.93999921903014, \"match_probability\": 0.9999999999696603, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17722.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05830353236105948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9416964676389405, \"precision\": 1.0, \"recall\": 0.05830353236105948, \"specificity\": 1.0, \"npv\": 0.9997762051430916, \"accuracy\": 0.9997762082439228, \"f1\": 0.11018300625149603, \"f2\": 0.07183239486172609, \"f0_5\": 0.23638851911036177, \"p4\": 0.19849300831961023, \"phi\": 0.2414342236104432}, {\"truth_threshold\": 34.95999921858311, \"match_probability\": 0.9999999999700779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17682.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286279.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05817193653133132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9418280634686687, \"precision\": 1.0, \"recall\": 0.05817193653133132, \"specificity\": 1.0, \"npv\": 0.999776173876246, \"accuracy\": 0.9997761769705105, \"f1\": 0.10994798581035496, \"f2\": 0.07167258736337945, \"f0_5\": 0.23595568591551927, \"p4\": 0.1981115657665155, \"phi\": 0.24116159754875208}, {\"truth_threshold\": 34.97999921813607, \"match_probability\": 0.9999999999704898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17595.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286366.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.057885715601672584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9421142843983275, \"precision\": 1.0, \"recall\": 0.057885715601672584, \"specificity\": 1.0, \"npv\": 0.9997761058708635, \"accuracy\": 0.9997761089508389, \"f1\": 0.10943661446217766, \"f2\": 0.071324970266061, \"f0_5\": 0.2350129961719395, \"p4\": 0.19728104212416034, \"phi\": 0.240567569156336}, {\"truth_threshold\": 34.99999921768904, \"match_probability\": 0.9999999999708962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17550.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.057737670293228405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9422623297067716, \"precision\": 1.0, \"recall\": 0.057737670293228405, \"specificity\": 1.0, \"npv\": 0.9997760706956692, \"accuracy\": 0.9997760737682502, \"f1\": 0.10917200344622735, \"f2\": 0.07114514907645084, \"f0_5\": 0.23452470995106384, \"p4\": 0.19685098387422936, \"phi\": 0.2402597368201463}, {\"truth_threshold\": 35.019999217242, \"match_probability\": 0.9999999999712968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17506.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05759291488052744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9424070851194726, \"precision\": 1.0, \"recall\": 0.05759291488052744, \"specificity\": 1.0, \"npv\": 0.9997760363021484, \"accuracy\": 0.9997760393674967, \"f1\": 0.10891320104396408, \"f2\": 0.07096931122552398, \"f0_5\": 0.23404682005962807, \"p4\": 0.19643016750509965, \"phi\": 0.23995836338486046}, {\"truth_threshold\": 35.03999921679497, \"match_probability\": 0.999999999971692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17459.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286502.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.057438289780596855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9425617102194032, \"precision\": 1.0, \"recall\": 0.057438289780596855, \"specificity\": 1.0, \"npv\": 0.9997759995636174, \"accuracy\": 0.9997760026212373, \"f1\": 0.10863667475577127, \"f2\": 0.07078147057130324, \"f0_5\": 0.23353584967241578, \"p4\": 0.19598031471197022, \"phi\": 0.23963602312386367}, {\"truth_threshold\": 35.05999921634793, \"match_probability\": 0.9999999999720818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17397.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286564.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05723431624451821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9427656837554818, \"precision\": 1.0, \"recall\": 0.05723431624451821, \"specificity\": 1.0, \"npv\": 0.9997759511000274, \"accuracy\": 0.9997759541474484, \"f1\": 0.10827177166897976, \"f2\": 0.0705336588712182, \"f0_5\": 0.23286101689470456, \"p4\": 0.1953863469995623, \"phi\": 0.2392101439298153}, {\"truth_threshold\": 35.0799992159009, \"match_probability\": 0.9999999999724661, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17365.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286596.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05712903958073569, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9428709604192643, \"precision\": 1.0, \"recall\": 0.05712903958073569, \"specificity\": 1.0, \"npv\": 0.9997759260865634, \"accuracy\": 0.9997759291287186, \"f1\": 0.10808337949621256, \"f2\": 0.0704057463090198, \"f0_5\": 0.23251236539991055, \"p4\": 0.19507954020406185, \"phi\": 0.2389900383975574}, {\"truth_threshold\": 35.09999921545386, \"match_probability\": 0.9999999999728452, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17312.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286649.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05695467510634588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9430453248936541, \"precision\": 1.0, \"recall\": 0.05695467510634588, \"specificity\": 1.0, \"npv\": 0.9997758846580165, \"accuracy\": 0.9997758876914474, \"f1\": 0.10777127240695608, \"f2\": 0.07019387652494899, \"f0_5\": 0.23193438529081561, \"p4\": 0.1945710273410646, \"phi\": 0.2386250420426508}, {\"truth_threshold\": 35.11999921500683, \"match_probability\": 0.999999999973219, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17286.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286675.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05686913781702258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9431308621829774, \"precision\": 1.0, \"recall\": 0.05686913781702258, \"specificity\": 1.0, \"npv\": 0.9997758643345797, \"accuracy\": 0.9997758673637295, \"f1\": 0.10761812561673728, \"f2\": 0.07008993374583378, \"f0_5\": 0.2316506077377682, \"p4\": 0.19432140203475357, \"phi\": 0.23844578296748314}, {\"truth_threshold\": 35.13999921455979, \"match_probability\": 0.9999999999735877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17196.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286765.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05657304720013423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9434269527998658, \"precision\": 1.0, \"recall\": 0.05657304720013423, \"specificity\": 1.0, \"npv\": 0.9997757939842277, \"accuracy\": 0.9997757969985519, \"f1\": 0.10708781063467401, \"f2\": 0.06973009796924674, \"f0_5\": 0.23066707802921568, \"p4\": 0.1934564686488853, \"phi\": 0.2378242274929562}, {\"truth_threshold\": 35.15999921411276, \"match_probability\": 0.9999999999739513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17143.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05639868272574442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9436013172742556, \"precision\": 1.0, \"recall\": 0.05639868272574442, \"specificity\": 1.0, \"npv\": 0.9997757525556916, \"accuracy\": 0.9997757555612807, \"f1\": 0.10677537495640042, \"f2\": 0.06951817010236118, \"f0_5\": 0.23008699900411508, \"p4\": 0.1929465041065096, \"phi\": 0.23745743927129515}, {\"truth_threshold\": 35.179999213665724, \"match_probability\": 0.99999999997431, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17110.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05629011616621869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9437098838337813, \"precision\": 1.0, \"recall\": 0.05629011616621869, \"specificity\": 1.0, \"npv\": 0.9997757267605671, \"accuracy\": 0.9997757297607156, \"f1\": 0.10658078742707999, \"f2\": 0.06938620581140902, \"f0_5\": 0.22972548408838858, \"p4\": 0.19262874842586775, \"phi\": 0.23722877523504196}, {\"truth_threshold\": 35.19999921321869, \"match_probability\": 0.9999999999746636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17057.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.056115751691828884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9438842483081711, \"precision\": 1.0, \"recall\": 0.056115751691828884, \"specificity\": 1.0, \"npv\": 0.9997756853320368, \"accuracy\": 0.9997756883234444, \"f1\": 0.10626818433857292, \"f2\": 0.06917424837841805, \"f0_5\": 0.2291443325837142, \"p4\": 0.19211804277128655, \"phi\": 0.23686106498456141}, {\"truth_threshold\": 35.219999212771654, \"match_probability\": 0.9999999999750124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17009.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286952.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.055957836696155096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9440421633038449, \"precision\": 1.0, \"recall\": 0.055957836696155096, \"specificity\": 1.0, \"npv\": 0.9997756478118612, \"accuracy\": 0.9997756507953498, \"f1\": 0.10598498302021996, \"f2\": 0.0689822712034606, \"f0_5\": 0.2286174350868421, \"p4\": 0.19165512208501487, \"phi\": 0.23652755110779128}, {\"truth_threshold\": 35.23999921232462, \"match_probability\": 0.9999999999753565, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16951.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287010.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.055767022743049274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9442329772569508, \"precision\": 1.0, \"recall\": 0.055767022743049274, \"specificity\": 1.0, \"npv\": 0.9997756024749862, \"accuracy\": 0.999775605448902, \"f1\": 0.10564266839507404, \"f2\": 0.0687502788379252, \"f0_5\": 0.22798004115503073, \"p4\": 0.19109525823638895, \"phi\": 0.2361239267019934}, {\"truth_threshold\": 35.259999211877584, \"match_probability\": 0.9999999999756958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16907.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287054.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0556222673303483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9443777326696517, \"precision\": 1.0, \"recall\": 0.0556222673303483, \"specificity\": 1.0, \"npv\": 0.9997755680814976, \"accuracy\": 0.9997755710481486, \"f1\": 0.10538289888676963, \"f2\": 0.06857427006751567, \"f0_5\": 0.2274959700098765, \"p4\": 0.19067016748883026, \"phi\": 0.2358172680661446}, {\"truth_threshold\": 35.27999921143055, \"match_probability\": 0.9999999999760303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16879.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05553015024953859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9444698497504614, \"precision\": 1.0, \"recall\": 0.05553015024953859, \"specificity\": 1.0, \"npv\": 0.9997755461947333, \"accuracy\": 0.99977554915676, \"f1\": 0.10521755392095748, \"f2\": 0.06846225794440437, \"f0_5\": 0.22718768591325977, \"p4\": 0.19039949040594317, \"phi\": 0.23562191387052278}, {\"truth_threshold\": 35.299999210983515, \"match_probability\": 0.9999999999763604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16820.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.055336046400689565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9446639535993104, \"precision\": 1.0, \"recall\": 0.055336046400689565, \"specificity\": 1.0, \"npv\": 0.9997755000761975, \"accuracy\": 0.999775503028477, \"f1\": 0.10486905396516627, \"f2\": 0.06822621574086693, \"f0_5\": 0.2265374783496435, \"p4\": 0.18982871508451984, \"phi\": 0.2352097435534699}, {\"truth_threshold\": 35.31999921053648, \"match_probability\": 0.9999999999766858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16766.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287195.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05515839203055655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9448416079694435, \"precision\": 1.0, \"recall\": 0.05515839203055655, \"specificity\": 1.0, \"npv\": 0.9997754578660158, \"accuracy\": 0.9997754608093705, \"f1\": 0.1045499755243556, \"f2\": 0.06801015730847551, \"f0_5\": 0.225941648136918, \"p4\": 0.18930581062269525, \"phi\": 0.23483186889241178}, {\"truth_threshold\": 35.339999210089445, \"match_probability\": 0.9999999999770067, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16717.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287244.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.054997187139139564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9450028128608604, \"precision\": 1.0, \"recall\": 0.054997187139139564, \"specificity\": 1.0, \"npv\": 0.9997754195641875, \"accuracy\": 0.9997754224994405, \"f1\": 0.10426034838685536, \"f2\": 0.06781408790315449, \"f0_5\": 0.22540038670114798, \"p4\": 0.18883090917778977, \"phi\": 0.2344884556793434}, {\"truth_threshold\": 35.35999920964241, \"match_probability\": 0.9999999999773234, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16671.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287290.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05484585193495218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9451541480650478, \"precision\": 1.0, \"recall\": 0.05484585193495218, \"specificity\": 1.0, \"npv\": 0.9997753836073716, \"accuracy\": 0.9997753865350164, \"f1\": 0.10398837296339729, \"f2\": 0.06763000855973356, \"f0_5\": 0.22489174277273402, \"p4\": 0.18838472435790854, \"phi\": 0.23416560946804274}, {\"truth_threshold\": 35.379999209195375, \"match_probability\": 0.9999999999776356, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16604.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05462542892015752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9453745710798425, \"precision\": 1.0, \"recall\": 0.05462542892015752, \"specificity\": 1.0, \"npv\": 0.9997753312354923, \"accuracy\": 0.9997753341520509, \"f1\": 0.10359209520690031, \"f2\": 0.06736186841148674, \"f0_5\": 0.2241499877152199, \"p4\": 0.18773422369385045, \"phi\": 0.23369457908246682}, {\"truth_threshold\": 35.39999920874834, \"match_probability\": 0.9999999999779434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16555.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05446422402874053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9455357759712595, \"precision\": 1.0, \"recall\": 0.05446422402874053, \"specificity\": 1.0, \"npv\": 0.9997752929336737, \"accuracy\": 0.999775295842121, \"f1\": 0.10330217524242159, \"f2\": 0.06716574745678956, \"f0_5\": 0.22360683017226707, \"p4\": 0.18725801620593693, \"phi\": 0.23334949224872825}, {\"truth_threshold\": 35.419999208301306, \"match_probability\": 0.9999999999782471, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16521.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287440.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.054352367573471595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9456476324265284, \"precision\": 1.0, \"recall\": 0.054352367573471595, \"specificity\": 1.0, \"npv\": 0.9997752663569033, \"accuracy\": 0.9997752692597206, \"f1\": 0.1031009541877547, \"f2\": 0.06702965436376399, \"f0_5\": 0.22322960720993393, \"p4\": 0.18692735377380684, \"phi\": 0.23310974404322074}, {\"truth_threshold\": 35.43999920785427, \"match_probability\": 0.9999999999785465, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16461.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287500.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05415497382887936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9458450261711207, \"precision\": 1.0, \"recall\": 0.05415497382887936, \"specificity\": 1.0, \"npv\": 0.9997752194567237, \"accuracy\": 0.9997752223496023, \"f1\": 0.10274575403686388, \"f2\": 0.06678947176226664, \"f0_5\": 0.2225632427901191, \"p4\": 0.18634336610656588, \"phi\": 0.23268605640313084}, {\"truth_threshold\": 35.459999207407236, \"match_probability\": 0.9999999999788419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16423.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287538.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.054029957790637614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9459700422093624, \"precision\": 1.0, \"recall\": 0.054029957790637614, \"specificity\": 1.0, \"npv\": 0.9997751897532787, \"accuracy\": 0.9997751926398606, \"f1\": 0.10252072512984418, \"f2\": 0.06663734401716512, \"f0_5\": 0.22214076444665673, \"p4\": 0.1859731993931426, \"phi\": 0.23241732143387325}, {\"truth_threshold\": 35.4799992069602, \"match_probability\": 0.9999999999791332, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16368.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287593.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0538490135247614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9461509864752387, \"precision\": 1.0, \"recall\": 0.0538490135247614, \"specificity\": 1.0, \"npv\": 0.9997751467614538, \"accuracy\": 0.9997751496389188, \"f1\": 0.10219493083673348, \"f2\": 0.06641714250469886, \"f0_5\": 0.22152866690306497, \"p4\": 0.18543700838244498, \"phi\": 0.23202781169436962}, {\"truth_threshold\": 35.499999206513166, \"match_probability\": 0.9999999999794205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16319.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287642.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05368780863334441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9463121913666556, \"precision\": 1.0, \"recall\": 0.05368780863334441, \"specificity\": 1.0, \"npv\": 0.9997751084596492, \"accuracy\": 0.9997751113289888, \"f1\": 0.10190458348944674, \"f2\": 0.0662209464169919, \"f0_5\": 0.22098272924977724, \"p4\": 0.18495888860090623, \"phi\": 0.23168024235864998}, {\"truth_threshold\": 35.51999920606613, \"match_probability\": 0.9999999999797038, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16284.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287677.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053572662282332276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9464273377176677, \"precision\": 1.0, \"recall\": 0.053572662282332276, \"specificity\": 1.0, \"npv\": 0.9997750811012193, \"accuracy\": 0.9997750839647531, \"f1\": 0.10169713812862027, \"f2\": 0.06608079680033244, \"f0_5\": 0.22059241879505928, \"p4\": 0.18461713052804676, \"phi\": 0.23143165897976659}, {\"truth_threshold\": 35.5399992056191, \"match_probability\": 0.9999999999799832, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16253.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287708.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05347067551429295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.946529324485707, \"precision\": 1.0, \"recall\": 0.05347067551429295, \"specificity\": 1.0, \"npv\": 0.9997750568694682, \"accuracy\": 0.9997750597278586, \"f1\": 0.10151336293853486, \"f2\": 0.065956657633287, \"f0_5\": 0.22024646789873514, \"p4\": 0.18431426059004719, \"phi\": 0.23121126195138314}, {\"truth_threshold\": 35.55999920517206, \"match_probability\": 0.9999999999802588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16234.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287727.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053408167495172076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9465918325048279, \"precision\": 1.0, \"recall\": 0.053408167495172076, \"specificity\": 1.0, \"npv\": 0.9997750420177504, \"accuracy\": 0.9997750448729879, \"f1\": 0.10140070894298786, \"f2\": 0.06588056924967413, \"f0_5\": 0.22003431852251443, \"p4\": 0.18412855166870334, \"phi\": 0.23107607600436855}, {\"truth_threshold\": 35.57999920472503, \"match_probability\": 0.9999999999805306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16174.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053210773750579844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9467892262494202, \"precision\": 1.0, \"recall\": 0.053210773750579844, \"specificity\": 1.0, \"npv\": 0.9997749951175918, \"accuracy\": 0.9997749979628695, \"f1\": 0.10104487169475378, \"f2\": 0.06564027473624574, \"f0_5\": 0.21936379886995228, \"p4\": 0.18354170810896722, \"phi\": 0.23064865286120628}, {\"truth_threshold\": 35.59999920427799, \"match_probability\": 0.9999999999807986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16123.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053042989067676447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9469570109323235, \"precision\": 1.0, \"recall\": 0.053042989067676447, \"specificity\": 1.0, \"npv\": 0.9997749552524604, \"accuracy\": 0.9997749580892689, \"f1\": 0.10074230514489946, \"f2\": 0.06543600599691388, \"f0_5\": 0.21879317036365561, \"p4\": 0.18304241960671702, \"phi\": 0.23028471947046977}, {\"truth_threshold\": 35.61999920383096, \"match_probability\": 0.9999999999810629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16065.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05285217511457062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9471478248854294, \"precision\": 1.0, \"recall\": 0.05285217511457062, \"specificity\": 1.0, \"npv\": 0.9997749099156482, \"accuracy\": 0.9997749127428212, \"f1\": 0.10039809265497178, \"f2\": 0.06520367981725923, \"f0_5\": 0.21814345189437864, \"p4\": 0.18247407402405758, \"phi\": 0.22987013423673794}, {\"truth_threshold\": 35.63999920338392, \"match_probability\": 0.9999999999813237, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16018.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.052697550014640035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.94730244998536, \"precision\": 1.0, \"recall\": 0.052697550014640035, \"specificity\": 1.0, \"npv\": 0.9997748731772, \"accuracy\": 0.9997748759965618, \"f1\": 0.10011907031398935, \"f2\": 0.06501539945221137, \"f0_5\": 0.21761635505511734, \"p4\": 0.18201310597025455, \"phi\": 0.22953362799955018}, {\"truth_threshold\": 35.65999920293689, \"match_probability\": 0.9999999999815808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16010.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.052671230848694406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9473287691513056, \"precision\": 1.0, \"recall\": 0.052671230848694406, \"specificity\": 1.0, \"npv\": 0.9997748669238473, \"accuracy\": 0.9997748697418793, \"f1\": 0.10007156898593936, \"f2\": 0.06498335029962966, \"f0_5\": 0.2175265828081989, \"p4\": 0.18193460654044022, \"phi\": 0.2294763012000775}, {\"truth_threshold\": 35.67999920248985, \"match_probability\": 0.9999999999818344, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15928.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05240145939775168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9475985406022484, \"precision\": 1.0, \"recall\": 0.05240145939775168, \"specificity\": 1.0, \"npv\": 0.9997748028269875, \"accuracy\": 0.9997748056313842, \"f1\": 0.09958454338848788, \"f2\": 0.06465482248338167, \"f0_5\": 0.21660551631476882, \"p4\": 0.18112936972343993, \"phi\": 0.22888787372255784}, {\"truth_threshold\": 35.69999920204282, \"match_probability\": 0.9999999999820844, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15857.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288104.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.052167876799984206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9478321232000158, \"precision\": 1.0, \"recall\": 0.052167876799984206, \"specificity\": 1.0, \"npv\": 0.9997747473284935, \"accuracy\": 0.9997747501210775, \"f1\": 0.09916264875648025, \"f2\": 0.0643703301369407, \"f0_5\": 0.21580667902414064, \"p4\": 0.1804312420626984, \"phi\": 0.22837715701525008}, {\"truth_threshold\": 35.71999920159578, \"match_probability\": 0.9999999999823311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15828.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288133.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0520724698234313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9479275301765687, \"precision\": 1.0, \"recall\": 0.0520724698234313, \"specificity\": 1.0, \"npv\": 0.9997747246600963, \"accuracy\": 0.9997747274478537, \"f1\": 0.09899027171040906, \"f2\": 0.064254119603271, \"f0_5\": 0.21548003800987275, \"p4\": 0.1801458479044124, \"phi\": 0.22816822561455}, {\"truth_threshold\": 35.73999920114875, \"match_probability\": 0.9999999999825744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15771.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288190.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.051884945766068676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9481150542339313, \"precision\": 1.0, \"recall\": 0.051884945766068676, \"specificity\": 1.0, \"npv\": 0.9997746801049738, \"accuracy\": 0.9997746828832412, \"f1\": 0.09865137052281285, \"f2\": 0.06402568984625877, \"f0_5\": 0.21483741775531612, \"p4\": 0.17958448874409746, \"phi\": 0.22775700879563557}, {\"truth_threshold\": 35.759999200701714, \"match_probability\": 0.9999999999828143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15709.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288252.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05168097222999003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.94831902777001, \"precision\": 1.0, \"recall\": 0.05168097222999003, \"specificity\": 1.0, \"npv\": 0.9997746316415117, \"accuracy\": 0.9997746344094524, \"f1\": 0.09828260393530829, \"f2\": 0.06377719838285482, \"f0_5\": 0.2141375202087258, \"p4\": 0.17897326663414248, \"phi\": 0.2273088757046532}, {\"truth_threshold\": 35.77999920025468, \"match_probability\": 0.9999999999830509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15681.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288280.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.051588855149180324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9484111448508197, \"precision\": 1.0, \"recall\": 0.051588855149180324, \"specificity\": 1.0, \"npv\": 0.9997746097547885, \"accuracy\": 0.9997746125180638, \"f1\": 0.09811601729434805, \"f2\": 0.063664968230446, \"f0_5\": 0.21382112712546192, \"p4\": 0.1786970184978056, \"phi\": 0.2271062031835944}, {\"truth_threshold\": 35.799999199807644, \"match_probability\": 0.9999999999832843, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15627.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288334.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05141120077904731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9485887992209527, \"precision\": 1.0, \"recall\": 0.05141120077904731, \"specificity\": 1.0, \"npv\": 0.9997745675446821, \"accuracy\": 0.9997745702989572, \"f1\": 0.0977946606255554, \"f2\": 0.06344850995273132, \"f0_5\": 0.21321039433076194, \"p4\": 0.17816388065534577, \"phi\": 0.2267148231277012}, {\"truth_threshold\": 35.81999919936061, \"match_probability\": 0.9999999999835144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15599.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288362.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0513190836982376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9486809163017624, \"precision\": 1.0, \"recall\": 0.0513190836982376, \"specificity\": 1.0, \"npv\": 0.9997745456579615, \"accuracy\": 0.9997745484075686, \"f1\": 0.09762798848416573, \"f2\": 0.06333626485350925, \"f0_5\": 0.21289343454608484, \"p4\": 0.17788724492094501, \"phi\": 0.22651161910151188}, {\"truth_threshold\": 35.839999198913574, \"match_probability\": 0.9999999999837413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15509.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288452.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05102299308134925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9489770069186507, \"precision\": 1.0, \"recall\": 0.05102299308134925, \"specificity\": 1.0, \"npv\": 0.9997744753077952, \"accuracy\": 0.9997744780423912, \"f1\": 0.09709205872225875, \"f2\": 0.06297544246044798, \"f0_5\": 0.21187332136602213, \"p4\": 0.17699716048489328, \"phi\": 0.22585722511475964}, {\"truth_threshold\": 35.85999919846654, \"match_probability\": 0.9999999999839652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15470.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288491.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0508946871473643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9491053128526357, \"precision\": 1.0, \"recall\": 0.0508946871473643, \"specificity\": 1.0, \"npv\": 0.9997744448227261, \"accuracy\": 0.9997744475508142, \"f1\": 0.09685972870510376, \"f2\": 0.06281906970926994, \"f0_5\": 0.21143064883378299, \"p4\": 0.17661103117918445, \"phi\": 0.22557306485301495}, {\"truth_threshold\": 35.879999198019505, \"match_probability\": 0.9999999999841859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15413.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288548.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05070716309000168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9492928369099983, \"precision\": 1.0, \"recall\": 0.05070716309000168, \"specificity\": 1.0, \"npv\": 0.9997744002676285, \"accuracy\": 0.9997744029862018, \"f1\": 0.09652006738181568, \"f2\": 0.06259050709965507, \"f0_5\": 0.21078298638177526, \"p4\": 0.17604622421317384, \"phi\": 0.2251571086321266}, {\"truth_threshold\": 35.89999919757247, \"match_probability\": 0.9999999999844036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15367.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288594.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0505558278858143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9494441721141857, \"precision\": 1.0, \"recall\": 0.0505558278858143, \"specificity\": 1.0, \"npv\": 0.9997743643108861, \"accuracy\": 0.9997743670217778, \"f1\": 0.09624586631927047, \"f2\": 0.06240603763286715, \"f0_5\": 0.21025972213480595, \"p4\": 0.17559001271683908, \"phi\": 0.22482086354862743}, {\"truth_threshold\": 35.919999197125435, \"match_probability\": 0.9999999999846183, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15305.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288656.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05035185434973566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9496481456502643, \"precision\": 1.0, \"recall\": 0.05035185434973566, \"specificity\": 1.0, \"npv\": 0.9997743158474546, \"accuracy\": 0.9997743185479888, \"f1\": 0.0958761659556608, \"f2\": 0.06215738306248878, \"f0_5\": 0.20955361861652166, \"p4\": 0.17497454951093197, \"phi\": 0.22436686639109096}, {\"truth_threshold\": 35.9399991966784, \"match_probability\": 0.9999999999848301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15265.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288696.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0502202585200075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9497797414799924, \"precision\": 1.0, \"recall\": 0.0502202585200075, \"specificity\": 1.0, \"npv\": 0.9997742845807271, \"accuracy\": 0.9997742872745765, \"f1\": 0.09563757338061436, \"f2\": 0.0619969474676897, \"f0_5\": 0.20909755877059127, \"p4\": 0.17457712905766176, \"phi\": 0.22407347686261236}, {\"truth_threshold\": 35.959999196231365, \"match_probability\": 0.999999999985039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15198.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288763.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04999983550521284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9500001644947872, \"precision\": 1.0, \"recall\": 0.04999983550521284, \"specificity\": 1.0, \"npv\": 0.999774232208963, \"accuracy\": 0.9997742348916111, \"f1\": 0.09523779683480647, \"f2\": 0.061728194488896396, \"f0_5\": 0.20833276217056473, \"p4\": 0.1739108384634585, \"phi\": 0.22358118693843324}, {\"truth_threshold\": 35.97999919578433, \"match_probability\": 0.9999999999852449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15146.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288815.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04982876092656624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9501712390734338, \"precision\": 1.0, \"recall\": 0.04982876092656624, \"specificity\": 1.0, \"npv\": 0.9997741915622245, \"accuracy\": 0.9997741942361752, \"f1\": 0.09492740679458614, \"f2\": 0.06151958992355746, \"f0_5\": 0.20773841363891976, \"p4\": 0.17339318900440884, \"phi\": 0.22319836283428496}, {\"truth_threshold\": 35.999999195337296, \"match_probability\": 0.9999999999854481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15119.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04973993374149973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9502600662585002, \"precision\": 1.0, \"recall\": 0.04973993374149973, \"specificity\": 1.0, \"npv\": 0.9997741704571884, \"accuracy\": 0.999774173126622, \"f1\": 0.0947662028331453, \"f2\": 0.06141126906332684, \"f0_5\": 0.20742954200588853, \"p4\": 0.1731242271097243, \"phi\": 0.22299932958420168}, {\"truth_threshold\": 36.01999919489026, \"match_probability\": 0.9999999999856484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15069.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04957543895433954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9504245610456604, \"precision\": 1.0, \"recall\": 0.04957543895433954, \"specificity\": 1.0, \"npv\": 0.9997741313737908, \"accuracy\": 0.9997741340348566, \"f1\": 0.09446760492743629, \"f2\": 0.061210662329506636, \"f0_5\": 0.2068570738283041, \"p4\": 0.17262581999365964, \"phi\": 0.22263027965227283}, {\"truth_threshold\": 36.039999194443226, \"match_probability\": 0.999999999985846, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15002.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.049355015939544875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9506449840604552, \"precision\": 1.0, \"recall\": 0.049355015939544875, \"specificity\": 1.0, \"npv\": 0.9997740790020427, \"accuracy\": 0.9997740816518912, \"f1\": 0.09406733696384847, \"f2\": 0.06094182375374336, \"f0_5\": 0.20608898010544854, \"p4\": 0.17195728266337598, \"phi\": 0.22213479152327673}, {\"truth_threshold\": 36.05999919399619, \"match_probability\": 0.9999999999860408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14931.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0491214333417774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9508785666582226, \"precision\": 1.0, \"recall\": 0.0491214333417774, \"specificity\": 1.0, \"npv\": 0.9997740235036291, \"accuracy\": 0.9997740261415845, \"f1\": 0.09364298884888927, \"f2\": 0.060656903170766385, \"f0_5\": 0.20527379462996825, \"p4\": 0.17124799161944335, \"phi\": 0.22160851304129564}, {\"truth_threshold\": 36.079999193549156, \"match_probability\": 0.999999999986233, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14866.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289095.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.048907590118469145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9510924098815309, \"precision\": 1.0, \"recall\": 0.048907590118469145, \"specificity\": 1.0, \"npv\": 0.9997739726952276, \"accuracy\": 0.9997739753222896, \"f1\": 0.09325433542328598, \"f2\": 0.06039603155901878, \"f0_5\": 0.20452638095893239, \"p4\": 0.17059788053307617, \"phi\": 0.22112561061010497}, {\"truth_threshold\": 36.09999919310212, \"match_probability\": 0.9999999999864225, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14803.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289158.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0487003266866473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9512996733133527, \"precision\": 1.0, \"recall\": 0.0487003266866473, \"specificity\": 1.0, \"npv\": 0.9997739234501666, \"accuracy\": 0.9997739260666653, \"f1\": 0.09287748930243064, \"f2\": 0.06014316046762394, \"f0_5\": 0.20380094335206636, \"p4\": 0.16996707827210517, \"phi\": 0.22065655821845456}, {\"truth_threshold\": 36.11999919265509, \"match_probability\": 0.9999999999866095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14763.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289198.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.048568730856919144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9514312691430808, \"precision\": 1.0, \"recall\": 0.048568730856919144, \"specificity\": 1.0, \"npv\": 0.9997738921834636, \"accuracy\": 0.9997738947932531, \"f1\": 0.09263814460159887, \"f2\": 0.05998259395566578, \"f0_5\": 0.20333982529551284, \"p4\": 0.16956621351022003, \"phi\": 0.2203582289982227}, {\"truth_threshold\": 36.13999919220805, \"match_probability\": 0.9999999999867939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14724.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289237.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04844042492293419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9515595750770658, \"precision\": 1.0, \"recall\": 0.04844042492293419, \"specificity\": 1.0, \"npv\": 0.9997738616984302, \"accuracy\": 0.9997738643016761, \"f1\": 0.0924047256695483, \"f2\": 0.05982603155615943, \"f0_5\": 0.20288984365741877, \"p4\": 0.16917510427609897, \"phi\": 0.22006696864253572}, {\"truth_threshold\": 36.15999919176102, \"match_probability\": 0.9999999999869756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14679.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289282.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04829237961449002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9517076203855099, \"precision\": 1.0, \"recall\": 0.04829237961449002, \"specificity\": 1.0, \"npv\": 0.9997738265233939, \"accuracy\": 0.9997738291190874, \"f1\": 0.09213532513181019, \"f2\": 0.059645370301896025, \"f0_5\": 0.2023701530563008, \"p4\": 0.16872349758098446, \"phi\": 0.21973041928485693}, {\"truth_threshold\": 36.17999919131398, \"match_probability\": 0.9999999999871549, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14612.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.048071956599695355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9519280434003047, \"precision\": 1.0, \"recall\": 0.048071956599695355, \"specificity\": 1.0, \"npv\": 0.9997737741516777, \"accuracy\": 0.9997737767361219, \"f1\": 0.09173407664805242, \"f2\": 0.059376361283946764, \"f0_5\": 0.2015954349919566, \"p4\": 0.16805045576782335, \"phi\": 0.2192283774526762}, {\"truth_threshold\": 36.19999919086695, \"match_probability\": 0.9999999999873318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14583.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04797654962314244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9520234503768575, \"precision\": 1.0, \"recall\": 0.04797654962314244, \"specificity\": 1.0, \"npv\": 0.9997737514833246, \"accuracy\": 0.999773754062898, \"f1\": 0.0915603495906374, \"f2\": 0.05925991546024267, \"f0_5\": 0.20125975384564426, \"p4\": 0.16775889785751089, \"phi\": 0.21901071891566173}, {\"truth_threshold\": 36.21999919041991, \"match_probability\": 0.9999999999875062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14536.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04782192452321186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9521780754767881, \"precision\": 1.0, \"recall\": 0.04782192452321186, \"specificity\": 1.0, \"npv\": 0.9997737147449616, \"accuracy\": 0.9997737173166387, \"f1\": 0.09127872476035881, \"f2\": 0.059071181261073816, \"f0_5\": 0.2007152621477196, \"p4\": 0.16728606298129042, \"phi\": 0.21865750187639274}, {\"truth_threshold\": 36.23999918997288, \"match_probability\": 0.9999999999876782, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14466.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.047591631821187586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9524083681788124, \"precision\": 1.0, \"recall\": 0.047591631821187586, \"specificity\": 1.0, \"npv\": 0.9997736600282555, \"accuracy\": 0.9997736625881672, \"f1\": 0.09085912940799618, \"f2\": 0.05879006104152612, \"f0_5\": 0.19990326815449458, \"p4\": 0.16658112918023804, \"phi\": 0.21813037370477753}, {\"truth_threshold\": 36.25999918952584, \"match_probability\": 0.9999999999878478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14421.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289540.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04744358651274341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9525564134872566, \"precision\": 1.0, \"recall\": 0.04744358651274341, \"specificity\": 1.0, \"npv\": 0.9997736248532334, \"accuracy\": 0.9997736274055785, \"f1\": 0.0905892921082222, \"f2\": 0.05860932400742929, \"f0_5\": 0.19938060805486044, \"p4\": 0.16612750715576327, \"phi\": 0.21779083190961793}, {\"truth_threshold\": 36.27999918907881, \"match_probability\": 0.9999999999880151, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14386.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.047328440161731274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9526715598382687, \"precision\": 1.0, \"recall\": 0.047328440161731274, \"specificity\": 1.0, \"npv\": 0.9997735974948846, \"accuracy\": 0.9997736000413429, \"f1\": 0.09037936591203938, \"f2\": 0.05846874161742113, \"f0_5\": 0.19897373480311475, \"p4\": 0.16577444607174116, \"phi\": 0.217526377444933}, {\"truth_threshold\": 36.29999918863177, \"match_probability\": 0.9999999999881801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14350.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.047210003914975936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.952789996085024, \"precision\": 1.0, \"recall\": 0.047210003914975936, \"specificity\": 1.0, \"npv\": 0.9997735693548702, \"accuracy\": 0.9997735718952718, \"f1\": 0.09016339366217316, \"f2\": 0.05832413424224147, \"f0_5\": 0.19855490769618195, \"p4\": 0.16541107460978774, \"phi\": 0.21725403131664295}, {\"truth_threshold\": 36.31999918818474, \"match_probability\": 0.9999999999883429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14295.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289666.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04702905964909972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9529709403509002, \"precision\": 1.0, \"recall\": 0.04702905964909972, \"specificity\": 1.0, \"npv\": 0.9997735263631846, \"accuracy\": 0.99977352889433, \"f1\": 0.0898333417123322, \"f2\": 0.0581031899647113, \"f0_5\": 0.19791438800911557, \"p4\": 0.16485548678447798, \"phi\": 0.216837286477499}, {\"truth_threshold\": 36.3399991877377, \"match_probability\": 0.9999999999885034, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14255.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289706.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.046897463819371564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9531025361806285, \"precision\": 1.0, \"recall\": 0.046897463819371564, \"specificity\": 1.0, \"npv\": 0.9997734950965065, \"accuracy\": 0.9997734976209178, \"f1\": 0.08959323226990472, \"f2\": 0.05794249080765044, \"f0_5\": 0.19744806513362198, \"p4\": 0.16445109076191153, \"phi\": 0.21653369556227287}, {\"truth_threshold\": 36.35999918729067, \"match_probability\": 0.9999999999886616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14219.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289742.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.046779027572616226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9532209724273838, \"precision\": 1.0, \"recall\": 0.046779027572616226, \"specificity\": 1.0, \"npv\": 0.9997734669564979, \"accuracy\": 0.9997734694748468, \"f1\": 0.08937708215475516, \"f2\": 0.05779785263031243, \"f0_5\": 0.1970280209623736, \"p4\": 0.16408689492270578, \"phi\": 0.21626009936446466}, {\"truth_threshold\": 36.379999186843634, \"match_probability\": 0.9999999999888177, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14156.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289805.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04657176414079438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9534282358592057, \"precision\": 1.0, \"recall\": 0.04657176414079438, \"specificity\": 1.0, \"npv\": 0.9997734177114866, \"accuracy\": 0.9997734202192226, \"f1\": 0.08899870173552497, \"f2\": 0.05754471544715447, \"f0_5\": 0.1962921363894782, \"p4\": 0.1634490057664981, \"phi\": 0.21578047132188596}, {\"truth_threshold\": 36.3999991863966, \"match_probability\": 0.9999999999889717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14118.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04644674810255263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9535532518974473, \"precision\": 1.0, \"recall\": 0.04644674810255263, \"specificity\": 1.0, \"npv\": 0.9997733880081489, \"accuracy\": 0.9997733905094809, \"f1\": 0.08877039980633741, \"f2\": 0.05739201698914275, \"f0_5\": 0.19584777198536205, \"p4\": 0.16306391057292216, \"phi\": 0.21549065574277254}, {\"truth_threshold\": 36.419999185949564, \"match_probability\": 0.9999999999891236, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14075.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289886.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04630528258559486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9536947174144051, \"precision\": 1.0, \"recall\": 0.04630528258559486, \"specificity\": 1.0, \"npv\": 0.9997733543964793, \"accuracy\": 0.9997733568905628, \"f1\": 0.08851199235306695, \"f2\": 0.05721921524913429, \"f0_5\": 0.19534448635850118, \"p4\": 0.16262783906220796, \"phi\": 0.21516223575915233}, {\"truth_threshold\": 36.43999918550253, \"match_probability\": 0.9999999999892732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14028.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04615065748566428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9538493425143357, \"precision\": 1.0, \"recall\": 0.04615065748566428, \"specificity\": 1.0, \"npv\": 0.9997733176581454, \"accuracy\": 0.9997733201443034, \"f1\": 0.08822946705703656, \"f2\": 0.057030325107003, \"f0_5\": 0.19479383347265694, \"p4\": 0.16215083084477847, \"phi\": 0.21480269073395544}, {\"truth_threshold\": 36.459999185055494, \"match_probability\": 0.9999999999894209, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13980.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04599274248999049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9540072575100095, \"precision\": 1.0, \"recall\": 0.04599274248999049, \"specificity\": 1.0, \"npv\": 0.9997732801381476, \"accuracy\": 0.9997732826162087, \"f1\": 0.08794084437049642, \"f2\": 0.05683740112406328, \"f0_5\": 0.1942308707600568, \"p4\": 0.16166327210676495, \"phi\": 0.2144348736138013}, {\"truth_threshold\": 36.47999918460846, \"match_probability\": 0.9999999999895666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13916.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290045.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04578218916242544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9542178108375745, \"precision\": 1.0, \"recall\": 0.04578218916242544, \"specificity\": 1.0, \"npv\": 0.9997732301114882, \"accuracy\": 0.9997732325787492, \"f1\": 0.08755587853163331, \"f2\": 0.05658014571948998, \"f0_5\": 0.19347931873479318, \"p4\": 0.16101256193103025, \"phi\": 0.2139434671601198}, {\"truth_threshold\": 36.499999184161425, \"match_probability\": 0.9999999999897102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13874.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04564401354121088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9543559864587892, \"precision\": 1.0, \"recall\": 0.04564401354121088, \"specificity\": 1.0, \"npv\": 0.9997731972814957, \"accuracy\": 0.9997731997416663, \"f1\": 0.08730316044488493, \"f2\": 0.05641130730785432, \"f0_5\": 0.19298553095363283, \"p4\": 0.16058514041021665, \"phi\": 0.21362036736897605}, {\"truth_threshold\": 36.51999918371439, \"match_probability\": 0.9999999999898519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13842.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.045538736877428355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9544612631225716, \"precision\": 1.0, \"recall\": 0.045538736877428355, \"specificity\": 1.0, \"npv\": 0.9997731722681695, \"accuracy\": 0.9997731747229365, \"f1\": 0.08711056849683609, \"f2\": 0.05628266077681619, \"f0_5\": 0.19260900177831458, \"p4\": 0.1602592766496636, \"phi\": 0.21337386772759223}, {\"truth_threshold\": 36.539999183267355, \"match_probability\": 0.9999999999899916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13763.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290198.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04527883511371525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9547211648862848, \"precision\": 1.0, \"recall\": 0.04527883511371525, \"specificity\": 1.0, \"npv\": 0.999773110516526, \"accuracy\": 0.9997731129579474, \"f1\": 0.08663494101799046, \"f2\": 0.055965035983041735, \"f0_5\": 0.1916782957720194, \"p4\": 0.15945402451300106, \"phi\": 0.21276409899746712}, {\"truth_threshold\": 36.55999918282032, \"match_probability\": 0.9999999999901295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13717.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290244.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.045127499909527864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9548725000904721, \"precision\": 1.0, \"recall\": 0.045127499909527864, \"specificity\": 1.0, \"npv\": 0.9997730745598762, \"accuracy\": 0.9997730769935232, \"f1\": 0.08635788439866783, \"f2\": 0.05578007109854655, \"f0_5\": 0.19113561055544562, \"p4\": 0.15898463400414614, \"phi\": 0.21240823743854476}, {\"truth_threshold\": 36.579999182373285, \"match_probability\": 0.9999999999902653, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13665.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290296.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04495642533088126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9550435746691187, \"precision\": 1.0, \"recall\": 0.04495642533088126, \"specificity\": 1.0, \"npv\": 0.9997730339132318, \"accuracy\": 0.9997730363380873, \"f1\": 0.08604459332674277, \"f2\": 0.05557096369363705, \"f0_5\": 0.19052146974103581, \"p4\": 0.15845356638537272, \"phi\": 0.2120052399044628}, {\"truth_threshold\": 36.59999918192625, \"match_probability\": 0.9999999999903993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13627.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290334.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04483140929263952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9551685907073605, \"precision\": 1.0, \"recall\": 0.04483140929263952, \"specificity\": 1.0, \"npv\": 0.9997730042099168, \"accuracy\": 0.9997730066283458, \"f1\": 0.08581558497172437, \"f2\": 0.05541814325022713, \"f0_5\": 0.19007222381851707, \"p4\": 0.15806517463205527, \"phi\": 0.21171025660431897}, {\"truth_threshold\": 36.619999181479216, \"match_probability\": 0.9999999999905315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13558.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290403.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.044604406486358446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9553955935136416, \"precision\": 1.0, \"recall\": 0.044604406486358446, \"specificity\": 1.0, \"npv\": 0.9997729502749546, \"accuracy\": 0.9997729526817096, \"f1\": 0.08539961388137403, \"f2\": 0.05514062934662543, \"f0_5\": 0.18925551308931218, \"p4\": 0.15735928006324845, \"phi\": 0.2111735756862821}, {\"truth_threshold\": 36.63999918103218, \"match_probability\": 0.9999999999906618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13505.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290456.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04443004201196864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9555699579880313, \"precision\": 1.0, \"recall\": 0.04443004201196864, \"specificity\": 1.0, \"npv\": 0.9997729088466544, \"accuracy\": 0.9997729112444385, \"f1\": 0.08507997706841047, \"f2\": 0.05492744533895582, \"f0_5\": 0.18862732938340304, \"p4\": 0.1568164950695492, \"phi\": 0.21076041455283995}, {\"truth_threshold\": 36.659999180585146, \"match_probability\": 0.9999999999907904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13412.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290549.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.044124081707850676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9558759182921494, \"precision\": 1.0, \"recall\": 0.044124081707850676, \"specificity\": 1.0, \"npv\": 0.9997728361517206, \"accuracy\": 0.9997728385337551, \"f1\": 0.08451884690884227, \"f2\": 0.054553323311010884, \"f0_5\": 0.18752324466106837, \"p4\": 0.15586284895395344, \"phi\": 0.2100334695034297}, {\"truth_threshold\": 36.67999918013811, \"match_probability\": 0.9999999999909172, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13356.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290605.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04393984754623126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9560601524537687, \"precision\": 1.0, \"recall\": 0.04393984754623126, \"specificity\": 1.0, \"npv\": 0.9997727923784322, \"accuracy\": 0.9997727947509779, \"f1\": 0.08418080342370564, \"f2\": 0.054328018223234624, \"f0_5\": 0.18685731074331602, \"p4\": 0.15528786427506122, \"phi\": 0.20959452301522158}, {\"truth_threshold\": 36.699999179691076, \"match_probability\": 0.9999999999910423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13300.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290661.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04375561338461184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9562443866153881, \"precision\": 1.0, \"recall\": 0.04375561338461184, \"specificity\": 1.0, \"npv\": 0.9997727486051478, \"accuracy\": 0.9997727509682008, \"f1\": 0.0838426406019019, \"f2\": 0.05410269260558567, \"f0_5\": 0.18619054152049075, \"p4\": 0.1547123177227541, \"phi\": 0.20915465536400946}, {\"truth_threshold\": 36.71999917924404, \"match_probability\": 0.9999999999911655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13236.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.043545060057046794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9564549399429532, \"precision\": 1.0, \"recall\": 0.043545060057046794, \"specificity\": 1.0, \"npv\": 0.9997726985785416, \"accuracy\": 0.9997727009307412, \"f1\": 0.08345602259794387, \"f2\": 0.0538451524717675, \"f0_5\": 0.18542749471147785, \"p4\": 0.15405386116901146, \"phi\": 0.20865081404825223}, {\"truth_threshold\": 36.73999917879701, \"match_probability\": 0.9999999999912872, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13194.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290767.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04340688443583223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9565931155641678, \"precision\": 1.0, \"recall\": 0.04340688443583223, \"specificity\": 1.0, \"npv\": 0.9997726657485839, \"accuracy\": 0.9997726680936584, \"f1\": 0.08320221973482997, \"f2\": 0.05367612718239794, \"f0_5\": 0.18492615007694743, \"p4\": 0.15362134904789132, \"phi\": 0.2083195059620023}, {\"truth_threshold\": 36.75999917834997, \"match_probability\": 0.9999999999914071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13169.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04332463704225213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9566753629577479, \"precision\": 1.0, \"recall\": 0.04332463704225213, \"specificity\": 1.0, \"npv\": 0.9997726462069436, \"accuracy\": 0.9997726485477757, \"f1\": 0.08305111468482956, \"f2\": 0.053575511406307334, \"f0_5\": 0.18462750640006506, \"p4\": 0.15336375068746488, \"phi\": 0.20812204837952125}, {\"truth_threshold\": 36.77999917790294, \"match_probability\": 0.9999999999915254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13146.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290815.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04324896944015844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9567510305598416, \"precision\": 1.0, \"recall\": 0.04324896944015844, \"specificity\": 1.0, \"npv\": 0.9997726282286351, \"accuracy\": 0.9997726305655638, \"f1\": 0.0829120769960928, \"f2\": 0.05348294127698354, \"f0_5\": 0.18435260626288408, \"p4\": 0.1531266608109852, \"phi\": 0.20794022180753566}, {\"truth_threshold\": 36.7999991774559, \"match_probability\": 0.9999999999916421, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13115.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290846.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04314698267211912, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9568530173278809, \"precision\": 1.0, \"recall\": 0.04314698267211912, \"specificity\": 1.0, \"npv\": 0.999772603997003, \"accuracy\": 0.9997726063286693, \"f1\": 0.08272464645700084, \"f2\": 0.05335816735952949, \"f0_5\": 0.18398186414380746, \"p4\": 0.15280695408873238, \"phi\": 0.20769489936134228}, {\"truth_threshold\": 36.81999917700887, \"match_probability\": 0.9999999999917571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13074.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290887.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04301209694664776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9569879030533522, \"precision\": 1.0, \"recall\": 0.04301209694664776, \"specificity\": 1.0, \"npv\": 0.999772571948717, \"accuracy\": 0.9997725742734217, \"f1\": 0.08247669815635497, \"f2\": 0.05319313412286255, \"f0_5\": 0.18349113140233034, \"p4\": 0.15238385001486673, \"phi\": 0.20736999491068517}, {\"truth_threshold\": 36.83999917656183, \"match_probability\": 0.9999999999918706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13015.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290946.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04281799309779873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9571820069022012, \"precision\": 1.0, \"recall\": 0.04281799309779873, \"specificity\": 1.0, \"npv\": 0.9997725258304556, \"accuracy\": 0.9997725281451386, \"f1\": 0.08211978193932663, \"f2\": 0.05295562794429629, \"f0_5\": 0.18278416160844443, \"p4\": 0.15177446038229842, \"phi\": 0.20690155415167197}, {\"truth_threshold\": 36.8599991761148, \"match_probability\": 0.9999999999919826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12956.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291005.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0426238892489497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9573761107510503, \"precision\": 1.0, \"recall\": 0.0426238892489497, \"specificity\": 1.0, \"npv\": 0.9997724797121984, \"accuracy\": 0.9997724820168556, \"f1\": 0.08176273282910036, \"f2\": 0.052718098958333334, \"f0_5\": 0.18207625391739393, \"p4\": 0.15116444146551772, \"phi\": 0.20643205044130275}, {\"truth_threshold\": 36.87999917566776, \"match_probability\": 0.999999999992093, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12914.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042485713627735136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9575142863722649, \"precision\": 1.0, \"recall\": 0.042485713627735136, \"specificity\": 1.0, \"npv\": 0.9997724468822552, \"accuracy\": 0.9997724491797728, \"f1\": 0.08150848126232742, \"f2\": 0.05254899662911656, \"f0_5\": 0.18157174713244867, \"p4\": 0.15072980674641132, \"phi\": 0.20609717579612663}, {\"truth_threshold\": 36.89999917522073, \"match_probability\": 0.9999999999922018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12857.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291104.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04229818957037251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9577018104296274, \"precision\": 1.0, \"recall\": 0.04229818957037251, \"specificity\": 1.0, \"npv\": 0.9997724023273357, \"accuracy\": 0.9997724046151604, \"f1\": 0.08116331774078493, \"f2\": 0.052319482119734584, \"f0_5\": 0.18088629642448134, \"p4\": 0.15013943385866987, \"phi\": 0.20564183086344176}, {\"truth_threshold\": 36.91999917477369, \"match_probability\": 0.9999999999923092, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12814.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042156724053414744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9578432759465852, \"precision\": 1.0, \"recall\": 0.042156724053414744, \"specificity\": 1.0, \"npv\": 0.9997723687157324, \"accuracy\": 0.9997723709962422, \"f1\": 0.08090284902533344, \"f2\": 0.052146325503109894, \"f0_5\": 0.18036861974511356, \"p4\": 0.14969367459982613, \"phi\": 0.20529765674302752}, {\"truth_threshold\": 36.93999917432666, \"match_probability\": 0.9999999999924151, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12791.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291170.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042081056451321056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9579189435486789, \"precision\": 1.0, \"recall\": 0.042081056451321056, \"specificity\": 1.0, \"npv\": 0.9997723507374339, \"accuracy\": 0.9997723530140302, \"f1\": 0.08076349952012932, \"f2\": 0.052053701872403116, \"f0_5\": 0.1800915170714537, \"p4\": 0.14945510731712505, \"phi\": 0.2051133265535224}, {\"truth_threshold\": 36.95999917387962, \"match_probability\": 0.9999999999925194, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12766.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291195.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04199880905774096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.958001190942259, \"precision\": 1.0, \"recall\": 0.04199880905774096, \"specificity\": 1.0, \"npv\": 0.9997723311958058, \"accuracy\": 0.9997723334681475, \"f1\": 0.08061200971183385, \"f2\": 0.051953020079602154, \"f0_5\": 0.17979015562284345, \"p4\": 0.14919568594525148, \"phi\": 0.2049127795895249}, {\"truth_threshold\": 36.97999917343259, \"match_probability\": 0.9999999999926225, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12716.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291245.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.041834314270580764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9581656857294192, \"precision\": 1.0, \"recall\": 0.041834314270580764, \"specificity\": 1.0, \"npv\": 0.9997722921125519, \"accuracy\": 0.9997722943763823, \"f1\": 0.0803089583392542, \"f2\": 0.05175164420134141, \"f0_5\": 0.17918692313112097, \"p4\": 0.14867650194574933, \"phi\": 0.2045110957069454}, {\"truth_threshold\": 36.999999172985554, \"match_probability\": 0.999999999992724, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12673.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291288.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.041692848753622995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.958307151246377, \"precision\": 1.0, \"recall\": 0.041692848753622995, \"specificity\": 1.0, \"npv\": 0.9997722585009561, \"accuracy\": 0.9997722607574641, \"f1\": 0.08004825760973237, \"f2\": 0.051578447835886686, \"f0_5\": 0.1786675990334214, \"p4\": 0.14822963941429887, \"phi\": 0.2041650155186937}, {\"truth_threshold\": 37.01999917253852, \"match_probability\": 0.9999999999928242, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12597.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291364.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.041442816677139505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9585571833228606, \"precision\": 1.0, \"recall\": 0.041442816677139505, \"specificity\": 1.0, \"npv\": 0.99977219909442, \"accuracy\": 0.9997722013379808, \"f1\": 0.07958731101409536, \"f2\": 0.051272303675960015, \"f0_5\": 0.17774849089457004, \"p4\": 0.14743901077808264, \"phi\": 0.2035518999321074}, {\"truth_threshold\": 37.039999172091484, \"match_probability\": 0.999999999992923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12533.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04123226334957445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9587677366504256, \"precision\": 1.0, \"recall\": 0.04123226334957445, \"specificity\": 1.0, \"npv\": 0.9997721490678688, \"accuracy\": 0.9997721513005213, \"f1\": 0.07919897375621655, \"f2\": 0.05101446868510238, \"f0_5\": 0.17697328103068968, \"p4\": 0.14677239949945767, \"phi\": 0.20303415609186642}, {\"truth_threshold\": 37.05999917164445, \"match_probability\": 0.9999999999930205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12484.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291477.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.041071058458157464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9589289415418425, \"precision\": 1.0, \"recall\": 0.041071058458157464, \"specificity\": 1.0, \"npv\": 0.999772110766294, \"accuracy\": 0.9997721129905913, \"f1\": 0.07890154687228429, \"f2\": 0.05081704560996737, \"f0_5\": 0.17637900293023112, \"p4\": 0.14626151844141064, \"phi\": 0.20263686438088685}, {\"truth_threshold\": 37.079999171197414, \"match_probability\": 0.9999999999931165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12428.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291533.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04088682429653804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.959113175703462, \"precision\": 1.0, \"recall\": 0.04088682429653804, \"specificity\": 1.0, \"npv\": 0.9997720669930691, \"accuracy\": 0.9997720692078143, \"f1\": 0.07856151762545474, \"f2\": 0.05059139995049956, \"f0_5\": 0.17569902141243465, \"p4\": 0.14567711538297728, \"phi\": 0.20218186080786843}, {\"truth_threshold\": 37.09999917075038, \"match_probability\": 0.9999999999932113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12391.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291570.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.040765098154039496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9592349018459605, \"precision\": 1.0, \"recall\": 0.040765098154039496, \"specificity\": 1.0, \"npv\": 0.9997720380714763, \"accuracy\": 0.9997720402799078, \"f1\": 0.07833678939915031, \"f2\": 0.050442301351125804, \"f0_5\": 0.1752492751573439, \"p4\": 0.14529067611935542, \"phi\": 0.20188067085198586}, {\"truth_threshold\": 37.119999170303345, \"match_probability\": 0.9999999999933048, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12348.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291613.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04062363263708173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9593763673629183, \"precision\": 1.0, \"recall\": 0.04062363263708173, \"specificity\": 1.0, \"npv\": 0.9997720044598974, \"accuracy\": 0.9997720066609898, \"f1\": 0.0780755527032111, \"f2\": 0.050269013313879264, \"f0_5\": 0.17472612373462232, \"p4\": 0.14484125492889421, \"phi\": 0.20153007376076087}, {\"truth_threshold\": 37.13999916985631, \"match_probability\": 0.999999999993397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12291.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04043610857971911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9595638914202809, \"precision\": 1.0, \"recall\": 0.04043610857971911, \"specificity\": 1.0, \"npv\": 0.9997719599050174, \"accuracy\": 0.9997719620963773, \"f1\": 0.07772915270101059, \"f2\": 0.05003928721191074, \"f0_5\": 0.17403185840707966, \"p4\": 0.1442449861576306, \"phi\": 0.2010643865175478}, {\"truth_threshold\": 37.159999169409275, \"match_probability\": 0.9999999999934879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12245.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291716.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04028477337553173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9597152266244683, \"precision\": 1.0, \"recall\": 0.04028477337553173, \"specificity\": 1.0, \"npv\": 0.9997719239484505, \"accuracy\": 0.9997719261319532, \"f1\": 0.07744951076197162, \"f2\": 0.0498538786684027, \"f0_5\": 0.17347092006879336, \"p4\": 0.1437633503398316, \"phi\": 0.20068778085245417}, {\"truth_threshold\": 37.17999916896224, \"match_probability\": 0.9999999999935775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12195.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291766.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.040120278588371534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9598797214116285, \"precision\": 1.0, \"recall\": 0.040120278588371534, \"specificity\": 1.0, \"npv\": 0.9997718848652284, \"accuracy\": 0.9997718870401879, \"f1\": 0.07714545983628335, \"f2\": 0.04965233188848237, \"f0_5\": 0.17286054073668783, \"p4\": 0.14323939038064856, \"phi\": 0.20027762367677093}, {\"truth_threshold\": 37.199999168515205, \"match_probability\": 0.999999999993666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12159.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.040001842341616196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9599981576583838, \"precision\": 1.0, \"recall\": 0.040001842341616196, \"specificity\": 1.0, \"npv\": 0.9997718567253104, \"accuracy\": 0.999771858894117, \"f1\": 0.07692648361381754, \"f2\": 0.04950720804428002, \"f0_5\": 0.1724206388596613, \"p4\": 0.14286185329379153, \"phi\": 0.1999817896467345}, {\"truth_threshold\": 37.21999916806817, \"match_probability\": 0.9999999999937531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12103.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291858.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03981760817999678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9601823918200032, \"precision\": 1.0, \"recall\": 0.03981760817999678, \"specificity\": 1.0, \"npv\": 0.9997718129521078, \"accuracy\": 0.9997718151113398, \"f1\": 0.07658575478384125, \"f2\": 0.04928144292872575, \"f0_5\": 0.171735632412245, \"p4\": 0.1422740969969111, \"phi\": 0.19952073154820793}, {\"truth_threshold\": 37.239999167621136, \"match_probability\": 0.9999999999938392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12078.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03973536078641668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9602646392135833, \"precision\": 1.0, \"recall\": 0.03973536078641668, \"specificity\": 1.0, \"npv\": 0.9997717934105008, \"accuracy\": 0.9997717955654571, \"f1\": 0.07643360471334235, \"f2\": 0.04918064828221988, \"f0_5\": 0.17142954469970734, \"p4\": 0.1420115183564183, \"phi\": 0.19931455771029144}, {\"truth_threshold\": 37.2599991671741, \"match_probability\": 0.999999999993924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12024.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.039557706416283665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9604422935837164, \"precision\": 1.0, \"recall\": 0.039557706416283665, \"specificity\": 1.0, \"npv\": 0.9997717512006322, \"accuracy\": 0.9997717533463507, \"f1\": 0.0761048783961264, \"f2\": 0.0489629178380738, \"f0_5\": 0.17076780180482137, \"p4\": 0.1414439531563132, \"phi\": 0.19886849277170177}, {\"truth_threshold\": 37.279999166727066, \"match_probability\": 0.9999999999940076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11981.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291980.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.039416240899325904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9605837591006741, \"precision\": 1.0, \"recall\": 0.039416240899325904, \"specificity\": 1.0, \"npv\": 0.9997717175890727, \"accuracy\": 0.9997717197274325, \"f1\": 0.07584303448101233, \"f2\": 0.04878952619469387, \"f0_5\": 0.17024027736334313, \"p4\": 0.1409916161404672, \"phi\": 0.1985125760873192}, {\"truth_threshold\": 37.29999916628003, \"match_probability\": 0.9999999999940901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11928.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.039241876424936095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.960758123575064, \"precision\": 1.0, \"recall\": 0.039241876424936095, \"specificity\": 1.0, \"npv\": 0.9997716761608745, \"accuracy\": 0.9997716782901613, \"f1\": 0.07552019855075676, \"f2\": 0.04857579420283245, \"f0_5\": 0.16958936284559803, \"p4\": 0.14043361182413394, \"phi\": 0.19807300817894463}, {\"truth_threshold\": 37.319999165832996, \"match_probability\": 0.9999999999941714, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11885.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292076.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03910041090797833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9608995890920217, \"precision\": 1.0, \"recall\": 0.03910041090797833, \"specificity\": 1.0, \"npv\": 0.99977164254932, \"accuracy\": 0.9997716446712432, \"f1\": 0.07525819544968117, \"f2\": 0.04840237544278909, \"f0_5\": 0.1690606854603543, \"p4\": 0.1399805074029667, \"phi\": 0.197715659566517}, {\"truth_threshold\": 37.33999916538596, \"match_probability\": 0.9999999999942517, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11843.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03896223528676376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9610377647132362, \"precision\": 1.0, \"recall\": 0.03896223528676376, \"specificity\": 1.0, \"npv\": 0.9997716097194318, \"accuracy\": 0.9997716118341603, \"f1\": 0.0750022165647047, \"f2\": 0.04823297794959139, \"f0_5\": 0.16854380317248877, \"p4\": 0.1395376078494727, \"phi\": 0.1973659967950788}, {\"truth_threshold\": 37.35999916493893, \"match_probability\": 0.9999999999943309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11805.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.038837219248522015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.961162780751478, \"precision\": 1.0, \"recall\": 0.038837219248522015, \"specificity\": 1.0, \"npv\": 0.9997715800162015, \"accuracy\": 0.9997715821244187, \"f1\": 0.07477055794480723, \"f2\": 0.048079703563477835, \"f0_5\": 0.1680757216364211, \"p4\": 0.13913660580805615, \"phi\": 0.1970491006108135}, {\"truth_threshold\": 37.37999916449189, \"match_probability\": 0.9999999999944089, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11734.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292227.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03860363665075454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9613963633492455, \"precision\": 1.0, \"recall\": 0.03860363665075454, \"specificity\": 1.0, \"npv\": 0.9997715245180653, \"accuracy\": 0.9997715266141121, \"f1\": 0.07433757265715327, \"f2\": 0.047793297045075754, \"f0_5\": 0.16720006155652514, \"p4\": 0.13838664273559426, \"phi\": 0.1964556353639832}, {\"truth_threshold\": 37.39999916404486, \"match_probability\": 0.9999999999944859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11713.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292248.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03853454884014726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9614654511598527, \"precision\": 1.0, \"recall\": 0.03853454884014726, \"specificity\": 1.0, \"npv\": 0.9997715081031248, \"accuracy\": 0.9997715101955706, \"f1\": 0.07420946926259368, \"f2\": 0.04770857890916674, \"f0_5\": 0.1669407918178631, \"p4\": 0.1381646421171435, \"phi\": 0.19627975954740604}, {\"truth_threshold\": 37.41999916359782, \"match_probability\": 0.9999999999945618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11684.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292277.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.038439141863594345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9615608581364057, \"precision\": 1.0, \"recall\": 0.038439141863594345, \"specificity\": 1.0, \"npv\": 0.9997714854348745, \"accuracy\": 0.9997714875223468, \"f1\": 0.07403253655213927, \"f2\": 0.04759158243233556, \"f0_5\": 0.16658254846776563, \"p4\": 0.1378579341798812, \"phi\": 0.19603662402675573}, {\"truth_threshold\": 37.43999916315079, \"match_probability\": 0.9999999999946366, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11659.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.038356894470014245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9616431055299858, \"precision\": 1.0, \"recall\": 0.038356894470014245, \"specificity\": 1.0, \"npv\": 0.9997714658932803, \"accuracy\": 0.9997714679764641, \"f1\": 0.07387998225714466, \"f2\": 0.047490718963619644, \"f0_5\": 0.16627352772556525, \"p4\": 0.13759340440269202, \"phi\": 0.19582678216066363}, {\"truth_threshold\": 37.45999916270375, \"match_probability\": 0.9999999999947105, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11596.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292365.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0381496310381924, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9618503689618076, \"precision\": 1.0, \"recall\": 0.0381496310381924, \"specificity\": 1.0, \"npv\": 0.9997714166484661, \"accuracy\": 0.9997714187208399, \"f1\": 0.07349543822510672, \"f2\": 0.047236524799582874, \"f0_5\": 0.16549401304428493, \"p4\": 0.13692626981349793, \"phi\": 0.19529698069266177}, {\"truth_threshold\": 37.47999916225672, \"match_probability\": 0.9999999999947833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11536.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.037952237293600165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9620477627063998, \"precision\": 1.0, \"recall\": 0.037952237293600165, \"specificity\": 1.0, \"npv\": 0.9997713697486477, \"accuracy\": 0.9997713718107215, \"f1\": 0.07312906303387988, \"f2\": 0.046994410858902706, \"f0_5\": 0.16475057482755173, \"p4\": 0.13629021102134284, \"phi\": 0.1947910682347842}, {\"truth_threshold\": 37.49999916180968, \"match_probability\": 0.9999999999948551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11491.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292470.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03780419198515599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9621958080148441, \"precision\": 1.0, \"recall\": 0.03780419198515599, \"specificity\": 1.0, \"npv\": 0.9997713345737866, \"accuracy\": 0.9997713366281328, \"f1\": 0.07285419017790346, \"f2\": 0.0468128098685363, \"f0_5\": 0.16419232692719868, \"p4\": 0.1358127228872625, \"phi\": 0.19441076995239503}, {\"truth_threshold\": 37.51999916136265, \"match_probability\": 0.999999999994926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11467.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292494.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0377252344873191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9622747655126809, \"precision\": 1.0, \"recall\": 0.0377252344873191, \"specificity\": 1.0, \"npv\": 0.9997713158138618, \"accuracy\": 0.9997713178640854, \"f1\": 0.07270755925282474, \"f2\": 0.046715950561838034, \"f0_5\": 0.16389435981579573, \"p4\": 0.13555790674563856, \"phi\": 0.19420763971268867}, {\"truth_threshold\": 37.53999916091561, \"match_probability\": 0.9999999999949958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11418.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.037564029595902104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9624359704040979, \"precision\": 1.0, \"recall\": 0.037564029595902104, \"specificity\": 1.0, \"npv\": 0.9997712775123508, \"accuracy\": 0.9997712795541555, \"f1\": 0.07240811848601207, \"f2\": 0.046518184381167185, \"f0_5\": 0.16328550222662047, \"p4\": 0.13503732023166629, \"phi\": 0.19379225437980435}, {\"truth_threshold\": 37.55999916046858, \"match_probability\": 0.9999999999950647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11381.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292580.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03744230345340356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9625576965465964, \"precision\": 1.0, \"recall\": 0.03744230345340356, \"specificity\": 1.0, \"npv\": 0.9997712485908036, \"accuracy\": 0.999771250626249, \"f1\": 0.0721819484876737, \"f2\": 0.04636884026971419, \"f0_5\": 0.16282530008440993, \"p4\": 0.1346439243106839, \"phi\": 0.19347800514199293}, {\"truth_threshold\": 37.57999916002154, \"match_probability\": 0.9999999999951327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11348.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292613.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03733373689387783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9626662631061221, \"precision\": 1.0, \"recall\": 0.03733373689387783, \"specificity\": 1.0, \"npv\": 0.9997712227959116, \"accuracy\": 0.999771224825684, \"f1\": 0.07198018451740991, \"f2\": 0.046235633869842696, \"f0_5\": 0.1624145205565717, \"p4\": 0.1342928396740353, \"phi\": 0.19319729756374202}, {\"truth_threshold\": 37.59999915957451, \"match_probability\": 0.9999999999951996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11298.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292663.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03716924210671764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9628307578932823, \"precision\": 1.0, \"recall\": 0.03716924210671764, \"specificity\": 1.0, \"npv\": 0.9997711837127443, \"accuracy\": 0.9997711857339188, \"f1\": 0.07167440104802718, \"f2\": 0.04603379234025076, \"f0_5\": 0.1617915355159486, \"p4\": 0.13376050118454272, \"phi\": 0.19277120422599084}, {\"truth_threshold\": 37.619999159127474, \"match_probability\": 0.9999999999952658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11252.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292709.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03701790690253026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9629820930974697, \"precision\": 1.0, \"recall\": 0.03701790690253026, \"specificity\": 1.0, \"npv\": 0.9997711477562332, \"accuracy\": 0.9997711497694947, \"f1\": 0.0713929945782693, \"f2\": 0.04584808360552067, \"f0_5\": 0.16121775859746854, \"p4\": 0.13327033209546246, \"phi\": 0.19237836487369378}, {\"truth_threshold\": 37.63999915868044, \"match_probability\": 0.999999999995331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11219.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292742.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03690934034300453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9630906596569955, \"precision\": 1.0, \"recall\": 0.03690934034300453, \"specificity\": 1.0, \"npv\": 0.9997711219613464, \"accuracy\": 0.9997711239689295, \"f1\": 0.07119106542293292, \"f2\": 0.045714849196822005, \"f0_5\": 0.16080576315012457, \"p4\": 0.132918442192615, \"phi\": 0.192096050468454}, {\"truth_threshold\": 37.659999158233404, \"match_probability\": 0.9999999999953952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11201.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03685012221962686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9631498777803731, \"precision\": 1.0, \"recall\": 0.03685012221962686, \"specificity\": 1.0, \"npv\": 0.9997711078914087, \"accuracy\": 0.999771109895894, \"f1\": 0.07108090442375667, \"f2\": 0.04564217286244596, \"f0_5\": 0.16058090691439794, \"p4\": 0.13272641524388806, \"phi\": 0.19194188578173907}, {\"truth_threshold\": 37.67999915778637, \"match_probability\": 0.9999999999954586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11159.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.036711946598412294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9632880534015877, \"precision\": 1.0, \"recall\": 0.036711946598412294, \"specificity\": 1.0, \"npv\": 0.9997710750615556, \"accuracy\": 0.9997710770588112, \"f1\": 0.07082381315054583, \"f2\": 0.04547258645659383, \"f0_5\": 0.1600558811464241, \"p4\": 0.1322781133377899, \"phi\": 0.1915816857590962}, {\"truth_threshold\": 37.699999157339334, \"match_probability\": 0.9999999999955211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11115.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292846.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03656719118571133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9634328088142887, \"precision\": 1.0, \"recall\": 0.03656719118571133, \"specificity\": 1.0, \"npv\": 0.9997710406683784, \"accuracy\": 0.9997710426580578, \"f1\": 0.07055440592111109, \"f2\": 0.04529491205492604, \"f0_5\": 0.1595053111035213, \"p4\": 0.13180810447184652, \"phi\": 0.19120360557808044}, {\"truth_threshold\": 37.7199991568923, \"match_probability\": 0.9999999999955828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11066.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03640598629429433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9635940137057056, \"precision\": 1.0, \"recall\": 0.03640598629429433, \"specificity\": 1.0, \"npv\": 0.9997710023668884, \"accuracy\": 0.9997710043481278, \"f1\": 0.0702542956635463, \"f2\": 0.045097032382163324, \"f0_5\": 0.1588915212865245, \"p4\": 0.13128425234970748, \"phi\": 0.19078167996325499}, {\"truth_threshold\": 37.739999156445265, \"match_probability\": 0.9999999999956436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11033.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.036297419734768605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9637025802652314, \"precision\": 1.0, \"recall\": 0.036297419734768605, \"specificity\": 1.0, \"npv\": 0.9997709765720092, \"accuracy\": 0.9997709785475627, \"f1\": 0.07005212797704083, \"f2\": 0.04496375757309005, \"f0_5\": 0.1584777631265208, \"p4\": 0.13093119647907955, \"phi\": 0.19049699938653553}, {\"truth_threshold\": 37.75999915599823, \"match_probability\": 0.9999999999957035, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11010.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.036221752132674916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9637782478673251, \"precision\": 1.0, \"recall\": 0.036221752132674916, \"specificity\": 1.0, \"npv\": 0.9997709585937608, \"accuracy\": 0.9997709605653506, \"f1\": 0.06991119817380012, \"f2\": 0.04487086482988196, \"f0_5\": 0.15818920060574537, \"p4\": 0.1306850045554004, \"phi\": 0.19029833381201738}, {\"truth_threshold\": 37.779999155551195, \"match_probability\": 0.9999999999957627, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10966.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292995.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03607699671997394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.963923003280026, \"precision\": 1.0, \"recall\": 0.03607699671997394, \"specificity\": 1.0, \"npv\": 0.9997709242005915, \"accuracy\": 0.9997709261645972, \"f1\": 0.06964153597500373, \"f2\": 0.04469314726811813, \"f0_5\": 0.15763674261482066, \"p4\": 0.13021374765771312, \"phi\": 0.18991769889378418}, {\"truth_threshold\": 37.79999915510416, \"match_probability\": 0.999999999995821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10921.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03592895141152977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9640710485884703, \"precision\": 1.0, \"recall\": 0.03592895141152977, \"specificity\": 1.0, \"npv\": 0.9997708890257619, \"accuracy\": 0.9997708909820084, \"f1\": 0.0693656671388012, \"f2\": 0.04451137748468533, \"f0_5\": 0.157071150167556, \"p4\": 0.1297313981835672, \"phi\": 0.1895276225104629}, {\"truth_threshold\": 37.819999154657125, \"match_probability\": 0.9999999999958786, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10869.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293092.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.035757876832883166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9642421231671169, \"precision\": 1.0, \"recall\": 0.035757876832883166, \"specificity\": 1.0, \"npv\": 0.9997708483792953, \"accuracy\": 0.9997708503265725, \"f1\": 0.06904678715497252, \"f2\": 0.044301315792691524, \"f0_5\": 0.15641684679524634, \"p4\": 0.12917353462102374, \"phi\": 0.18907586534894913}, {\"truth_threshold\": 37.83999915421009, \"match_probability\": 0.9999999999959354, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10817.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293144.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03558680225423656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9644131977457634, \"precision\": 1.0, \"recall\": 0.03558680225423656, \"specificity\": 1.0, \"npv\": 0.9997708077328319, \"accuracy\": 0.9997708096711366, \"f1\": 0.06872780181588294, \"f2\": 0.044091236291037214, \"f0_5\": 0.15576175953045396, \"p4\": 0.12861515364409867, \"phi\": 0.18862302625699404}, {\"truth_threshold\": 37.859999153763056, \"match_probability\": 0.9999999999959913, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10756.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293205.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.035386118613901126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9646138813860988, \"precision\": 1.0, \"recall\": 0.035386118613901126, \"specificity\": 1.0, \"npv\": 0.9997707600514079, \"accuracy\": 0.999770761979183, \"f1\": 0.06835347312029538, \"f2\": 0.04384477417250938, \"f0_5\": 0.1549922907330288, \"p4\": 0.12795946934192753, \"phi\": 0.18809042161122716}, {\"truth_threshold\": 37.87999915331602, \"match_probability\": 0.9999999999960465, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10693.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293268.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03517885518207928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9648211448179207, \"precision\": 1.0, \"recall\": 0.03517885518207928, \"specificity\": 1.0, \"npv\": 0.9997707108066632, \"accuracy\": 0.9997707127235588, \"f1\": 0.06796671899928175, \"f2\": 0.04359020559510231, \"f0_5\": 0.15419645663954687, \"p4\": 0.12728153749825172, \"phi\": 0.18753876679436726}, {\"truth_threshold\": 37.899999152868986, \"match_probability\": 0.9999999999961009, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10626.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293335.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03495843216728462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9650415678327153, \"precision\": 1.0, \"recall\": 0.03495843216728462, \"specificity\": 1.0, \"npv\": 0.9997706584352736, \"accuracy\": 0.9997706603405933, \"f1\": 0.06755523909125298, \"f2\": 0.043319445237144, \"f0_5\": 0.1533488231134458, \"p4\": 0.12655972506257998, \"phi\": 0.1869503002023559}, {\"truth_threshold\": 37.91999915242195, \"match_probability\": 0.9999999999961546, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10589.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293372.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03483670602478608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9651632939752139, \"precision\": 1.0, \"recall\": 0.03483670602478608, \"specificity\": 1.0, \"npv\": 0.9997706295137622, \"accuracy\": 0.999770631412687, \"f1\": 0.06732792878715625, \"f2\": 0.04316990818087902, \"f0_5\": 0.15288016470459145, \"p4\": 0.12616074176111633, \"phi\": 0.18662453084357974}, {\"truth_threshold\": 37.93999915197492, \"match_probability\": 0.9999999999962075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10570.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.034774198005665204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9652258019943348, \"precision\": 1.0, \"recall\": 0.034774198005665204, \"specificity\": 1.0, \"npv\": 0.9997706146621759, \"accuracy\": 0.9997706165578162, \"f1\": 0.06721118109184786, \"f2\": 0.04309311537539526, \"f0_5\": 0.15263934658229383, \"p4\": 0.12595575589557956, \"phi\": 0.1864570227009648}, {\"truth_threshold\": 37.95999915152788, \"match_probability\": 0.9999999999962598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10533.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03465247186316665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9653475281368333, \"precision\": 1.0, \"recall\": 0.03465247186316665, \"specificity\": 1.0, \"npv\": 0.999770585740667, \"accuracy\": 0.9997705876299099, \"f1\": 0.06698378983382831, \"f2\": 0.04294356466241621, \"f0_5\": 0.15217008145209523, \"p4\": 0.1255563730283708, \"phi\": 0.18613039002806636}, {\"truth_threshold\": 37.97999915108085, \"match_probability\": 0.9999999999963113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10492.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293469.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.034517586137695296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9654824138623047, \"precision\": 1.0, \"recall\": 0.034517586137695296, \"specificity\": 1.0, \"npv\": 0.9997705536925106, \"accuracy\": 0.9997705555746623, \"f1\": 0.06673175323498265, \"f2\": 0.042777835764423455, \"f0_5\": 0.15164961596165688, \"p4\": 0.12511350488705297, \"phi\": 0.18576777493691568}, {\"truth_threshold\": 37.99999915063381, \"match_probability\": 0.999999999996362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10435.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293526.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03433006208033267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9656699379196674, \"precision\": 1.0, \"recall\": 0.03433006208033267, \"specificity\": 1.0, \"npv\": 0.9997705091377598, \"accuracy\": 0.9997705110100499, \"f1\": 0.06638125166986858, \"f2\": 0.04254741376146864, \"f0_5\": 0.15092522150644633, \"p4\": 0.12449727020731768, \"phi\": 0.1852624723056051}, {\"truth_threshold\": 38.01999915018678, \"match_probability\": 0.9999999999964121, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10391.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293570.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.034185306667631706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9658146933323682, \"precision\": 1.0, \"recall\": 0.034185306667631706, \"specificity\": 1.0, \"npv\": 0.9997704747446217, \"accuracy\": 0.9997704766092964, \"f1\": 0.06611060212755128, \"f2\": 0.04236952949475427, \"f0_5\": 0.15036538600680124, \"p4\": 0.12402115017285885, \"phi\": 0.18487146961169704}, {\"truth_threshold\": 38.03999914973974, \"match_probability\": 0.9999999999964615, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10345.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293616.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03403397146344432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9659660285365557, \"precision\": 1.0, \"recall\": 0.03403397146344432, \"specificity\": 1.0, \"npv\": 0.9997704387881615, \"accuracy\": 0.9997704406448724, \"f1\": 0.06582756931143535, \"f2\": 0.04218354592970578, \"f0_5\": 0.14977949331240717, \"p4\": 0.12352298710709446, \"phi\": 0.18446180792703812}, {\"truth_threshold\": 38.05999914929271, \"match_probability\": 0.9999999999965102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10315.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293646.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03393527459114821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9660647254088518, \"precision\": 1.0, \"recall\": 0.03393527459114821, \"specificity\": 1.0, \"npv\": 0.9997704153382976, \"accuracy\": 0.9997704171898132, \"f1\": 0.06564293805444896, \"f2\": 0.042062244782283535, \"f0_5\": 0.14939705290234373, \"p4\": 0.12319787695653574, \"phi\": 0.18419414641245097}, {\"truth_threshold\": 38.07999914884567, \"match_probability\": 0.9999999999965583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10279.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293682.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03381683834439286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9661831616556071, \"precision\": 1.0, \"recall\": 0.03381683834439286, \"specificity\": 1.0, \"npv\": 0.9997703871984623, \"accuracy\": 0.9997703890437422, \"f1\": 0.06542133401221996, \"f2\": 0.041916675570069235, \"f0_5\": 0.14893777330856592, \"p4\": 0.12280751403642405, \"phi\": 0.18387243829731922}, {\"truth_threshold\": 38.09999914839864, \"match_probability\": 0.9999999999966056, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10250.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.033721431367839956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.96627856863216, \"precision\": 1.0, \"recall\": 0.033721431367839956, \"specificity\": 1.0, \"npv\": 0.9997703645302629, \"accuracy\": 0.9997703663705183, \"f1\": 0.06524278271607296, \"f2\": 0.041799405265827906, \"f0_5\": 0.14856751922681113, \"p4\": 0.12249287180438606, \"phi\": 0.18361287463330994}, {\"truth_threshold\": 38.1199991479516, \"match_probability\": 0.9999999999966523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10206.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03357667595513898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.966423324044861, \"precision\": 1.0, \"recall\": 0.03357667595513898, \"specificity\": 1.0, \"npv\": 0.9997703301371346, \"accuracy\": 0.9997703319697648, \"f1\": 0.06497181435351262, \"f2\": 0.041621467313731085, \"f0_5\": 0.1480052786519135, \"p4\": 0.12201517109394588, \"phi\": 0.18321835171340478}, {\"truth_threshold\": 38.13999914750457, \"match_probability\": 0.9999999999966984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10170.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293791.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.033458239708383644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9665417602916163, \"precision\": 1.0, \"recall\": 0.033458239708383644, \"specificity\": 1.0, \"npv\": 0.9997703019973042, \"accuracy\": 0.9997703038236938, \"f1\": 0.06475005650508864, \"f2\": 0.04147587221679361, \"f0_5\": 0.14754483651103611, \"p4\": 0.12162404458822021, \"phi\": 0.18289492726029585}, {\"truth_threshold\": 38.15999914705753, \"match_probability\": 0.9999999999967439, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10126.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293835.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03331348429568267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9666865157043173, \"precision\": 1.0, \"recall\": 0.03331348429568267, \"specificity\": 1.0, \"npv\": 0.9997702676041802, \"accuracy\": 0.9997702694229404, \"f1\": 0.06447895009981311, \"f2\": 0.04129791104186889, \"f0_5\": 0.14698155110098268, \"p4\": 0.12114565790321742, \"phi\": 0.18249885235015129}, {\"truth_threshold\": 38.1799991466105, \"match_probability\": 0.9999999999967888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10089.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03319175815318413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9668082418468159, \"precision\": 1.0, \"recall\": 0.03319175815318413, \"specificity\": 1.0, \"npv\": 0.9997702386826914, \"accuracy\": 0.999770240495034, \"f1\": 0.06425091545932177, \"f2\": 0.041148251984406976, \"f0_5\": 0.14650743355686766, \"p4\": 0.12074308569517526, \"phi\": 0.1821651228174786}, {\"truth_threshold\": 38.199999146163464, \"match_probability\": 0.999999999996833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10052.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293909.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.033070032010685584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9669299679893144, \"precision\": 1.0, \"recall\": 0.033070032010685584, \"specificity\": 1.0, \"npv\": 0.9997702097612043, \"accuracy\": 0.9997702115671278, \"f1\": 0.0640228270804075, \"f2\": 0.04099858389292403, \"f0_5\": 0.14603290825146947, \"p4\": 0.12034024598573441, \"phi\": 0.18183078078293802}, {\"truth_threshold\": 38.21999914571643, \"match_probability\": 0.9999999999968766, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10015.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293946.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03294830586818704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9670516941318129, \"precision\": 1.0, \"recall\": 0.03294830586818704, \"specificity\": 1.0, \"npv\": 0.9997701808397189, \"accuracy\": 0.9997701826392215, \"f1\": 0.06379468494407216, \"f2\": 0.04084890676660203, \"f0_5\": 0.14555797465852374, \"p4\": 0.11993713850817353, \"phi\": 0.18149582286157367}, {\"truth_threshold\": 38.239999145269394, \"match_probability\": 0.9999999999969196, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9989.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293972.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.032862768578863735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9671372314211363, \"precision\": 1.0, \"recall\": 0.032862768578863735, \"specificity\": 1.0, \"npv\": 0.9997701605165139, \"accuracy\": 0.9997701623115035, \"f1\": 0.06363433667781494, \"f2\": 0.04074372283989744, \"f0_5\": 0.14522399299831065, \"p4\": 0.11965371345883591, \"phi\": 0.18126007673259892}, {\"truth_threshold\": 38.25999914482236, \"match_probability\": 0.999999999996962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9967.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293994.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03279039087251325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9672096091274868, \"precision\": 1.0, \"recall\": 0.03279039087251325, \"specificity\": 1.0, \"npv\": 0.9997701433199565, \"accuracy\": 0.9997701451111268, \"f1\": 0.0634986366300553, \"f2\": 0.040654717570653226, \"f0_5\": 0.14494123532337297, \"p4\": 0.11941378881788865, \"phi\": 0.1810603594996154}, {\"truth_threshold\": 38.279999144375324, \"match_probability\": 0.9999999999970038, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9915.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03261931629386665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9673806837061334, \"precision\": 1.0, \"recall\": 0.03261931629386665, \"specificity\": 1.0, \"npv\": 0.9997701026735505, \"accuracy\": 0.9997701044556909, \"f1\": 0.0631778154430412, \"f2\": 0.04044432877914827, \"f0_5\": 0.14427232328641149, \"p4\": 0.11884631692450574, \"phi\": 0.1805874225970903}, {\"truth_threshold\": 38.29999914392829, \"match_probability\": 0.999999999997045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9895.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294066.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03255351837900257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9674464816209974, \"precision\": 1.0, \"recall\": 0.03255351837900257, \"specificity\": 1.0, \"npv\": 0.9997700870403182, \"accuracy\": 0.9997700888189848, \"f1\": 0.06305439437194127, \"f2\": 0.04036340526001049, \"f0_5\": 0.14401483374619042, \"p4\": 0.1186279171959564, \"phi\": 0.1804051936703708}, {\"truth_threshold\": 38.319999143481255, \"match_probability\": 0.9999999999970858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9863.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294098.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.032448241715220046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9675517582847799, \"precision\": 1.0, \"recall\": 0.032448241715220046, \"specificity\": 1.0, \"npv\": 0.9997700620271477, \"accuracy\": 0.999770063800255, \"f1\": 0.06285688793718772, \"f2\": 0.04023392213636701, \"f0_5\": 0.14360260094987667, \"p4\": 0.11827831418825868, \"phi\": 0.18011324391142766}, {\"truth_threshold\": 38.33999914303422, \"match_probability\": 0.9999999999971259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9801.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0322442681791414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9677557318208586, \"precision\": 1.0, \"recall\": 0.0322442681791414, \"specificity\": 1.0, \"npv\": 0.9997700135641334, \"accuracy\": 0.999770015326466, \"f1\": 0.06247410457607996, \"f2\": 0.0399830293437333, \"f0_5\": 0.14280302478399604, \"p4\": 0.1176003853335632, \"phi\": 0.1795462403806489}, {\"truth_threshold\": 38.359999142587185, \"match_probability\": 0.9999999999971654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9754.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294207.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03208964307921082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9679103569207892, \"precision\": 1.0, \"recall\": 0.03208964307921082, \"specificity\": 1.0, \"npv\": 0.999769976826045, \"accuracy\": 0.9997699785802067, \"f1\": 0.06218382927179127, \"f2\": 0.03979281950525376, \"f0_5\": 0.14219612393833989, \"p4\": 0.11708596717541311, \"phi\": 0.17911521911233186}, {\"truth_threshold\": 38.37999914214015, \"match_probability\": 0.9999999999972045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9713.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294248.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03195475735373946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9680452426462606, \"precision\": 1.0, \"recall\": 0.03195475735373946, \"specificity\": 1.0, \"npv\": 0.9997699447779276, \"accuracy\": 0.9997699465249591, \"f1\": 0.06193053934977078, \"f2\": 0.0396268798595251, \"f0_5\": 0.1416661561842754, \"p4\": 0.11663686374025627, \"phi\": 0.17873837303427648}, {\"truth_threshold\": 38.399999141693115, \"match_probability\": 0.9999999999972429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9678.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294283.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03183961100272732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9681603889972726, \"precision\": 1.0, \"recall\": 0.03183961100272732, \"specificity\": 1.0, \"npv\": 0.9997699174197802, \"accuracy\": 0.9997699191607234, \"f1\": 0.061714263851115454, \"f2\": 0.039485215279693064, \"f0_5\": 0.1412133433331485, \"p4\": 0.11625322024301225, \"phi\": 0.17841604541877565}, {\"truth_threshold\": 38.41999914124608, \"match_probability\": 0.9999999999972808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9643.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03172446465171519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9682755353482848, \"precision\": 1.0, \"recall\": 0.03172446465171519, \"specificity\": 1.0, \"npv\": 0.9997698900616342, \"accuracy\": 0.9997698917964878, \"f1\": 0.061497940077294935, \"f2\": 0.03934354260795912, \"f0_5\": 0.14076016033491665, \"p4\": 0.11586933471280973, \"phi\": 0.178093134446866}, {\"truth_threshold\": 38.439999140799046, \"match_probability\": 0.9999999999973184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9613.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294348.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03162576777941907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9683742322205809, \"precision\": 1.0, \"recall\": 0.03162576777941907, \"specificity\": 1.0, \"npv\": 0.999769866611796, \"accuracy\": 0.9997698683414286, \"f1\": 0.06131248126439054, \"f2\": 0.03922210244831112, \"f0_5\": 0.14037142281397028, \"p4\": 0.11554009716048975, \"phi\": 0.17781588690082065}, {\"truth_threshold\": 38.45999914035201, \"match_probability\": 0.9999999999973552, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9599.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294362.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.031579709239014216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9684202907609858, \"precision\": 1.0, \"recall\": 0.031579709239014216, \"specificity\": 1.0, \"npv\": 0.9997698556685386, \"accuracy\": 0.9997698573957343, \"f1\": 0.06122592167368287, \"f2\": 0.03916542833897619, \"f0_5\": 0.14018991871058573, \"p4\": 0.11538639201715918, \"phi\": 0.17768635667361649}, {\"truth_threshold\": 38.479999139904976, \"match_probability\": 0.9999999999973916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9538.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294423.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03137902559867878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9686209744013212, \"precision\": 1.0, \"recall\": 0.03137902559867878, \"specificity\": 1.0, \"npv\": 0.9997698079872054, \"accuracy\": 0.9997698097037806, \"f1\": 0.06084867894315452, \"f2\": 0.038918476034412126, \"f0_5\": 0.13939838591342626, \"p4\": 0.11471622363180316, \"phi\": 0.17712086945816602}, {\"truth_threshold\": 38.49999913945794, \"match_probability\": 0.9999999999974276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9502.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03126058935192344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9687394106480766, \"precision\": 1.0, \"recall\": 0.03126058935192344, \"specificity\": 1.0, \"npv\": 0.9997697798474043, \"accuracy\": 0.9997697815577097, \"f1\": 0.06062597499545401, \"f2\": 0.03877272215357948, \"f0_5\": 0.13893072179057167, \"p4\": 0.11432036821902723, \"phi\": 0.1767862905721838}, {\"truth_threshold\": 38.519999139010906, \"match_probability\": 0.999999999997463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9472.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294489.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03116189247962732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9688381075203727, \"precision\": 1.0, \"recall\": 0.03116189247962732, \"specificity\": 1.0, \"npv\": 0.9997697563975714, \"accuracy\": 0.9997697581026505, \"f1\": 0.06044034929315037, \"f2\": 0.03865125404385481, \"f0_5\": 0.1385407007187384, \"p4\": 0.11399029218338332, \"phi\": 0.17650699038067674}, {\"truth_threshold\": 38.53999913856387, \"match_probability\": 0.9999999999974979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9440.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.031056615815844797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9689433841841552, \"precision\": 1.0, \"recall\": 0.031056615815844797, \"specificity\": 1.0, \"npv\": 0.9997697313844174, \"accuracy\": 0.9997697330839207, \"f1\": 0.060242309373613995, \"f2\": 0.03852168150404314, \"f0_5\": 0.13812437631869273, \"p4\": 0.11363801398242683, \"phi\": 0.17620858223116204}, {\"truth_threshold\": 38.55999913811684, \"match_probability\": 0.9999999999975323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9418.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03098423810949431, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9690157618905056, \"precision\": 1.0, \"recall\": 0.03098423810949431, \"specificity\": 1.0, \"npv\": 0.9997697141878747, \"accuracy\": 0.9997697158835439, \"f1\": 0.060106133467781826, \"f2\": 0.03843259645692105, \"f0_5\": 0.1378379723270293, \"p4\": 0.11339570461039875, \"phi\": 0.17600313315125438}, {\"truth_threshold\": 38.5799991376698, \"match_probability\": 0.9999999999975663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9351.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294610.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030763815094699647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9692361849053004, \"precision\": 1.0, \"recall\": 0.030763815094699647, \"specificity\": 1.0, \"npv\": 0.9997696618165893, \"accuracy\": 0.9997696635005785, \"f1\": 0.05969129813093658, \"f2\": 0.03816127228726856, \"f0_5\": 0.13696483236418497, \"p4\": 0.11265716895275654, \"phi\": 0.17537596475405617}, {\"truth_threshold\": 38.59999913722277, \"match_probability\": 0.9999999999975998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9306.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030615769786255475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9693842302137445, \"precision\": 1.0, \"recall\": 0.030615769786255475, \"specificity\": 1.0, \"npv\": 0.9997696266418485, \"accuracy\": 0.9997696283179897, \"f1\": 0.05941257776912346, \"f2\": 0.037979022976778354, \"f0_5\": 0.13637762504213258, \"p4\": 0.11216063531742916, \"phi\": 0.17495347018152405}, {\"truth_threshold\": 38.61999913677573, \"match_probability\": 0.9999999999976329, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9245.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294716.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030415086145920037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.96958491385408, \"precision\": 1.0, \"recall\": 0.030415086145920037, \"specificity\": 1.0, \"npv\": 0.9997695789605373, \"accuracy\": 0.999769580626036, \"f1\": 0.05903462896623947, \"f2\": 0.03773195253569332, \"f0_5\": 0.13558064298514994, \"p4\": 0.11148691106044845, \"phi\": 0.17437912108436304}, {\"truth_threshold\": 38.6399991363287, \"match_probability\": 0.9999999999976654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9204.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030280200420448676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9697197995795513, \"precision\": 1.0, \"recall\": 0.030280200420448676, \"specificity\": 1.0, \"npv\": 0.9997695469124454, \"accuracy\": 0.9997695485707885, \"f1\": 0.058780515063943925, \"f2\": 0.0375658749697971, \"f0_5\": 0.13504432517452764, \"p4\": 0.11103366206928326, \"phi\": 0.17399201779038603}, {\"truth_threshold\": 38.65999913588166, \"match_probability\": 0.9999999999976976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9164.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294797.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03014860459072052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9698513954092794, \"precision\": 1.0, \"recall\": 0.03014860459072052, \"specificity\": 1.0, \"npv\": 0.9997695156460161, \"accuracy\": 0.9997695172973763, \"f1\": 0.05853253493013972, \"f2\": 0.03740383736269477, \"f0_5\": 0.13452059057533827, \"p4\": 0.1105911437220727, \"phi\": 0.17361352426889995}, {\"truth_threshold\": 38.67999913543463, \"match_probability\": 0.9999999999977293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9127.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294834.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030026878448221977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9699731215517781, \"precision\": 1.0, \"recall\": 0.030026878448221977, \"specificity\": 1.0, \"npv\": 0.9997694867245709, \"accuracy\": 0.99976948836947, \"f1\": 0.05830309689288635, \"f2\": 0.03725394315457264, \"f0_5\": 0.13403569781683503, \"p4\": 0.11018152886208686, \"phi\": 0.17326268165453276}, {\"truth_threshold\": 38.69999913498759, \"match_probability\": 0.9999999999977606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9092.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294869.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02991173209720984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9700882679027901, \"precision\": 1.0, \"recall\": 0.02991173209720984, \"specificity\": 1.0, \"npv\": 0.9997694593664485, \"accuracy\": 0.9997694610052342, \"f1\": 0.05808601099494335, \"f2\": 0.037112143001756824, \"f0_5\": 0.1335766273223851, \"p4\": 0.10979380265742898, \"phi\": 0.17293014840548054}, {\"truth_threshold\": 38.71999913454056, \"match_probability\": 0.9999999999977914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9071.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02984264428660256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9701573557133975, \"precision\": 1.0, \"recall\": 0.02984264428660256, \"specificity\": 1.0, \"npv\": 0.9997694429515758, \"accuracy\": 0.9997694445866928, \"f1\": 0.05795573615477012, \"f2\": 0.037027059020421825, \"f0_5\": 0.13330100368851858, \"p4\": 0.10956104891400194, \"phi\": 0.1727303211790526}, {\"truth_threshold\": 38.73999913409352, \"match_probability\": 0.9999999999978217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9021.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029678149499442363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9703218505005576, \"precision\": 1.0, \"recall\": 0.029678149499442363, \"specificity\": 1.0, \"npv\": 0.9997694038685477, \"accuracy\": 0.9997694054949275, \"f1\": 0.057645487599925875, \"f2\": 0.0368244663697632, \"f0_5\": 0.1326442088547104, \"p4\": 0.10900651672236213, \"phi\": 0.17225360905646978}, {\"truth_threshold\": 38.75999913364649, \"match_probability\": 0.9999999999978518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8999.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294962.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029605771793091876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9703942282069081, \"precision\": 1.0, \"recall\": 0.029605771793091876, \"specificity\": 1.0, \"npv\": 0.9997693866720164, \"accuracy\": 0.9997693882945509, \"f1\": 0.05750894683026585, \"f2\": 0.036735320363507816, \"f0_5\": 0.13235497430557394, \"p4\": 0.108762363304596, \"phi\": 0.1720434372695778}, {\"truth_threshold\": 38.77999913319945, \"match_probability\": 0.9999999999978814, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8968.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294993.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029503785025052555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9704962149749474, \"precision\": 1.0, \"recall\": 0.029503785025052555, \"specificity\": 1.0, \"npv\": 0.9997693624405414, \"accuracy\": 0.9997693640576564, \"f1\": 0.05731651588699034, \"f2\": 0.036609700100913446, \"f0_5\": 0.1319471622826506, \"p4\": 0.10841816360368094, \"phi\": 0.17174684958996944}, {\"truth_threshold\": 38.79999913275242, \"match_probability\": 0.9999999999979106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8928.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0293721891953244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9706278108046756, \"precision\": 1.0, \"recall\": 0.0293721891953244, \"specificity\": 1.0, \"npv\": 0.9997693311741237, \"accuracy\": 0.9997693327842442, \"f1\": 0.05706816155249945, \"f2\": 0.03644760004311007, \"f0_5\": 0.13142051325833964, \"p4\": 0.1079737489193787, \"phi\": 0.1713633973371481}, {\"truth_threshold\": 38.819999132305384, \"match_probability\": 0.9999999999979393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8872.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295089.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02918795503370498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.970812044966295, \"precision\": 1.0, \"recall\": 0.02918795503370498, \"specificity\": 1.0, \"npv\": 0.9997692874011422, \"accuracy\": 0.999769289001467, \"f1\": 0.05672035878567798, \"f2\": 0.03622064217336917, \"f0_5\": 0.13068237054756385, \"p4\": 0.10735102627947592, \"phi\": 0.17082511819034052}, {\"truth_threshold\": 38.83999913185835, \"match_probability\": 0.9999999999979676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8863.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295098.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029158345972016147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9708416540279838, \"precision\": 1.0, \"recall\": 0.029158345972016147, \"specificity\": 1.0, \"npv\": 0.9997692803661992, \"accuracy\": 0.9997692819649493, \"f1\": 0.05666445029793111, \"f2\": 0.0361841648655556, \"f0_5\": 0.13056364959503614, \"p4\": 0.10725088681128306, \"phi\": 0.17073845076347402}, {\"truth_threshold\": 38.859999131411314, \"match_probability\": 0.9999999999979956, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8822.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295139.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029023460246544786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9709765397534552, \"precision\": 1.0, \"recall\": 0.029023460246544786, \"specificity\": 1.0, \"npv\": 0.9997692483181264, \"accuracy\": 0.9997692499097017, \"f1\": 0.056409715361768385, \"f2\": 0.036017983678815285, \"f0_5\": 0.13002249085479986, \"p4\": 0.10679448879542874, \"phi\": 0.1703430745122299}, {\"truth_threshold\": 38.87999913096428, \"match_probability\": 0.9999999999980232, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8738.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02874710900411566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9712528909958843, \"precision\": 1.0, \"recall\": 0.02874710900411566, \"specificity\": 1.0, \"npv\": 0.9997691826586665, \"accuracy\": 0.9997691842355361, \"f1\": 0.055887610769462005, \"f2\": 0.03567748015241119, \"f0_5\": 0.1289121396936677, \"p4\": 0.10585836737148512, \"phi\": 0.16953015564448792}, {\"truth_threshold\": 38.899999130517244, \"match_probability\": 0.9999999999980504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8700.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295261.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02862209296587391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9713779070341261, \"precision\": 1.0, \"recall\": 0.02862209296587391, \"specificity\": 1.0, \"npv\": 0.9997691529555804, \"accuracy\": 0.9997691545257944, \"f1\": 0.05565132843558998, \"f2\": 0.03552342749627616, \"f0_5\": 0.1284091143903814, \"p4\": 0.10543441424423747, \"phi\": 0.16916112331238414}, {\"truth_threshold\": 38.91999913007021, \"match_probability\": 0.9999999999980773, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8670.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.028523396093577794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9714766039064222, \"precision\": 1.0, \"recall\": 0.028523396093577794, \"specificity\": 1.0, \"npv\": 0.9997691295057768, \"accuracy\": 0.9997691310707353, \"f1\": 0.05546474917714494, \"f2\": 0.03540180022441557, \"f0_5\": 0.12801167017579088, \"p4\": 0.10509950746970735, \"phi\": 0.16886921235981633}, {\"truth_threshold\": 38.939999129623175, \"match_probability\": 0.9999999999981037, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8616.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295345.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.028345741723444784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9716542582765552, \"precision\": 1.0, \"recall\": 0.028345741723444784, \"specificity\": 1.0, \"npv\": 0.9997690872961331, \"accuracy\": 0.9997690888516287, \"f1\": 0.05512881625967361, \"f2\": 0.03518285611616549, \"f0_5\": 0.1272955603161705, \"p4\": 0.10449621463386491, \"phi\": 0.16834249710509913}, {\"truth_threshold\": 38.95999912917614, \"match_probability\": 0.9999999999981298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8581.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295380.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.028230595372432648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9717694046275673, \"precision\": 1.0, \"recall\": 0.028230595372432648, \"specificity\": 1.0, \"npv\": 0.9997690599380327, \"accuracy\": 0.9997690614873931, \"f1\": 0.05491101995891752, \"f2\": 0.035040937582947095, \"f0_5\": 0.12683092658557132, \"p4\": 0.10410487482123701, \"phi\": 0.16800022558612224}, {\"truth_threshold\": 38.979999128729105, \"match_probability\": 0.9999999999981556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8533.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02807268037675886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9719273196232412, \"precision\": 1.0, \"recall\": 0.02807268037675886, \"specificity\": 1.0, \"npv\": 0.9997690224183544, \"accuracy\": 0.9997690239592983, \"f1\": 0.05461224855517226, \"f2\": 0.03484629325771392, \"f0_5\": 0.12619308888382783, \"p4\": 0.10356777469301533, \"phi\": 0.1675296875689056}, {\"truth_threshold\": 38.99999912828207, \"match_probability\": 0.999999999998181, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8508.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295453.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027990432983178763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9720095670168213, \"precision\": 1.0, \"recall\": 0.027990432983178763, \"specificity\": 1.0, \"npv\": 0.9997690028768564, \"accuracy\": 0.9997690044134158, \"f1\": 0.054456602094927815, \"f2\": 0.034744909960534226, \"f0_5\": 0.12586059474604502, \"p4\": 0.10328784909497728, \"phi\": 0.16728409151405912}, {\"truth_threshold\": 39.019999127835035, \"match_probability\": 0.9999999999982061, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8476.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295485.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02788515631939624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9721148436806037, \"precision\": 1.0, \"recall\": 0.02788515631939624, \"specificity\": 1.0, \"npv\": 0.9997689778637401, \"accuracy\": 0.999768979394686, \"f1\": 0.054257338279397126, \"f2\": 0.034615133298484056, \"f0_5\": 0.12543471504891007, \"p4\": 0.10292935830571036, \"phi\": 0.16696920144449812}, {\"truth_threshold\": 39.039999127388, \"match_probability\": 0.9999999999982307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8433.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02774369080243847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9722563091975616, \"precision\": 1.0, \"recall\": 0.02774369080243847, \"specificity\": 1.0, \"npv\": 0.9997689442523671, \"accuracy\": 0.9997689457757678, \"f1\": 0.05398951324289199, \"f2\": 0.034440735225769986, \"f0_5\": 0.12486193080697557, \"p4\": 0.10244730710075156, \"phi\": 0.16654513040980218}, {\"truth_threshold\": 39.059999126940966, \"match_probability\": 0.9999999999982551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8411.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295550.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027671313096087984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.972328686903912, \"precision\": 1.0, \"recall\": 0.027671313096087984, \"specificity\": 1.0, \"npv\": 0.9997689270558515, \"accuracy\": 0.9997689285753911, \"f1\": 0.053852457966783195, \"f2\": 0.03435150356747573, \"f0_5\": 0.12456865271545149, \"p4\": 0.10220053014874868, \"phi\": 0.16632774574406525}, {\"truth_threshold\": 39.07999912649393, \"match_probability\": 0.9999999999982792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8387.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02759235559825109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9724076444017489, \"precision\": 1.0, \"recall\": 0.02759235559825109, \"specificity\": 1.0, \"npv\": 0.9997689082960171, \"accuracy\": 0.9997689098113437, \"f1\": 0.05370292110082344, \"f2\": 0.034254156282596995, \"f0_5\": 0.12424853855749032, \"p4\": 0.10193120604130021, \"phi\": 0.16609027435036341}, {\"truth_threshold\": 39.099999126046896, \"match_probability\": 0.9999999999983028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8367.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295594.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027526557683387014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.972473442316613, \"precision\": 1.0, \"recall\": 0.027526557683387014, \"specificity\": 1.0, \"npv\": 0.9997688926628222, \"accuracy\": 0.9997688941746377, \"f1\": 0.05357828949053559, \"f2\": 0.03417303062952383, \"f0_5\": 0.1239816376185805, \"p4\": 0.10170667924848809, \"phi\": 0.16589212185616029}, {\"truth_threshold\": 39.11999912559986, \"match_probability\": 0.9999999999983262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8321.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295640.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027375222479199633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9726247775208003, \"precision\": 1.0, \"recall\": 0.027375222479199633, \"specificity\": 1.0, \"npv\": 0.9997688567064759, \"accuracy\": 0.9997688582102136, \"f1\": 0.0532915762035596, \"f2\": 0.03398643156763998, \"f0_5\": 0.1233672849115628, \"p4\": 0.10118995674372762, \"phi\": 0.16543547044124135}, {\"truth_threshold\": 39.139999125152826, \"match_probability\": 0.9999999999983492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8304.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295657.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02731929425156517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9726807057484348, \"precision\": 1.0, \"recall\": 0.02731929425156517, \"specificity\": 1.0, \"npv\": 0.9997688434182616, \"accuracy\": 0.9997688449190134, \"f1\": 0.05318559556786703, \"f2\": 0.033917467495760314, \"f0_5\": 0.12314007183170857, \"p4\": 0.10099888432728496, \"phi\": 0.16526638864841958}, {\"truth_threshold\": 39.15999912470579, \"match_probability\": 0.999999999998372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8258.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295703.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027167959047377788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9728320409526222, \"precision\": 1.0, \"recall\": 0.027167959047377788, \"specificity\": 1.0, \"npv\": 0.9997688074619188, \"accuracy\": 0.9997688089545893, \"f1\": 0.052898766570900556, \"f2\": 0.03373084922661674, \"f0_5\": 0.12252480021840216, \"p4\": 0.10048156757703684, \"phi\": 0.16480800350095604}, {\"truth_threshold\": 39.17999912425876, \"match_probability\": 0.9999999999983944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8217.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295744.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02703307332190643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9729669266780936, \"precision\": 1.0, \"recall\": 0.02703307332190643, \"specificity\": 1.0, \"npv\": 0.9997687754138762, \"accuracy\": 0.9997687768993417, \"f1\": 0.052643043391911025, \"f2\": 0.03356450372979778, \"f0_5\": 0.12197583937250059, \"p4\": 0.10002011466589546, \"phi\": 0.16439836559624282}, {\"truth_threshold\": 39.19999912381172, \"match_probability\": 0.9999999999984165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8205.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295756.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026993594572987983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.973006405427012, \"precision\": 1.0, \"recall\": 0.026993594572987983, \"specificity\": 1.0, \"npv\": 0.9997687660339618, \"accuracy\": 0.9997687675173181, \"f1\": 0.05256818487599546, \"f2\": 0.03351581513485163, \"f0_5\": 0.12181506676445523, \"p4\": 0.09988498991680912, \"phi\": 0.16427827834822606}, {\"truth_threshold\": 39.21999912336469, \"match_probability\": 0.9999999999984382, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8178.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026904767387921476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9730952326120785, \"precision\": 1.0, \"recall\": 0.026904767387921476, \"specificity\": 1.0, \"npv\": 0.9997687449291548, \"accuracy\": 0.9997687464077648, \"f1\": 0.05239973217060348, \"f2\": 0.03340626230574287, \"f0_5\": 0.1214531607821239, \"p4\": 0.09958085093757173, \"phi\": 0.16400776056038663}, {\"truth_threshold\": 39.23999912291765, \"match_probability\": 0.9999999999984598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8150.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026812650307111767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9731873496928882, \"precision\": 1.0, \"recall\": 0.026812650307111767, \"specificity\": 1.0, \"npv\": 0.9997687230426893, \"accuracy\": 0.9997687245163763, \"f1\": 0.05222500969206468, \"f2\": 0.03329264685938003, \"f0_5\": 0.1210776055455029, \"p4\": 0.09926528907636595, \"phi\": 0.16372675150668353}, {\"truth_threshold\": 39.25999912247062, \"match_probability\": 0.999999999998481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8111.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026684344373126816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9733156556268732, \"precision\": 1.0, \"recall\": 0.026684344373126816, \"specificity\": 1.0, \"npv\": 0.9997686925579711, \"accuracy\": 0.9997686940247994, \"f1\": 0.051981593991130254, \"f2\": 0.033134388110674005, \"f0_5\": 0.12055409402357278, \"p4\": 0.09882548735944315, \"phi\": 0.16333454039390335}, {\"truth_threshold\": 39.27999912202358, \"match_probability\": 0.9999999999985019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8087.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295874.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026605386875289922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9733946131247101, \"precision\": 1.0, \"recall\": 0.026605386875289922, \"specificity\": 1.0, \"npv\": 0.9997686737981454, \"accuracy\": 0.999768675260752, \"f1\": 0.05183176947136338, \"f2\": 0.03303699309846715, \"f0_5\": 0.12023169168829856, \"p4\": 0.0985546842918629, \"phi\": 0.16309271091068167}, {\"truth_threshold\": 39.29999912157655, \"match_probability\": 0.9999999999985225, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8032.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026424442609413706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9735755573905863, \"precision\": 1.0, \"recall\": 0.026424442609413706, \"specificity\": 1.0, \"npv\": 0.9997686308068808, \"accuracy\": 0.9997686322598102, \"f1\": 0.05148833467417538, \"f2\": 0.03281378178835111, \"f0_5\": 0.11949215832710978, \"p4\": 0.09793364556211609, \"phi\": 0.1625371613122628}, {\"truth_threshold\": 39.31999912112951, \"match_probability\": 0.9999999999985428, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7985.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026269817509483123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9737301824905169, \"precision\": 1.0, \"recall\": 0.026269817509483123, \"specificity\": 1.0, \"npv\": 0.9997685940688941, \"accuracy\": 0.9997685955135508, \"f1\": 0.05119475806710136, \"f2\": 0.03262302168031645, \"f0_5\": 0.11885942584273343, \"p4\": 0.09740244446873014, \"phi\": 0.16206090990088376}, {\"truth_threshold\": 39.33999912068248, \"match_probability\": 0.9999999999985629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7960.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296001.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026187570115903027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.973812429884097, \"precision\": 1.0, \"recall\": 0.026187570115903027, \"specificity\": 1.0, \"npv\": 0.9997685745274129, \"accuracy\": 0.9997685759676682, \"f1\": 0.05103856425184582, \"f2\": 0.03252154756807463, \"f0_5\": 0.11852257735980536, \"p4\": 0.09711970452090246, \"phi\": 0.1618070135844335}, {\"truth_threshold\": 39.35999912023544, \"match_probability\": 0.9999999999985827, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7918.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026049394494688464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9739506055053115, \"precision\": 1.0, \"recall\": 0.026049394494688464, \"specificity\": 1.0, \"npv\": 0.9997685416977261, \"accuracy\": 0.9997685431305854, \"f1\": 0.050776102270431805, \"f2\": 0.03235106172605458, \"f0_5\": 0.11795622003795812, \"p4\": 0.0966444100515895, \"phi\": 0.1613795685521047}, {\"truth_threshold\": 39.37999911978841, \"match_probability\": 0.9999999999986022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7881.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296080.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02592766835218992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.97407233164781, \"precision\": 1.0, \"recall\": 0.02592766835218992, \"specificity\": 1.0, \"npv\": 0.9997685127763372, \"accuracy\": 0.9997685142026791, \"f1\": 0.05054482718812732, \"f2\": 0.03220086212180024, \"f0_5\": 0.11745681625109916, \"p4\": 0.09622539532629452, \"phi\": 0.16100206963957642}, {\"truth_threshold\": 39.39999911934137, \"match_probability\": 0.9999999999986214, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7856.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296105.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02584542095860982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9741545790413901, \"precision\": 1.0, \"recall\": 0.02584542095860982, \"specificity\": 1.0, \"npv\": 0.9997684932348592, \"accuracy\": 0.9997684946567964, \"f1\": 0.05038852916935254, \"f2\": 0.032099370760807384, \"f0_5\": 0.11711913174411497, \"p4\": 0.09594211647830364, \"phi\": 0.16074650095355106}, {\"truth_threshold\": 39.41999911889434, \"match_probability\": 0.9999999999986404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7787.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296174.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.025618418152328754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9743815818476712, \"precision\": 1.0, \"recall\": 0.025618418152328754, \"specificity\": 1.0, \"npv\": 0.9997684393003837, \"accuracy\": 0.9997684407101604, \"f1\": 0.0499570165646612, \"f2\": 0.03181923308579138, \"f0_5\": 0.11618607676905127, \"p4\": 0.09515959322008337, \"phi\": 0.16003901378569646}, {\"truth_threshold\": 39.439999118447304, \"match_probability\": 0.9999999999986592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7734.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296227.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.025444053677938946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9745559463220611, \"precision\": 1.0, \"recall\": 0.025444053677938946, \"specificity\": 1.0, \"npv\": 0.9997683978724572, \"accuracy\": 0.9997683992728891, \"f1\": 0.049625435120871364, \"f2\": 0.031604033416749895, \"f0_5\": 0.11546833802631853, \"p4\": 0.09455785216455585, \"phi\": 0.1594934505895895}, {\"truth_threshold\": 39.45999911800027, \"match_probability\": 0.9999999999986776, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7704.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296257.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02534535680564283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9746546431943571, \"precision\": 1.0, \"recall\": 0.02534535680564283, \"specificity\": 1.0, \"npv\": 0.9997683744226891, \"accuracy\": 0.99976837581783, \"f1\": 0.04943769752779427, \"f2\": 0.03148221402021008, \"f0_5\": 0.1150616679162547, \"p4\": 0.09421698469811925, \"phi\": 0.15918381253362593}, {\"truth_threshold\": 39.479999117553234, \"match_probability\": 0.9999999999986958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7671.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296290.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0252367902461171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9747632097538829, \"precision\": 1.0, \"recall\": 0.0252367902461171, \"specificity\": 1.0, \"npv\": 0.9997683486279453, \"accuracy\": 0.9997683500172648, \"f1\": 0.04923114442675977, \"f2\": 0.03134820578415467, \"f0_5\": 0.11461399393387021, \"p4\": 0.09384181373649526, \"phi\": 0.1588425135441716}, {\"truth_threshold\": 39.4999991171062, \"match_probability\": 0.9999999999987138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7605.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296356.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.025019657127065643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9749803428729343, \"precision\": 1.0, \"recall\": 0.025019657127065643, \"specificity\": 1.0, \"npv\": 0.9997682970384618, \"accuracy\": 0.9997682984161347, \"f1\": 0.04881790696032302, \"f2\": 0.031080167624478013, \"f0_5\": 0.11371758562837003, \"p4\": 0.09309078979670424, \"phi\": 0.1581577060987312}, {\"truth_threshold\": 39.519999116659164, \"match_probability\": 0.9999999999987315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7582.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024943989524971955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9750560104750281, \"precision\": 1.0, \"recall\": 0.024943989524971955, \"specificity\": 1.0, \"npv\": 0.9997682790603099, \"accuracy\": 0.9997682804339226, \"f1\": 0.048673858825266494, \"f2\": 0.030986753591962245, \"f0_5\": 0.11340486824274804, \"p4\": 0.0928288554283362, \"phi\": 0.15791836334093515}, {\"truth_threshold\": 39.53999911621213, \"match_probability\": 0.999999999998749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7572.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024911090567539915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9750889094324601, \"precision\": 1.0, \"recall\": 0.024911090567539915, \"specificity\": 1.0, \"npv\": 0.9997682712437221, \"accuracy\": 0.9997682726155696, \"f1\": 0.04861122256711167, \"f2\": 0.03094613769968678, \"f0_5\": 0.11326885046776505, \"p4\": 0.09271493640512408, \"phi\": 0.15781418805514658}, {\"truth_threshold\": 39.559999115765095, \"match_probability\": 0.9999999999987662, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7539.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296422.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024802524008014186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9751974759919858, \"precision\": 1.0, \"recall\": 0.024802524008014186, \"specificity\": 1.0, \"npv\": 0.9997682454489838, \"accuracy\": 0.9997682468150045, \"f1\": 0.04840449438202247, \"f2\": 0.030812100544146844, \"f0_5\": 0.11281976074249439, \"p4\": 0.092338855123061, \"phi\": 0.15746992065216342}, {\"truth_threshold\": 39.57999911531806, \"match_probability\": 0.9999999999987832, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7508.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296453.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024700537239974864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9752994627600251, \"precision\": 1.0, \"recall\": 0.024700537239974864, \"specificity\": 1.0, \"npv\": 0.999768221217564, \"accuracy\": 0.99976822257811, \"f1\": 0.04821025527420064, \"f2\": 0.030686180265369248, \"f0_5\": 0.11239756521843272, \"p4\": 0.09198535886922632, \"phi\": 0.15714583093269727}, {\"truth_threshold\": 39.599999114871025, \"match_probability\": 0.9999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7478.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296483.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02460184036767875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9753981596323212, \"precision\": 1.0, \"recall\": 0.02460184036767875, \"specificity\": 1.0, \"npv\": 0.9997681977678041, \"accuracy\": 0.9997681991230508, \"f1\": 0.04802224512665402, \"f2\": 0.03056431585469729, \"f0_5\": 0.11198869031038748, \"p4\": 0.0916430739058431, \"phi\": 0.15683155806841106}, {\"truth_threshold\": 39.61999911442399, \"match_probability\": 0.9999999999988164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7447.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296514.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024499853599639427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9755001464003605, \"precision\": 1.0, \"recall\": 0.024499853599639427, \"specificity\": 1.0, \"npv\": 0.9997681735363868, \"accuracy\": 0.9997681748861563, \"f1\": 0.04782792991830653, \"f2\": 0.030438383017613962, \"f0_5\": 0.11156587735094338, \"p4\": 0.091289181067683, \"phi\": 0.1565061464774479}, {\"truth_threshold\": 39.639999113976955, \"match_probability\": 0.9999999999988327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7429.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296532.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024440635476261758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9755593645237383, \"precision\": 1.0, \"recall\": 0.024440635476261758, \"specificity\": 1.0, \"npv\": 0.9997681594665321, \"accuracy\": 0.9997681608131208, \"f1\": 0.04771508397829089, \"f2\": 0.03036525779609294, \"f0_5\": 0.11132022884406177, \"p4\": 0.0910836023098587, \"phi\": 0.15631688695177703}, {\"truth_threshold\": 39.65999911352992, \"match_probability\": 0.9999999999988488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7398.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296563.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024338648708222436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9756613512917776, \"precision\": 1.0, \"recall\": 0.024338648708222436, \"specificity\": 1.0, \"npv\": 0.9997681352351165, \"accuracy\": 0.9997681365762264, \"f1\": 0.04752070760761693, \"f2\": 0.030239314869829517, \"f0_5\": 0.11089691893042485, \"p4\": 0.09072939042038033, \"phi\": 0.15599040173408787}, {\"truth_threshold\": 39.679999113082886, \"match_probability\": 0.9999999999988647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7354.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296607.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024193893295521466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9758061067044785, \"precision\": 1.0, \"recall\": 0.024193893295521466, \"specificity\": 1.0, \"npv\": 0.9997681008421416, \"accuracy\": 0.999768102175473, \"f1\": 0.04724475209996306, \"f2\": 0.030060546207564105, \"f0_5\": 0.11029555128278196, \"p4\": 0.0902262910703199, \"phi\": 0.15552582663995365}, {\"truth_threshold\": 39.69999911263585, \"match_probability\": 0.9999999999988802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7323.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024091906527482145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9759080934725178, \"precision\": 1.0, \"recall\": 0.024091906527482145, \"specificity\": 1.0, \"npv\": 0.999768076610729, \"accuracy\": 0.9997680779385785, \"f1\": 0.04705028205754231, \"f2\": 0.02993458783632979, \"f0_5\": 0.10987147902644537, \"p4\": 0.08987159000071233, \"phi\": 0.15519767733721498}, {\"truth_threshold\": 39.719999112188816, \"match_probability\": 0.9999999999988957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7285.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023966890489240396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9760331095107596, \"precision\": 1.0, \"recall\": 0.023966890489240396, \"specificity\": 1.0, \"npv\": 0.9997680469077085, \"accuracy\": 0.9997680482288368, \"f1\": 0.04681184657794799, \"f2\": 0.02978017854208346, \"f0_5\": 0.10935121779880577, \"p4\": 0.089436518885047, \"phi\": 0.15479448082822206}, {\"truth_threshold\": 39.73999911174178, \"match_probability\": 0.9999999999989109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7244.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296717.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023832004763769035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.976167995236231, \"precision\": 1.0, \"recall\": 0.023832004763769035, \"specificity\": 1.0, \"npv\": 0.9997680148597148, \"accuracy\": 0.9997680161735893, \"f1\": 0.046554521938914864, \"f2\": 0.02961356827963319, \"f0_5\": 0.10878935053778943, \"p4\": 0.08896675844012279, \"phi\": 0.15435827186387077}, {\"truth_threshold\": 39.759999111294746, \"match_probability\": 0.9999999999989259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7205.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296756.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023703698829784084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9762963011702159, \"precision\": 1.0, \"recall\": 0.023703698829784084, \"specificity\": 1.0, \"npv\": 0.9997679843750398, \"accuracy\": 0.9997679856820124, \"f1\": 0.0463096867909733, \"f2\": 0.02945507498064264, \"f0_5\": 0.10825437750352333, \"p4\": 0.08851958372207605, \"phi\": 0.1539421943499774}, {\"truth_threshold\": 39.77999911084771, \"match_probability\": 0.9999999999989406, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7178.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02361487164471758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9763851283552825, \"precision\": 1.0, \"recall\": 0.02361487164471758, \"specificity\": 1.0, \"npv\": 0.9997679632702657, \"accuracy\": 0.9997679645724591, \"f1\": 0.04614014957944841, \"f2\": 0.02934534292923594, \"f0_5\": 0.10788371764465406, \"p4\": 0.08820981289173971, \"phi\": 0.1536534806866673}, {\"truth_threshold\": 39.79999911040068, \"match_probability\": 0.9999999999989553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7130.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023456956649043792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9765430433509562, \"precision\": 1.0, \"recall\": 0.023456956649043792, \"specificity\": 1.0, \"npv\": 0.9997679257506699, \"accuracy\": 0.9997679270443645, \"f1\": 0.045838677428790935, \"f2\": 0.029150251763324486, \"f0_5\": 0.10722417220833672, \"p4\": 0.0876587283222179, \"phi\": 0.1531388680036453}, {\"truth_threshold\": 39.81999910995364, \"match_probability\": 0.9999999999989696, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7101.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296860.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023361549672490878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9766384503275091, \"precision\": 1.0, \"recall\": 0.023361549672490878, \"specificity\": 1.0, \"npv\": 0.999767903082582, \"accuracy\": 0.9997679043711406, \"f1\": 0.0456564929178106, \"f2\": 0.029032376762650813, \"f0_5\": 0.10682532757661005, \"p4\": 0.087325544922256, \"phi\": 0.15282711647095154}, {\"truth_threshold\": 39.83999910950661, \"match_probability\": 0.9999999999989838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7050.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02319376498958748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9768062350104125, \"precision\": 1.0, \"recall\": 0.02319376498958748, \"specificity\": 1.0, \"npv\": 0.9997678632180163, \"accuracy\": 0.99976786449754, \"f1\": 0.04533601705405918, \"f2\": 0.02882506578656858, \"f0_5\": 0.10612323541896851, \"p4\": 0.0867391691231943, \"phi\": 0.15227731565673433}, {\"truth_threshold\": 39.85999910905957, \"match_probability\": 0.9999999999989978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7028.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023121387283236993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.976878612716763, \"precision\": 1.0, \"recall\": 0.023121387283236993, \"specificity\": 1.0, \"npv\": 0.9997678460215379, \"accuracy\": 0.9997678472971633, \"f1\": 0.04519774011299435, \"f2\": 0.028735632183908046, \"f0_5\": 0.10582010582010581, \"p4\": 0.0864860522650075, \"phi\": 0.15203953288928385}, {\"truth_threshold\": 39.87999910861254, \"match_probability\": 0.9999999999990116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7007.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296954.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02305229947262971, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9769477005273702, \"precision\": 1.0, \"recall\": 0.02305229947262971, \"specificity\": 1.0, \"npv\": 0.9997678296067182, \"accuracy\": 0.9997678308786219, \"f1\": 0.04506573023590852, \"f2\": 0.028650260743132237, \"f0_5\": 0.1055306049296814, \"p4\": 0.08624434480546674, \"phi\": 0.15181221100818965}, {\"truth_threshold\": 39.8999991081655, \"match_probability\": 0.9999999999990252, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6958.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297003.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02289109458121272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9771089054187873, \"precision\": 1.0, \"recall\": 0.02289109458121272, \"specificity\": 1.0, \"npv\": 0.9997677913054742, \"accuracy\": 0.9997677925686919, \"f1\": 0.04475763784136704, \"f2\": 0.02845104931133577, \"f0_5\": 0.10485453279605055, \"p4\": 0.08567999610258616, \"phi\": 0.15128046493193942}, {\"truth_threshold\": 39.91999910771847, \"match_probability\": 0.9999999999990387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6910.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297051.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022733179585538936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9772668204144611, \"precision\": 1.0, \"recall\": 0.022733179585538936, \"specificity\": 1.0, \"npv\": 0.9997677537858912, \"accuracy\": 0.9997677550405972, \"f1\": 0.04445573887561079, \"f2\": 0.02825588793821161, \"f0_5\": 0.1041914831378675, \"p4\": 0.085126669218332, \"phi\": 0.15075775234012193}, {\"truth_threshold\": 39.93999910727143, \"match_probability\": 0.9999999999990519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6868.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297093.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02259500396432437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9774049960356757, \"precision\": 1.0, \"recall\": 0.02259500396432437, \"specificity\": 1.0, \"npv\": 0.9997677209562583, \"accuracy\": 0.9997677222035143, \"f1\": 0.044191500793040545, \"f2\": 0.028085109167162833, \"f0_5\": 0.10361068451240522, \"p4\": 0.08464210540173688, \"phi\": 0.15029888761534532}, {\"truth_threshold\": 39.9599991068244, \"match_probability\": 0.999999999999065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6815.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297146.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022420639489934564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9775793605100654, \"precision\": 1.0, \"recall\": 0.022420639489934564, \"specificity\": 1.0, \"npv\": 0.9997676795283914, \"accuracy\": 0.9997676807662431, \"f1\": 0.04385795556928463, \"f2\": 0.027869585877992147, \"f0_5\": 0.10287693111245966, \"p4\": 0.08403009478018075, \"phi\": 0.14971783700145583}, {\"truth_threshold\": 39.97999910637736, \"match_probability\": 0.9999999999990778, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6803.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297158.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022381160741016117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9776188392589839, \"precision\": 1.0, \"recall\": 0.022381160741016117, \"specificity\": 1.0, \"npv\": 0.9997676701484975, \"accuracy\": 0.9997676713842195, \"f1\": 0.0437824201001403, \"f2\": 0.027820785557892018, \"f0_5\": 0.10271066783825976, \"p4\": 0.0838914430292804, \"phi\": 0.14958596501431778}, {\"truth_threshold\": 39.99999910593033, \"match_probability\": 0.9999999999990905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6774.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297187.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022285753764463203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9777142462355368, \"precision\": 1.0, \"recall\": 0.022285753764463203, \"specificity\": 1.0, \"npv\": 0.9997676474804212, \"accuracy\": 0.9997676487109955, \"f1\": 0.043599851963892065, \"f2\": 0.027702847496110804, \"f0_5\": 0.10230866587928968, \"p4\": 0.08355624086242999, \"phi\": 0.14926679340504811}, {\"truth_threshold\": 40.01999910548329, \"match_probability\": 0.999999999999103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6750.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297211.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022206796266626312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9777932037333736, \"precision\": 1.0, \"recall\": 0.022206796266626312, \"specificity\": 1.0, \"npv\": 0.9997676287206347, \"accuracy\": 0.9997676299469482, \"f1\": 0.04344873531995971, \"f2\": 0.027605239351739006, \"f0_5\": 0.10197576149455675, \"p4\": 0.0832786961160912, \"phi\": 0.14900213436379772}, {\"truth_threshold\": 40.03999910503626, \"match_probability\": 0.9999999999991154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6741.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297220.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022177187204937474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9778228127950626, \"precision\": 1.0, \"recall\": 0.022177187204937474, \"specificity\": 1.0, \"npv\": 0.9997676216857151, \"accuracy\": 0.9997676229104305, \"f1\": 0.043392060559635924, \"f2\": 0.027568635309610373, \"f0_5\": 0.10185087255420412, \"p4\": 0.08317458505006899, \"phi\": 0.14890276594999574}, {\"truth_threshold\": 40.059999104589224, \"match_probability\": 0.9999999999991276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6710.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022075200436898156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9779247995631019, \"precision\": 1.0, \"recall\": 0.022075200436898156, \"specificity\": 1.0, \"npv\": 0.9997675974543255, \"accuracy\": 0.999767598673536, \"f1\": 0.043196822361919844, \"f2\": 0.027442550594902148, \"f0_5\": 0.1014204914737259, \"p4\": 0.08281584747864337, \"phi\": 0.14855998823411487}, {\"truth_threshold\": 40.07999910414219, \"match_probability\": 0.9999999999991396, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6692.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297269.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022015982313520484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9779840176864795, \"precision\": 1.0, \"recall\": 0.022015982313520484, \"specificity\": 1.0, \"npv\": 0.999767583384487, \"accuracy\": 0.9997675846005005, \"f1\": 0.04308344036593884, \"f2\": 0.027369337181072786, \"f0_5\": 0.10117044468431859, \"p4\": 0.08260745374175234, \"phi\": 0.1483605925892182}, {\"truth_threshold\": 40.099999103695154, \"match_probability\": 0.9999999999991515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6629.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02180871888169864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9781912811183013, \"precision\": 1.0, \"recall\": 0.02180871888169864, \"specificity\": 1.0, \"npv\": 0.9997675341400554, \"accuracy\": 0.9997675353448763, \"f1\": 0.04268649988731125, \"f2\": 0.027113073253969618, \"f0_5\": 0.10029442290991507, \"p4\": 0.08187752833448252, \"phi\": 0.14766058749412286}, {\"truth_threshold\": 40.11999910324812, \"match_probability\": 0.9999999999991631, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6588.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297373.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021673833156227278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9783261668437727, \"precision\": 1.0, \"recall\": 0.021673833156227278, \"specificity\": 1.0, \"npv\": 0.9997675020920945, \"accuracy\": 0.9997675032896287, \"f1\": 0.042428087032964204, \"f2\": 0.02694628412868773, \"f0_5\": 0.09972359549881477, \"p4\": 0.08140203965652469, \"phi\": 0.14720324057357626}, {\"truth_threshold\": 40.139999102801085, \"match_probability\": 0.9999999999991747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6545.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021532367639269512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9784676323607305, \"precision\": 1.0, \"recall\": 0.021532367639269512, \"specificity\": 1.0, \"npv\": 0.9997674684808208, \"accuracy\": 0.9997674696707106, \"f1\": 0.042156995355967355, \"f2\": 0.026771346928023732, \"f0_5\": 0.09912431355087675, \"p4\": 0.08090296803302512, \"phi\": 0.14672205248397674}, {\"truth_threshold\": 40.15999910235405, \"match_probability\": 0.999999999999186, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6530.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021483019203121453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9785169807968785, \"precision\": 1.0, \"recall\": 0.021483019203121453, \"specificity\": 1.0, \"npv\": 0.9997674567559584, \"accuracy\": 0.999767457943181, \"f1\": 0.04206241082672284, \"f2\": 0.026710319427605628, \"f0_5\": 0.09891511477485829, \"p4\": 0.08072877964907717, \"phi\": 0.14655382448828874}, {\"truth_threshold\": 40.179999101907015, \"match_probability\": 0.9999999999991972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6513.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021427090975486986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.978572909024513, \"precision\": 1.0, \"recall\": 0.021427090975486986, \"specificity\": 1.0, \"npv\": 0.9997674434677812, \"accuracy\": 0.9997674446519808, \"f1\": 0.04195520397843298, \"f2\": 0.026641153116479063, \"f0_5\": 0.09867793086938999, \"p4\": 0.08053130755991186, \"phi\": 0.14636293234803063}, {\"truth_threshold\": 40.19999910145998, \"match_probability\": 0.9999999999992082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6481.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297480.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021321814311704462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9786781856882956, \"precision\": 1.0, \"recall\": 0.021321814311704462, \"specificity\": 1.0, \"npv\": 0.9997674184547429, \"accuracy\": 0.999767419633251, \"f1\": 0.04175337100005798, \"f2\": 0.02651095248808623, \"f0_5\": 0.09823120178243934, \"p4\": 0.08015942642236357, \"phi\": 0.14600292891303296}, {\"truth_threshold\": 40.219999101012945, \"match_probability\": 0.9999999999992192, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6447.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297514.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021209957856435528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9787900421435645, \"precision\": 1.0, \"recall\": 0.021209957856435528, \"specificity\": 1.0, \"npv\": 0.9997673918783911, \"accuracy\": 0.9997673930508506, \"f1\": 0.041538877863972576, \"f2\": 0.026372606850578136, \"f0_5\": 0.09775617211879338, \"p4\": 0.07976406071111651, \"phi\": 0.14561945010189795}, {\"truth_threshold\": 40.23999910056591, \"match_probability\": 0.9999999999992298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6419.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297542.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02111784077562582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9788821592243742, \"precision\": 1.0, \"recall\": 0.02111784077562582, \"specificity\": 1.0, \"npv\": 0.9997673699919849, \"accuracy\": 0.999767371159462, \"f1\": 0.04136220117275598, \"f2\": 0.026258669369849205, \"f0_5\": 0.09736467690216814, \"p4\": 0.07943827803844287, \"phi\": 0.14530288411506817}, {\"truth_threshold\": 40.259999100118876, \"match_probability\": 0.9999999999992405, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6404.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021068492339477763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9789315076605223, \"precision\": 1.0, \"recall\": 0.021068492339477763, \"specificity\": 1.0, \"npv\": 0.9997673582671248, \"accuracy\": 0.9997673594319325, \"f1\": 0.04126753983213313, \"f2\": 0.02619762928636414, \"f0_5\": 0.09715483786793375, \"p4\": 0.07926368193661826, \"phi\": 0.14513301116186778}, {\"truth_threshold\": 40.27999909967184, \"match_probability\": 0.9999999999992509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6385.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02100598432035689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9789940156796431, \"precision\": 1.0, \"recall\": 0.02100598432035689, \"specificity\": 1.0, \"npv\": 0.9997673434156357, \"accuracy\": 0.9997673445770616, \"f1\": 0.041147622331204524, \"f2\": 0.02612030969646441, \"f0_5\": 0.09688893205179953, \"p4\": 0.07904245705608501, \"phi\": 0.14491755290437974}, {\"truth_threshold\": 40.299999099224806, \"match_probability\": 0.9999999999992613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6371.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297590.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020959925779952034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.979040074220048, \"precision\": 1.0, \"recall\": 0.020959925779952034, \"specificity\": 1.0, \"npv\": 0.9997673324724335, \"accuracy\": 0.9997673336313674, \"f1\": 0.04105925267133264, \"f2\": 0.026063335828802624, \"f0_5\": 0.09669292294616703, \"p4\": 0.07887939929520119, \"phi\": 0.1447585889881593}, {\"truth_threshold\": 40.31999909877777, \"match_probability\": 0.9999999999992715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6350.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020890837969344753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9791091620306552, \"precision\": 1.0, \"recall\": 0.020890837969344753, \"specificity\": 1.0, \"npv\": 0.9997673160576307, \"accuracy\": 0.999767317212826, \"f1\": 0.040926683230694365, \"f2\": 0.025977872579966848, \"f0_5\": 0.09639878431265389, \"p4\": 0.07863473314146223, \"phi\": 0.14451981527391544}, {\"truth_threshold\": 40.339999098330736, \"match_probability\": 0.9999999999992815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6329.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02082175015873747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9791782498412626, \"precision\": 1.0, \"recall\": 0.02082175015873747, \"specificity\": 1.0, \"npv\": 0.9997672996428284, \"accuracy\": 0.9997673007942846, \"f1\": 0.04079409584582165, \"f2\": 0.025892406394184785, \"f0_5\": 0.0961044956070421, \"p4\": 0.07838997152318691, \"phi\": 0.14428064641537544}, {\"truth_threshold\": 40.3599990978837, \"match_probability\": 0.9999999999992913, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6278.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297683.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02065396547583407, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9793460345241659, \"precision\": 1.0, \"recall\": 0.02065396547583407, \"specificity\": 1.0, \"npv\": 0.9997672597783107, \"accuracy\": 0.9997672609206839, \"f1\": 0.04047202318212733, \"f2\": 0.025684833429068455, \"f0_5\": 0.09538916896858751, \"p4\": 0.07779515266248502, \"phi\": 0.1436981505355252}, {\"truth_threshold\": 40.37999909743667, \"match_probability\": 0.9999999999993011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6247.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297714.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02055197870779475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9794480212922052, \"precision\": 1.0, \"recall\": 0.02055197870779475, \"specificity\": 1.0, \"npv\": 0.9997672355469388, \"accuracy\": 0.9997672366837895, \"f1\": 0.04027620177429338, \"f2\": 0.025558653160852998, \"f0_5\": 0.09495392902851202, \"p4\": 0.0774333204615376, \"phi\": 0.14334292775617324}, {\"truth_threshold\": 40.39999909698963, \"match_probability\": 0.9999999999993108, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6224.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297737.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02047631110570106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.979523688894299, \"precision\": 1.0, \"recall\": 0.02047631110570106, \"specificity\": 1.0, \"npv\": 0.9997672175688248, \"accuracy\": 0.9997672187015775, \"f1\": 0.04013088963038187, \"f2\": 0.02546503140578102, \"f0_5\": 0.0946307969725443, \"p4\": 0.07716472950624435, \"phi\": 0.14307880548921414}, {\"truth_threshold\": 40.4199990965426, \"match_probability\": 0.9999999999993202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6159.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020262467882392807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9797375321176072, \"precision\": 1.0, \"recall\": 0.020262467882392807, \"specificity\": 1.0, \"npv\": 0.9997671667611152, \"accuracy\": 0.9997671678822826, \"f1\": 0.03972010834515671, \"f2\": 0.025200429131516044, \"f0_5\": 0.093716619445704, \"p4\": 0.07640504657678289, \"phi\": 0.14232972320063}, {\"truth_threshold\": 40.43999909609556, \"match_probability\": 0.9999999999993295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6125.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297836.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020150611427123873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798493885728762, \"precision\": 1.0, \"recall\": 0.020150611427123873, \"specificity\": 1.0, \"npv\": 0.9997671401847767, \"accuracy\": 0.9997671412998822, \"f1\": 0.03950516953361326, \"f2\": 0.025062010574736348, \"f0_5\": 0.09323785776697995, \"p4\": 0.07600730780329751, \"phi\": 0.1419363207902414}, {\"truth_threshold\": 40.45999909564853, \"match_probability\": 0.9999999999993389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6118.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020127582156921446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798724178430785, \"precision\": 1.0, \"recall\": 0.020127582156921446, \"specificity\": 1.0, \"npv\": 0.9997671347131779, \"accuracy\": 0.999767135827035, \"f1\": 0.03946091157414723, \"f2\": 0.025033511680395953, \"f0_5\": 0.0931392399667512, \"p4\": 0.07592538915717405, \"phi\": 0.14185519074651248}, {\"truth_threshold\": 40.47999909520149, \"match_probability\": 0.999999999999348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6096.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297865.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020055204450570963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.979944795549429, \"precision\": 1.0, \"recall\": 0.020055204450570963, \"specificity\": 1.0, \"npv\": 0.9997671175167245, \"accuracy\": 0.9997671186266583, \"f1\": 0.03932180212025531, \"f2\": 0.024943941601060608, \"f0_5\": 0.09282918881054988, \"p4\": 0.07566786104216339, \"phi\": 0.14159990799698957}, {\"truth_threshold\": 40.49999909475446, \"match_probability\": 0.9999999999993568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6050.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01990386924638358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9800961307536165, \"precision\": 1.0, \"recall\": 0.01990386924638358, \"specificity\": 1.0, \"npv\": 0.9997670815605059, \"accuracy\": 0.9997670826622342, \"f1\": 0.03903087309805136, \"f2\": 0.024756648285366816, \"f0_5\": 0.092180362687827, \"p4\": 0.07512905211786915, \"phi\": 0.1410646421617367}, {\"truth_threshold\": 40.51999909430742, \"match_probability\": 0.9999999999993657, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6022.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019811752165573873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9801882478344262, \"precision\": 1.0, \"recall\": 0.019811752165573873, \"specificity\": 1.0, \"npv\": 0.9997670596741132, \"accuracy\": 0.9997670607708457, \"f1\": 0.03885374359239055, \"f2\": 0.02464263675394847, \"f0_5\": 0.09178506869400607, \"p4\": 0.07480085535500933, \"phi\": 0.14073783147955649}, {\"truth_threshold\": 40.53999909386039, \"match_probability\": 0.9999999999993745, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6002.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019745954250709796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9802540457492902, \"precision\": 1.0, \"recall\": 0.019745954250709796, \"specificity\": 1.0, \"npv\": 0.9997670440409762, \"accuracy\": 0.9997670451341396, \"f1\": 0.03872720292421999, \"f2\": 0.02456119674656217, \"f0_5\": 0.09150255054593574, \"p4\": 0.07456632424114228, \"phi\": 0.14050392988454266}, {\"truth_threshold\": 40.55999909341335, \"match_probability\": 0.999999999999383, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5980.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01967357654435931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9803264234556407, \"precision\": 1.0, \"recall\": 0.01967357654435931, \"specificity\": 1.0, \"npv\": 0.9997670268445259, \"accuracy\": 0.9997670279337628, \"f1\": 0.03858798932700094, \"f2\": 0.024471609659001622, \"f0_5\": 0.09119162135042896, \"p4\": 0.07430823902741171, \"phi\": 0.14024618757439472}, {\"truth_threshold\": 40.57999909296632, \"match_probability\": 0.9999999999993916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5918.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019469603008280666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9805303969917193, \"precision\": 1.0, \"recall\": 0.019469603008280666, \"specificity\": 1.0, \"npv\": 0.9997669783818058, \"accuracy\": 0.9997669794599738, \"f1\": 0.038195553748398565, \"f2\": 0.024219119599398247, \"f0_5\": 0.09031446771234888, \"p4\": 0.073580338210682, \"phi\": 0.1395172611897255}, {\"truth_threshold\": 40.59999909251928, \"match_probability\": 0.9999999999993999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5892.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019384065718957365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9806159342810427, \"precision\": 1.0, \"recall\": 0.019384065718957365, \"specificity\": 1.0, \"npv\": 0.9997669580587311, \"accuracy\": 0.999766959132256, \"f1\": 0.03803093725088994, \"f2\": 0.02411322904457264, \"f0_5\": 0.08994623376861285, \"p4\": 0.07327483891499836, \"phi\": 0.1392104465140908}, {\"truth_threshold\": 40.61999909207225, \"match_probability\": 0.9999999999994083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5849.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0192426002019996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9807573997980004, \"precision\": 1.0, \"recall\": 0.0192426002019996, \"specificity\": 1.0, \"npv\": 0.9997669244474938, \"accuracy\": 0.9997669255133378, \"f1\": 0.03775862625480133, \"f2\": 0.02393809246676538, \"f0_5\": 0.08933671801733276, \"p4\": 0.07276926475709602, \"phi\": 0.13870153287662637}, {\"truth_threshold\": 40.639999091625214, \"match_probability\": 0.9999999999994164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5809.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019111004372271444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9808889956277286, \"precision\": 1.0, \"recall\": 0.019111004372271444, \"specificity\": 1.0, \"npv\": 0.9997668931812287, \"accuracy\": 0.9997668942399256, \"f1\": 0.03750524582754947, \"f2\": 0.023775163651216836, \"f0_5\": 0.08876915130639951, \"p4\": 0.07229859881630525, \"phi\": 0.13822644271932452}, {\"truth_threshold\": 40.65999909117818, \"match_probability\": 0.9999999999994243, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5774.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298187.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018995858021259308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9810041419787406, \"precision\": 1.0, \"recall\": 0.018995858021259308, \"specificity\": 1.0, \"npv\": 0.9997668658232483, \"accuracy\": 0.9997668668756898, \"f1\": 0.03728348426881044, \"f2\": 0.023632592185118425, \"f0_5\": 0.08827207489825932, \"p4\": 0.07188647768429753, \"phi\": 0.13780939531663952}, {\"truth_threshold\": 40.679999090731144, \"match_probability\": 0.9999999999994323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5749.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018913610627679208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9810863893723208, \"precision\": 1.0, \"recall\": 0.018913610627679208, \"specificity\": 1.0, \"npv\": 0.9997668462818347, \"accuracy\": 0.9997668473298073, \"f1\": 0.03712505246843822, \"f2\": 0.023530750421785325, \"f0_5\": 0.08791675969622917, \"p4\": 0.07159194047387345, \"phi\": 0.1375107299414756}, {\"truth_threshold\": 40.69999909028411, \"match_probability\": 0.9999999999994401, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5715.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298246.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018801754172410277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9811982458275897, \"precision\": 1.0, \"recall\": 0.018801754172410277, \"specificity\": 1.0, \"npv\": 0.9997668197055133, \"accuracy\": 0.9997668207474069, \"f1\": 0.036909544168744104, \"f2\": 0.023392238934017925, \"f0_5\": 0.08743318207826302, \"p4\": 0.07119114904966115, \"phi\": 0.13710350095397086}, {\"truth_threshold\": 40.719999089837074, \"match_probability\": 0.9999999999994479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5677.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298284.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01867673813416853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9813232618658315, \"precision\": 1.0, \"recall\": 0.01867673813416853, \"specificity\": 1.0, \"npv\": 0.9997667900025675, \"accuracy\": 0.9997667910376652, \"f1\": 0.0366686259438441, \"f2\": 0.023237422852329187, \"f0_5\": 0.08689223648402511, \"p4\": 0.07074290424458017, \"phi\": 0.13664692653739494}, {\"truth_threshold\": 40.73999908939004, \"match_probability\": 0.9999999999994554, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5643.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018564881678899595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9814351183211004, \"precision\": 1.0, \"recall\": 0.018564881678899595, \"specificity\": 1.0, \"npv\": 0.9997667634262491, \"accuracy\": 0.9997667644552648, \"f1\": 0.03645301740287593, \"f2\": 0.023098895035313514, \"f0_5\": 0.08640780564292123, \"p4\": 0.07034157311870118, \"phi\": 0.13623711560916402}, {\"truth_threshold\": 40.759999088943005, \"match_probability\": 0.999999999999463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5606.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298355.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01844315553640105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9815568444635989, \"precision\": 1.0, \"recall\": 0.01844315553640105, \"specificity\": 1.0, \"npv\": 0.9997667345049631, \"accuracy\": 0.9997667355273585, \"f1\": 0.03621833076523014, \"f2\": 0.022948135412829015, \"f0_5\": 0.08588017218928566, \"p4\": 0.06990454040151359, \"phi\": 0.1357897396145777}, {\"truth_threshold\": 40.77999908849597, \"match_probability\": 0.9999999999994703, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5583.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018367487934307362, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9816325120656927, \"precision\": 1.0, \"recall\": 0.018367487934307362, \"specificity\": 1.0, \"npv\": 0.9997667165268672, \"accuracy\": 0.9997667175451465, \"f1\": 0.036072416199312535, \"f2\": 0.02285441536825369, \"f0_5\": 0.08555194257921561, \"p4\": 0.0696327189288734, \"phi\": 0.13551089662063834}, {\"truth_threshold\": 40.799999088048935, \"match_probability\": 0.9999999999994776, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5548.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018252341583295226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9817476584167047, \"precision\": 1.0, \"recall\": 0.018252341583295226, \"specificity\": 1.0, \"npv\": 0.9997666891688965, \"accuracy\": 0.9997666901809108, \"f1\": 0.03585033068505278, \"f2\": 0.02271179113667029, \"f0_5\": 0.08505210744650517, \"p4\": 0.06921885304851746, \"phi\": 0.13508546596251886}, {\"truth_threshold\": 40.8199990876019, \"match_probability\": 0.9999999999994849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5519.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298442.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018156934606742312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9818430653932577, \"precision\": 1.0, \"recall\": 0.018156934606742312, \"specificity\": 1.0, \"npv\": 0.9997666665008648, \"accuracy\": 0.999766667507687, \"f1\": 0.03566627891947784, \"f2\": 0.022593610580965692, \"f0_5\": 0.08463763315206556, \"p4\": 0.0688757301723053, \"phi\": 0.1347319486449185}, {\"truth_threshold\": 40.839999087154865, \"match_probability\": 0.999999999999492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5479.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298482.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018025338777014156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9819746612229858, \"precision\": 1.0, \"recall\": 0.018025338777014156, \"specificity\": 1.0, \"npv\": 0.9997666352346157, \"accuracy\": 0.9997666362342746, \"f1\": 0.035412357807652534, \"f2\": 0.02243059370862581, \"f0_5\": 0.08406546028102628, \"p4\": 0.06840215144980573, \"phi\": 0.13424281097347257}, {\"truth_threshold\": 40.85999908670783, \"match_probability\": 0.999999999999499, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5440.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017897032843029206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9821029671569708, \"precision\": 1.0, \"recall\": 0.017897032843029206, \"specificity\": 1.0, \"npv\": 0.9997666047500248, \"accuracy\": 0.9997666057426977, \"f1\": 0.03516472151027308, \"f2\": 0.02227164197680474, \"f0_5\": 0.08350705051255522, \"p4\": 0.06794007049554021, \"phi\": 0.1337641796617278}, {\"truth_threshold\": 40.879999086260796, \"match_probability\": 0.9999999999995058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5410.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298551.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017798335970733086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9822016640292669, \"precision\": 1.0, \"recall\": 0.017798335970733086, \"specificity\": 1.0, \"npv\": 0.9997665813003407, \"accuracy\": 0.9997665822876386, \"f1\": 0.03497418956527923, \"f2\": 0.02214936450566385, \"f0_5\": 0.08307714042647289, \"p4\": 0.06758439379879023, \"phi\": 0.13339483313192718}, {\"truth_threshold\": 40.89999908581376, \"match_probability\": 0.9999999999995126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5368.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298593.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017660160349518523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9823398396504814, \"precision\": 1.0, \"recall\": 0.017660160349518523, \"specificity\": 1.0, \"npv\": 0.9997665484707849, \"accuracy\": 0.9997665494505558, \"f1\": 0.034707382754284276, \"f2\": 0.021978165953167837, \"f0_5\": 0.08247473366253576, \"p4\": 0.06708611035325698, \"phi\": 0.13287602326258394}, {\"truth_threshold\": 40.919999085366726, \"match_probability\": 0.9999999999995193, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5349.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298612.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01759765233039765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9824023476696023, \"precision\": 1.0, \"recall\": 0.01759765233039765, \"specificity\": 1.0, \"npv\": 0.9997665336193199, \"accuracy\": 0.999766534595685, \"f1\": 0.03458666063172869, \"f2\": 0.021900715120378188, \"f0_5\": 0.08220201194380326, \"p4\": 0.06686056749907786, \"phi\": 0.13264065692765398}, {\"truth_threshold\": 40.93999908491969, \"match_probability\": 0.9999999999995259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5324.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298637.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017515404936817552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9824845950631824, \"precision\": 1.0, \"recall\": 0.017515404936817552, \"specificity\": 1.0, \"npv\": 0.9997665140779192, \"accuracy\": 0.9997665150498023, \"f1\": 0.03442779313578091, \"f2\": 0.02179880245797466, \"f0_5\": 0.08184297340257089, \"p4\": 0.06656367813499146, \"phi\": 0.1323303265935109}, {\"truth_threshold\": 40.959999084472656, \"match_probability\": 0.9999999999995325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5292.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298669.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01741012827303503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.982589871726965, \"precision\": 1.0, \"recall\": 0.01741012827303503, \"specificity\": 1.0, \"npv\": 0.9997664890649275, \"accuracy\": 0.9997664900310725, \"f1\": 0.034224405260417846, \"f2\": 0.02166834816105659, \"f0_5\": 0.08138308179215019, \"p4\": 0.06618345655869028, \"phi\": 0.13193203863240444}, {\"truth_threshold\": 40.97999908402562, \"match_probability\": 0.9999999999995389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5263.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298698.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017314721296482115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9826852787035179, \"precision\": 1.0, \"recall\": 0.017314721296482115, \"specificity\": 1.0, \"npv\": 0.9997664663969047, \"accuracy\": 0.9997664673578487, \"f1\": 0.034040048637880634, \"f2\": 0.021550118048623095, \"f0_5\": 0.08096599212954558, \"p4\": 0.0658386835327738, \"phi\": 0.13157004874678416}, {\"truth_threshold\": 40.99999908357859, \"match_probability\": 0.9999999999995453, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5212.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298749.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017146936613578717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9828530633864213, \"precision\": 1.0, \"recall\": 0.017146936613578717, \"specificity\": 1.0, \"npv\": 0.9997664265324535, \"accuracy\": 0.999766427484248, \"f1\": 0.03371575137544352, \"f2\": 0.021342182504324125, \"f0_5\": 0.08023176697690027, \"p4\": 0.06523190320657657, \"phi\": 0.13093101826586426}, {\"truth_threshold\": 41.01999908313155, \"match_probability\": 0.9999999999995515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5178.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017035080158309783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9829649198416902, \"precision\": 1.0, \"recall\": 0.017035080158309783, \"specificity\": 1.0, \"npv\": 0.9997663999561545, \"accuracy\": 0.9997664009018477, \"f1\": 0.033499493755236316, \"f2\": 0.02120354915800043, \"f0_5\": 0.07974177095108001, \"p4\": 0.0648270601045286, \"phi\": 0.13050325958702294}, {\"truth_threshold\": 41.03999908268452, \"match_probability\": 0.9999999999995577, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5143.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016919933807297647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9830800661927024, \"precision\": 1.0, \"recall\": 0.016919933807297647, \"specificity\": 1.0, \"npv\": 0.9997663725982011, \"accuracy\": 0.999766373537612, \"f1\": 0.03327682592266681, \"f2\": 0.02106083029549045, \"f0_5\": 0.07923693430252085, \"p4\": 0.06441003973295009, \"phi\": 0.13006145027302918}, {\"truth_threshold\": 41.05999908223748, \"match_probability\": 0.9999999999995638, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5113.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01682123693500153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9831787630649985, \"precision\": 1.0, \"recall\": 0.01682123693500153, \"specificity\": 1.0, \"npv\": 0.9997663491485279, \"accuracy\": 0.9997663500825528, \"f1\": 0.03308592764192394, \"f2\": 0.020938493329412913, \"f0_5\": 0.07880387037510828, \"p4\": 0.06405237538838295, \"phi\": 0.1296815585913003}, {\"truth_threshold\": 41.07999908179045, \"match_probability\": 0.9999999999995698, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5101.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298860.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016781758186083084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9832182418139169, \"precision\": 1.0, \"recall\": 0.016781758186083084, \"specificity\": 1.0, \"npv\": 0.9997663397686589, \"accuracy\": 0.999766340700529, \"f1\": 0.03300955795277323, \"f2\": 0.0208895568596456, \"f0_5\": 0.07863055508454982, \"p4\": 0.06390925318452617, \"phi\": 0.12952928995629914}, {\"truth_threshold\": 41.09999908134341, \"match_probability\": 0.9999999999995757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5070.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016679771418043762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9833202285819562, \"precision\": 1.0, \"recall\": 0.016679771418043762, \"specificity\": 1.0, \"npv\": 0.9997663155373316, \"accuracy\": 0.9997663164636347, \"f1\": 0.03281224213752018, \"f2\": 0.020763133193656556, \"f0_5\": 0.0781825864094917, \"p4\": 0.06353937137839376, \"phi\": 0.12913509830647324}, {\"truth_threshold\": 41.11999908089638, \"match_probability\": 0.9999999999995816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5047.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016604103815950073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9833958961840499, \"precision\": 1.0, \"recall\": 0.016604103815950073, \"specificity\": 1.0, \"npv\": 0.9997662975592508, \"accuracy\": 0.9997662984814226, \"f1\": 0.03266582094961943, \"f2\": 0.020669330841164364, \"f0_5\": 0.07785000107975036, \"p4\": 0.06326480361126, \"phi\": 0.1288418542103529}, {\"truth_threshold\": 41.13999908044934, \"match_probability\": 0.9999999999995873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5037.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016571204858518034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983428795141482, \"precision\": 1.0, \"recall\": 0.016571204858518034, \"specificity\": 1.0, \"npv\": 0.9997662897426941, \"accuracy\": 0.9997662906630695, \"f1\": 0.03260215276474281, \"f2\": 0.020628546107278267, \"f0_5\": 0.07770533987022885, \"p4\": 0.06314538927878803, \"phi\": 0.12871414839856057}, {\"truth_threshold\": 41.15999908000231, \"match_probability\": 0.999999999999593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5005.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01646592819473551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9835340718052645, \"precision\": 1.0, \"recall\": 0.01646592819473551, \"specificity\": 1.0, \"npv\": 0.9997662647297136, \"accuracy\": 0.9997662656443398, \"f1\": 0.0323983868775205, \"f2\": 0.020498030468960534, \"f0_5\": 0.07724218395523194, \"p4\": 0.06276311245899183, \"phi\": 0.1283046356393969}, {\"truth_threshold\": 41.17999907955527, \"match_probability\": 0.9999999999995985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4986.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298975.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016403420175614636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9835965798243854, \"precision\": 1.0, \"recall\": 0.016403420175614636, \"specificity\": 1.0, \"npv\": 0.999766249878257, \"accuracy\": 0.9997662507894689, \"f1\": 0.03227738090999427, \"f2\": 0.02042053357142272, \"f0_5\": 0.07696701193251107, \"p4\": 0.06253602669828161, \"phi\": 0.12806086784865853}, {\"truth_threshold\": 41.19999907910824, \"match_probability\": 0.9999999999996041, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4975.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298986.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01636723132243939, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9836327686775606, \"precision\": 1.0, \"recall\": 0.01636723132243939, \"specificity\": 1.0, \"npv\": 0.9997662412800455, \"accuracy\": 0.9997662421892806, \"f1\": 0.03220731802056089, \"f2\": 0.020375665843994892, \"f0_5\": 0.07680764278502197, \"p4\": 0.062404518886746765, \"phi\": 0.1279195268103985}, {\"truth_threshold\": 41.2199990786612, \"match_probability\": 0.9999999999996095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4950.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299011.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016284983928859294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9837150160711408, \"precision\": 1.0, \"recall\": 0.016284983928859294, \"specificity\": 1.0, \"npv\": 0.9997662217386563, \"accuracy\": 0.999766222643398, \"f1\": 0.03204806562407943, \"f2\": 0.020273690729148405, \"f0_5\": 0.07644527907932086, \"p4\": 0.062105536240968914, \"phi\": 0.12759771492323205}, {\"truth_threshold\": 41.23999907821417, \"match_probability\": 0.999999999999615, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4910.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299051.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01615338809913114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9838466119008689, \"precision\": 1.0, \"recall\": 0.01615338809913114, \"specificity\": 1.0, \"npv\": 0.9997661904724351, \"accuracy\": 0.9997661913699857, \"f1\": 0.03179320816781116, \"f2\": 0.020110521857802637, \"f0_5\": 0.07586503131943349, \"p4\": 0.06162687128130936, \"phi\": 0.12708112087596293}, {\"truth_threshold\": 41.259999077767134, \"match_probability\": 0.9999999999996202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4883.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01606456091406463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9839354390859354, \"precision\": 1.0, \"recall\": 0.01606456091406463, \"specificity\": 1.0, \"npv\": 0.9997661693677369, \"accuracy\": 0.9997661702604325, \"f1\": 0.03162114206524977, \"f2\": 0.020000376824629913, \"f0_5\": 0.0754730396020934, \"p4\": 0.061303568587057, \"phi\": 0.12673122948835094}, {\"truth_threshold\": 41.2799990773201, \"match_probability\": 0.9999999999996255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4846.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01594283477156609, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9840571652284339, \"precision\": 1.0, \"recall\": 0.01594283477156609, \"specificity\": 1.0, \"npv\": 0.9997661404464852, \"accuracy\": 0.9997661413325262, \"f1\": 0.03138529890837967, \"f2\": 0.019849429421065136, \"f0_5\": 0.07493544047379734, \"p4\": 0.06086025705558783, \"phi\": 0.1262501738111463}, {\"truth_threshold\": 41.299999076873064, \"match_probability\": 0.9999999999996306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4782.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015732281444001038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9842677185559989, \"precision\": 1.0, \"recall\": 0.015732281444001038, \"specificity\": 1.0, \"npv\": 0.9997660904205403, \"accuracy\": 0.9997660912950666, \"f1\": 0.030977220536174098, \"f2\": 0.019588309605071495, \"f0_5\": 0.07400437650306882, \"p4\": 0.06009271793340048, \"phi\": 0.12541372138910692}, {\"truth_threshold\": 41.31999907642603, \"match_probability\": 0.9999999999996357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4741.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299220.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01559739571852968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9844026042814703, \"precision\": 1.0, \"recall\": 0.01559739571852968, \"specificity\": 1.0, \"npv\": 0.9997660583726721, \"accuracy\": 0.9997660592398191, \"f1\": 0.030715706409417495, \"f2\": 0.019421015332811726, \"f0_5\": 0.07340713788031276, \"p4\": 0.059600526363864, \"phi\": 0.12487492477832854}, {\"truth_threshold\": 41.339999075978994, \"match_probability\": 0.9999999999996407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4720.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299241.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015528307907922399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9844716920920776, \"precision\": 1.0, \"recall\": 0.015528307907922399, \"specificity\": 1.0, \"npv\": 0.999766041957911, \"accuracy\": 0.9997660428212777, \"f1\": 0.03058173324564842, \"f2\": 0.019335323670041062, \"f0_5\": 0.0731010001827525, \"p4\": 0.059348280834737865, \"phi\": 0.12459805349766627}, {\"truth_threshold\": 41.35999907553196, \"match_probability\": 0.9999999999996457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4708.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299253.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015488829159003951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984511170840996, \"precision\": 1.0, \"recall\": 0.015488829159003951, \"specificity\": 1.0, \"npv\": 0.9997660325780479, \"accuracy\": 0.999766033439254, \"f1\": 0.030505168967405214, \"f2\": 0.019286355681691562, \"f0_5\": 0.0729259928189273, \"p4\": 0.05920409566727281, \"phi\": 0.12443956475967184}, {\"truth_threshold\": 41.379999075084925, \"match_probability\": 0.9999999999996505, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4693.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299268.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015439480722855893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984560519277144, \"precision\": 1.0, \"recall\": 0.015439480722855893, \"specificity\": 1.0, \"npv\": 0.9997660208532191, \"accuracy\": 0.9997660217117244, \"f1\": 0.030409455247623552, \"f2\": 0.019225144342203473, \"f0_5\": 0.07270716040813924, \"p4\": 0.059023818302395205, \"phi\": 0.12424116953059326}, {\"truth_threshold\": 41.39999907463789, \"match_probability\": 0.9999999999996554, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4678.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299283.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015390132286707834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9846098677132922, \"precision\": 1.0, \"recall\": 0.015390132286707834, \"specificity\": 1.0, \"npv\": 0.9997660091283906, \"accuracy\": 0.9997660099841947, \"f1\": 0.030313732224378644, \"f2\": 0.01916393149816226, \"f0_5\": 0.07248824661499413, \"p4\": 0.05884348991114271, \"phi\": 0.12404245699049936}, {\"truth_threshold\": 41.419999074190855, \"match_probability\": 0.9999999999996602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4660.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299301.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015330914163330165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9846690858366698, \"precision\": 1.0, \"recall\": 0.015330914163330165, \"specificity\": 1.0, \"npv\": 0.9997659950585968, \"accuracy\": 0.9997659959111593, \"f1\": 0.03019885231400326, \"f2\": 0.019090474099224583, \"f0_5\": 0.07222544257457354, \"p4\": 0.05862702845631582, \"phi\": 0.12380358094037391}, {\"truth_threshold\": 41.43999907374382, \"match_probability\": 0.9999999999996648, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4640.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015265116248466087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984734883751534, \"precision\": 1.0, \"recall\": 0.015265116248466087, \"specificity\": 1.0, \"npv\": 0.9997659794254931, \"accuracy\": 0.9997659802744532, \"f1\": 0.030071192251483306, \"f2\": 0.019008852225838275, \"f0_5\": 0.07193330046725639, \"p4\": 0.05838642946868873, \"phi\": 0.1235376213838995}, {\"truth_threshold\": 41.459999073296785, \"match_probability\": 0.9999999999996694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4605.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299356.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015149969897453949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984850030102546, \"precision\": 1.0, \"recall\": 0.015149969897453949, \"specificity\": 1.0, \"npv\": 0.9997659520675626, \"accuracy\": 0.9997659529102174, \"f1\": 0.029847747321480655, \"f2\": 0.0188660075103507, \"f0_5\": 0.0714217028919198, \"p4\": 0.05796516260214661, \"phi\": 0.12307080920479463}, {\"truth_threshold\": 41.47999907284975, \"match_probability\": 0.9999999999996739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4587.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299374.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01509075177407628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9849092482259237, \"precision\": 1.0, \"recall\": 0.01509075177407628, \"specificity\": 1.0, \"npv\": 0.9997659379977705, \"accuracy\": 0.999765938837182, \"f1\": 0.029732813046916527, \"f2\": 0.018792541323516036, \"f0_5\": 0.07115842250759365, \"p4\": 0.05774840264240638, \"phi\": 0.12283004356630707}, {\"truth_threshold\": 41.499999072402716, \"match_probability\": 0.9999999999996785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4561.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299400.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015005214484752978, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984994785515247, \"precision\": 1.0, \"recall\": 0.015005214484752978, \"specificity\": 1.0, \"npv\": 0.999765917674738, \"accuracy\": 0.9997659185094641, \"f1\": 0.029566773196076777, \"f2\": 0.018686419672158013, \"f0_5\": 0.07077792088887509, \"p4\": 0.057435174802633555, \"phi\": 0.12248143544739884}, {\"truth_threshold\": 41.51999907195568, \"match_probability\": 0.9999999999996829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4551.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014972315527320939, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9850276844726791, \"precision\": 1.0, \"recall\": 0.014972315527320939, \"specificity\": 1.0, \"npv\": 0.9997659098581873, \"accuracy\": 0.999765910691111, \"f1\": 0.029502904263043254, \"f2\": 0.018645602448387612, \"f0_5\": 0.07063150869895861, \"p4\": 0.05731466158878015, \"phi\": 0.12234709091701317}, {\"truth_threshold\": 41.539999071508646, \"match_probability\": 0.9999999999996873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4527.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299434.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014893358029484046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.985106641970516, \"precision\": 1.0, \"recall\": 0.014893358029484046, \"specificity\": 1.0, \"npv\": 0.9997658910984659, \"accuracy\": 0.9997658919270637, \"f1\": 0.029349601929410545, \"f2\": 0.01854763838209856, \"f0_5\": 0.0702799710621016, \"p4\": 0.05702533696257134, \"phi\": 0.12202406058558947}, {\"truth_threshold\": 41.55999907106161, \"match_probability\": 0.9999999999996916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4503.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299458.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014814400531647152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9851855994683528, \"precision\": 1.0, \"recall\": 0.014814400531647152, \"specificity\": 1.0, \"npv\": 0.9997658723387454, \"accuracy\": 0.9997658731630162, \"f1\": 0.029196275740442968, \"f2\": 0.018449670462581544, \"f0_5\": 0.06992822379516295, \"p4\": 0.05673588109322395, \"phi\": 0.1217001728458008}, {\"truth_threshold\": 41.579999070614576, \"match_probability\": 0.9999999999996958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4477.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299484.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01472886324232385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9852711367576762, \"precision\": 1.0, \"recall\": 0.01472886324232385, \"specificity\": 1.0, \"npv\": 0.9997658520157157, \"accuracy\": 0.9997658528352983, \"f1\": 0.029030145442520052, \"f2\": 0.01834353420124705, \"f0_5\": 0.06954692747670636, \"p4\": 0.056422155693592636, \"phi\": 0.12134831893637776}, {\"truth_threshold\": 41.59999907016754, \"match_probability\": 0.9999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4458.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299503.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014666355223202976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.985333644776797, \"precision\": 1.0, \"recall\": 0.014666355223202976, \"specificity\": 1.0, \"npv\": 0.9997658371642713, \"accuracy\": 0.9997658379804275, \"f1\": 0.028908724819158352, \"f2\": 0.01826597022704216, \"f0_5\": 0.06926813199789927, \"p4\": 0.05619279728588589, \"phi\": 0.12109054838373681}, {\"truth_threshold\": 41.61999906972051, \"match_probability\": 0.9999999999997041, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4450.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299511.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014640036057257345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9853599639427426, \"precision\": 1.0, \"recall\": 0.014640036057257345, \"specificity\": 1.0, \"npv\": 0.9997658309110317, \"accuracy\": 0.9997658317257451, \"f1\": 0.028857595870445608, \"f2\": 0.018233310988991176, \"f0_5\": 0.06915070502640158, \"p4\": 0.05609620067103026, \"phi\": 0.12098184910701007}, {\"truth_threshold\": 41.63999906927347, \"match_probability\": 0.9999999999997082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4429.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299532.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014570948246650063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9854290517533499, \"precision\": 1.0, \"recall\": 0.014570948246650063, \"specificity\": 1.0, \"npv\": 0.9997658144962781, \"accuracy\": 0.9997658153072037, \"f1\": 0.028723369759071304, \"f2\": 0.018147578451707117, \"f0_5\": 0.06884234806964751, \"p4\": 0.055842565015697836, \"phi\": 0.12069604774720344}, {\"truth_threshold\": 41.65999906882644, \"match_probability\": 0.9999999999997122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4405.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299556.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014491990748813171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9855080092511869, \"precision\": 1.0, \"recall\": 0.014491990748813171, \"specificity\": 1.0, \"npv\": 0.9997657957365604, \"accuracy\": 0.9997657965431563, \"f1\": 0.028569946103007466, \"f2\": 0.018049594795816262, \"f0_5\": 0.06848974286416175, \"p4\": 0.05555257230895176, \"phi\": 0.1203685866943451}, {\"truth_threshold\": 41.6799990683794, \"match_probability\": 0.9999999999997161, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4386.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014429482729692297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9855705172703078, \"precision\": 1.0, \"recall\": 0.014429482729692297, \"specificity\": 1.0, \"npv\": 0.9997657808851178, \"accuracy\": 0.9997657816882856, \"f1\": 0.02844846877057341, \"f2\": 0.01797202166804619, \"f0_5\": 0.06821044773798231, \"p4\": 0.05532290135342517, \"phi\": 0.12010871354326938}, {\"truth_threshold\": 41.69999906793237, \"match_probability\": 0.9999999999997201, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4365.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299596.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014360394919085015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.985639605080915, \"precision\": 1.0, \"recall\": 0.014360394919085015, \"specificity\": 1.0, \"npv\": 0.9997657644703659, \"accuracy\": 0.9997657652697441, \"f1\": 0.028314186932013517, \"f2\": 0.017886280137255173, \"f0_5\": 0.06790159945989839, \"p4\": 0.05506895842440413, \"phi\": 0.11982082959308614}, {\"truth_threshold\": 41.71999906748533, \"match_probability\": 0.9999999999997239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4346.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299615.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01429788689996414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9857021131000359, \"precision\": 1.0, \"recall\": 0.01429788689996414, \"specificity\": 1.0, \"npv\": 0.9997657496189242, \"accuracy\": 0.9997657504148733, \"f1\": 0.02819267807737093, \"f2\": 0.017808701923470935, \"f0_5\": 0.06762202617124898, \"p4\": 0.05483911355506218, \"phi\": 0.11955976586841095}, {\"truth_threshold\": 41.7399990670383, \"match_probability\": 0.9999999999997278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4318.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299643.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014205769819154432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9857942301808456, \"precision\": 1.0, \"recall\": 0.014205769819154432, \"specificity\": 1.0, \"npv\": 0.9997657277325898, \"accuracy\": 0.9997657285234848, \"f1\": 0.028013585096617024, \"f2\": 0.01769437173096687, \"f0_5\": 0.06720978230754623, \"p4\": 0.054500244088500856, \"phi\": 0.1191739980081586}, {\"truth_threshold\": 41.75999906659126, \"match_probability\": 0.9999999999997314, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4295.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299666.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014130102217060741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9858698977829392, \"precision\": 1.0, \"recall\": 0.014130102217060741, \"specificity\": 1.0, \"npv\": 0.9997657097545302, \"accuracy\": 0.9997657105412727, \"f1\": 0.02786644866604381, \"f2\": 0.017600453718797614, \"f0_5\": 0.06687093831058631, \"p4\": 0.05422175260262889, \"phi\": 0.11885618062155537}, {\"truth_threshold\": 41.77999906614423, \"match_probability\": 0.9999999999997352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4273.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299688.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014057724510710256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9859422754892897, \"precision\": 1.0, \"recall\": 0.014057724510710256, \"specificity\": 1.0, \"npv\": 0.9997656925581259, \"accuracy\": 0.9997656933408959, \"f1\": 0.02772568892464816, \"f2\": 0.017510615785207483, \"f0_5\": 0.06654664494647301, \"p4\": 0.053955255911262184, \"phi\": 0.11855138413886855}, {\"truth_threshold\": 41.79999906569719, \"match_probability\": 0.9999999999997388, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4259.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299702.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014011665970305402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9859883340296945, \"precision\": 1.0, \"recall\": 0.014011665970305402, \"specificity\": 1.0, \"npv\": 0.9997656816149597, \"accuracy\": 0.9997656823952017, \"f1\": 0.02763610408150023, \"f2\": 0.01745344450427546, \"f0_5\": 0.06634018386464671, \"p4\": 0.05378560927777997, \"phi\": 0.11835701406914385}, {\"truth_threshold\": 41.81999906525016, \"match_probability\": 0.9999999999997424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4248.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013975477117130158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9860245228828698, \"precision\": 1.0, \"recall\": 0.013975477117130158, \"specificity\": 1.0, \"npv\": 0.999765673016758, \"accuracy\": 0.9997656737950134, \"f1\": 0.027565710281010614, \"f2\": 0.0174085232916862, \"f0_5\": 0.06617791390016607, \"p4\": 0.05365228392627526, \"phi\": 0.11820407051255863}, {\"truth_threshold\": 41.83999906480312, \"match_probability\": 0.999999999999746, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4206.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013837301495915595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9861626985040844, \"precision\": 1.0, \"recall\": 0.013837301495915595, \"specificity\": 1.0, \"npv\": 0.9997656401872619, \"accuracy\": 0.9997656409579305, \"f1\": 0.027296887726460002, \"f2\": 0.017236998483668702, \"f0_5\": 0.0655579282073663, \"p4\": 0.053142967801951005, \"phi\": 0.11761827489182201}, {\"truth_threshold\": 41.85999906435609, \"match_probability\": 0.9999999999997494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4163.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299798.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013695835978957826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9863041640210422, \"precision\": 1.0, \"recall\": 0.013695835978957826, \"specificity\": 1.0, \"npv\": 0.9997656065761132, \"accuracy\": 0.9997656073390123, \"f1\": 0.027021588711038415, \"f2\": 0.01706137751668638, \"f0_5\": 0.06492250782095549, \"p4\": 0.05262110488655214, \"phi\": 0.1170154936966457}, {\"truth_threshold\": 41.879999063909054, \"match_probability\": 0.9999999999997529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4139.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013616878481120934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9863831215188791, \"precision\": 1.0, \"recall\": 0.013616878481120934, \"specificity\": 1.0, \"npv\": 0.9997655878164033, \"accuracy\": 0.999765588574965, \"f1\": 0.026867900032456996, \"f2\": 0.01696335112866327, \"f0_5\": 0.06456755803904317, \"p4\": 0.052329647498232004, \"phi\": 0.11667770360656918}, {\"truth_threshold\": 41.89999906346202, \"match_probability\": 0.9999999999997563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4117.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013544500774770447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9864554992252296, \"precision\": 1.0, \"recall\": 0.013544500774770447, \"specificity\": 1.0, \"npv\": 0.9997655706200033, \"accuracy\": 0.9997655713745883, \"f1\": 0.026726997708372554, \"f2\": 0.016873490218129925, \"f0_5\": 0.06424200056798854, \"p4\": 0.05206236165700387, \"phi\": 0.11636720133203965}, {\"truth_threshold\": 41.919999063014984, \"match_probability\": 0.9999999999997596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4096.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299865.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013475412964163165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9865245870358368, \"precision\": 1.0, \"recall\": 0.013475412964163165, \"specificity\": 1.0, \"npv\": 0.9997655542052583, \"accuracy\": 0.9997655549560468, \"f1\": 0.026592481261584706, \"f2\": 0.016787710871026443, \"f0_5\": 0.06393107431050898, \"p4\": 0.05180712109279266, \"phi\": 0.11607003795235578}, {\"truth_threshold\": 41.93999906256795, \"match_probability\": 0.999999999999763, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4072.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013396455466326273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9866035445336737, \"precision\": 1.0, \"recall\": 0.013396455466326273, \"specificity\": 1.0, \"npv\": 0.9997655354455504, \"accuracy\": 0.9997655361919995, \"f1\": 0.026438725720945484, \"f2\": 0.01668967371523941, \"f0_5\": 0.0635755302904927, \"p4\": 0.05151529303134578, \"phi\": 0.11572948834400054}, {\"truth_threshold\": 41.959999062120914, \"match_probability\": 0.9999999999997662, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4057.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013347107030178215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9866528929698218, \"precision\": 1.0, \"recall\": 0.013347107030178215, \"specificity\": 1.0, \"npv\": 0.9997655237207332, \"accuracy\": 0.99976552446447, \"f1\": 0.026342616340603472, \"f2\": 0.016628398533979398, \"f0_5\": 0.06335320701210848, \"p4\": 0.05133283298479709, \"phi\": 0.11551613502096926}, {\"truth_threshold\": 41.97999906167388, \"match_probability\": 0.9999999999997694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4039.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299922.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013287888906800544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9867121110931995, \"precision\": 1.0, \"recall\": 0.013287888906800544, \"specificity\": 1.0, \"npv\": 0.9997655096509531, \"accuracy\": 0.9997655103914345, \"f1\": 0.026227272727272728, \"f2\": 0.016554866327344507, \"f0_5\": 0.06308630906824693, \"p4\": 0.051113812345119504, \"phi\": 0.1152595897315824}, {\"truth_threshold\": 41.999999061226845, \"match_probability\": 0.9999999999997726, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4013.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299948.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013202351617477242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9867976483825227, \"precision\": 1.0, \"recall\": 0.013202351617477242, \"specificity\": 1.0, \"npv\": 0.9997654893279381, \"accuracy\": 0.9997654900637165, \"f1\": 0.02606064148272257, \"f2\": 0.016448649308894402, \"f0_5\": 0.06270057778902732, \"p4\": 0.05079731703756997, \"phi\": 0.11488801297405499}, {\"truth_threshold\": 42.01999906077981, \"match_probability\": 0.9999999999997757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4006.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013179322347274815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9868206776527252, \"precision\": 1.0, \"recall\": 0.013179322347274815, \"specificity\": 1.0, \"npv\": 0.9997654838563572, \"accuracy\": 0.9997654845908693, \"f1\": 0.026015774417388875, \"f2\": 0.016420051645694142, \"f0_5\": 0.06259668421957279, \"p4\": 0.05071208006311119, \"phi\": 0.1147877675687706}, {\"truth_threshold\": 42.039999060332775, \"match_probability\": 0.9999999999997788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3997.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299964.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01314971328558598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.986850286714414, \"precision\": 1.0, \"recall\": 0.01314971328558598, \"specificity\": 1.0, \"npv\": 0.9997654768214677, \"accuracy\": 0.9997654775543516, \"f1\": 0.025958085193435468, \"f2\": 0.01638328273930783, \"f0_5\": 0.06246308005338351, \"p4\": 0.050602473016990154, \"phi\": 0.11465875183791882}, {\"truth_threshold\": 42.05999905988574, \"match_probability\": 0.9999999999997818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3972.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299989.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013067465892005883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9869325341079941, \"precision\": 1.0, \"recall\": 0.013067465892005883, \"specificity\": 1.0, \"npv\": 0.9997654572801082, \"accuracy\": 0.9997654580084689, \"f1\": 0.025797819655574428, \"f2\": 0.016281144041396408, \"f0_5\": 0.062091799567921116, \"p4\": 0.050297910678170396, \"phi\": 0.1142996107299298}, {\"truth_threshold\": 42.079999059438705, \"match_probability\": 0.9999999999997848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3949.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012991798289912192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9870082017100879, \"precision\": 1.0, \"recall\": 0.012991798289912192, \"specificity\": 1.0, \"npv\": 0.9997654393020583, \"accuracy\": 0.9997654400262569, \"f1\": 0.025650352375694196, \"f2\": 0.016187172741604517, \"f0_5\": 0.06175001641871796, \"p4\": 0.050017585554613005, \"phi\": 0.11396820137493525}, {\"truth_threshold\": 42.09999905899167, \"match_probability\": 0.9999999999997878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3928.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01292271047930491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9870772895206951, \"precision\": 1.0, \"recall\": 0.01292271047930491, \"specificity\": 1.0, \"npv\": 0.9997654228873176, \"accuracy\": 0.9997654236077155, \"f1\": 0.025515689095745545, \"f2\": 0.016101369764185438, \"f0_5\": 0.06143778173320862, \"p4\": 0.049761529519162954, \"phi\": 0.11366476634028967}, {\"truth_threshold\": 42.119999058544636, \"match_probability\": 0.9999999999997907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3887.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300074.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01278782475383355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9872121752461664, \"precision\": 1.0, \"recall\": 0.01278782475383355, \"specificity\": 1.0, \"npv\": 0.9997653908394921, \"accuracy\": 0.9997653915524679, \"f1\": 0.025252722122605962, \"f2\": 0.015933841150220826, \"f0_5\": 0.060827707513716356, \"p4\": 0.04926131596274325, \"phi\": 0.11306999873088941}, {\"truth_threshold\": 42.1399990580976, \"match_probability\": 0.9999999999997936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3870.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300091.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012731896526199086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9872681034738009, \"precision\": 1.0, \"recall\": 0.012731896526199086, \"specificity\": 1.0, \"npv\": 0.99976537755137, \"accuracy\": 0.9997653782612678, \"f1\": 0.025143666492328583, \"f2\": 0.015864374763264175, \"f0_5\": 0.060574566195322456, \"p4\": 0.04905379597379453, \"phi\": 0.11282246822978304}, {\"truth_threshold\": 42.159999057650566, \"match_probability\": 0.9999999999997965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3852.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300109.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012672678402821415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9873273215971786, \"precision\": 1.0, \"recall\": 0.012672678402821415, \"specificity\": 1.0, \"npv\": 0.999765363481594, \"accuracy\": 0.9997653641882323, \"f1\": 0.025028182695337752, \"f2\": 0.015790820007608453, \"f0_5\": 0.060306416715460796, \"p4\": 0.04883399579897661, \"phi\": 0.11255978380257355}, {\"truth_threshold\": 42.17999905720353, \"match_probability\": 0.9999999999997993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3838.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300123.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01262661986241656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9873733801375835, \"precision\": 1.0, \"recall\": 0.01262661986241656, \"specificity\": 1.0, \"npv\": 0.9997653525384351, \"accuracy\": 0.999765353242538, \"f1\": 0.024938352626226856, \"f2\": 0.01573360925224772, \"f0_5\": 0.06009777240513227, \"p4\": 0.04866298808130111, \"phi\": 0.11235504909935155}, {\"truth_threshold\": 42.199999056756496, \"match_probability\": 0.999999999999802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3813.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300148.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012544372468836463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9874556275311636, \"precision\": 1.0, \"recall\": 0.012544372468836463, \"specificity\": 1.0, \"npv\": 0.9997653329970806, \"accuracy\": 0.9997653336966553, \"f1\": 0.024777921461851878, \"f2\": 0.01563144392234866, \"f0_5\": 0.05972501119941857, \"p4\": 0.0483575038689313, \"phi\": 0.11198852047663499}, {\"truth_threshold\": 42.21999905630946, \"match_probability\": 0.9999999999998048, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3803.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300158.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012511473511404424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9874885264885955, \"precision\": 1.0, \"recall\": 0.012511473511404424, \"specificity\": 1.0, \"npv\": 0.9997653251805391, \"accuracy\": 0.9997653258783022, \"f1\": 0.024713741698184324, \"f2\": 0.015590576617660683, \"f0_5\": 0.05957584131489819, \"p4\": 0.048235269497556583, \"phi\": 0.11184157269824556}, {\"truth_threshold\": 42.23999905586243, \"match_probability\": 0.9999999999998075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3775.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300186.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012419356430594714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9875806435694053, \"precision\": 1.0, \"recall\": 0.012419356430594714, \"specificity\": 1.0, \"npv\": 0.9997653032942232, \"accuracy\": 0.9997653039869137, \"f1\": 0.024534016169703902, \"f2\": 0.015476144599255998, \"f0_5\": 0.05915796665841328, \"p4\": 0.047892889496817685, \"phi\": 0.11142908798223462}, {\"truth_threshold\": 42.25999905541539, \"match_probability\": 0.9999999999998102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3760.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300201.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012370007994446656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9876299920055533, \"precision\": 1.0, \"recall\": 0.012370007994446656, \"specificity\": 1.0, \"npv\": 0.9997652915694116, \"accuracy\": 0.9997652922593842, \"f1\": 0.024437721182499733, \"f2\": 0.015414839570877104, \"f0_5\": 0.05893398453296385, \"p4\": 0.04770939657721117, \"phi\": 0.11120748468193999}, {\"truth_threshold\": 42.27999905496836, \"match_probability\": 0.9999999999998127, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3727.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300234.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012261441434920927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9877385585650791, \"precision\": 1.0, \"recall\": 0.012261441434920927, \"specificity\": 1.0, \"npv\": 0.9997652657748269, \"accuracy\": 0.999765266458819, \"f1\": 0.024225839161748263, \"f2\": 0.015279963200174487, \"f0_5\": 0.05844092715190251, \"p4\": 0.04730552768222387, \"phi\": 0.11071839619036304}, {\"truth_threshold\": 42.29999905452132, \"match_probability\": 0.9999999999998154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3705.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300256.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012189063728570442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9878109362714296, \"precision\": 1.0, \"recall\": 0.012189063728570442, \"specificity\": 1.0, \"npv\": 0.999765248578438, \"accuracy\": 0.9997652492584423, \"f1\": 0.02408455922981415, \"f2\": 0.015190041564545582, \"f0_5\": 0.05811199538240987, \"p4\": 0.04703614074230263, \"phi\": 0.11039113337824125}, {\"truth_threshold\": 42.31999905407429, \"match_probability\": 0.9999999999998178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3686.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300275.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012126555709449567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9878734442905505, \"precision\": 1.0, \"recall\": 0.012126555709449567, \"specificity\": 1.0, \"npv\": 0.9997652337270115, \"accuracy\": 0.9997652344035715, \"f1\": 0.023962528482319022, \"f2\": 0.015112379359261355, \"f0_5\": 0.05782777176385686, \"p4\": 0.046803397538689465, \"phi\": 0.11010771454880659}, {\"truth_threshold\": 42.33999905362725, \"match_probability\": 0.9999999999998204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3643.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0119850901924918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9880149098075082, \"precision\": 1.0, \"recall\": 0.0119850901924918, \"specificity\": 1.0, \"npv\": 0.9997652001158902, \"accuracy\": 0.9997652007846534, \"f1\": 0.023686297967516676, \"f2\": 0.014936608590333477, \"f0_5\": 0.05718402802849312, \"p4\": 0.046276351764184105, \"phi\": 0.1094635834179731}, {\"truth_threshold\": 42.35999905318022, \"match_probability\": 0.9999999999998228, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3605.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300356.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011860074154250052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.98813992584575, \"precision\": 1.0, \"recall\": 0.011860074154250052, \"specificity\": 1.0, \"npv\": 0.9997651704130407, \"accuracy\": 0.9997651710749117, \"f1\": 0.023442122991488006, \"f2\": 0.014781265965202317, \"f0_5\": 0.05661455928588704, \"p4\": 0.045810230798255386, \"phi\": 0.10889117989045348}, {\"truth_threshold\": 42.37999905273318, \"match_probability\": 0.9999999999998253, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3572.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011751507594724323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9882484924052757, \"precision\": 1.0, \"recall\": 0.011751507594724323, \"specificity\": 1.0, \"npv\": 0.9997651446184623, \"accuracy\": 0.9997651452743467, \"f1\": 0.023230027346658733, \"f2\": 0.01464635530450642, \"f0_5\": 0.05611957932310863, \"p4\": 0.0454051675225761, \"phi\": 0.10839164031383842}, {\"truth_threshold\": 42.39999905228615, \"match_probability\": 0.9999999999998277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3543.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300418.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01165610061817141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9883438993818285, \"precision\": 1.0, \"recall\": 0.01165610061817141, \"specificity\": 1.0, \"npv\": 0.9997651219505006, \"accuracy\": 0.9997651226011228, \"f1\": 0.023043602684843123, \"f2\": 0.014527791423067492, \"f0_5\": 0.05568425784184602, \"p4\": 0.045048992347629505, \"phi\": 0.10795074273016118}, {\"truth_threshold\": 42.41999905183911, \"match_probability\": 0.99999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3531.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011616621869252964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9883833781307471, \"precision\": 1.0, \"recall\": 0.011616621869252964, \"specificity\": 1.0, \"npv\": 0.9997651125706547, \"accuracy\": 0.9997651132190991, \"f1\": 0.022966451159704967, \"f2\": 0.014478728856996413, \"f0_5\": 0.05550403194114781, \"p4\": 0.044901551881279866, \"phi\": 0.10776777473254431}, {\"truth_threshold\": 42.43999905139208, \"match_probability\": 0.9999999999998324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3507.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01153766437141607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9884623356285839, \"precision\": 1.0, \"recall\": 0.01153766437141607, \"specificity\": 1.0, \"npv\": 0.9997650938109633, \"accuracy\": 0.9997650944550518, \"f1\": 0.022812130042801203, \"f2\": 0.01438060082781742, \"f0_5\": 0.05514341691064785, \"p4\": 0.04460656967253995, \"phi\": 0.10740090363981207}, {\"truth_threshold\": 42.459999050945044, \"match_probability\": 0.9999999999998347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3499.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300462.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011511345205470438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9884886547945295, \"precision\": 1.0, \"recall\": 0.011511345205470438, \"specificity\": 1.0, \"npv\": 0.9997650875577331, \"accuracy\": 0.9997650882003694, \"f1\": 0.022760684316659077, \"f2\": 0.014347890626345498, \"f0_5\": 0.05502316350953116, \"p4\": 0.044508212249313284, \"phi\": 0.10727833447278368}, {\"truth_threshold\": 42.47999905049801, \"match_probability\": 0.999999999999837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3462.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300499.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011389619062971895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9886103809370281, \"precision\": 1.0, \"recall\": 0.011389619062971895, \"specificity\": 1.0, \"npv\": 0.999765058636544, \"accuracy\": 0.9997650592724631, \"f1\": 0.02252271300455724, \"f2\": 0.01419660036118907, \"f0_5\": 0.054466676525837844, \"p4\": 0.04405311378899986, \"phi\": 0.10670962079559647}, {\"truth_threshold\": 42.499999050050974, \"match_probability\": 0.9999999999998392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3441.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300520.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011320531252364612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9886794687476353, \"precision\": 1.0, \"recall\": 0.011320531252364612, \"specificity\": 1.0, \"npv\": 0.9997650422218158, \"accuracy\": 0.9997650428539216, \"f1\": 0.022387622722038245, \"f2\": 0.014110728828780802, \"f0_5\": 0.054150601935636165, \"p4\": 0.04379467164773638, \"phi\": 0.10638548493800125}, {\"truth_threshold\": 42.51999904960394, \"match_probability\": 0.9999999999998415, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3434.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300527.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011297501982162185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9887024980178378, \"precision\": 1.0, \"recall\": 0.011297501982162185, \"specificity\": 1.0, \"npv\": 0.9997650367502399, \"accuracy\": 0.9997650373810745, \"f1\": 0.022342588526163405, \"f2\": 0.014082104327315017, \"f0_5\": 0.05404520659622219, \"p4\": 0.04370850123910311, \"phi\": 0.10627721996920264}, {\"truth_threshold\": 42.539999049156904, \"match_probability\": 0.9999999999998436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3408.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300553.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011211964692838883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9887880353071611, \"precision\": 1.0, \"recall\": 0.011211964692838883, \"specificity\": 1.0, \"npv\": 0.999765016427244, \"accuracy\": 0.9997650170533565, \"f1\": 0.022175300697207592, \"f2\": 0.013975781872820385, \"f0_5\": 0.05365357548812474, \"p4\": 0.043388338862165504, \"phi\": 0.10587412368146311}, {\"truth_threshold\": 42.55999904870987, \"match_probability\": 0.9999999999998458, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3373.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300588.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011096818341826747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9889031816581733, \"precision\": 1.0, \"recall\": 0.011096818341826747, \"specificity\": 1.0, \"npv\": 0.9997649890693663, \"accuracy\": 0.9997649896891208, \"f1\": 0.021950060845854998, \"f2\": 0.013832648330854966, \"f0_5\": 0.05312597455371346, \"p4\": 0.04295709991165235, \"phi\": 0.10532905804297864}, {\"truth_threshold\": 42.579999048262835, \"match_probability\": 0.9999999999998479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3350.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011021150739733058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9889788492602669, \"precision\": 1.0, \"recall\": 0.011021150739733058, \"specificity\": 1.0, \"npv\": 0.9997649710913332, \"accuracy\": 0.9997649717069088, \"f1\": 0.02180201815099362, \"f2\": 0.013738584671512491, \"f0_5\": 0.05277901191387726, \"p4\": 0.04267355727414259, \"phi\": 0.10496933100054724}, {\"truth_threshold\": 42.5999990478158, \"match_probability\": 0.99999999999985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3335.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010971802303585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989028197696415, \"precision\": 1.0, \"recall\": 0.010971802303585, \"specificity\": 1.0, \"npv\": 0.9997649593665293, \"accuracy\": 0.9997649599793792, \"f1\": 0.02170545662813704, \"f2\": 0.01367723689466436, \"f0_5\": 0.0525526235341206, \"p4\": 0.04248857101424055, \"phi\": 0.10473406076449654}, {\"truth_threshold\": 42.619999047368765, \"match_probability\": 0.999999999999852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3325.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300636.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01093890334615296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989061096653847, \"precision\": 1.0, \"recall\": 0.01093890334615296, \"specificity\": 1.0, \"npv\": 0.9997649515499936, \"accuracy\": 0.9997649521610261, \"f1\": 0.02164107704223427, \"f2\": 0.013636337538109975, \"f0_5\": 0.05240165037618869, \"p4\": 0.04236521737637328, \"phi\": 0.10457691989094284}, {\"truth_threshold\": 42.63999904692173, \"match_probability\": 0.9999999999998541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3318.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300643.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010915874075950533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9890841259240495, \"precision\": 1.0, \"recall\": 0.010915874075950533, \"specificity\": 1.0, \"npv\": 0.9997649460784187, \"accuracy\": 0.999764946688179, \"f1\": 0.021596008838872815, \"f2\": 0.013607707589311346, \"f0_5\": 0.052295946512500274, \"p4\": 0.04227885580042741, \"phi\": 0.1044667806383517}, {\"truth_threshold\": 42.659999046474695, \"match_probability\": 0.9999999999998561, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3308.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010882975118518495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9891170248814815, \"precision\": 1.0, \"recall\": 0.010882975118518495, \"specificity\": 1.0, \"npv\": 0.9997649382618832, \"accuracy\": 0.999764938869826, \"f1\": 0.02153162212914417, \"f2\": 0.013566807092142735, \"f0_5\": 0.05214490862030373, \"p4\": 0.04215546207327683, \"phi\": 0.10430923711479848}, {\"truth_threshold\": 42.67999904602766, \"match_probability\": 0.9999999999998581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3296.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300665.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010843496369600048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9891565036304, \"precision\": 1.0, \"recall\": 0.010843496369600048, \"specificity\": 1.0, \"npv\": 0.9997649288820406, \"accuracy\": 0.9997649294878023, \"f1\": 0.02145435254526341, \"f2\": 0.013517725609856129, \"f0_5\": 0.051963612858471675, \"p4\": 0.042007358459899606, \"phi\": 0.10411987023035447}, {\"truth_threshold\": 42.699999045580626, \"match_probability\": 0.99999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3287.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300674.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010813887307911212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9891861126920888, \"precision\": 1.0, \"recall\": 0.010813887307911212, \"specificity\": 1.0, \"npv\": 0.9997649218471589, \"accuracy\": 0.9997649224512846, \"f1\": 0.021396396396396396, \"f2\": 0.013480913864055626, \"f0_5\": 0.05182760501909438, \"p4\": 0.041896258449279945, \"phi\": 0.10397761874200541}, {\"truth_threshold\": 42.71999904513359, \"match_probability\": 0.999999999999862, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3250.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010692161165412668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9893078388345873, \"precision\": 1.0, \"recall\": 0.010692161165412668, \"specificity\": 1.0, \"npv\": 0.9997648929259794, \"accuracy\": 0.9997648935233782, \"f1\": 0.0211580965525323, \"f2\": 0.013329570976479254, \"f0_5\": 0.051268137089421094, \"p4\": 0.04143931302650553, \"phi\": 0.10339075085657377}, {\"truth_threshold\": 42.739999044686556, \"match_probability\": 0.9999999999998639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3228.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300733.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010619783459062183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9893802165409378, \"precision\": 1.0, \"recall\": 0.010619783459062183, \"specificity\": 1.0, \"npv\": 0.9997648757296033, \"accuracy\": 0.9997648763230015, \"f1\": 0.021016377539560337, \"f2\": 0.013239578958420832, \"f0_5\": 0.050935232727307156, \"p4\": 0.04116746240916956, \"phi\": 0.10304021782888756}, {\"truth_threshold\": 42.75999904423952, \"match_probability\": 0.9999999999998658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3194.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300767.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010507927003793249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9894920729962068, \"precision\": 1.0, \"recall\": 0.010507927003793249, \"specificity\": 1.0, \"npv\": 0.9997648491533866, \"accuracy\": 0.9997648497406011, \"f1\": 0.02079731731536195, \"f2\": 0.013100493996085438, \"f0_5\": 0.05042038031552992, \"p4\": 0.040747104508155045, \"phi\": 0.10249612702859634}, {\"truth_threshold\": 42.779999043792486, \"match_probability\": 0.9999999999998676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3179.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010458578567645191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9895414214323548, \"precision\": 1.0, \"recall\": 0.010458578567645191, \"specificity\": 1.0, \"npv\": 0.9997648374285857, \"accuracy\": 0.9997648380130715, \"f1\": 0.020700657680536562, \"f2\": 0.013039130516815515, \"f0_5\": 0.05019309896203387, \"p4\": 0.040561565527622856, \"phi\": 0.10225516662455686}, {\"truth_threshold\": 42.79999904334545, \"match_probability\": 0.9999999999998694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3171.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01043225940169956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9895677405983004, \"precision\": 1.0, \"recall\": 0.01043225940169956, \"specificity\": 1.0, \"npv\": 0.9997648311753585, \"accuracy\": 0.999764831758389, \"f1\": 0.020649102014768893, \"f2\": 0.013006402710385024, \"f0_5\": 0.05007184702111197, \"p4\": 0.04046258962187036, \"phi\": 0.10212642194612376}, {\"truth_threshold\": 42.81999904289842, \"match_probability\": 0.9999999999998712, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3154.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010376331174065095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9896236688259349, \"precision\": 1.0, \"recall\": 0.010376331174065095, \"specificity\": 1.0, \"npv\": 0.9997648178872512, \"accuracy\": 0.9997648184671889, \"f1\": 0.020539537306872017, \"f2\": 0.012936854695413775, \"f0_5\": 0.04981410525717282, \"p4\": 0.04025221548934363, \"phi\": 0.10185229917177618}, {\"truth_threshold\": 42.83999904245138, \"match_probability\": 0.999999999999873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3134.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010310533259201017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9896894667407989, \"precision\": 1.0, \"recall\": 0.010310533259201017, \"specificity\": 1.0, \"npv\": 0.9997648022541843, \"accuracy\": 0.9997648028304827, \"f1\": 0.02041062212019082, \"f2\": 0.012855031017787032, \"f0_5\": 0.04951073785849471, \"p4\": 0.04000462883384934, \"phi\": 0.10152885424853515}, {\"truth_threshold\": 42.85999904200435, \"match_probability\": 0.9999999999998748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3111.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010234865657107326, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9897651343428927, \"precision\": 1.0, \"recall\": 0.010234865657107326, \"specificity\": 1.0, \"npv\": 0.9997647842761579, \"accuracy\": 0.9997647848482707, \"f1\": 0.020262348895373074, \"f2\": 0.012760930469131347, \"f0_5\": 0.04916167570044721, \"p4\": 0.03971978693484315, \"phi\": 0.10115561405959318}, {\"truth_threshold\": 42.87999904155731, \"match_probability\": 0.9999999999998764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3109.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010228285865620919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989771714134379, \"precision\": 1.0, \"recall\": 0.010228285865620919, \"specificity\": 1.0, \"npv\": 0.9997647827128513, \"accuracy\": 0.9997647832846001, \"f1\": 0.02024945452177028, \"f2\": 0.012752747644905095, \"f0_5\": 0.04913131287591222, \"p4\": 0.039695012144044056, \"phi\": 0.10112309328717861}, {\"truth_threshold\": 42.89999904111028, \"match_probability\": 0.9999999999998782, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3080.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010132878889068005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989867121110932, \"precision\": 1.0, \"recall\": 0.010132878889068005, \"specificity\": 1.0, \"npv\": 0.999764760044906, \"accuracy\": 0.9997647606113762, \"f1\": 0.02006246722750382, \"f2\": 0.012634093676061837, \"f0_5\": 0.04869087931301596, \"p4\": 0.03933567100061581, \"phi\": 0.10065036130632203}, {\"truth_threshold\": 42.91999904066324, \"match_probability\": 0.9999999999998799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3060.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010067080974203927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989932919025796, \"precision\": 1.0, \"recall\": 0.010067080974203927, \"specificity\": 1.0, \"npv\": 0.9997647444118408, \"accuracy\": 0.9997647449746702, \"f1\": 0.019933489891570934, \"f2\": 0.012552260063138688, \"f0_5\": 0.048386943747805986, \"p4\": 0.039087733177128686, \"phi\": 0.10032304140698833}, {\"truth_threshold\": 42.93999904021621, \"match_probability\": 0.9999999999998815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3052.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300909.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010040761808258296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9899592381917417, \"precision\": 1.0, \"recall\": 0.010040761808258296, \"specificity\": 1.0, \"npv\": 0.999764738158615, \"accuracy\": 0.9997647387199876, \"f1\": 0.019881894252034932, \"f2\": 0.012519525866029587, \"f0_5\": 0.048265326455155314, \"p4\": 0.03898853144000677, \"phi\": 0.10019181403760678}, {\"truth_threshold\": 42.95999903976917, \"match_probability\": 0.9999999999998831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3036.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009988123476367034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990011876523633, \"precision\": 1.0, \"recall\": 0.009988123476367034, \"specificity\": 1.0, \"npv\": 0.9997647256521633, \"accuracy\": 0.9997647262106227, \"f1\": 0.019778694905813413, \"f2\": 0.012454056182725125, \"f0_5\": 0.048022018000347985, \"p4\": 0.03879008233328253, \"phi\": 0.09992884231857198}, {\"truth_threshold\": 42.97999903932214, \"match_probability\": 0.9999999999998848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3020.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300941.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00993548514447577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9900645148555243, \"precision\": 1.0, \"recall\": 0.00993548514447577, \"specificity\": 1.0, \"npv\": 0.999764713145712, \"accuracy\": 0.9997647137012579, \"f1\": 0.019675484801991, \"f2\": 0.012388584780582575, \"f0_5\": 0.04777861100300278, \"p4\": 0.03859157235992376, \"phi\": 0.09966517674408802}, {\"truth_threshold\": 42.9999990388751, \"match_probability\": 0.9999999999998863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3008.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009896006395557325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9901039936044427, \"precision\": 1.0, \"recall\": 0.009896006395557325, \"specificity\": 1.0, \"npv\": 0.9997647037658738, \"accuracy\": 0.9997647043192343, \"f1\": 0.0195980701634367, \"f2\": 0.012339480100947448, \"f0_5\": 0.04759599105043466, \"p4\": 0.038442649919327956, \"phi\": 0.09946696890183979}, {\"truth_threshold\": 43.01999903842807, \"match_probability\": 0.9999999999998879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3004.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009882846812584509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9901171531874154, \"precision\": 1.0, \"recall\": 0.009882846812584509, \"specificity\": 1.0, \"npv\": 0.999764700639261, \"accuracy\": 0.999764701191893, \"f1\": 0.01957226393888554, \"f2\": 0.01232311165953425, \"f0_5\": 0.04753510540324137, \"p4\": 0.038393001491922624, \"phi\": 0.09940081179269727}, {\"truth_threshold\": 43.03999903798103, \"match_probability\": 0.9999999999998894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2994.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300967.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009849947855152471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9901500521448475, \"precision\": 1.0, \"recall\": 0.009849947855152471, \"specificity\": 1.0, \"npv\": 0.9997646928227294, \"accuracy\": 0.9997646933735399, \"f1\": 0.019507745434998617, \"f2\": 0.012282190085967126, \"f0_5\": 0.04738286430522541, \"p4\": 0.03826886376390953, \"phi\": 0.09923522606275662}, {\"truth_threshold\": 43.059999037534, \"match_probability\": 0.999999999999891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2972.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300989.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009777570148801984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990222429851198, \"precision\": 1.0, \"recall\": 0.009777570148801984, \"specificity\": 1.0, \"npv\": 0.9997646756263601, \"accuracy\": 0.9997646761731632, \"f1\": 0.019365789928095057, \"f2\": 0.012192160260449485, \"f0_5\": 0.04704779815671412, \"p4\": 0.037995676959876, \"phi\": 0.09886996130388136}, {\"truth_threshold\": 43.079999037086964, \"match_probability\": 0.9999999999998924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2960.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301001.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009738091399883539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9902619086001164, \"precision\": 1.0, \"recall\": 0.009738091399883539, \"specificity\": 1.0, \"npv\": 0.9997646662465225, \"accuracy\": 0.9997646667911395, \"f1\": 0.019288351074054886, \"f2\": 0.012143051712990767, \"f0_5\": 0.04686495609576917, \"p4\": 0.037846617388060395, \"phi\": 0.09867015606698255}, {\"truth_threshold\": 43.09999903663993, \"match_probability\": 0.999999999999894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2937.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301024.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009662423797789848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9903375762022102, \"precision\": 1.0, \"recall\": 0.009662423797789848, \"specificity\": 1.0, \"npv\": 0.999764648268501, \"accuracy\": 0.9997646488089275, \"f1\": 0.019139909676830737, \"f2\": 0.012048924294028214, \"f0_5\": 0.046514353407726736, \"p4\": 0.037560823957366866, \"phi\": 0.09828606070862013}, {\"truth_threshold\": 43.119999036192894, \"match_probability\": 0.9999999999998954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2924.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301037.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009619655153128197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9903803448468718, \"precision\": 1.0, \"recall\": 0.009619655153128197, \"specificity\": 1.0, \"npv\": 0.9997646381070109, \"accuracy\": 0.9997646386450685, \"f1\": 0.019055998175212214, \"f2\": 0.01199572026833655, \"f0_5\": 0.04631609626905153, \"p4\": 0.03739923275080366, \"phi\": 0.09806829789937957}, {\"truth_threshold\": 43.13999903574586, \"match_probability\": 0.9999999999998969, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2886.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301075.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009494639114886448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905053608851135, \"precision\": 1.0, \"recall\": 0.009494639114886448, \"specificity\": 1.0, \"npv\": 0.9997646084041948, \"accuracy\": 0.9997646089353269, \"f1\": 0.018810677634130364, \"f2\": 0.011840194300624421, \"f0_5\": 0.04573620069412529, \"p4\": 0.03692665803528381, \"phi\": 0.09742896980176687}, {\"truth_threshold\": 43.159999035298824, \"match_probability\": 0.9999999999998982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2874.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009455160365968003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990544839634032, \"precision\": 1.0, \"recall\": 0.009455160365968003, \"specificity\": 1.0, \"npv\": 0.9997645990243585, \"accuracy\": 0.9997645995533032, \"f1\": 0.018733195365587367, \"f2\": 0.011791078822172152, \"f0_5\": 0.045552959674377176, \"p4\": 0.03677735229588036, \"phi\": 0.097226203319851}, {\"truth_threshold\": 43.17999903485179, \"match_probability\": 0.9999999999998996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2859.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009405811929819943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905941880701801, \"precision\": 1.0, \"recall\": 0.009405811929819943, \"specificity\": 1.0, \"npv\": 0.9997645872995634, \"accuracy\": 0.9997645878257737, \"f1\": 0.01863633400690959, \"f2\": 0.01172968311393342, \"f0_5\": 0.045323829966676915, \"p4\": 0.03659067174882956, \"phi\": 0.09697214900286447}, {\"truth_threshold\": 43.199999034404755, \"match_probability\": 0.9999999999999011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2844.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301117.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009356463493671885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906435365063281, \"precision\": 1.0, \"recall\": 0.009356463493671885, \"specificity\": 1.0, \"npv\": 0.9997645755747685, \"accuracy\": 0.9997645760982441, \"f1\": 0.018539463176936492, \"f2\": 0.01166828589433883, \"f0_5\": 0.045094613064752945, \"p4\": 0.03640393743255338, \"phi\": 0.09671742735221862}, {\"truth_threshold\": 43.21999903395772, \"match_probability\": 0.9999999999999024, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2840.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301121.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00934330391069907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990656696089301, \"precision\": 1.0, \"recall\": 0.00934330391069907, \"specificity\": 1.0, \"npv\": 0.9997645724481566, \"accuracy\": 0.9997645729709028, \"f1\": 0.01851362935583652, \"f2\": 0.011651913047188607, \"f0_5\": 0.045033473825086184, \"p4\": 0.03635413253089047, \"phi\": 0.09664938820051189}, {\"truth_threshold\": 43.239999033510685, \"match_probability\": 0.9999999999999037, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2827.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301134.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00930053526603742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906994647339625, \"precision\": 1.0, \"recall\": 0.00930053526603742, \"specificity\": 1.0, \"npv\": 0.999764562286668, \"accuracy\": 0.9997645628070438, \"f1\": 0.018429664784802534, \"f2\": 0.011598700551666528, \"f0_5\": 0.04483472843825432, \"p4\": 0.03619224017708433, \"phi\": 0.09642792940471978}, {\"truth_threshold\": 43.25999903306365, \"match_probability\": 0.9999999999999051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2811.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009247896934146157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9907521030658538, \"precision\": 1.0, \"recall\": 0.009247896934146157, \"specificity\": 1.0, \"npv\": 0.9997645497802209, \"accuracy\": 0.999764550297679, \"f1\": 0.018326314005189522, \"f2\": 0.011533206690983093, \"f0_5\": 0.04459002871147349, \"p4\": 0.03599293255455274, \"phi\": 0.09615466455029893}, {\"truth_threshold\": 43.279999032616615, \"match_probability\": 0.9999999999999064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2790.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301171.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009178809123538875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9908211908764611, \"precision\": 1.0, \"recall\": 0.009178809123538875, \"specificity\": 1.0, \"npv\": 0.9997645333655094, \"accuracy\": 0.9997645338791376, \"f1\": 0.018190649745233104, \"f2\": 0.011447243388909222, \"f0_5\": 0.0442687094798506, \"p4\": 0.0357312483255251, \"phi\": 0.09579482146883475}, {\"truth_threshold\": 43.29999903216958, \"match_probability\": 0.9999999999999076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2781.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301180.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00914920006185004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.99085079993815, \"precision\": 1.0, \"recall\": 0.00914920006185004, \"specificity\": 1.0, \"npv\": 0.9997645263306332, \"accuracy\": 0.9997645268426198, \"f1\": 0.018132502233147076, \"f2\": 0.01141040106677608, \"f0_5\": 0.04413094879159592, \"p4\": 0.035619065619652945, \"phi\": 0.09564018855136007}, {\"truth_threshold\": 43.319999031722546, \"match_probability\": 0.999999999999909, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2767.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301194.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009103141521445186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9908968584785548, \"precision\": 1.0, \"recall\": 0.009103141521445186, \"specificity\": 1.0, \"npv\": 0.9997645153874927, \"accuracy\": 0.9997645158969255, \"f1\": 0.018042043765160012, \"f2\": 0.01135308970623111, \"f0_5\": 0.04391659180583375, \"p4\": 0.03544452062501837, \"phi\": 0.09539915026713504}, {\"truth_threshold\": 43.33999903127551, \"match_probability\": 0.9999999999999102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2755.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009063662772526739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9909363372274732, \"precision\": 1.0, \"recall\": 0.009063662772526739, \"specificity\": 1.0, \"npv\": 0.9997645060076581, \"accuracy\": 0.9997645065149019, \"f1\": 0.01796450136282424, \"f2\": 0.011303964634797829, \"f0_5\": 0.0437327965813811, \"p4\": 0.03529487325138957, \"phi\": 0.09519206024871608}, {\"truth_threshold\": 43.359999030828476, \"match_probability\": 0.9999999999999114, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2739.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301222.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009011024440635475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9909889755593645, \"precision\": 1.0, \"recall\": 0.009011024440635475, \"specificity\": 1.0, \"npv\": 0.9997644935012123, \"accuracy\": 0.999764494005537, \"f1\": 0.017861102054124552, \"f2\": 0.011238463034524526, \"f0_5\": 0.04348764912659526, \"p4\": 0.03509528972691834, \"phi\": 0.09491523737429608}, {\"truth_threshold\": 43.37999903038144, \"match_probability\": 0.9999999999999126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2723.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301238.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008958386108744214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9910416138912558, \"precision\": 1.0, \"recall\": 0.008958386108744214, \"specificity\": 1.0, \"npv\": 0.9997644809947668, \"accuracy\": 0.999764481496172, \"f1\": 0.017757691956541588, \"f2\": 0.011172959714156053, \"f0_5\": 0.043242402009826805, \"p4\": 0.0348956448131039, \"phi\": 0.09463760478033766}, {\"truth_threshold\": 43.399999029934406, \"match_probability\": 0.9999999999999138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2718.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301243.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008941936630028194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9910580633699718, \"precision\": 1.0, \"recall\": 0.008941936630028194, \"specificity\": 1.0, \"npv\": 0.9997644770865027, \"accuracy\": 0.9997644775869956, \"f1\": 0.017725374088216016, \"f2\": 0.011152489573776304, \"f0_5\": 0.04316574183773619, \"p4\": 0.03483324318344768, \"phi\": 0.09455067741196137}, {\"truth_threshold\": 43.41999902948737, \"match_probability\": 0.9999999999999151, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2684.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301277.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008830080174759261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9911699198252407, \"precision\": 1.0, \"recall\": 0.008830080174759261, \"specificity\": 1.0, \"npv\": 0.9997644505103073, \"accuracy\": 0.9997644510045952, \"f1\": 0.017505584633696947, \"f2\": 0.011013288164079938, \"f0_5\": 0.042644194256697715, \"p4\": 0.03440875297231459, \"phi\": 0.09395743852340883}, {\"truth_threshold\": 43.43999902904034, \"match_probability\": 0.9999999999999162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2666.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301295.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008770862051381592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9912291379486184, \"precision\": 1.0, \"recall\": 0.008770862051381592, \"specificity\": 1.0, \"npv\": 0.9997644364405573, \"accuracy\": 0.9997644369315597, \"f1\": 0.017389205777703854, \"f2\": 0.010939590155189536, \"f0_5\": 0.042367898291617, \"p4\": 0.034183910472274884, \"phi\": 0.09364184938315447}, {\"truth_threshold\": 43.4599990285933, \"match_probability\": 0.9999999999999174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2651.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301310.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008721513615233533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9912784863847665, \"precision\": 1.0, \"recall\": 0.008721513615233533, \"specificity\": 1.0, \"npv\": 0.999764424715766, \"accuracy\": 0.9997644252040301, \"f1\": 0.01729221295970151, \"f2\": 0.010878173484503425, \"f0_5\": 0.042137555036319996, \"p4\": 0.03399648224783591, \"phi\": 0.09337804368364479}, {\"truth_threshold\": 43.47999902814627, \"match_probability\": 0.9999999999999185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2628.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301333.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008645846013139844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9913541539868601, \"precision\": 1.0, \"recall\": 0.008645846013139844, \"specificity\": 1.0, \"npv\": 0.9997644067377532, \"accuracy\": 0.999764407221818, \"f1\": 0.01714347220546073, \"f2\": 0.01078399831920635, \"f0_5\": 0.0417841913296213, \"p4\": 0.03370898723574241, \"phi\": 0.09297208780097779}, {\"truth_threshold\": 43.49999902769923, \"match_probability\": 0.9999999999999196, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2618.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301343.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008612947055707804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9913870529442922, \"precision\": 1.0, \"recall\": 0.008612947055707804, \"specificity\": 1.0, \"npv\": 0.9997643989212261, \"accuracy\": 0.999764399403465, \"f1\": 0.017078795351279766, \"f2\": 0.010743051486217872, \"f0_5\": 0.041630490438344575, \"p4\": 0.03358394971510846, \"phi\": 0.09279503131143423}, {\"truth_threshold\": 43.5199990272522, \"match_probability\": 0.9999999999999207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2596.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301365.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008540569349357319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9914594306506427, \"precision\": 1.0, \"recall\": 0.008540569349357319, \"specificity\": 1.0, \"npv\": 0.9997643817248669, \"accuracy\": 0.9997643822030883, \"f1\": 0.016936491419214043, \"f2\": 0.01065296608778438, \"f0_5\": 0.04129221078751054, \"p4\": 0.03330878245441236, \"phi\": 0.09240431286005307}, {\"truth_threshold\": 43.53999902680516, \"match_probability\": 0.9999999999999218, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2582.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008494510808952464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9915054891910475, \"precision\": 1.0, \"recall\": 0.008494510808952464, \"specificity\": 1.0, \"npv\": 0.9997643707817295, \"accuracy\": 0.9997643712573939, \"f1\": 0.016845923736637274, \"f2\": 0.010595637322250181, \"f0_5\": 0.041076843287547446, \"p4\": 0.033133615340479886, \"phi\": 0.09215481134488292}, {\"truth_threshold\": 43.55999902635813, \"match_probability\": 0.9999999999999228, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2565.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301396.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008438582581317997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991561417418682, \"precision\": 1.0, \"recall\": 0.008438582581317997, \"specificity\": 1.0, \"npv\": 0.9997643574936345, \"accuracy\": 0.9997643579661938, \"f1\": 0.016735937571364257, \"f2\": 0.010526022050066931, \"f0_5\": 0.04081522240715929, \"p4\": 0.03292084893982732, \"phi\": 0.09185093408653157}, {\"truth_threshold\": 43.57999902591109, \"match_probability\": 0.999999999999924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2542.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301419.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008362914979224308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9916370850207757, \"precision\": 1.0, \"recall\": 0.008362914979224308, \"specificity\": 1.0, \"npv\": 0.9997643395156242, \"accuracy\": 0.9997643399839817, \"f1\": 0.016587113339836805, \"f2\": 0.0104318335896834, \"f0_5\": 0.04046108445893248, \"p4\": 0.032632877644769936, \"phi\": 0.09143819864055454}, {\"truth_threshold\": 43.59999902546406, \"match_probability\": 0.999999999999925, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2522.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301439.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00829711706436023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9917028829356398, \"precision\": 1.0, \"recall\": 0.00829711706436023, \"specificity\": 1.0, \"npv\": 0.9997643238825721, \"accuracy\": 0.9997643243472756, \"f1\": 0.016457682807855575, \"f2\": 0.010349927690037312, \"f0_5\": 0.04015296975949613, \"p4\": 0.03238236412314081, \"phi\": 0.09107777792647698}, {\"truth_threshold\": 43.61999902501702, \"match_probability\": 0.9999999999999261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2505.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301456.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008241188836725763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9917588111632742, \"precision\": 1.0, \"recall\": 0.008241188836725763, \"specificity\": 1.0, \"npv\": 0.9997643105944783, \"accuracy\": 0.9997643110560754, \"f1\": 0.016347653573316454, \"f2\": 0.010280305561050241, \"f0_5\": 0.03989094881537418, \"p4\": 0.03216935174034014, \"phi\": 0.09077029511810593}, {\"truth_threshold\": 43.63999902456999, \"match_probability\": 0.9999999999999271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2488.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301473.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008185260609091298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9918147393909087, \"precision\": 1.0, \"recall\": 0.008185260609091298, \"specificity\": 1.0, \"npv\": 0.9997642973063848, \"accuracy\": 0.9997642977648752, \"f1\": 0.016237612131219225, \"f2\": 0.010210681489117909, \"f0_5\": 0.03962881435302138, \"p4\": 0.03195626958503965, \"phi\": 0.09046176717883525}, {\"truth_threshold\": 43.65999902412295, \"match_probability\": 0.9999999999999281, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2463.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301498.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0081030132155112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9918969867844888, \"precision\": 1.0, \"recall\": 0.0081030132155112, \"specificity\": 1.0, \"npv\": 0.9997642777650716, \"accuracy\": 0.9997642782189926, \"f1\": 0.01607576430044644, \"f2\": 0.01010828961829818, \"f0_5\": 0.03924311612329636, \"p4\": 0.03164278665288933, \"phi\": 0.09000612843093735}, {\"truth_threshold\": 43.67999902367592, \"match_probability\": 0.9999999999999291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2443.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008037215300647122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9919627846993528, \"precision\": 1.0, \"recall\": 0.008037215300647122, \"specificity\": 1.0, \"npv\": 0.9997642621320215, \"accuracy\": 0.9997642625822865, \"f1\": 0.015946267020012794, \"f2\": 0.010026373095994622, \"f0_5\": 0.038934380508266586, \"p4\": 0.031391891538140815, \"phi\": 0.0896399499366642}, {\"truth_threshold\": 43.699999023228884, \"match_probability\": 0.9999999999999301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2435.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301526.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008010896134701491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9919891038652985, \"precision\": 1.0, \"recall\": 0.008010896134701491, \"specificity\": 1.0, \"npv\": 0.9997642558788017, \"accuracy\": 0.999764256327604, \"f1\": 0.015894463374195485, \"f2\": 0.009993605733990326, \"f0_5\": 0.038810842171367, \"p4\": 0.03129150640700886, \"phi\": 0.08949305902153644}, {\"truth_threshold\": 43.71999902278185, \"match_probability\": 0.9999999999999309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2396.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301565.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007882590200716539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921174097992834, \"precision\": 1.0, \"recall\": 0.007882590200716539, \"specificity\": 1.0, \"npv\": 0.9997642253943558, \"accuracy\": 0.9997642258360271, \"f1\": 0.015641881856787995, \"f2\": 0.009833858681376411, \"f0_5\": 0.038208231673284535, \"p4\": 0.03080190711012301, \"phi\": 0.08877348526514271}, {\"truth_threshold\": 43.739999022334814, \"match_probability\": 0.9999999999999319, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2383.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007839821556054888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921601784439451, \"precision\": 1.0, \"recall\": 0.007839821556054888, \"specificity\": 1.0, \"npv\": 0.9997642152328743, \"accuracy\": 0.9997642156721681, \"f1\": 0.015557673726268508, \"f2\": 0.009780607390904979, \"f0_5\": 0.038007228231571356, \"p4\": 0.030638625504995718, \"phi\": 0.08853232768630331}, {\"truth_threshold\": 43.75999902188778, \"match_probability\": 0.9999999999999328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2378.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00782337207733887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921766279226611, \"precision\": 1.0, \"recall\": 0.00782337207733887, \"specificity\": 1.0, \"npv\": 0.9997642113246122, \"accuracy\": 0.9997642117629916, \"f1\": 0.015525284080707974, \"f2\": 0.0097601258227154, \"f0_5\": 0.037929901458817826, \"p4\": 0.0305758139858581, \"phi\": 0.08843939967457766}, {\"truth_threshold\": 43.779999021440744, \"match_probability\": 0.9999999999999338, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2359.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301602.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007760864058217995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.992239135941782, \"precision\": 1.0, \"recall\": 0.007760864058217995, \"specificity\": 1.0, \"npv\": 0.9997641964732167, \"accuracy\": 0.9997641969081208, \"f1\": 0.015402193784277879, \"f2\": 0.009682294330255302, \"f0_5\": 0.03763596971253713, \"p4\": 0.030337074957730956, \"phi\": 0.08808537914490794}, {\"truth_threshold\": 43.79999902099371, \"match_probability\": 0.9999999999999347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2338.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301623.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007691776247610713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923082237523893, \"precision\": 1.0, \"recall\": 0.007691776247610713, \"specificity\": 1.0, \"npv\": 0.9997641800585169, \"accuracy\": 0.9997641804895794, \"f1\": 0.015266128847955756, \"f2\": 0.009596267224437727, \"f0_5\": 0.03731093187962198, \"p4\": 0.030073103675127662, \"phi\": 0.08769243053642714}, {\"truth_threshold\": 43.819999020546675, \"match_probability\": 0.9999999999999356, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2332.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00767203687315149, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923279631268485, \"precision\": 1.0, \"recall\": 0.00767203687315149, \"specificity\": 1.0, \"npv\": 0.9997641753686026, \"accuracy\": 0.9997641757985676, \"f1\": 0.01522724972493658, \"f2\": 0.009571687506567195, \"f0_5\": 0.037218031913025994, \"p4\": 0.02999766366122108, \"phi\": 0.08757983568084501}, {\"truth_threshold\": 43.83999902009964, \"match_probability\": 0.9999999999999365, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2323.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007642427811462655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923575721885374, \"precision\": 1.0, \"recall\": 0.007642427811462655, \"specificity\": 1.0, \"npv\": 0.9997641683337315, \"accuracy\": 0.9997641687620498, \"f1\": 0.015168928184299539, \"f2\": 0.009534817475764817, \"f0_5\": 0.03707865527225597, \"p4\": 0.029884487261799823, \"phi\": 0.08741067145936783}, {\"truth_threshold\": 43.859999019652605, \"match_probability\": 0.9999999999999374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2295.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301666.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0075503107306529454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9924496892693471, \"precision\": 1.0, \"recall\": 0.0075503107306529454, \"specificity\": 1.0, \"npv\": 0.9997641464474664, \"accuracy\": 0.9997641468706612, \"f1\": 0.014987461470142625, \"f2\": 0.009420107229142159, \"f0_5\": 0.036644834116260724, \"p4\": 0.02953225716558517, \"phi\": 0.08688227646099282}, {\"truth_threshold\": 43.87999901920557, \"match_probability\": 0.9999999999999383, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2283.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301678.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007510831981734499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9924891680182655, \"precision\": 1.0, \"recall\": 0.007510831981734499, \"specificity\": 1.0, \"npv\": 0.9997641370676388, \"accuracy\": 0.9997641374886376, \"f1\": 0.014909679863115685, \"f2\": 0.009370944080543326, \"f0_5\": 0.036458815751230465, \"p4\": 0.029381243123453023, \"phi\": 0.08665483515002964}, {\"truth_threshold\": 43.899999018758535, \"match_probability\": 0.999999999999939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2265.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301696.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0074516138583568285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9925483861416432, \"precision\": 1.0, \"recall\": 0.0074516138583568285, \"specificity\": 1.0, \"npv\": 0.9997641229978976, \"accuracy\": 0.9997641234156021, \"f1\": 0.01479299602254544, \"f2\": 0.009297197541435126, \"f0_5\": 0.036179681235444267, \"p4\": 0.029154656451097348, \"phi\": 0.08631254945845995}, {\"truth_threshold\": 43.9199990183115, \"match_probability\": 0.9999999999999399, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2260.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007435164379640809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9925648356203592, \"precision\": 1.0, \"recall\": 0.007435164379640809, \"specificity\": 1.0, \"npv\": 0.9997641190896362, \"accuracy\": 0.9997641195064255, \"f1\": 0.014760581410158024, \"f2\": 0.009276712004886282, \"f0_5\": 0.03610212107948537, \"p4\": 0.029091701731733994, \"phi\": 0.08621722894119387}, {\"truth_threshold\": 43.939999017864466, \"match_probability\": 0.9999999999999407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2246.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301715.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007389105839235955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9926108941607641, \"precision\": 1.0, \"recall\": 0.007389105839235955, \"specificity\": 1.0, \"npv\": 0.9997641081465046, \"accuracy\": 0.9997641085607313, \"f1\": 0.014669814863801285, \"f2\": 0.009219351607845068, \"f0_5\": 0.035884899902538785, \"p4\": 0.02891539617645879, \"phi\": 0.0859497691059369}, {\"truth_threshold\": 43.95999901741743, \"match_probability\": 0.9999999999999416, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2225.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0073200180286286725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9926799819713713, \"precision\": 1.0, \"recall\": 0.0073200180286286725, \"specificity\": 1.0, \"npv\": 0.9997640917318077, \"accuracy\": 0.9997640921421899, \"f1\": 0.014533649481034404, \"f2\": 0.009133308539992398, \"f0_5\": 0.03555892233292101, \"p4\": 0.02865084844557173, \"phi\": 0.08554701149574076}, {\"truth_threshold\": 43.979999016970396, \"match_probability\": 0.9999999999999424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2207.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007260799905251003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.992739200094749, \"precision\": 1.0, \"recall\": 0.007260799905251003, \"specificity\": 1.0, \"npv\": 0.9997640776620679, \"accuracy\": 0.9997640780691543, \"f1\": 0.014416921428758068, \"f2\": 0.00905955497758304, \"f0_5\": 0.03527937363526211, \"p4\": 0.028424007819764587, \"phi\": 0.08520027535379271}, {\"truth_threshold\": 43.99999901652336, \"match_probability\": 0.9999999999999432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2198.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301763.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007231190843562167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9927688091564378, \"precision\": 1.0, \"recall\": 0.007231190843562167, \"specificity\": 1.0, \"npv\": 0.9997640706271981, \"accuracy\": 0.9997640710326365, \"f1\": 0.014358552255527356, \"f2\": 0.009022677378940957, \"f0_5\": 0.03513955101949462, \"p4\": 0.02831055792195033, \"phi\": 0.08502637704407871}, {\"truth_threshold\": 44.019999016076326, \"match_probability\": 0.9999999999999439, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2187.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301774.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007195001990386925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9928049980096131, \"precision\": 1.0, \"recall\": 0.007195001990386925, \"specificity\": 1.0, \"npv\": 0.999764062029024, \"accuracy\": 0.9997640624324482, \"f1\": 0.014287207494414466, \"f2\": 0.008977604018288532, \"f0_5\": 0.0349686129916312, \"p4\": 0.02817187014120579, \"phi\": 0.0848133504597958}, {\"truth_threshold\": 44.03999901562929, \"match_probability\": 0.9999999999999447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2157.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007096305118090808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9929036948819092, \"precision\": 1.0, \"recall\": 0.007096305118090808, \"specificity\": 1.0, \"npv\": 0.9997640385794593, \"accuracy\": 0.9997640389773891, \"f1\": 0.014092604812523276, \"f2\": 0.008854672533109578, \"f0_5\": 0.0345021737809072, \"p4\": 0.027793480861016708, \"phi\": 0.0842296305575096}, {\"truth_threshold\": 44.05999901518226, \"match_probability\": 0.9999999999999455, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2150.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0070732758478883806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9929267241521116, \"precision\": 1.0, \"recall\": 0.0070732758478883806, \"specificity\": 1.0, \"npv\": 0.9997640331078943, \"accuracy\": 0.9997640335045419, \"f1\": 0.01404719203164865, \"f2\": 0.008825987648543424, \"f0_5\": 0.03439328643048877, \"p4\": 0.02770515845462069, \"phi\": 0.08409284624133939}, {\"truth_threshold\": 44.07999901473522, \"match_probability\": 0.9999999999999463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2128.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0070008981415378944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9929991018584621, \"precision\": 1.0, \"recall\": 0.0070008981415378944, \"specificity\": 1.0, \"npv\": 0.9997640159115477, \"accuracy\": 0.9997640163041651, \"f1\": 0.013904452626523659, \"f2\": 0.008735833007655349, \"f0_5\": 0.03405094200138892, \"p4\": 0.027427495926693676, \"phi\": 0.0836614967650688}, {\"truth_threshold\": 44.09999901428819, \"match_probability\": 0.9999999999999469, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2110.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006941680018160225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930583199818398, \"precision\": 1.0, \"recall\": 0.006941680018160225, \"specificity\": 1.0, \"npv\": 0.99976400184181, \"accuracy\": 0.9997640022311297, \"f1\": 0.01378765057780711, \"f2\": 0.008662067697137987, \"f0_5\": 0.033770698557302956, \"p4\": 0.027200229630514976, \"phi\": 0.08330691324530752}, {\"truth_threshold\": 44.11999901384115, \"match_probability\": 0.9999999999999477, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2108.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301853.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0069351002266738165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930648997733262, \"precision\": 1.0, \"recall\": 0.0069351002266738165, \"specificity\": 1.0, \"npv\": 0.9997640002785059, \"accuracy\": 0.9997640006674591, \"f1\": 0.013774671724349739, \"f2\": 0.00865387141693597, \"f0_5\": 0.03373955242274955, \"p4\": 0.027174972936499463, \"phi\": 0.08326742187045176}, {\"truth_threshold\": 44.13999901339412, \"match_probability\": 0.9999999999999484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2107.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301854.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006931810330930613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930681896690694, \"precision\": 1.0, \"recall\": 0.006931810330930613, \"specificity\": 1.0, \"npv\": 0.9997639994968538, \"accuracy\": 0.9997639998856237, \"f1\": 0.013768182234013356, \"f2\": 0.008649773266740615, \"f0_5\": 0.03372397875725458, \"p4\": 0.02716234422316766, \"phi\": 0.08324766915778962}, {\"truth_threshold\": 44.15999901294708, \"match_probability\": 0.9999999999999492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2100.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006908781060728186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930912189392718, \"precision\": 1.0, \"recall\": 0.006908781060728186, \"specificity\": 1.0, \"npv\": 0.9997639940252893, \"accuracy\": 0.9997639944127766, \"f1\": 0.01372275461427624, \"f2\": 0.008621086026943767, \"f0_5\": 0.03361495193061874, \"p4\": 0.027073936391134923, \"phi\": 0.08310926871967941}, {\"truth_threshold\": 44.17999901250005, \"match_probability\": 0.9999999999999498, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2083.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301878.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006852852833093719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931471471669063, \"precision\": 1.0, \"recall\": 0.006852852833093719, \"specificity\": 1.0, \"npv\": 0.9997639807372042, \"accuracy\": 0.9997639811215764, \"f1\": 0.013612421743278744, \"f2\": 0.00855141564313789, \"f0_5\": 0.03335009110034487, \"p4\": 0.0268591818192628, \"phi\": 0.0827721899421539}, {\"truth_threshold\": 44.19999901205301, \"match_probability\": 0.9999999999999505, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2077.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006833113458634496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931668865413655, \"precision\": 1.0, \"recall\": 0.006833113458634496, \"specificity\": 1.0, \"npv\": 0.999763976047292, \"accuracy\": 0.9997639764305646, \"f1\": 0.013573477803410033, \"f2\": 0.008526825631547531, \"f0_5\": 0.03325658326635049, \"p4\": 0.026783369226511956, \"phi\": 0.08265289275147414}, {\"truth_threshold\": 44.21999901160598, \"match_probability\": 0.9999999999999512, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2071.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006813374084175272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931866259158247, \"precision\": 1.0, \"recall\": 0.006813374084175272, \"specificity\": 1.0, \"npv\": 0.9997639713573797, \"accuracy\": 0.9997639717395528, \"f1\": 0.013534532336487687, \"f2\": 0.00850223537767414, \"f0_5\": 0.033163061057823184, \"p4\": 0.026707547833988002, \"phi\": 0.08253342312504988}, {\"truth_threshold\": 44.23999901115894, \"match_probability\": 0.9999999999999518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2057.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006767315543770418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932326844562296, \"precision\": 1.0, \"recall\": 0.006767315543770418, \"specificity\": 1.0, \"npv\": 0.9997639604142513, \"accuracy\": 0.9997639607938584, \"f1\": 0.013443653641289074, \"f2\": 0.008444857176404322, \"f0_5\": 0.032944786651675745, \"p4\": 0.02653059702148448, \"phi\": 0.08225398585729955}, {\"truth_threshold\": 44.25999901071191, \"match_probability\": 0.9999999999999525, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2054.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006757445856540806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932425541434592, \"precision\": 1.0, \"recall\": 0.006757445856540806, \"specificity\": 1.0, \"npv\": 0.9997639580692952, \"accuracy\": 0.9997639584483525, \"f1\": 0.013424178553338889, \"f2\": 0.008432561675936737, \"f0_5\": 0.03289800337628973, \"p4\": 0.02649267275410594, \"phi\": 0.08219398284530441}, {\"truth_threshold\": 44.27999901026487, \"match_probability\": 0.9999999999999531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2049.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301912.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006740996377824787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932590036221752, \"precision\": 1.0, \"recall\": 0.006740996377824787, \"specificity\": 1.0, \"npv\": 0.9997639541610351, \"accuracy\": 0.999763954539176, \"f1\": 0.013391719224861933, \"f2\": 0.008412069040547898, \"f0_5\": 0.03282002325752746, \"p4\": 0.02642946074968668, \"phi\": 0.0820938803668052}, {\"truth_threshold\": 44.29999900981784, \"match_probability\": 0.9999999999999538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2048.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301913.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0067377064820815825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932622935179184, \"precision\": 1.0, \"recall\": 0.0067377064820815825, \"specificity\": 1.0, \"npv\": 0.9997639533793832, \"accuracy\": 0.9997639537573407, \"f1\": 0.0133852272318788, \"f2\": 0.00840797049327855, \"f0_5\": 0.0328044260346689, \"p4\": 0.026416817614920676, \"phi\": 0.0820738452202392}, {\"truth_threshold\": 44.319999009370804, \"match_probability\": 0.9999999999999545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2040.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006711387316135952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993288612683864, \"precision\": 1.0, \"recall\": 0.006711387316135952, \"specificity\": 1.0, \"npv\": 0.9997639471261671, \"accuracy\": 0.9997639475026583, \"f1\": 0.013333289760490979, \"f2\": 0.008375181872822043, \"f0_5\": 0.032679633859945344, \"p4\": 0.02631566372901387, \"phi\": 0.081913387635188}, {\"truth_threshold\": 44.33999900892377, \"match_probability\": 0.999999999999955, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2029.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301932.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006675198462960709, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9933248015370393, \"precision\": 1.0, \"recall\": 0.006675198462960709, \"specificity\": 1.0, \"npv\": 0.9997639385279953, \"accuracy\": 0.99976393890247, \"f1\": 0.013261871302983758, \"f2\": 0.008330096816334709, \"f0_5\": 0.032508002832634254, \"p4\": 0.026176551563919296, \"phi\": 0.08169224385329135}, {\"truth_threshold\": 44.359999008476734, \"match_probability\": 0.9999999999999557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1996.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301965.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00656663190343498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993433368096565, \"precision\": 1.0, \"recall\": 0.00656663190343498, \"specificity\": 1.0, \"npv\": 0.9997639127334804, \"accuracy\": 0.9997639131019048, \"f1\": 0.0130475851181702, \"f2\": 0.008194836760165539, \"f0_5\": 0.03199281924698264, \"p4\": 0.025759037321293816, \"phi\": 0.08102519117693373}, {\"truth_threshold\": 44.3799990080297, \"match_probability\": 0.9999999999999564, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1978.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301983.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00650741378005731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9934925862199427, \"precision\": 1.0, \"recall\": 0.00650741378005731, \"specificity\": 1.0, \"npv\": 0.9997638986637456, \"accuracy\": 0.9997638990288693, \"f1\": 0.012930682260189123, \"f2\": 0.008121055458022601, \"f0_5\": 0.031711626206821365, \"p4\": 0.02553118983495383, \"phi\": 0.08065901915451414}, {\"truth_threshold\": 44.399999007582664, \"match_probability\": 0.9999999999999569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1965.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301996.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00646464513539566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935353548646043, \"precision\": 1.0, \"recall\": 0.00646464513539566, \"specificity\": 1.0, \"npv\": 0.9997638885022707, \"accuracy\": 0.9997638888650103, \"f1\": 0.012846243862894948, \"f2\": 0.008067767605593324, \"f0_5\": 0.03150846158533261, \"p4\": 0.025366583923381387, \"phi\": 0.08039352435582392}, {\"truth_threshold\": 44.41999900713563, \"match_probability\": 0.9999999999999575, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1957.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006438325969450028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.99356167403055, \"precision\": 1.0, \"recall\": 0.006438325969450028, \"specificity\": 1.0, \"npv\": 0.9997638822490555, \"accuracy\": 0.9997638826103279, \"f1\": 0.012794278205270694, \"f2\": 0.008034974515540716, \"f0_5\": 0.03138340351968799, \"p4\": 0.025265267379116416, \"phi\": 0.08022970625898038}, {\"truth_threshold\": 44.439999006688595, \"match_probability\": 0.9999999999999581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1936.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006369238158842746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9936307618411573, \"precision\": 1.0, \"recall\": 0.006369238158842746, \"specificity\": 1.0, \"npv\": 0.9997638658343659, \"accuracy\": 0.9997638661917865, \"f1\": 0.012657855421923065, \"f2\": 0.007948890604214226, \"f0_5\": 0.031055003929997913, \"p4\": 0.024999236749823257, \"phi\": 0.07979808371198135}, {\"truth_threshold\": 44.45999900624156, \"match_probability\": 0.9999999999999587, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1931.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0063527886801267265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9936472113198733, \"precision\": 1.0, \"recall\": 0.0063527886801267265, \"specificity\": 1.0, \"npv\": 0.9997638619261067, \"accuracy\": 0.9997638622826099, \"f1\": 0.012625371045990088, \"f2\": 0.00792839399724908, \"f0_5\": 0.030976787461700114, \"p4\": 0.024935880172609257, \"phi\": 0.07969497189185745}, {\"truth_threshold\": 44.479999005794525, \"match_probability\": 0.9999999999999593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1904.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006263961495060221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9937360385049397, \"precision\": 1.0, \"recall\": 0.006263961495060221, \"specificity\": 1.0, \"npv\": 0.9997638408215067, \"accuracy\": 0.9997638411730567, \"f1\": 0.01244993706373727, \"f2\": 0.007817709411142536, \"f0_5\": 0.030554245018085416, \"p4\": 0.024593648587140804, \"phi\": 0.07913584651129622}, {\"truth_threshold\": 44.49999900534749, \"match_probability\": 0.9999999999999598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1900.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006250801912087406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9937491980879126, \"precision\": 1.0, \"recall\": 0.006250801912087406, \"specificity\": 1.0, \"npv\": 0.9997638376948994, \"accuracy\": 0.9997638380457154, \"f1\": 0.01242394420995158, \"f2\": 0.007801311277247106, \"f0_5\": 0.03049162122345223, \"p4\": 0.024542932383410238, \"phi\": 0.07905267679401577}, {\"truth_threshold\": 44.519999004900455, \"match_probability\": 0.9999999999999604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1892.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006224482746141775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9937755172538583, \"precision\": 1.0, \"recall\": 0.006224482746141775, \"specificity\": 1.0, \"npv\": 0.9997638314416848, \"accuracy\": 0.999763831791033, \"f1\": 0.012371956462745175, \"f2\": 0.007768514686270259, \"f0_5\": 0.03036635433619342, \"p4\": 0.024441488181992724, \"phi\": 0.07888607430355095}, {\"truth_threshold\": 44.53999900445342, \"match_probability\": 0.9999999999999609, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1886.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302075.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0062047433716825515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9937952566283175, \"precision\": 1.0, \"recall\": 0.0062047433716825515, \"specificity\": 1.0, \"npv\": 0.999763826751774, \"accuracy\": 0.9997638271000212, \"f1\": 0.012332963867554692, \"f2\": 0.007743916960245703, \"f0_5\": 0.03027238728110303, \"p4\": 0.024365394709417728, \"phi\": 0.07876089116614952}, {\"truth_threshold\": 44.559999004006386, \"match_probability\": 0.9999999999999615, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1878.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006178424205736921, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938215757942631, \"precision\": 1.0, \"recall\": 0.006178424205736921, \"specificity\": 1.0, \"npv\": 0.9997638204985595, \"accuracy\": 0.9997638208453388, \"f1\": 0.012280971360748629, \"f2\": 0.007711119615150256, \"f0_5\": 0.030147075348425065, \"p4\": 0.02426392298103447, \"phi\": 0.07859367015598852}, {\"truth_threshold\": 44.57999900355935, \"match_probability\": 0.9999999999999619, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1869.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302092.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006148815144048085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938511848559519, \"precision\": 1.0, \"recall\": 0.006148815144048085, \"specificity\": 1.0, \"npv\": 0.9997638134636934, \"accuracy\": 0.999763813808821, \"f1\": 0.012222476539253834, \"f2\": 0.0076742220868135595, \"f0_5\": 0.030006068643096358, \"p4\": 0.024149748478506834, \"phi\": 0.07840512021989905}, {\"truth_threshold\": 44.599999003112316, \"match_probability\": 0.9999999999999625, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1859.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006115916186616046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993884083813384, \"precision\": 1.0, \"recall\": 0.006115916186616046, \"specificity\": 1.0, \"npv\": 0.9997638056471755, \"accuracy\": 0.9997638059904679, \"f1\": 0.012157478255182787, \"f2\": 0.007633224193419906, \"f0_5\": 0.029849356287953963, \"p4\": 0.02402286455757056, \"phi\": 0.07819508706914022}, {\"truth_threshold\": 44.61999900266528, \"match_probability\": 0.999999999999963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1845.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006069857646211192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9939301423537888, \"precision\": 1.0, \"recall\": 0.006069857646211192, \"specificity\": 1.0, \"npv\": 0.9997637947040507, \"accuracy\": 0.9997637950447736, \"f1\": 0.012066473515889159, \"f2\": 0.007575826011403569, \"f0_5\": 0.02962989134100552, \"p4\": 0.02384518574017824, \"phi\": 0.07790008930475946}, {\"truth_threshold\": 44.63999900221825, \"match_probability\": 0.9999999999999635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1830.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006020509210063133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9939794907899369, \"precision\": 1.0, \"recall\": 0.006020509210063133, \"specificity\": 1.0, \"npv\": 0.9997637829792745, \"accuracy\": 0.999763783317244, \"f1\": 0.01196895919108149, \"f2\": 0.007514326494611858, \"f0_5\": 0.029394662700261177, \"p4\": 0.023654762053349116, \"phi\": 0.07758277555820159}, {\"truth_threshold\": 44.65999900177121, \"match_probability\": 0.999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1823.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302138.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005997479939860706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940025200601393, \"precision\": 1.0, \"recall\": 0.005997479939860706, \"specificity\": 1.0, \"npv\": 0.9997637775077124, \"accuracy\": 0.999763777844397, \"f1\": 0.011923449232137718, \"f2\": 0.0074856262015805634, \"f0_5\": 0.029284858298554553, \"p4\": 0.0235658787103478, \"phi\": 0.07743425082095046}, {\"truth_threshold\": 44.67999900132418, \"match_probability\": 0.9999999999999645, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1819.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302142.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00598432035688789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940156796431121, \"precision\": 1.0, \"recall\": 0.00598432035688789, \"specificity\": 1.0, \"npv\": 0.9997637743811054, \"accuracy\": 0.9997637747170557, \"f1\": 0.011897442605795016, \"f2\": 0.007469225885979947, \"f0_5\": 0.029222104055751725, \"p4\": 0.02351508281132036, \"phi\": 0.07734925149675284}, {\"truth_threshold\": 44.69999900087714, \"match_probability\": 0.999999999999965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1808.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005948131503712648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940518684962873, \"precision\": 1.0, \"recall\": 0.005948131503712648, \"specificity\": 1.0, \"npv\": 0.9997637657829365, \"accuracy\": 0.9997637661168673, \"f1\": 0.011825920874908837, \"f2\": 0.007424124462490104, \"f0_5\": 0.029049496614641075, \"p4\": 0.023375373769739267, \"phi\": 0.07711502027182433}, {\"truth_threshold\": 44.71999900043011, \"match_probability\": 0.9999999999999655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1803.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302158.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005931682024996628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940683179750034, \"precision\": 1.0, \"recall\": 0.005931682024996628, \"specificity\": 1.0, \"npv\": 0.999763761874678, \"accuracy\": 0.9997637622076908, \"f1\": 0.011793409296058398, \"f2\": 0.007403623546068771, \"f0_5\": 0.028971022550156985, \"p4\": 0.02331185980625849, \"phi\": 0.07700831601557741}, {\"truth_threshold\": 44.73999899998307, \"match_probability\": 0.9999999999999659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1788.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302173.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00588233358884857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9941176664111514, \"precision\": 1.0, \"recall\": 0.00588233358884857, \"specificity\": 1.0, \"npv\": 0.9997637501499025, \"accuracy\": 0.9997637504801612, \"f1\": 0.011695868179454389, \"f2\": 0.007342119786602192, \"f0_5\": 0.028735539819936807, \"p4\": 0.023121280953438485, \"phi\": 0.07668731243445671}, {\"truth_threshold\": 44.75999899953604, \"match_probability\": 0.9999999999999665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1773.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302188.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005832985152700511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9941670148472995, \"precision\": 1.0, \"recall\": 0.005832985152700511, \"specificity\": 1.0, \"npv\": 0.9997637384251272, \"accuracy\": 0.9997637387526316, \"f1\": 0.01159831749167577, \"f2\": 0.0072806145117881894, \"f0_5\": 0.028499966243694805, \"p4\": 0.022930646638227022, \"phi\": 0.07636495951967842}, {\"truth_threshold\": 44.779998999089, \"match_probability\": 0.9999999999999669, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1748.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302213.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005750737759120414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9942492622408796, \"precision\": 1.0, \"recall\": 0.005750737759120414, \"specificity\": 1.0, \"npv\": 0.9997637188838359, \"accuracy\": 0.999763719206749, \"f1\": 0.011435711738941281, \"f2\": 0.0071781023528406885, \"f0_5\": 0.02810714159374568, \"p4\": 0.022612799464006277, \"phi\": 0.07582465936872991}, {\"truth_threshold\": 44.79999899864197, \"match_probability\": 0.9999999999999674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1740.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005724418593174782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9942755814068253, \"precision\": 1.0, \"recall\": 0.005724418593174782, \"specificity\": 1.0, \"npv\": 0.9997637126306228, \"accuracy\": 0.9997637129520666, \"f1\": 0.011383672281085113, \"f2\": 0.007145297572898461, \"f0_5\": 0.027981384338787024, \"p4\": 0.022511055797790308, \"phi\": 0.07565094834411652}, {\"truth_threshold\": 44.81999899819493, \"match_probability\": 0.9999999999999678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1733.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302228.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005701389322972355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9942986106770276, \"precision\": 1.0, \"recall\": 0.005701389322972355, \"specificity\": 1.0, \"npv\": 0.9997637071590614, \"accuracy\": 0.9997637074792194, \"f1\": 0.011338135521142058, \"f2\": 0.007116593036826419, \"f0_5\": 0.027871325504273174, \"p4\": 0.02242201713066033, \"phi\": 0.07549862333507766}, {\"truth_threshold\": 44.8399989977479, \"match_probability\": 0.9999999999999682, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1729.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302232.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0056882297399995395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943117702600005, \"precision\": 1.0, \"recall\": 0.0056882297399995395, \"specificity\": 1.0, \"npv\": 0.9997637040324548, \"accuracy\": 0.9997637043518782, \"f1\": 0.011312113579116097, \"f2\": 0.007100190296598233, \"f0_5\": 0.027808425840444934, \"p4\": 0.022371132460780832, \"phi\": 0.07541144232972545}, {\"truth_threshold\": 44.85999899730086, \"match_probability\": 0.9999999999999687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1722.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005665200469797112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943347995302029, \"precision\": 1.0, \"recall\": 0.005665200469797112, \"specificity\": 1.0, \"npv\": 0.9997636985608936, \"accuracy\": 0.999763698879031, \"f1\": 0.011266573541871808, \"f2\": 0.007071485241867792, \"f0_5\": 0.0276983358479519, \"p4\": 0.02228207478167199, \"phi\": 0.07525863255981517}, {\"truth_threshold\": 44.87999899685383, \"match_probability\": 0.9999999999999691, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1697.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302264.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005582953076217014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994417046923783, \"precision\": 1.0, \"recall\": 0.005582953076217014, \"specificity\": 1.0, \"npv\": 0.9997636790196037, \"accuracy\": 0.9997636793331484, \"f1\": 0.011103913524265683, \"f2\": 0.006968964494830154, \"f0_5\": 0.02730499534994481, \"p4\": 0.021963912835324506, \"phi\": 0.07471033199814157}, {\"truth_threshold\": 44.899998996406794, \"match_probability\": 0.9999999999999696, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1684.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302277.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0055401844315553644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9944598155684446, \"precision\": 1.0, \"recall\": 0.0055401844315553644, \"specificity\": 1.0, \"npv\": 0.9997636688581333, \"accuracy\": 0.9997636691692894, \"f1\": 0.01101931979911335, \"f2\": 0.006915652042499228, \"f0_5\": 0.027100358226825494, \"p4\": 0.021798407583445336, \"phi\": 0.07442361932506711}, {\"truth_threshold\": 44.91999899595976, \"match_probability\": 0.9999999999999699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1663.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302298.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005471096620948082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945289033790519, \"precision\": 1.0, \"recall\": 0.005471096620948082, \"specificity\": 1.0, \"npv\": 0.9997636524434508, \"accuracy\": 0.999763652750748, \"f1\": 0.01088265319477528, \"f2\": 0.006829529522212193, \"f0_5\": 0.026769645829376104, \"p4\": 0.02153096467175966, \"phi\": 0.07395812018047834}, {\"truth_threshold\": 44.939998995512724, \"match_probability\": 0.9999999999999704, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1649.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0054250380805432276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945749619194568, \"precision\": 1.0, \"recall\": 0.0054250380805432276, \"specificity\": 1.0, \"npv\": 0.9997636415003294, \"accuracy\": 0.9997636418050537, \"f1\": 0.010791531690716926, \"f2\": 0.006772112858143743, \"f0_5\": 0.026549071507001934, \"p4\": 0.02135260878883975, \"phi\": 0.0736461528301503}, {\"truth_threshold\": 44.95999899506569, \"match_probability\": 0.9999999999999708, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1645.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302316.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005411878497570412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945881215024296, \"precision\": 1.0, \"recall\": 0.005411878497570412, \"specificity\": 1.0, \"npv\": 0.9997636383737233, \"accuracy\": 0.9997636386777125, \"f1\": 0.01076549544184342, \"f2\": 0.0067557078544446805, \"f0_5\": 0.026486035660347587, \"p4\": 0.021301641056041477, \"phi\": 0.07355677628313732}, {\"truth_threshold\": 44.979998994618654, \"match_probability\": 0.9999999999999711, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1630.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302331.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005362530061422353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946374699385776, \"precision\": 1.0, \"recall\": 0.005362530061422353, \"specificity\": 1.0, \"npv\": 0.9997636266489507, \"accuracy\": 0.999763626950183, \"f1\": 0.01066785343809209, \"f2\": 0.006694188130506278, \"f0_5\": 0.026249593372863395, \"p4\": 0.02111047678152807, \"phi\": 0.0732206425963446}, {\"truth_threshold\": 44.99999899417162, \"match_probability\": 0.9999999999999716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1624.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0053427906869631305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946572093130369, \"precision\": 1.0, \"recall\": 0.0053427906869631305, \"specificity\": 1.0, \"npv\": 0.9997636219590418, \"accuracy\": 0.999763622259171, \"f1\": 0.010628793952582751, \"f2\": 0.006669579816471562, \"f0_5\": 0.0261549908683006, \"p4\": 0.021033995471999745, \"phi\": 0.07308575626322338}, {\"truth_threshold\": 45.019998993724585, \"match_probability\": 0.999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1604.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0052769927720990525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994723007227901, \"precision\": 1.0, \"recall\": 0.0052769927720990525, \"specificity\": 1.0, \"npv\": 0.9997636063260122, \"accuracy\": 0.999763606622465, \"f1\": 0.010498584589203606, \"f2\": 0.0065875503512265, \"f0_5\": 0.02583954352287702, \"p4\": 0.020778993368114493, \"phi\": 0.07263432607514198}, {\"truth_threshold\": 45.03999899327755, \"match_probability\": 0.9999999999999724, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1591.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302370.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005234224127437402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9947657758725627, \"precision\": 1.0, \"recall\": 0.005234224127437402, \"specificity\": 1.0, \"npv\": 0.9997635961645432, \"accuracy\": 0.999763596458606, \"f1\": 0.010413939362203488, \"f2\": 0.006534229753539203, \"f0_5\": 0.02563441553210344, \"p4\": 0.020613188845948333, \"phi\": 0.07233938579209831}, {\"truth_threshold\": 45.059998992830515, \"match_probability\": 0.9999999999999727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1581.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302380.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005201325170005363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9947986748299946, \"precision\": 1.0, \"recall\": 0.005201325170005363, \"specificity\": 1.0, \"npv\": 0.9997635883480288, \"accuracy\": 0.9997635886402529, \"f1\": 0.01034882274777281, \"f2\": 0.006493213134279319, \"f0_5\": 0.02547657798475595, \"p4\": 0.02048561839608468, \"phi\": 0.0721116877914356}, {\"truth_threshold\": 45.07999899238348, \"match_probability\": 0.9999999999999731, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1574.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302387.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005178295899802936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9948217041001971, \"precision\": 1.0, \"recall\": 0.005178295899802936, \"specificity\": 1.0, \"npv\": 0.9997635828764688, \"accuracy\": 0.9997635831674058, \"f1\": 0.010303238581504575, \"f2\": 0.006464501099868738, \"f0_5\": 0.025366067485987423, \"p4\": 0.020396304326189534, \"phi\": 0.07195187045505844}, {\"truth_threshold\": 45.099998991936445, \"match_probability\": 0.9999999999999735, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1544.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302417.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005079599027506819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949204009724932, \"precision\": 1.0, \"recall\": 0.005079599027506819, \"specificity\": 1.0, \"npv\": 0.9997635594269265, \"accuracy\": 0.9997635597123466, \"f1\": 0.010107854208605424, \"f2\": 0.00634144578392427, \"f0_5\": 0.02489222504892999, \"p4\": 0.020013392047448456, \"phi\": 0.07126287956714751}, {\"truth_threshold\": 45.11999899148941, \"match_probability\": 0.9999999999999738, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1530.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005033540487101963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949664595128981, \"precision\": 1.0, \"recall\": 0.005033540487101963, \"specificity\": 1.0, \"npv\": 0.9997635484838071, \"accuracy\": 0.9997635487666523, \"f1\": 0.0100166617019814, \"f2\": 0.006284017894254354, \"f0_5\": 0.024670973068327308, \"p4\": 0.019834623199130857, \"phi\": 0.07093906045911498}, {\"truth_threshold\": 45.139998991042376, \"match_probability\": 0.9999999999999742, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1513.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004977612259467497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950223877405325, \"precision\": 1.0, \"recall\": 0.004977612259467497, \"specificity\": 1.0, \"npv\": 0.9997635351957339, \"accuracy\": 0.9997635354754522, \"f1\": 0.00990591670649548, \"f2\": 0.006214282252453471, \"f0_5\": 0.02440220248828275, \"p4\": 0.019617481295848234, \"phi\": 0.07054385323583375}, {\"truth_threshold\": 45.15999899059534, \"match_probability\": 0.9999999999999746, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1505.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302456.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004951293093521866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950487069064782, \"precision\": 1.0, \"recall\": 0.004951293093521866, \"specificity\": 1.0, \"npv\": 0.9997635289425232, \"accuracy\": 0.9997635292207697, \"f1\": 0.009853797149273568, \"f2\": 0.006181464805902005, \"f0_5\": 0.02427568141273175, \"p4\": 0.019515272024688314, \"phi\": 0.07035710522760415}, {\"truth_threshold\": 45.179998990148306, \"match_probability\": 0.9999999999999749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1500.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004934843614805846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950651563851941, \"precision\": 1.0, \"recall\": 0.004934843614805846, \"specificity\": 1.0, \"npv\": 0.9997635250342665, \"accuracy\": 0.9997635253115932, \"f1\": 0.00982122103967446, \"f2\": 0.006160953682771674, \"f0_5\": 0.02419659247453712, \"p4\": 0.01945138315287921, \"phi\": 0.0702401355909222}, {\"truth_threshold\": 45.19999898970127, \"match_probability\": 0.9999999999999752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1498.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302463.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004928263823319439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950717361766805, \"precision\": 1.0, \"recall\": 0.004928263823319439, \"specificity\": 1.0, \"npv\": 0.9997635234709638, \"accuracy\": 0.9997635237479225, \"f1\": 0.009808190297224833, \"f2\": 0.006152749186342047, \"f0_5\": 0.024164954041419183, \"p4\": 0.01942582586416822, \"phi\": 0.07019329315964827}, {\"truth_threshold\": 45.219998989254236, \"match_probability\": 0.9999999999999756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1493.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302468.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004911814344603419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950881856553966, \"precision\": 1.0, \"recall\": 0.004911814344603419, \"specificity\": 1.0, \"npv\": 0.9997635195627071, \"accuracy\": 0.999763519838746, \"f1\": 0.009775612694546479, \"f2\": 0.006132237827323083, \"f0_5\": 0.02408585081291763, \"p4\": 0.01936192829191463, \"phi\": 0.07007605009273359}, {\"truth_threshold\": 45.2399989888072, \"match_probability\": 0.9999999999999759, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1492.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302469.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0049085244488602155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950914755511397, \"precision\": 1.0, \"recall\": 0.0049085244488602155, \"specificity\": 1.0, \"npv\": 0.9997635187810557, \"accuracy\": 0.9997635190569107, \"f1\": 0.009769097046026722, \"f2\": 0.006128135535300032, \"f0_5\": 0.024070028942112548, \"p4\": 0.019349148031609968, \"phi\": 0.07005257793268804}, {\"truth_threshold\": 45.25999898836017, \"match_probability\": 0.9999999999999762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1486.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004888785074400992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995111214925599, \"precision\": 1.0, \"recall\": 0.004888785074400992, \"specificity\": 1.0, \"npv\": 0.9997635140911478, \"accuracy\": 0.9997635143658989, \"f1\": 0.009730002258984374, \"f2\": 0.006103521641625525, \"f0_5\": 0.02397508914022039, \"p4\": 0.019272461248194896, \"phi\": 0.06991157948165304}, {\"truth_threshold\": 45.27999898791313, \"match_probability\": 0.9999999999999766, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1472.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302489.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0048427265339961376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9951572734660039, \"precision\": 1.0, \"recall\": 0.0048427265339961376, \"specificity\": 1.0, \"npv\": 0.9997635031480294, \"accuracy\": 0.9997635034202046, \"f1\": 0.009638775115982883, \"f2\": 0.006046088279460715, \"f0_5\": 0.02375350573989266, \"p4\": 0.019093490602533392, \"phi\": 0.0695814719908676}, {\"truth_threshold\": 45.2999989874661, \"match_probability\": 0.9999999999999769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1464.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302497.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004816407368050507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9951835926319494, \"precision\": 1.0, \"recall\": 0.004816407368050507, \"specificity\": 1.0, \"npv\": 0.999763496894819, \"accuracy\": 0.9997634971655222, \"f1\": 0.009586641565032332, \"f2\": 0.006013268622238579, \"f0_5\": 0.023626850689277865, \"p4\": 0.018991199770785828, \"phi\": 0.06939213408414635}, {\"truth_threshold\": 45.31999898701906, \"match_probability\": 0.9999999999999772, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1455.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302506.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004786798306361671, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952132016936384, \"precision\": 1.0, \"recall\": 0.004786798306361671, \"specificity\": 1.0, \"npv\": 0.9997634898599574, \"accuracy\": 0.9997634901290045, \"f1\": 0.009527988055635593, \"f2\": 0.005976345992233625, \"f0_5\": 0.023484332480042353, \"p4\": 0.018876103548763467, \"phi\": 0.06917850952444608}, {\"truth_threshold\": 45.33999898657203, \"match_probability\": 0.9999999999999776, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1440.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004737449870213613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952625501297864, \"precision\": 1.0, \"recall\": 0.004737449870213613, \"specificity\": 1.0, \"npv\": 0.9997634781351884, \"accuracy\": 0.9997634784014748, \"f1\": 0.009430224524477653, \"f2\": 0.005914807062279632, \"f0_5\": 0.023246728507269446, \"p4\": 0.01868423170680082, \"phi\": 0.06882099505046303}, {\"truth_threshold\": 45.35999898612499, \"match_probability\": 0.9999999999999779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1432.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302529.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004711130704267982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995288869295732, \"precision\": 1.0, \"recall\": 0.004711130704267982, \"specificity\": 1.0, \"npv\": 0.9997634718819783, \"accuracy\": 0.9997634721467924, \"f1\": 0.009378080047676273, \"f2\": 0.005881985679500787, \"f0_5\": 0.023119968742835555, \"p4\": 0.018581877150155905, \"phi\": 0.06862955915193356}, {\"truth_threshold\": 45.37999898567796, \"match_probability\": 0.9999999999999781, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1417.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302544.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0046617822681199236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.99533821773188, \"precision\": 1.0, \"recall\": 0.0046617822681199236, \"specificity\": 1.0, \"npv\": 0.9997634601572096, \"accuracy\": 0.9997634604192628, \"f1\": 0.009280301789912829, \"f2\": 0.005820444423997812, \"f0_5\": 0.022882223564330215, \"p4\": 0.01838991938881169, \"phi\": 0.0682691699881806}, {\"truth_threshold\": 45.39999898523092, \"match_probability\": 0.9999999999999785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1386.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004559795500080602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9954402044999194, \"precision\": 1.0, \"recall\": 0.004559795500080602, \"specificity\": 1.0, \"npv\": 0.9997634359260219, \"accuracy\": 0.9997634361823683, \"f1\": 0.009078196281607482, \"f2\": 0.005693254356202197, \"f0_5\": 0.02239059142824833, \"p4\": 0.01799302898908921, \"phi\": 0.06751827024058447}, {\"truth_threshold\": 45.41999898478389, \"match_probability\": 0.9999999999999788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1376.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302585.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004526896542648563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9954731034573514, \"precision\": 1.0, \"recall\": 0.004526896542648563, \"specificity\": 1.0, \"npv\": 0.9997634281095099, \"accuracy\": 0.9997634283640152, \"f1\": 0.00901299220205871, \"f2\": 0.005652223920080183, \"f0_5\": 0.02223191637180295, \"p4\": 0.017864948710189617, \"phi\": 0.06727425663785083}, {\"truth_threshold\": 45.43999898433685, \"match_probability\": 0.999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1365.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302596.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0044907076894733205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955092923105267, \"precision\": 1.0, \"recall\": 0.0044907076894733205, \"specificity\": 1.0, \"npv\": 0.999763419511347, \"accuracy\": 0.9997634197638269, \"f1\": 0.008941262781420515, \"f2\": 0.005607089661676836, \"f0_5\": 0.022057326425808203, \"p4\": 0.017724031588354387, \"phi\": 0.06700481531691395}, {\"truth_threshold\": 45.45999898388982, \"match_probability\": 0.9999999999999793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1345.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302616.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0044249097746092425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955750902253907, \"precision\": 1.0, \"recall\": 0.0044249097746092425, \"specificity\": 1.0, \"npv\": 0.9997634038783237, \"accuracy\": 0.9997634041271208, \"f1\": 0.008810832410761662, \"f2\": 0.005525025283665889, \"f0_5\": 0.021739762915358778, \"p4\": 0.01746774126959038, \"phi\": 0.06651212564726677}, {\"truth_threshold\": 45.47999898344278, \"match_probability\": 0.9999999999999796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1331.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302630.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004378851234204388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956211487657957, \"precision\": 1.0, \"recall\": 0.004378851234204388, \"specificity\": 1.0, \"npv\": 0.9997633929352078, \"accuracy\": 0.9997633931814265, \"f1\": 0.008719520983189864, \"f2\": 0.005467578614414525, \"f0_5\": 0.021517370709863072, \"p4\": 0.017288278620240613, \"phi\": 0.06616506001710193}, {\"truth_threshold\": 45.49999898299575, \"match_probability\": 0.9999999999999799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1329.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00437227144271798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995627728557282, \"precision\": 1.0, \"recall\": 0.00437227144271798, \"specificity\": 1.0, \"npv\": 0.9997633913719055, \"accuracy\": 0.9997633916177558, \"f1\": 0.008706475809885683, \"f2\": 0.005459371839500219, \"f0_5\": 0.02148559382042635, \"p4\": 0.017262637102464028, \"phi\": 0.06611533048824805}, {\"truth_threshold\": 45.519998982548714, \"match_probability\": 0.9999999999999801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1319.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302642.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004339372485285941, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956606275147141, \"precision\": 1.0, \"recall\": 0.004339372485285941, \"specificity\": 1.0, \"npv\": 0.9997633835553943, \"accuracy\": 0.9997633837994029, \"f1\": 0.008641247379454927, \"f2\": 0.005418337560376055, \"f0_5\": 0.021326684711079204, \"p4\": 0.017134414523131, \"phi\": 0.06586611965492314}, {\"truth_threshold\": 45.53999898210168, \"match_probability\": 0.9999999999999805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1314.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302647.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004322923006569922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956770769934301, \"precision\": 1.0, \"recall\": 0.004322923006569922, \"specificity\": 1.0, \"npv\": 0.9997633796471388, \"accuracy\": 0.9997633798902263, \"f1\": 0.008608631561706657, \"f2\": 0.005397820167965047, \"f0_5\": 0.02124721473916376, \"p4\": 0.01707029386288115, \"phi\": 0.06574115997609652}, {\"truth_threshold\": 45.559998981654644, \"match_probability\": 0.9999999999999807, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1301.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302660.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004280154361908271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9957198456380917, \"precision\": 1.0, \"recall\": 0.004280154361908271, \"specificity\": 1.0, \"npv\": 0.9997633694856745, \"accuracy\": 0.9997633697263674, \"f1\": 0.008523825435199927, \"f2\": 0.0053444741587896265, \"f0_5\": 0.021040544692963306, \"p4\": 0.016903550902033666, \"phi\": 0.06541514768599258}, {\"truth_threshold\": 45.57999898120761, \"match_probability\": 0.999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1300.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302661.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0042768644661650675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995723135533835, \"precision\": 1.0, \"recall\": 0.0042768644661650675, \"specificity\": 1.0, \"npv\": 0.9997633687040233, \"accuracy\": 0.999763368944532, \"f1\": 0.008517301587821569, \"f2\": 0.0053403705724219975, \"f0_5\": 0.021024644117466303, \"p4\": 0.01689072277045317, \"phi\": 0.06539000249414066}, {\"truth_threshold\": 45.599998980760574, \"match_probability\": 0.9999999999999812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1293.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302668.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00425383519596264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9957461648040373, \"precision\": 1.0, \"recall\": 0.00425383519596264, \"specificity\": 1.0, \"npv\": 0.9997633632324657, \"accuracy\": 0.9997633634716849, \"f1\": 0.008471633459348609, \"f2\": 0.005311645279044183, \"f0_5\": 0.020913328567315686, \"p4\": 0.016800918848049625, \"phi\": 0.06521371467837302}, {\"truth_threshold\": 45.61999898031354, \"match_probability\": 0.9999999999999815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1271.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004181457489612154, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958185425103878, \"precision\": 1.0, \"recall\": 0.004181457489612154, \"specificity\": 1.0, \"npv\": 0.9997633460361421, \"accuracy\": 0.9997633462713081, \"f1\": 0.008328091418986213, \"f2\": 0.005221363634496329, \"f0_5\": 0.020563348379685806, \"p4\": 0.01651859816047228, \"phi\": 0.06465653819315209}, {\"truth_threshold\": 45.639998979866505, \"match_probability\": 0.9999999999999818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1265.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302696.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004161718115152931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995838281884847, \"precision\": 1.0, \"recall\": 0.004161718115152931, \"specificity\": 1.0, \"npv\": 0.9997633413462358, \"accuracy\": 0.9997633415802963, \"f1\": 0.008288939998558445, \"f2\": 0.005196740801357972, \"f0_5\": 0.020467864643503194, \"p4\": 0.01644158059198295, \"phi\": 0.06450374569392425}, {\"truth_threshold\": 45.65999897941947, \"match_probability\": 0.999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1253.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302708.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004122239366234484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958777606337655, \"precision\": 1.0, \"recall\": 0.004122239366234484, \"specificity\": 1.0, \"npv\": 0.9997633319664233, \"accuracy\": 0.9997633321982726, \"f1\": 0.008210632539791752, \"f2\": 0.0051474944067728375, \"f0_5\": 0.0202768526699744, \"p4\": 0.016287518422181613, \"phi\": 0.06419706974582051}, {\"truth_threshold\": 45.679998978972435, \"match_probability\": 0.9999999999999822, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1244.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302717.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004092630304545649, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9959073696954543, \"precision\": 1.0, \"recall\": 0.004092630304545649, \"specificity\": 1.0, \"npv\": 0.999763324931564, \"accuracy\": 0.9997633251617549, \"f1\": 0.008151897904687015, \"f2\": 0.005110558973549981, \"f0_5\": 0.020133554737697328, \"p4\": 0.01617194813488329, \"phi\": 0.0639660979034069}, {\"truth_threshold\": 45.6999989785254, \"match_probability\": 0.9999999999999825, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1226.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302735.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004033412181167979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9959665878188321, \"precision\": 1.0, \"recall\": 0.004033412181167979, \"specificity\": 1.0, \"npv\": 0.9997633108618458, \"accuracy\": 0.9997633110887194, \"f1\": 0.008034418241930357, \"f2\": 0.005036686468321461, \"f0_5\": 0.019846858659932333, \"p4\": 0.015940746697281325, \"phi\": 0.06350163396570987}, {\"truth_threshold\": 45.719998978078365, \"match_probability\": 0.9999999999999828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1216.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302745.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00400051322373594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995999486776264, \"precision\": 1.0, \"recall\": 0.00400051322373594, \"specificity\": 1.0, \"npv\": 0.9997633030453358, \"accuracy\": 0.9997633032703663, \"f1\": 0.007969145774419435, \"f2\": 0.00499564524345554, \"f0_5\": 0.019687525297498582, \"p4\": 0.015812266376408694, \"phi\": 0.06324212452502515}, {\"truth_threshold\": 45.73999897763133, \"match_probability\": 0.999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1208.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0039741940577903085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960258059422097, \"precision\": 1.0, \"recall\": 0.0039741940577903085, \"specificity\": 1.0, \"npv\": 0.9997632967921278, \"accuracy\": 0.9997632970156839, \"f1\": 0.007916924720400826, \"f2\": 0.0049628117779684025, \"f0_5\": 0.019560028886665175, \"p4\": 0.015709464073384603, \"phi\": 0.06303374773332238}, {\"truth_threshold\": 45.77999897673726, \"match_probability\": 0.9999999999999835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1205.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302756.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003964324370560697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960356756294393, \"precision\": 1.0, \"recall\": 0.003964324370560697, \"specificity\": 1.0, \"npv\": 0.9997632944471749, \"accuracy\": 0.999763294670178, \"f1\": 0.007897341119259682, \"f2\": 0.004950499117126755, \"f0_5\": 0.019512210919713325, \"p4\": 0.01567090907328702, \"phi\": 0.06295542862191461}, {\"truth_threshold\": 45.799998976290226, \"match_probability\": 0.9999999999999837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1204.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003961034474817493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960389655251826, \"precision\": 1.0, \"recall\": 0.003961034474817493, \"specificity\": 1.0, \"npv\": 0.999763293665524, \"accuracy\": 0.9997632938883426, \"f1\": 0.007890813166647552, \"f2\": 0.004946394883357107, \"f0_5\": 0.0194962707714629, \"p4\": 0.015658056905139613, \"phi\": 0.06292930059095068}, {\"truth_threshold\": 45.85999897494912, \"match_probability\": 0.9999999999999843, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1193.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302768.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00392484562164225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960751543783577, \"precision\": 1.0, \"recall\": 0.00392484562164225, \"specificity\": 1.0, \"npv\": 0.9997632850673633, \"accuracy\": 0.9997632852881543, \"f1\": 0.00781900286412762, \"f2\": 0.004901247866745218, \"f0_5\": 0.019320901879617665, \"p4\": 0.01551666650530557, \"phi\": 0.06264117297812448}, {\"truth_threshold\": 45.87999897450209, \"match_probability\": 0.9999999999999846, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1190.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003914975934412639, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960850240655874, \"precision\": 1.0, \"recall\": 0.003914975934412639, \"specificity\": 1.0, \"npv\": 0.9997632827224104, \"accuracy\": 0.9997632829426484, \"f1\": 0.007799417337645952, \"f2\": 0.0048889349023938525, \"f0_5\": 0.01927306532435435, \"p4\": 0.015478100220421651, \"phi\": 0.06256236242316633}, {\"truth_threshold\": 45.89999897405505, \"match_probability\": 0.9999999999999848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1177.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302784.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003872207289750988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996127792710249, \"precision\": 1.0, \"recall\": 0.003872207289750988, \"specificity\": 1.0, \"npv\": 0.9997632725609481, \"accuracy\": 0.9997632727787894, \"f1\": 0.007714542272676625, \"f2\": 0.004835578022071928, \"f0_5\": 0.01906573060462826, \"p4\": 0.015310953562780494, \"phi\": 0.06221969649585095}, {\"truth_threshold\": 45.91999897360802, \"match_probability\": 0.999999999999985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1174.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003862337602521376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961376623974786, \"precision\": 1.0, \"recall\": 0.003862337602521376, \"specificity\": 1.0, \"npv\": 0.9997632702159952, \"accuracy\": 0.9997632704332835, \"f1\": 0.0076949546921854265, \"f2\": 0.004823264733964493, \"f0_5\": 0.019017874209883462, \"p4\": 0.015272375235329204, \"phi\": 0.06214035140047872}, {\"truth_threshold\": 45.93999897316098, \"match_probability\": 0.9999999999999852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1173.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302788.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003859047706778172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961409522932219, \"precision\": 1.0, \"recall\": 0.003859047706778172, \"specificity\": 1.0, \"npv\": 0.9997632694343443, \"accuracy\": 0.9997632696514482, \"f1\": 0.007688425413097197, \"f2\": 0.004819160291105218, \"f0_5\": 0.0190019212513729, \"p4\": 0.015259515290942048, \"phi\": 0.062113880511779775}, {\"truth_threshold\": 45.95999897271395, \"match_probability\": 0.9999999999999853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1171.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0038524679152917643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961475320847082, \"precision\": 1.0, \"recall\": 0.0038524679152917643, \"specificity\": 1.0, \"npv\": 0.9997632678710424, \"accuracy\": 0.9997632680877776, \"f1\": 0.007675366726531468, \"f2\": 0.004810951385151374, \"f0_5\": 0.01897001409386188, \"p4\": 0.01523379464926857, \"phi\": 0.06206090486256574}, {\"truth_threshold\": 45.97999897226691, \"match_probability\": 0.9999999999999856, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1167.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302794.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003839308332318949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961606916676811, \"precision\": 1.0, \"recall\": 0.003839308332318949, \"specificity\": 1.0, \"npv\": 0.9997632647444387, \"accuracy\": 0.9997632649604363, \"f1\": 0.0076492488398311525, \"f2\": 0.004794533492302041, \"f0_5\": 0.018906194816430084, \"p4\": 0.015182350354119231, \"phi\": 0.06195481767126524}, {\"truth_threshold\": 45.99999897181988, \"match_probability\": 0.9999999999999858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1162.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302799.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0038228588536029294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961771411463971, \"precision\": 1.0, \"recall\": 0.0038228588536029294, \"specificity\": 1.0, \"npv\": 0.999763260836184, \"accuracy\": 0.9997632610512598, \"f1\": 0.007616600518479433, \"f2\": 0.004774010974473421, \"f0_5\": 0.01882641141379545, \"p4\": 0.01511803933744689, \"phi\": 0.061821952680213364}, {\"truth_threshold\": 46.01999897137284, \"match_probability\": 0.999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1153.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003793249791914094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9962067502080859, \"precision\": 1.0, \"recall\": 0.003793249791914094, \"specificity\": 1.0, \"npv\": 0.9997632538013258, \"accuracy\": 0.9997632540147421, \"f1\": 0.007557830843553557, \"f2\": 0.004737070017428145, \"f0_5\": 0.01868277522660764, \"p4\": 0.01500226369099876, \"phi\": 0.06158207332044965}, {\"truth_threshold\": 46.03999897092581, \"match_probability\": 0.9999999999999862, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1147.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003773510417454871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9962264895825451, \"precision\": 1.0, \"recall\": 0.003773510417454871, \"specificity\": 1.0, \"npv\": 0.9997632491114203, \"accuracy\": 0.9997632493237303, \"f1\": 0.007518649134077114, \"f2\": 0.0047124424091879065, \"f0_5\": 0.01858699914762323, \"p4\": 0.014925068627039038, \"phi\": 0.061421633285923566}, {\"truth_threshold\": 46.05999897047877, \"match_probability\": 0.9999999999999863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1135.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003734031668536424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9962659683314635, \"precision\": 1.0, \"recall\": 0.003734031668536424, \"specificity\": 1.0, \"npv\": 0.9997632397316095, \"accuracy\": 0.9997632399417066, \"f1\": 0.007440281091853056, \"f2\": 0.004663186464187139, \"f0_5\": 0.018395402283947215, \"p4\": 0.014770651372785817, \"phi\": 0.061099489344808786}, {\"truth_threshold\": 46.07999897003174, \"match_probability\": 0.9999999999999866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1121.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0036879731281315694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963120268718685, \"precision\": 1.0, \"recall\": 0.0036879731281315694, \"specificity\": 1.0, \"npv\": 0.9997632287884971, \"accuracy\": 0.9997632289960123, \"f1\": 0.007348843917373034, \"f2\": 0.004605719967295691, \"f0_5\": 0.018171797240999207, \"p4\": 0.014590452182313578, \"phi\": 0.060721494730169745}, {\"truth_threshold\": 46.0999989695847, \"match_probability\": 0.9999999999999868, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1119.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0036813933366451617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963186066633548, \"precision\": 1.0, \"recall\": 0.0036813933366451617, \"specificity\": 1.0, \"npv\": 0.9997632272251954, \"accuracy\": 0.9997632274323417, \"f1\": 0.007335780778812115, \"f2\": 0.004597510359805516, \"f0_5\": 0.018139847035213024, \"p4\": 0.014564705419747052, \"phi\": 0.060667303244249265}, {\"truth_threshold\": 46.11999896913767, \"match_probability\": 0.9999999999999869, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1109.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0036484943792131227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963515056207869, \"precision\": 1.0, \"recall\": 0.0036484943792131227, \"specificity\": 1.0, \"npv\": 0.9997632194086867, \"accuracy\": 0.9997632196139886, \"f1\": 0.007270462516799423, \"f2\": 0.004556461917592545, \"f0_5\": 0.017980071142066883, \"p4\": 0.014435956524072115, \"phi\": 0.060395616451499275}, {\"truth_threshold\": 46.139998968690634, \"match_probability\": 0.9999999999999871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1094.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003599145943065064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964008540569349, \"precision\": 1.0, \"recall\": 0.003599145943065064, \"specificity\": 1.0, \"npv\": 0.999763207683924, \"accuracy\": 0.999763207886459, \"f1\": 0.0071724770942944716, \"f2\": 0.004494887989363468, \"f0_5\": 0.017740329574459115, \"p4\": 0.014242786034250072, \"phi\": 0.05998577908939177}, {\"truth_threshold\": 46.1599989682436, \"match_probability\": 0.9999999999999872, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1084.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302877.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003566246985633025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996433753014367, \"precision\": 1.0, \"recall\": 0.003566246985633025, \"specificity\": 1.0, \"npv\": 0.9997631998674157, \"accuracy\": 0.999763200068106, \"f1\": 0.007107148125686374, \"f2\": 0.004453837860580083, \"f0_5\": 0.01758045002059702, \"p4\": 0.014113974266085308, \"phi\": 0.05971099143268348}, {\"truth_threshold\": 46.19999896734953, \"match_probability\": 0.9999999999999877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1082.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0035596671941466175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964403328058534, \"precision\": 1.0, \"recall\": 0.0035596671941466175, \"specificity\": 1.0, \"npv\": 0.999763198304114, \"accuracy\": 0.9997631985044354, \"f1\": 0.007094081817973203, \"f2\": 0.0044456277538650665, \"f0_5\": 0.017548469131237247, \"p4\": 0.014088208893261218, \"phi\": 0.05965588201441878}, {\"truth_threshold\": 46.219998966902494, \"match_probability\": 0.9999999999999878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1079.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302882.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0035497975069170057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996450202493083, \"precision\": 1.0, \"recall\": 0.0035497975069170057, \"specificity\": 1.0, \"npv\": 0.9997631959591615, \"accuracy\": 0.9997631961589295, \"f1\": 0.007074482035142932, \"f2\": 0.004433312543192955, \"f0_5\": 0.017500494684974877, \"p4\": 0.014049558946754175, \"phi\": 0.05957312229960093}, {\"truth_threshold\": 46.23999896645546, \"match_probability\": 0.999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1078.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003546507611173802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964534923888262, \"precision\": 1.0, \"recall\": 0.003546507611173802, \"specificity\": 1.0, \"npv\": 0.9997631951775107, \"accuracy\": 0.9997631953770941, \"f1\": 0.0070679486885283525, \"f2\": 0.004429207459475628, \"f0_5\": 0.01748450237289675, \"p4\": 0.014036675127950093, \"phi\": 0.059545510167169455}, {\"truth_threshold\": 46.259998966008425, \"match_probability\": 0.9999999999999881, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1076.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003539927819687394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964600721803126, \"precision\": 1.0, \"recall\": 0.003539927819687394, \"specificity\": 1.0, \"npv\": 0.9997631936142091, \"accuracy\": 0.9997631938134235, \"f1\": 0.0070548818667899305, \"f2\": 0.00442099727180094, \"f0_5\": 0.01745251650365757, \"p4\": 0.014010906735345087, \"phi\": 0.05949024745430509}, {\"truth_threshold\": 46.27999896556139, \"match_probability\": 0.9999999999999883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1067.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003510318757998559, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964896812420014, \"precision\": 1.0, \"recall\": 0.003510318757998559, \"specificity\": 1.0, \"npv\": 0.9997631865793517, \"accuracy\": 0.9997631867769058, \"f1\": 0.006996079048480795, \"f2\": 0.004384051093300989, \"f0_5\": 0.01730855954501361, \"p4\": 0.013894936509714465, \"phi\": 0.059240927300354705}, {\"truth_threshold\": 46.299998965114355, \"match_probability\": 0.9999999999999885, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1062.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0034938692792825395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965061307207175, \"precision\": 1.0, \"recall\": 0.0034938692792825395, \"specificity\": 1.0, \"npv\": 0.9997631826710976, \"accuracy\": 0.9997631828677292, \"f1\": 0.00696340931667448, \"f2\": 0.004363525202439629, \"f0_5\": 0.017228568925631634, \"p4\": 0.013830499795880547, \"phi\": 0.05910196164673628}, {\"truth_threshold\": 46.31999896466732, \"match_probability\": 0.9999999999999886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1059.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0034839995920529277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965160004079471, \"precision\": 1.0, \"recall\": 0.0034839995920529277, \"specificity\": 1.0, \"npv\": 0.9997631803261453, \"accuracy\": 0.9997631805222233, \"f1\": 0.006943806963477805, \"f2\": 0.004351209586959684, \"f0_5\": 0.01718056957076156, \"p4\": 0.013791834746265124, \"phi\": 0.05901842519422073}, {\"truth_threshold\": 46.339998964220285, \"match_probability\": 0.9999999999999888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1042.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302919.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0034280713644184615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965719286355815, \"precision\": 1.0, \"recall\": 0.0034280713644184615, \"specificity\": 1.0, \"npv\": 0.9997631670380819, \"accuracy\": 0.9997631672310231, \"f1\": 0.0068327196781671, \"f2\": 0.004281419952238747, \"f0_5\": 0.01690850260767406, \"p4\": 0.013572689986026246, \"phi\": 0.05854280044654133}, {\"truth_threshold\": 46.35999896377325, \"match_probability\": 0.9999999999999889, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1041.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302920.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003424781468675258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965752185313247, \"precision\": 1.0, \"recall\": 0.003424781468675258, \"specificity\": 1.0, \"npv\": 0.9997631662564311, \"accuracy\": 0.9997631664491878, \"f1\": 0.006826184746329532, \"f2\": 0.004277314618883461, \"f0_5\": 0.016892494929006085, \"p4\": 0.013559796850772073, \"phi\": 0.058514702125697655}, {\"truth_threshold\": 46.379998963326216, \"match_probability\": 0.9999999999999891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1040.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003421491572932054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996578508427068, \"precision\": 1.0, \"recall\": 0.003421491572932054, \"specificity\": 1.0, \"npv\": 0.9997631654747803, \"accuracy\": 0.9997631656673526, \"f1\": 0.006819649771640093, \"f2\": 0.004273209278780886, \"f0_5\": 0.01687648683471753, \"p4\": 0.013546903463581715, \"phi\": 0.05848659030581142}, {\"truth_threshold\": 46.39999896287918, \"match_probability\": 0.9999999999999892, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1033.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0033984623027296266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966015376972703, \"precision\": 1.0, \"recall\": 0.0033984623027296266, \"specificity\": 1.0, \"npv\": 0.999763160003225, \"accuracy\": 0.9997631601945054, \"f1\": 0.006773903748926209, \"f2\": 0.0042444717091374064, \"f0_5\": 0.016764418535961546, \"p4\": 0.013456642698415674, \"phi\": 0.05828942795163466}, {\"truth_threshold\": 46.419998962432146, \"match_probability\": 0.9999999999999893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1028.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003382012824013607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966179871759864, \"precision\": 1.0, \"recall\": 0.003382012824013607, \"specificity\": 1.0, \"npv\": 0.9997631560949711, \"accuracy\": 0.9997631562853289, \"f1\": 0.006741226732767411, \"f2\": 0.004223944671255481, \"f0_5\": 0.01668435727895661, \"p4\": 0.01339216316358666, \"phi\": 0.058148188405912606}, {\"truth_threshold\": 46.43999896198511, \"match_probability\": 0.9999999999999896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1022.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0033622734495543836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966377265504456, \"precision\": 1.0, \"recall\": 0.0033622734495543836, \"specificity\": 1.0, \"npv\": 0.9997631514050666, \"accuracy\": 0.9997631515943171, \"f1\": 0.006702012899079621, \"f2\": 0.00419931200312935, \"f0_5\": 0.016588270047946916, \"p4\": 0.013314779404647672, \"phi\": 0.05797824678111675}, {\"truth_threshold\": 46.459998961538076, \"match_probability\": 0.9999999999999897, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1018.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003349113866581568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966508861334185, \"precision\": 1.0, \"recall\": 0.003349113866581568, \"specificity\": 1.0, \"npv\": 0.9997631482784636, \"accuracy\": 0.9997631484669758, \"f1\": 0.0066758694860957635, \"f2\": 0.0041828900894267385, \"f0_5\": 0.016524203575590927, \"p4\": 0.01326318519058934, \"phi\": 0.057864675089355215}, {\"truth_threshold\": 46.47999896109104, \"match_probability\": 0.9999999999999898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1013.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302948.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0033326643878655486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966673356121345, \"precision\": 1.0, \"recall\": 0.0033326643878655486, \"specificity\": 1.0, \"npv\": 0.9997631443702099, \"accuracy\": 0.9997631445577992, \"f1\": 0.006643189255477516, \"f2\": 0.004162362545475763, \"f0_5\": 0.01644411112517978, \"p4\": 0.013198686750573606, \"phi\": 0.05772239623874845}, {\"truth_threshold\": 46.49999896064401, \"match_probability\": 0.9999999999999899, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1001.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003293185638947102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967068143610529, \"precision\": 1.0, \"recall\": 0.003293185638947102, \"specificity\": 1.0, \"npv\": 0.999763134990401, \"accuracy\": 0.9997631351757756, \"f1\": 0.006564752329798466, \"f2\": 0.004113095751718584, \"f0_5\": 0.016251846800772816, \"p4\": 0.013043864774183546, \"phi\": 0.05737948761098448}, {\"truth_threshold\": 46.51999896019697, \"match_probability\": 0.9999999999999901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 997.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302964.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003280026055974286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967199739440257, \"precision\": 1.0, \"recall\": 0.003280026055974286, \"specificity\": 1.0, \"npv\": 0.9997631318637981, \"accuracy\": 0.9997631320484344, \"f1\": 0.006538605316141895, \"f2\": 0.0040966732711997704, \"f0_5\": 0.016187745373422224, \"p4\": 0.012992249377933746, \"phi\": 0.05726472843134519}, {\"truth_threshold\": 46.53999895974994, \"match_probability\": 0.9999999999999902, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 978.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302983.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003217518036853412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967824819631466, \"precision\": 1.0, \"recall\": 0.003217518036853412, \"specificity\": 1.0, \"npv\": 0.9997631170124346, \"accuracy\": 0.9997631171935636, \"f1\": 0.006414397633625086, \"f2\": 0.00401866501427489, \"f0_5\": 0.015883172606886604, \"p4\": 0.012747021118551943, \"phi\": 0.056716451419039755}, {\"truth_threshold\": 46.5599989593029, \"match_probability\": 0.9999999999999903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 974.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302987.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0032043584538805963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967956415461194, \"precision\": 1.0, \"recall\": 0.0032043584538805963, \"specificity\": 1.0, \"npv\": 0.9997631138858318, \"accuracy\": 0.9997631140662223, \"f1\": 0.006388246675521013, \"f2\": 0.004002241912923707, \"f0_5\": 0.01581903286266026, \"p4\": 0.012695382507787924, \"phi\": 0.05660034793053886}, {\"truth_threshold\": 46.57999895885587, \"match_probability\": 0.9999999999999905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 969.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003187908975164577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968120910248355, \"precision\": 1.0, \"recall\": 0.003187908975164577, \"specificity\": 1.0, \"npv\": 0.9997631099775783, \"accuracy\": 0.9997631101570458, \"f1\": 0.00635555701308497, \"f2\": 0.003981712884395548, \"f0_5\": 0.015738848806348814, \"p4\": 0.012630828564566461, \"phi\": 0.05645488279445784}, {\"truth_threshold\": 46.59999895840883, \"match_probability\": 0.9999999999999907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 959.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303002.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003155010017732538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968449899822674, \"precision\": 1.0, \"recall\": 0.003155010017732538, \"specificity\": 1.0, \"npv\": 0.9997631021610714, \"accuracy\": 0.9997631023386928, \"f1\": 0.006290174471992654, \"f2\": 0.003940654321200721, \"f0_5\": 0.015578449432580565, \"p4\": 0.01250170174205134, \"phi\": 0.05616282224637165}, {\"truth_threshold\": 46.6199989579618, \"match_probability\": 0.9999999999999908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 949.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003122111060300499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968778889396995, \"precision\": 1.0, \"recall\": 0.003122111060300499, \"specificity\": 1.0, \"npv\": 0.9997630943445648, \"accuracy\": 0.9997630945203397, \"f1\": 0.006224787642255092, \"f2\": 0.003899595083140682, \"f0_5\": 0.015418008363741523, \"p4\": 0.012372549665267353, \"phi\": 0.055869234955683945}, {\"truth_threshold\": 46.63999895751476, \"match_probability\": 0.9999999999999909, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 948.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303013.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0031188211645572952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968811788354427, \"precision\": 1.0, \"recall\": 0.0031188211645572952, \"specificity\": 1.0, \"npv\": 0.9997630935629142, \"accuracy\": 0.9997630937385044, \"f1\": 0.006218248723389602, \"f2\": 0.003895489122216451, \"f0_5\": 0.015401961963002798, \"p4\": 0.01235963306831892, \"phi\": 0.055839791329725545}, {\"truth_threshold\": 46.65999895706773, \"match_probability\": 0.999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 947.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003115531268814091, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968844687311859, \"precision\": 1.0, \"recall\": 0.003115531268814091, \"specificity\": 1.0, \"npv\": 0.9997630927812634, \"accuracy\": 0.9997630929566691, \"f1\": 0.006211709761633017, \"f2\": 0.003891383154543385, \"f0_5\": 0.015385915145134509, \"p4\": 0.012346716218746293, \"phi\": 0.05581033217036349}, {\"truth_threshold\": 46.67999895662069, \"match_probability\": 0.9999999999999911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 944.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303017.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0031056615815844794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968943384184156, \"precision\": 1.0, \"recall\": 0.0031056615815844794, \"specificity\": 1.0, \"npv\": 0.9997630904363115, \"accuracy\": 0.9997630906111632, \"f1\": 0.006192092619012479, \"f2\": 0.0038790652110310096, \"f0_5\": 0.015337772188589607, \"p4\": 0.01230796415420913, \"phi\": 0.055721861245423436}, {\"truth_threshold\": 46.69999895617366, \"match_probability\": 0.9999999999999912, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 935.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303026.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0030760525198956445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969239474801044, \"precision\": 1.0, \"recall\": 0.0030760525198956445, \"specificity\": 1.0, \"npv\": 0.9997630834014556, \"accuracy\": 0.9997630835746454, \"f1\": 0.006133238874895046, \"f2\": 0.0038421110160513946, \"f0_5\": 0.015193320788687719, \"p4\": 0.012191694316489527, \"phi\": 0.05545560162865143}, {\"truth_threshold\": 46.71999895572662, \"match_probability\": 0.9999999999999913, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 934.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303027.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003072762624152441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969272373758475, \"precision\": 1.0, \"recall\": 0.003072762624152441, \"specificity\": 1.0, \"npv\": 0.999763082619805, \"accuracy\": 0.9997630827928101, \"f1\": 0.006126699355515833, \"f2\": 0.003838004960641958, \"f0_5\": 0.015177268546654663, \"p4\": 0.012178774182127818, \"phi\": 0.05542593827154905}, {\"truth_threshold\": 46.73999895527959, \"match_probability\": 0.9999999999999915, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 924.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303037.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003039863666720402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969601363332796, \"precision\": 1.0, \"recall\": 0.003039863666720402, \"specificity\": 1.0, \"npv\": 0.9997630748032985, \"accuracy\": 0.999763074974457, \"f1\": 0.006061301802318907, \"f2\": 0.003796944035346097, \"f0_5\": 0.01501672316898364, \"p4\": 0.012049558937248045, \"phi\": 0.05512842684516962}, {\"truth_threshold\": 46.759998954832554, \"match_probability\": 0.9999999999999916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 915.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0030102546050315665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969897453949684, \"precision\": 1.0, \"recall\": 0.0030102546050315665, \"specificity\": 1.0, \"npv\": 0.9997630677684429, \"accuracy\": 0.9997630679379393, \"f1\": 0.006002440336399061, \"f2\": 0.003759988625520748, \"f0_5\": 0.014872196631569367, \"p4\": 0.011933243602483542, \"phi\": 0.05485928707785439}, {\"truth_threshold\": 46.77999895438552, \"match_probability\": 0.9999999999999917, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 908.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0029872253348291393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970127746651709, \"precision\": 1.0, \"recall\": 0.0029872253348291393, \"specificity\": 1.0, \"npv\": 0.9997630622968886, \"accuracy\": 0.9997630624650922, \"f1\": 0.005956656793573633, \"f2\": 0.003731245151025024, \"f0_5\": 0.014759763713738609, \"p4\": 0.011842761959505899, \"phi\": 0.05464903977673925}, {\"truth_threshold\": 46.799998953938484, \"match_probability\": 0.9999999999999918, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 905.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303056.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0029773556475995275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970226443524005, \"precision\": 1.0, \"recall\": 0.0029773556475995275, \"specificity\": 1.0, \"npv\": 0.9997630599519367, \"accuracy\": 0.9997630601195863, \"f1\": 0.005937034631608641, \"f2\": 0.003718926417856107, \"f0_5\": 0.014711571911138855, \"p4\": 0.011803980318850691, \"phi\": 0.054558685768714074}, {\"truth_threshold\": 46.81999895349145, \"match_probability\": 0.9999999999999919, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 894.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002941166794424285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970588332055758, \"precision\": 1.0, \"recall\": 0.002941166794424285, \"specificity\": 1.0, \"npv\": 0.9997630513537801, \"accuracy\": 0.9997630515193979, \"f1\": 0.005865083400305063, \"f2\": 0.003673757209851258, \"f0_5\": 0.01453483645870253, \"p4\": 0.011661761491634285, \"phi\": 0.054226099702394594}, {\"truth_threshold\": 46.839998953044415, \"match_probability\": 0.999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 891.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303070.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002931297107194673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970687028928054, \"precision\": 1.0, \"recall\": 0.002931297107194673, \"specificity\": 1.0, \"npv\": 0.9997630490088283, \"accuracy\": 0.999763049173892, \"f1\": 0.005845459436054216, \"f2\": 0.003661438193197368, \"f0_5\": 0.01448662710348752, \"p4\": 0.011622969225651458, \"phi\": 0.0541350397934619}, {\"truth_threshold\": 46.85999895259738, \"match_probability\": 0.9999999999999921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 884.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303077.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002908267836992246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970917321630077, \"precision\": 1.0, \"recall\": 0.002908267836992246, \"specificity\": 1.0, \"npv\": 0.9997630435372742, \"accuracy\": 0.9997630437010449, \"f1\": 0.005799668684085355, \"f2\": 0.0036326935847617544, \"f0_5\": 0.014374123975193253, \"p4\": 0.01153244508136248, \"phi\": 0.05392196865965608}, {\"truth_threshold\": 46.879998952150345, \"match_probability\": 0.9999999999999922, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 875.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0028786587753034105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971213412246966, \"precision\": 1.0, \"recall\": 0.0028786587753034105, \"specificity\": 1.0, \"npv\": 0.9997630365024189, \"accuracy\": 0.999763036664527, \"f1\": 0.005740791770000918, \"f2\": 0.0035957357450652123, \"f0_5\": 0.014229446986772306, \"p4\": 0.011416038672354804, \"phi\": 0.05364677658771003}, {\"truth_threshold\": 46.89999895170331, \"match_probability\": 0.9999999999999923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 869.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303092.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0028589194008441874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971410805991558, \"precision\": 1.0, \"recall\": 0.0028589194008441874, \"specificity\": 1.0, \"npv\": 0.9997630318125156, \"accuracy\": 0.9997630319735152, \"f1\": 0.0057015385624774465, \"f2\": 0.0035710968815160188, \"f0_5\": 0.01413297683753094, \"p4\": 0.01133842300754742, \"phi\": 0.05346252825947913}, {\"truth_threshold\": 46.919998951256275, \"match_probability\": 0.9999999999999925, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 863.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303098.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002839180026384964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997160819973615, \"precision\": 1.0, \"recall\": 0.002839180026384964, \"specificity\": 1.0, \"npv\": 0.9997630271226121, \"accuracy\": 0.9997630272825034, \"f1\": 0.005662283809673779, \"f2\": 0.003546457774961433, \"f0_5\": 0.014036491625272842, \"p4\": 0.011260798227158371, \"phi\": 0.053277642756832715}, {\"truth_threshold\": 46.93999895080924, \"match_probability\": 0.9999999999999926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 859.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0028260204434121484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971739795565878, \"precision\": 1.0, \"recall\": 0.0028260204434121484, \"specificity\": 1.0, \"npv\": 0.9997630239960099, \"accuracy\": 0.9997630241551622, \"f1\": 0.005636113115937274, \"f2\": 0.0035300315689202706, \"f0_5\": 0.01397215978034919, \"p4\": 0.011209043308560563, \"phi\": 0.05315402848684448}, {\"truth_threshold\": 46.959998950362206, \"match_probability\": 0.9999999999999927, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 854.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303107.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002809570964696129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971904290353039, \"precision\": 1.0, \"recall\": 0.002809570964696129, \"specificity\": 1.0, \"npv\": 0.9997630200877572, \"accuracy\": 0.9997630202459856, \"f1\": 0.005603398782868297, \"f2\": 0.0035094986594865775, \"f0_5\": 0.013891735556011022, \"p4\": 0.011144343961345934, \"phi\": 0.052999105207687}, {\"truth_threshold\": 46.97999894991517, \"match_probability\": 0.9999999999999928, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 845.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0027799619030072936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972200380969927, \"precision\": 1.0, \"recall\": 0.0027799619030072936, \"specificity\": 1.0, \"npv\": 0.9997630130529023, \"accuracy\": 0.9997630132094679, \"f1\": 0.005544510278669055, \"f2\": 0.0034725389972293658, \"f0_5\": 0.013746945575110383, \"p4\": 0.011027869176439279, \"phi\": 0.052719096049940496}, {\"truth_threshold\": 46.999998949468136, \"match_probability\": 0.9999999999999929, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 839.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0027602225285480704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997239777471452, \"precision\": 1.0, \"recall\": 0.0027602225285480704, \"specificity\": 1.0, \"npv\": 0.9997630083629991, \"accuracy\": 0.9997630085184561, \"f1\": 0.005505249343832021, \"f2\": 0.003447898918617257, \"f0_5\": 0.013650400075492081, \"p4\": 0.010950207917659723, \"phi\": 0.052531594101954904}, {\"truth_threshold\": 47.0199989490211, \"match_probability\": 0.999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 830.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002730613466859235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972693865331408, \"precision\": 1.0, \"recall\": 0.002730613466859235, \"specificity\": 1.0, \"npv\": 0.9997630013281443, \"accuracy\": 0.9997630014819383, \"f1\": 0.005446355043291961, \"f2\": 0.0034109383450291533, \"f0_5\": 0.013505553548706233, \"p4\": 0.010833698922208913, \"phi\": 0.05224907956217256}, {\"truth_threshold\": 47.039998948574066, \"match_probability\": 0.9999999999999931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 817.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303144.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0026878448221975848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973121551778024, \"precision\": 1.0, \"recall\": 0.0026878448221975848, \"specificity\": 1.0, \"npv\": 0.9997629911666878, \"accuracy\": 0.9997629913180793, \"f1\": 0.005361279357433936, \"f2\": 0.003357549884478914, \"f0_5\": 0.013296270859847215, \"p4\": 0.010665371898973106, \"phi\": 0.05183828487934521}, {\"truth_threshold\": 47.05999894812703, \"match_probability\": 0.9999999999999932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 814.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002677975134967973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973220248650321, \"precision\": 1.0, \"recall\": 0.002677975134967973, \"specificity\": 1.0, \"npv\": 0.9997629888217362, \"accuracy\": 0.9997629889725734, \"f1\": 0.0053416454761709455, \"f2\": 0.0033452293084827453, \"f0_5\": 0.013247964793614937, \"p4\": 0.01062652111555724, \"phi\": 0.051743022958905996}, {\"truth_threshold\": 47.07999894768, \"match_probability\": 0.9999999999999932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 810.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303151.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002664815551995157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973351844480048, \"precision\": 1.0, \"recall\": 0.002664815551995157, \"specificity\": 1.0, \"npv\": 0.9997629856951342, \"accuracy\": 0.9997629858452323, \"f1\": 0.005315466366550624, \"f2\": 0.0033288017793061957, \"f0_5\": 0.013183550834795459, \"p4\": 0.010574716520288952, \"phi\": 0.05161573357600864}, {\"truth_threshold\": 47.09999894723296, \"match_probability\": 0.9999999999999933, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 803.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303158.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00264178628179273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973582137182073, \"precision\": 1.0, \"recall\": 0.00264178628179273, \"specificity\": 1.0, \"npv\": 0.9997629802235808, \"accuracy\": 0.9997629803723851, \"f1\": 0.005269651271147511, \"f2\": 0.0033000533433280156, \"f0_5\": 0.013070810260016342, \"p4\": 0.010484048712767743, \"phi\": 0.051392218537429105}, {\"truth_threshold\": 47.11999894678593, \"match_probability\": 0.9999999999999934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 796.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303165.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0026187570115903027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973812429884097, \"precision\": 1.0, \"recall\": 0.0026187570115903027, \"specificity\": 1.0, \"npv\": 0.9997629747520275, \"accuracy\": 0.9997629748995379, \"f1\": 0.005223834071079582, \"f2\": 0.0032713045765386637, \"f0_5\": 0.012958049129889791, \"p4\": 0.010393368473853248, \"phi\": 0.05116772713400753}, {\"truth_threshold\": 47.13999894633889, \"match_probability\": 0.9999999999999936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 795.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303166.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0026154671158470986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973845328841529, \"precision\": 1.0, \"recall\": 0.0026154671158470986, \"specificity\": 1.0, \"npv\": 0.999762973970377, \"accuracy\": 0.9997629741177027, \"f1\": 0.005217288584966334, \"f2\": 0.0032671975828491443, \"f0_5\": 0.012941938718699229, \"p4\": 0.010380413139051622, \"phi\": 0.05113557648116446}, {\"truth_threshold\": 47.15999894589186, \"match_probability\": 0.9999999999999937, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 790.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303171.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002599017637131079, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974009823628689, \"precision\": 1.0, \"recall\": 0.002599017637131079, \"specificity\": 1.0, \"npv\": 0.9997629700621246, \"accuracy\": 0.9997629702085261, \"f1\": 0.005184560510055751, \"f2\": 0.0032466625131304895, \"f0_5\": 0.012861380367998282, \"p4\": 0.010315632658471255, \"phi\": 0.05097451904767727}, {\"truth_threshold\": 47.17999894544482, \"match_probability\": 0.9999999999999938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 783.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002575988366928652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974240116330714, \"precision\": 1.0, \"recall\": 0.002575988366928652, \"specificity\": 1.0, \"npv\": 0.9997629645905713, \"accuracy\": 0.9997629647356789, \"f1\": 0.0051387394009398055, \"f2\": 0.0032179131319623844, \"f0_5\": 0.012748581048737679, \"p4\": 0.010224929325899289, \"phi\": 0.0507481799325987}, {\"truth_threshold\": 47.19999894499779, \"match_probability\": 0.9999999999999938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 780.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00256611867969904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997433881320301, \"precision\": 1.0, \"recall\": 0.00256611867969904, \"specificity\": 1.0, \"npv\": 0.9997629622456199, \"accuracy\": 0.999762962390173, \"f1\": 0.005119101138343708, \"f2\": 0.003205591867331238, \"f0_5\": 0.012700232186296123, \"p4\": 0.010186052661466416, \"phi\": 0.05065086783747868}, {\"truth_threshold\": 47.21999894455075, \"match_probability\": 0.9999999999999939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 778.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303183.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025595388882126324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974404611117874, \"precision\": 1.0, \"recall\": 0.0025595388882126324, \"specificity\": 1.0, \"npv\": 0.9997629606823191, \"accuracy\": 0.9997629608265024, \"f1\": 0.0051060087484700025, \"f2\": 0.0031973776571523446, \"f0_5\": 0.012667997511992263, \"p4\": 0.010160133615823203, \"phi\": 0.05058588910813956}, {\"truth_threshold\": 47.23999894410372, \"match_probability\": 0.999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 772.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025397995137534093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974602004862466, \"precision\": 1.0, \"recall\": 0.0025397995137534093, \"specificity\": 1.0, \"npv\": 0.9997629559924163, \"accuracy\": 0.9997629561354906, \"f1\": 0.005066730547725386, \"f2\": 0.0031727348645751823, \"f0_5\": 0.012571283410791112, \"p4\": 0.010082370385334796, \"phi\": 0.05039045018153945}, {\"truth_threshold\": 47.25999894365668, \"match_probability\": 0.9999999999999941, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 771.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303190.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025365096180102052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974634903819898, \"precision\": 1.0, \"recall\": 0.0025365096180102052, \"specificity\": 1.0, \"npv\": 0.9997629552107659, \"accuracy\": 0.9997629553536553, \"f1\": 0.0050601840305579985, \"f2\": 0.00316862770884791, \"f0_5\": 0.012555162924001368, \"p4\": 0.010069408958197726, \"phi\": 0.05035780328432142}, {\"truth_threshold\": 47.27999894320965, \"match_probability\": 0.9999999999999941, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 767.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303194.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00252335003503739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974766499649627, \"precision\": 1.0, \"recall\": 0.00252335003503739, \"specificity\": 1.0, \"npv\": 0.9997629520841641, \"accuracy\": 0.9997629522263141, \"f1\": 0.00503399753222546, \"f2\": 0.0031521990184208426, \"f0_5\": 0.012490676776460855, \"p4\": 0.010017560710169144, \"phi\": 0.050227003495835386}, {\"truth_threshold\": 47.31999894231558, \"match_probability\": 0.9999999999999943, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 765.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303196.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025167702435509817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997483229756449, \"precision\": 1.0, \"recall\": 0.0025167702435509817, \"specificity\": 1.0, \"npv\": 0.9997629505208632, \"accuracy\": 0.9997629506626434, \"f1\": 0.005020904025255475, \"f2\": 0.0031439846326962893, \"f0_5\": 0.012458431182231835, \"p4\": 0.00999163506236218, \"phi\": 0.05016147570073713}, {\"truth_threshold\": 47.339998941868544, \"match_probability\": 0.9999999999999943, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 734.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303227.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002414783475511661, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9975852165244884, \"precision\": 1.0, \"recall\": 0.002414783475511661, \"specificity\": 1.0, \"npv\": 0.9997629262897002, \"accuracy\": 0.9997629264257489, \"f1\": 0.004817932686785146, \"f2\": 0.0030166582002962407, \"f0_5\": 0.011958409498952417, \"p4\": 0.009589657570927293, \"phi\": 0.04913462113249222}, {\"truth_threshold\": 47.35999894142151, \"match_probability\": 0.9999999999999944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 728.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303233.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0023950441010524375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976049558989476, \"precision\": 1.0, \"recall\": 0.0023950441010524375, \"specificity\": 1.0, \"npv\": 0.9997629215997977, \"accuracy\": 0.9997629217347371, \"f1\": 0.004778643141038896, \"f2\": 0.0029920136251697393, \"f0_5\": 0.011861584433951505, \"p4\": 0.009511827264646432, \"phi\": 0.04893338622891886}, {\"truth_threshold\": 47.379998940974474, \"match_probability\": 0.9999999999999946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 726.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303235.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00238846430956603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976115356904339, \"precision\": 1.0, \"recall\": 0.00238846430956603, \"specificity\": 1.0, \"npv\": 0.999762920036497, \"accuracy\": 0.9997629201710665, \"f1\": 0.0047655462819221036, \"f2\": 0.0029837987127744395, \"f0_5\": 0.011829306046632885, \"p4\": 0.00948588179520526, \"phi\": 0.04886612377235062}, {\"truth_threshold\": 47.39999894052744, \"match_probability\": 0.9999999999999946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 712.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303249.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0023424057691611754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976575942308388, \"precision\": 1.0, \"recall\": 0.0023424057691611754, \"specificity\": 1.0, \"npv\": 0.9997629090933916, \"accuracy\": 0.9997629092253723, \"f1\": 0.004673863453604356, \"f2\": 0.0029262935697164784, \"f0_5\": 0.011603310202764587, \"p4\": 0.009304235026777366, \"phi\": 0.04839266892881318}, {\"truth_threshold\": 47.419998940080404, \"match_probability\": 0.9999999999999947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 709.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303252.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0023325360819315636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976674639180685, \"precision\": 1.0, \"recall\": 0.0023325360819315636, \"specificity\": 1.0, \"npv\": 0.9997629067484405, \"accuracy\": 0.9997629068798664, \"f1\": 0.004654216037023665, \"f2\": 0.002913970866867288, \"f0_5\": 0.011554871788185673, \"p4\": 0.009265304233230957, \"phi\": 0.04829061040582857}, {\"truth_threshold\": 47.43999893963337, \"match_probability\": 0.9999999999999948, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 707.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002325956290445156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976740437095548, \"precision\": 1.0, \"recall\": 0.002325956290445156, \"specificity\": 1.0, \"npv\": 0.9997629051851398, \"accuracy\": 0.9997629053161957, \"f1\": 0.004641117544343351, \"f2\": 0.002905755697870455, \"f0_5\": 0.011522577406621489, \"p4\": 0.00923934909885999, \"phi\": 0.048222451392158604}, {\"truth_threshold\": 47.459998939186335, \"match_probability\": 0.9999999999999948, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 688.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303273.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0022634482713242816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977365517286757, \"precision\": 1.0, \"recall\": 0.0022634482713242816, \"specificity\": 1.0, \"npv\": 0.999762890333783, \"accuracy\": 0.9997628904613249, \"f1\": 0.004516673286306536, \"f2\": 0.0028277102451887827, \"f0_5\": 0.011215696758859259, \"p4\": 0.00899272455732662, \"phi\": 0.047570070273861995}, {\"truth_threshold\": 47.499998938292265, \"match_probability\": 0.999999999999995, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 683.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303278.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002246998792608262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977530012073917, \"precision\": 1.0, \"recall\": 0.002246998792608262, \"specificity\": 1.0, \"npv\": 0.9997628864255312, \"accuracy\": 0.9997628865521484, \"f1\": 0.0044839222174078595, \"f2\": 0.0028071715629821616, \"f0_5\": 0.011134913415043707, \"p4\": 0.008927808090622278, \"phi\": 0.04739689861892569}, {\"truth_threshold\": 47.51999893784523, \"match_probability\": 0.999999999999995, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 669.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303292.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0022009402522034077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977990597477966, \"precision\": 1.0, \"recall\": 0.0022009402522034077, \"specificity\": 1.0, \"npv\": 0.9997628754824266, \"accuracy\": 0.9997628756064542, \"f1\": 0.004392213504907593, \"f2\": 0.0027496623546151996, \"f0_5\": 0.010908663990320804, \"p4\": 0.008746008119269138, \"phi\": 0.046908617068806197}, {\"truth_threshold\": 47.539998937398195, \"match_probability\": 0.9999999999999951, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 660.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303301.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0021713311905145727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978286688094854, \"precision\": 1.0, \"recall\": 0.0021713311905145727, \"specificity\": 1.0, \"npv\": 0.9997628684475738, \"accuracy\": 0.9997628685699363, \"f1\": 0.004333253452650999, \"f2\": 0.002712691450254171, \"f0_5\": 0.01076317428840741, \"p4\": 0.008629110348613016, \"phi\": 0.04659201969627991}, {\"truth_threshold\": 47.55999893695116, \"match_probability\": 0.9999999999999952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 654.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303307.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002151591816055349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978484081839446, \"precision\": 1.0, \"recall\": 0.002151591816055349, \"specificity\": 1.0, \"npv\": 0.999762863757672, \"accuracy\": 0.9997628638789245, \"f1\": 0.004293944815586888, \"f2\": 0.0026880438767675737, \"f0_5\": 0.01066616217133053, \"p4\": 0.00855116703716204, \"phi\": 0.04637975415692785}, {\"truth_threshold\": 47.579998936504126, \"match_probability\": 0.9999999999999952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 647.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002128562545852922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978714374541471, \"precision\": 1.0, \"recall\": 0.002128562545852922, \"specificity\": 1.0, \"npv\": 0.9997628582861199, \"accuracy\": 0.9997628584060774, \"f1\": 0.004248082781804811, \"f2\": 0.002659288067071602, \"f0_5\": 0.01055296216918013, \"p4\": 0.008460221579572798, \"phi\": 0.046130876589142514}, {\"truth_threshold\": 47.59999893605709, \"match_probability\": 0.9999999999999953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 645.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303316.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0021219827543665143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978780172456335, \"precision\": 1.0, \"recall\": 0.0021219827543665143, \"specificity\": 1.0, \"npv\": 0.9997628567228193, \"accuracy\": 0.9997628568424067, \"f1\": 0.004234978956422395, \"f2\": 0.002651072060659817, \"f0_5\": 0.010520615513096127, \"p4\": 0.008434234869417192, \"phi\": 0.046059521712909945}, {\"truth_threshold\": 47.619998935610056, \"match_probability\": 0.9999999999999953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 638.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303323.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002098953484164087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979010465158359, \"precision\": 1.0, \"recall\": 0.002098953484164087, \"specificity\": 1.0, \"npv\": 0.9997628512512673, \"accuracy\": 0.9997628513695597, \"f1\": 0.004189114212456377, \"f2\": 0.0026223158254704963, \"f0_5\": 0.01040738891988268, \"p4\": 0.008343273354657243, \"phi\": 0.045808904374277155}, {\"truth_threshold\": 47.63999893516302, \"match_probability\": 0.9999999999999954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 632.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0020792141097048635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979207858902951, \"precision\": 1.0, \"recall\": 0.0020792141097048635, \"specificity\": 1.0, \"npv\": 0.9997628465613656, \"accuracy\": 0.9997628466785478, \"f1\": 0.004149799896911616, \"f2\": 0.002597667360474025, \"f0_5\": 0.010310321088195662, \"p4\": 0.008265296399609863, \"phi\": 0.04559299306833332}, {\"truth_threshold\": 47.659998934715986, \"match_probability\": 0.9999999999999954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 628.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303333.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002066054526732048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997933945473268, \"precision\": 1.0, \"recall\": 0.002066054526732048, \"specificity\": 1.0, \"npv\": 0.9997628434347645, \"accuracy\": 0.9997628435512066, \"f1\": 0.004123589492726264, \"f2\": 0.0025812349153946823, \"f0_5\": 0.010245600754389456, \"p4\": 0.0082133066633967, \"phi\": 0.04544848235460562}, {\"truth_threshold\": 47.67999893426895, \"match_probability\": 0.9999999999999956, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 624.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002052894943759232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979471050562407, \"precision\": 1.0, \"recall\": 0.002052894943759232, \"specificity\": 1.0, \"npv\": 0.9997628403081634, \"accuracy\": 0.9997628404238653, \"f1\": 0.004097378400118193, \"f2\": 0.00256480236224874, \"f0_5\": 0.01018087366253667, \"p4\": 0.008161312847011298, \"phi\": 0.045303510678831475}, {\"truth_threshold\": 47.69999893382192, \"match_probability\": 0.9999999999999957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 618.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303343.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002033155569300009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979668444306999, \"precision\": 1.0, \"recall\": 0.002033155569300009, \"specificity\": 1.0, \"npv\": 0.9997628356182618, \"accuracy\": 0.9997628357328535, \"f1\": 0.004058060470354161, \"f2\": 0.0025401533299026194, \"f0_5\": 0.010083770351104483, \"p4\": 0.008083314471059458, \"phi\": 0.045085179130357665}, {\"truth_threshold\": 47.71999893337488, \"match_probability\": 0.9999999999999957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 613.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303348.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0020167060905839896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997983293909416, \"precision\": 1.0, \"recall\": 0.0020167060905839896, \"specificity\": 1.0, \"npv\": 0.9997628317100106, \"accuracy\": 0.999762831823677, \"f1\": 0.004025294345544925, \"f2\": 0.002519612283870289, \"f0_5\": 0.010002839305120866, \"p4\": 0.008018308809641446, \"phi\": 0.04490242523348905}, {\"truth_threshold\": 47.73999893292785, \"match_probability\": 0.9999999999999958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 612.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0020134161948407855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979865838051593, \"precision\": 1.0, \"recall\": 0.0020134161948407855, \"specificity\": 1.0, \"npv\": 0.9997628309283603, \"accuracy\": 0.9997628310418417, \"f1\": 0.004018740991486441, \"f2\": 0.0025155040544006524, \"f0_5\": 0.009986651828112099, \"p4\": 0.008005306912017765, \"phi\": 0.04486578512397873}, {\"truth_threshold\": 47.79999893158674, \"match_probability\": 0.9999999999999959, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 598.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001967357654435931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980326423455641, \"precision\": 1.0, \"recall\": 0.001967357654435931, \"specificity\": 1.0, \"npv\": 0.9997628199852568, \"accuracy\": 0.9997628200961474, \"f1\": 0.0039269895159886915, \"f2\": 0.0024579881326031163, \"f0_5\": 0.009759982764980267, \"p4\": 0.00782325355312641, \"phi\": 0.044349645280638346}, {\"truth_threshold\": 47.81999893113971, \"match_probability\": 0.999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 590.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303371.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0019410384884902998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980589615115097, \"precision\": 1.0, \"recall\": 0.0019410384884902998, \"specificity\": 1.0, \"npv\": 0.999762813732055, \"accuracy\": 0.9997628138414649, \"f1\": 0.0038745563140492067, \"f2\": 0.0024251212971686093, \"f0_5\": 0.009630420376010786, \"p4\": 0.00771920060288155, \"phi\": 0.04405199315371868}, {\"truth_threshold\": 47.83999893069267, \"match_probability\": 0.999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 586.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303375.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0019278789055174842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980721210944825, \"precision\": 1.0, \"recall\": 0.0019278789055174842, \"specificity\": 1.0, \"npv\": 0.9997628106054541, \"accuracy\": 0.9997628107141238, \"f1\": 0.0038483386800723697, \"f2\": 0.0024086877173367972, \"f0_5\": 0.00956562902988851, \"p4\": 0.0076671680008916785, \"phi\": 0.0439024103334558}, {\"truth_threshold\": 47.85999893024564, \"match_probability\": 0.9999999999999961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 571.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018785304693694257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981214695306305, \"precision\": 1.0, \"recall\": 0.0018785304693694257, \"specificity\": 1.0, \"npv\": 0.999762798880701, \"accuracy\": 0.9997627989865941, \"f1\": 0.0037500164186358084, \"f2\": 0.0023470608303909437, \"f0_5\": 0.009322601185325475, \"p4\": 0.007472009355513394, \"phi\": 0.04333687667379196}, {\"truth_threshold\": 47.8799989297986, \"match_probability\": 0.9999999999999961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 568.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001868660782139814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981313392178602, \"precision\": 1.0, \"recall\": 0.001868660782139814, \"specificity\": 1.0, \"npv\": 0.9997627965357503, \"accuracy\": 0.9997627966410882, \"f1\": 0.003730350804028516, \"f2\": 0.002334735270615548, \"f0_5\": 0.009273984188510056, \"p4\": 0.007432970730396335, \"phi\": 0.04322288201090694}, {\"truth_threshold\": 47.89999892935157, \"match_probability\": 0.9999999999999962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 566.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018620809906534062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981379190093466, \"precision\": 1.0, \"recall\": 0.0018620809906534062, \"specificity\": 1.0, \"npv\": 0.9997627949724499, \"accuracy\": 0.9997627950774176, \"f1\": 0.0037172401790317444, \"f2\": 0.002326518196989502, \"f0_5\": 0.00924157074046861, \"p4\": 0.007406943703022885, \"phi\": 0.04314671824925643}, {\"truth_threshold\": 47.91999892890453, \"match_probability\": 0.9999999999999962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 564.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018555011991669985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998144498800833, \"precision\": 1.0, \"recall\": 0.0018555011991669985, \"specificity\": 1.0, \"npv\": 0.9997627934091495, \"accuracy\": 0.999762793513747, \"f1\": 0.003704129381824152, \"f2\": 0.0023183010963426743, \"f0_5\": 0.009209155598807382, \"p4\": 0.007380915653742894, \"phi\": 0.04307041980354063}, {\"truth_threshold\": 47.9399989284575, \"match_probability\": 0.9999999999999963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 555.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018258921374781634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981741078625218, \"precision\": 1.0, \"recall\": 0.0018258921374781634, \"specificity\": 1.0, \"npv\": 0.9997627863742978, \"accuracy\": 0.9997627864772293, \"f1\": 0.0036451286631901114, \"f2\": 0.0022813238090462094, \"f0_5\": 0.009063266499227582, \"p4\": 0.007263776784275582, \"phi\": 0.04272539070604377}, {\"truth_threshold\": 47.97999892756343, \"match_probability\": 0.9999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 552.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018160224502485516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981839775497514, \"precision\": 1.0, \"recall\": 0.0018160224502485516, \"specificity\": 1.0, \"npv\": 0.9997627840293473, \"accuracy\": 0.9997627841317234, \"f1\": 0.0036254609819613612, \"f2\": 0.0022689979250178397, \"f0_5\": 0.009014629175390062, \"p4\": 0.0072247258946547205, \"phi\": 0.04260976015797659}, {\"truth_threshold\": 47.999998927116394, \"match_probability\": 0.9999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 551.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018127325545053477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981872674454947, \"precision\": 1.0, \"recall\": 0.0018127325545053477, \"specificity\": 1.0, \"npv\": 0.9997627832476972, \"accuracy\": 0.999762783349888, \"f1\": 0.0036189050021017233, \"f2\": 0.002264889283497548, \"f0_5\": 0.008998415886858393, \"p4\": 0.007211708420293825, \"phi\": 0.042571146848258315}, {\"truth_threshold\": 48.01999892666936, \"match_probability\": 0.9999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 548.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001802862867275736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981971371327243, \"precision\": 1.0, \"recall\": 0.001802862867275736, \"specificity\": 1.0, \"npv\": 0.9997627809027466, \"accuracy\": 0.9997627810043821, \"f1\": 0.0035992368041667076, \"f2\": 0.0022525633184039356, \"f0_5\": 0.008949773479273435, \"p4\": 0.007172654463643928, \"phi\": 0.042455096204977436}, {\"truth_threshold\": 48.039998926222324, \"match_probability\": 0.9999999999999966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 541.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303420.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017798335970733087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982201664029267, \"precision\": 1.0, \"recall\": 0.0017798335970733087, \"specificity\": 1.0, \"npv\": 0.9997627754311954, \"accuracy\": 0.9997627755315349, \"f1\": 0.0035533428351866327, \"f2\": 0.0022238024967423963, \"f0_5\": 0.00883625969783585, \"p4\": 0.007081519618019284, \"phi\": 0.04218306978890582}, {\"truth_threshold\": 48.05999892577529, \"match_probability\": 0.9999999999999966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 540.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303421.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017765437013301049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982234562986699, \"precision\": 1.0, \"recall\": 0.0017765437013301049, \"specificity\": 1.0, \"npv\": 0.9997627746495452, \"accuracy\": 0.9997627747496997, \"f1\": 0.003546786381653919, \"f2\": 0.0022196937809112914, \"f0_5\": 0.008820041748197609, \"p4\": 0.007068499331759631, \"phi\": 0.04214406553867292}, {\"truth_threshold\": 48.079998925328255, \"match_probability\": 0.9999999999999967, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 539.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303422.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001773253805586901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982267461944131, \"precision\": 1.0, \"recall\": 0.001773253805586901, \"specificity\": 1.0, \"npv\": 0.999762773867895, \"accuracy\": 0.9997627739678644, \"f1\": 0.003540229885057471, \"f2\": 0.0022155850583245574, \"f0_5\": 0.008803823374722736, \"p4\": 0.00705547878982764, \"phi\": 0.042105025156688375}, {\"truth_threshold\": 48.09999892488122, \"match_probability\": 0.9999999999999967, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 531.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017469346396412698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982530653603587, \"precision\": 1.0, \"recall\": 0.0017469346396412698, \"specificity\": 1.0, \"npv\": 0.9997627676146938, \"accuracy\": 0.999762767713182, \"f1\": 0.0034877763619405437, \"f2\": 0.002182715034426061, \"f0_5\": 0.00867406112681118, \"p4\": 0.006951305249263753, \"phi\": 0.04179138918688554}, {\"truth_threshold\": 48.119998924434185, \"match_probability\": 0.9999999999999968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 522.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303439.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017173255779524346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982826744220475, \"precision\": 1.0, \"recall\": 0.0017173255779524346, \"specificity\": 1.0, \"npv\": 0.9997627605798425, \"accuracy\": 0.9997627606766641, \"f1\": 0.003428762853755382, \"f2\": 0.002145735740722776, \"f0_5\": 0.0085280461625426, \"p4\": 0.006834090451817344, \"phi\": 0.0414357111756043}, {\"truth_threshold\": 48.13999892398715, \"match_probability\": 0.9999999999999968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 518.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303443.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017041659949796192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982958340050204, \"precision\": 1.0, \"recall\": 0.0017041659949796192, \"specificity\": 1.0, \"npv\": 0.999762757453242, \"accuracy\": 0.999762757549323, \"f1\": 0.003402533508058027, \"f2\": 0.0021293003234234545, \"f0_5\": 0.008463139596056634, \"p4\": 0.006781988335605648, \"phi\": 0.04127664829293764}, {\"truth_threshold\": 48.159998923540115, \"match_probability\": 0.9999999999999968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 510.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303451.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001677846829033988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983221531709661, \"precision\": 1.0, \"recall\": 0.001677846829033988, \"specificity\": 1.0, \"npv\": 0.9997627512000409, \"accuracy\": 0.9997627512946405, \"f1\": 0.0033500727491288167, \"f2\": 0.002096429164535982, \"f0_5\": 0.008333306100306862, \"p4\": 0.006677771822471532, \"phi\": 0.04095666932121415}, {\"truth_threshold\": 48.17999892309308, \"match_probability\": 0.9999999999999969, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 503.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303458.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0016548175588315607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983451824411684, \"precision\": 1.0, \"recall\": 0.0016548175588315607, \"specificity\": 1.0, \"npv\": 0.99976274572849, \"accuracy\": 0.9997627458217934, \"f1\": 0.0033041673235587785, \"f2\": 0.0020676665458129956, \"f0_5\": 0.008219679514205502, \"p4\": 0.006586568938945177, \"phi\": 0.04067462287836432}, {\"truth_threshold\": 48.199998922646046, \"match_probability\": 0.9999999999999969, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 500.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001644947871601949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998355052128398, \"precision\": 1.0, \"recall\": 0.001644947871601949, \"specificity\": 1.0, \"npv\": 0.9997627433835397, \"accuracy\": 0.9997627434762875, \"f1\": 0.0032844929235599962, \"f2\": 0.002055339607874088, \"f0_5\": 0.008170976039429862, \"p4\": 0.006547478149745529, \"phi\": 0.04055314533837886}, {\"truth_threshold\": 48.21999892219901, \"match_probability\": 0.999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 495.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303466.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0016284983928859294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983715016071141, \"precision\": 1.0, \"recall\": 0.0016284983928859294, \"specificity\": 1.0, \"npv\": 0.999762739475289, \"accuracy\": 0.9997627395671109, \"f1\": 0.0032517013952755077, \"f2\": 0.00203479457618312, \"f0_5\": 0.008089795091210397, \"p4\": 0.006482321714836004, \"phi\": 0.04034987006797844}, {\"truth_threshold\": 48.239998921751976, \"match_probability\": 0.999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 487.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303474.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0016021792269402982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983978207730597, \"precision\": 1.0, \"recall\": 0.0016021792269402982, \"specificity\": 1.0, \"npv\": 0.9997627332220882, \"accuracy\": 0.9997627333124285, \"f1\": 0.0031992327096909815, \"f2\": 0.0020019221741450315, \"f0_5\": 0.007959883494764782, \"p4\": 0.006378058105988982, \"phi\": 0.04002248221984095}, {\"truth_threshold\": 48.279998920857906, \"match_probability\": 0.9999999999999971, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 482.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303479.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015857297482242787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984142702517758, \"precision\": 1.0, \"recall\": 0.0015857297482242787, \"specificity\": 1.0, \"npv\": 0.9997627293138378, \"accuracy\": 0.999762729403252, \"f1\": 0.003166438380912026, \"f2\": 0.001981376703285139, \"f0_5\": 0.007878674944179098, \"p4\": 0.00631288502836838, \"phi\": 0.039816497849997426}, {\"truth_threshold\": 48.29999892041087, \"match_probability\": 0.9999999999999971, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 481.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303480.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015824398524810748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984175601475189, \"precision\": 1.0, \"recall\": 0.0015824398524810748, \"specificity\": 1.0, \"npv\": 0.9997627285321876, \"accuracy\": 0.9997627286214167, \"f1\": 0.0031598793858928793, \"f2\": 0.0019772675888434423, \"f0_5\": 0.007862431959723425, \"p4\": 0.00629984964454557, \"phi\": 0.039775172968254356}, {\"truth_threshold\": 48.31999891996384, \"match_probability\": 0.9999999999999971, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 474.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303487.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015594105822786476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984405894177214, \"precision\": 1.0, \"recall\": 0.0015594105822786476, \"specificity\": 1.0, \"npv\": 0.9997627230606371, \"accuracy\": 0.9997627231485695, \"f1\": 0.0031139652142493472, \"f2\": 0.0019485035985655067, \"f0_5\": 0.007748719172685274, \"p4\": 0.006208594786082254, \"phi\": 0.03948468779297203}, {\"truth_threshold\": 48.3399989195168, \"match_probability\": 0.9999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 463.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303498.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015232217291034048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984767782708966, \"precision\": 1.0, \"recall\": 0.0015232217291034048, \"specificity\": 1.0, \"npv\": 0.9997627144624862, \"accuracy\": 0.9997627145483812, \"f1\": 0.0030418101069560875, \"f2\": 0.001903302373496165, \"f0_5\": 0.0075699855794227194, \"p4\": 0.006065168932382377, \"phi\": 0.03902384259163443}, {\"truth_threshold\": 48.35999891906977, \"match_probability\": 0.9999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 452.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001487032875928162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985129671240719, \"precision\": 1.0, \"recall\": 0.001487032875928162, \"specificity\": 1.0, \"npv\": 0.9997627058643355, \"accuracy\": 0.9997627059481927, \"f1\": 0.0029696497849960417, \"f2\": 0.0018581003308405192, \"f0_5\": 0.007391200546818023, \"p4\": 0.005921712072057817, \"phi\": 0.03855748969716732}, {\"truth_threshold\": 48.37999891862273, \"match_probability\": 0.9999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 451.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014837429801849579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985162570198151, \"precision\": 1.0, \"recall\": 0.0014837429801849579, \"specificity\": 1.0, \"npv\": 0.9997627050826854, \"accuracy\": 0.9997627051663575, \"f1\": 0.002963089497128891, \"f2\": 0.001853991013693224, \"f0_5\": 0.007374944810557127, \"p4\": 0.005908669001434949, \"phi\": 0.038514813974848155}, {\"truth_threshold\": 48.3999989181757, \"match_probability\": 0.9999999999999973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 444.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303517.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014607137099825307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985392862900174, \"precision\": 1.0, \"recall\": 0.0014607137099825307, \"specificity\": 1.0, \"npv\": 0.9997626996111351, \"accuracy\": 0.9997626996935103, \"f1\": 0.002917166275192589, \"f2\": 0.001825225604462101, \"f0_5\": 0.007261142746870676, \"p4\": 0.005817360329026374, \"phi\": 0.038214749535370914}, {\"truth_threshold\": 48.41999891772866, \"match_probability\": 0.9999999999999973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 443.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014574238142393268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985425761857607, \"precision\": 1.0, \"recall\": 0.0014574238142393268, \"specificity\": 1.0, \"npv\": 0.999762698829485, \"accuracy\": 0.999762698911675, \"f1\": 0.0029106056425014125, \"f2\": 0.0018211162332574466, \"f0_5\": 0.007244883607592245, \"p4\": 0.005804315207441807, \"phi\": 0.03817169063405852}, {\"truth_threshold\": 48.43999891728163, \"match_probability\": 0.9999999999999973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 442.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303519.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001454133918496123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985458660815039, \"precision\": 1.0, \"recall\": 0.001454133918496123, \"specificity\": 1.0, \"npv\": 0.999762698047835, \"accuracy\": 0.9997626981298398, \"f1\": 0.0029040449667053214, \"f2\": 0.0018170068552955472, \"f0_5\": 0.007228624042861488, \"p4\": 0.005791269829453013, \"phi\": 0.03812858310609711}, {\"truth_threshold\": 48.45999891683459, \"match_probability\": 0.9999999999999974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 441.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303520.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014508440227529189, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998549155977247, \"precision\": 1.0, \"recall\": 0.0014508440227529189, \"specificity\": 1.0, \"npv\": 0.9997626972661849, \"accuracy\": 0.9997626973480044, \"f1\": 0.0028974842478038908, \"f2\": 0.0018128974705763864, \"f0_5\": 0.0072123640526617055, \"p4\": 0.005778224195052433, \"phi\": 0.038085426786370405}, {\"truth_threshold\": 48.47999891638756, \"match_probability\": 0.9999999999999974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 440.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001447554127009715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985524458729903, \"precision\": 1.0, \"recall\": 0.001447554127009715, \"specificity\": 1.0, \"npv\": 0.9997626964845349, \"accuracy\": 0.9997626965661691, \"f1\": 0.002890923485796696, \"f2\": 0.001808788079099947, \"f0_5\": 0.007196103636976197, \"p4\": 0.005765178304232506, \"phi\": 0.03804222150882555}, {\"truth_threshold\": 48.49999891594052, \"match_probability\": 0.9999999999999974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 433.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014245248568072878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985754751431927, \"precision\": 1.0, \"recall\": 0.0014245248568072878, \"specificity\": 1.0, \"npv\": 0.9997626910129847, \"accuracy\": 0.9997626910933219, \"f1\": 0.0028449969447492396, \"f2\": 0.0017800221495596809, \"f0_5\": 0.007082268812174305, \"p4\": 0.0056738498881161985, \"phi\": 0.0377383995985063}, {\"truth_threshold\": 48.51999891549349, \"match_probability\": 0.9999999999999976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 419.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303542.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013784663164024332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986215336835975, \"precision\": 1.0, \"recall\": 0.0013784663164024332, \"specificity\": 1.0, \"npv\": 0.9997626800698842, \"accuracy\": 0.9997626801476277, \"f1\": 0.002753137525461594, \"f2\": 0.0017224892971339258, \"f0_5\": 0.006854536590792345, \"p4\": 0.0054911553507528835, \"phi\": 0.037123296982791786}, {\"truth_threshold\": 48.53999891504645, \"match_probability\": 0.9999999999999976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 418.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013751764206592293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986248235793408, \"precision\": 1.0, \"recall\": 0.0013751764206592293, \"specificity\": 1.0, \"npv\": 0.9997626792882343, \"accuracy\": 0.9997626793657923, \"f1\": 0.0027465758150200903, \"f2\": 0.0017183797569931478, \"f0_5\": 0.006838266810193926, \"p4\": 0.005478103816794027, \"phi\": 0.03707897062773284}, {\"truth_threshold\": 48.55999891459942, \"match_probability\": 0.9999999999999976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 412.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303549.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001355437046200006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986445629538, \"precision\": 1.0, \"recall\": 0.001355437046200006, \"specificity\": 1.0, \"npv\": 0.9997626745983342, \"accuracy\": 0.9997626746747805, \"f1\": 0.0027072046469299184, \"f2\": 0.0016937223742370027, \"f0_5\": 0.006740639182746581, \"p4\": 0.005399789224316499, \"phi\": 0.03681189164602362}, {\"truth_threshold\": 48.59999891370535, \"match_probability\": 0.9999999999999977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 411.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303550.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013521471504568021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986478528495432, \"precision\": 1.0, \"recall\": 0.0013521471504568021, \"specificity\": 1.0, \"npv\": 0.9997626738166842, \"accuracy\": 0.9997626738929453, \"f1\": 0.002700642634670732, \"f2\": 0.0016896127867922434, \"f0_5\": 0.006724366420706468, \"p4\": 0.005386735894045546, \"phi\": 0.03676718986452871}, {\"truth_threshold\": 48.619998913258314, \"match_probability\": 0.9999999999999977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 409.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303552.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013455673589703942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986544326410296, \"precision\": 1.0, \"recall\": 0.0013455673589703942, \"specificity\": 1.0, \"npv\": 0.9997626722533842, \"accuracy\": 0.9997626723292746, \"f1\": 0.002687518480796399, \"f2\": 0.001681393591629373, \"f0_5\": 0.006691819618648089, \"p4\": 0.0053606284635572075, \"phi\": 0.036677622857829405}, {\"truth_threshold\": 48.659998912364244, \"match_probability\": 0.9999999999999978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 404.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013291178802543747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986708821197456, \"precision\": 1.0, \"recall\": 0.0013291178802543747, \"specificity\": 1.0, \"npv\": 0.9997626683451342, \"accuracy\": 0.9997626684200981, \"f1\": 0.0026547073415143004, \"f2\": 0.0016608454854602022, \"f0_5\": 0.006610445157848922, \"p4\": 0.0052953553956289244, \"phi\": 0.03645274253754225}, {\"truth_threshold\": 48.67999891191721, \"match_probability\": 0.9999999999999978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 403.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303558.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013258279845111708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986741720154888, \"precision\": 1.0, \"recall\": 0.0013258279845111708, \"specificity\": 1.0, \"npv\": 0.9997626675634842, \"accuracy\": 0.9997626676382628, \"f1\": 0.0026481449842951205, \"f2\": 0.0016567358439527498, \"f0_5\": 0.006594168987443263, \"p4\": 0.005282300011975715, \"phi\": 0.036407599790774535}, {\"truth_threshold\": 48.699998911470175, \"match_probability\": 0.9999999999999978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 401.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303560.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013192481930247631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986807518069752, \"precision\": 1.0, \"recall\": 0.0013192481930247631, \"specificity\": 1.0, \"npv\": 0.9997626660001842, \"accuracy\": 0.9997626660745922, \"f1\": 0.0026350201404906, \"f2\": 0.0016485165406640932, \"f0_5\": 0.006561615368252254, \"p4\": 0.005256188474541174, \"phi\": 0.0363171459585464}, {\"truth_threshold\": 48.71999891102314, \"match_probability\": 0.9999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 397.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303564.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013060886100519475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998693911389948, \"precision\": 1.0, \"recall\": 0.0013060886100519475, \"specificity\": 1.0, \"npv\": 0.9997626628735842, \"accuracy\": 0.9997626629472509, \"f1\": 0.0026087699354050164, \"f2\": 0.0016320778529913067, \"f0_5\": 0.006496503015882886, \"p4\": 0.005203962318947586, \"phi\": 0.036135559034480055}, {\"truth_threshold\": 48.75999891012907, \"match_probability\": 0.9999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 384.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303577.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012633199653902967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987366800346097, \"precision\": 1.0, \"recall\": 0.0012633199653902967, \"specificity\": 1.0, \"npv\": 0.9997626527121345, \"accuracy\": 0.9997626527833919, \"f1\": 0.0025234520034828896, \"f2\": 0.001578651371288936, \"f0_5\": 0.006284840767667113, \"p4\": 0.005034198939630048, \"phi\": 0.03553899435581718}, {\"truth_threshold\": 48.779998909682035, \"match_probability\": 0.9999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 383.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012600300696470929, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987399699303529, \"precision\": 1.0, \"recall\": 0.0012600300696470929, \"specificity\": 1.0, \"npv\": 0.9997626519304844, \"accuracy\": 0.9997626520015567, \"f1\": 0.00251688878374471, \"f2\": 0.0015745415946200833, \"f0_5\": 0.006268556071661217, \"p4\": 0.005021138420400878, \"phi\": 0.035492689443637974}, {\"truth_threshold\": 48.799998909235, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 381.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303580.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012534502781606852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987465497218393, \"precision\": 1.0, \"recall\": 0.0012534502781606852, \"specificity\": 1.0, \"npv\": 0.9997626503671845, \"accuracy\": 0.999762650437886, \"f1\": 0.0025037622148766847, \"f2\": 0.001566322021007626, \"f0_5\": 0.006235985400265152, \"p4\": 0.004995016611359936, \"phi\": 0.03539989791224561}, {\"truth_threshold\": 48.819998908787966, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 380.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303581.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001250160382417481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987498396175826, \"precision\": 1.0, \"recall\": 0.001250160382417481, \"specificity\": 1.0, \"npv\": 0.9997626495855345, \"accuracy\": 0.9997626496560508, \"f1\": 0.0024971988657459887, \"f2\": 0.0015622122240639882, \"f0_5\": 0.006219699424841479, \"p4\": 0.004981955321533011, \"phi\": 0.035353410816108904}, {\"truth_threshold\": 48.83999890834093, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 373.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303588.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012271311122150539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987728688877849, \"precision\": 1.0, \"recall\": 0.0012271311122150539, \"specificity\": 1.0, \"npv\": 0.9997626441139849, \"accuracy\": 0.9997626441832036, \"f1\": 0.002451254214120013, \"f2\": 0.0015334434562253281, \"f0_5\": 0.006105685653766701, \"p4\": 0.004890519099650036, \"phi\": 0.035026273644546566}, {\"truth_threshold\": 48.859998907893896, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 371.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303590.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012205513207286462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987794486792714, \"precision\": 1.0, \"recall\": 0.0012205513207286462, \"specificity\": 1.0, \"npv\": 0.9997626425506849, \"accuracy\": 0.999762642619533, \"f1\": 0.0024381267825926947, \"f2\": 0.0015252237474459697, \"f0_5\": 0.0060731064512432684, \"p4\": 0.004864392152532856, \"phi\": 0.03493224318277313}, {\"truth_threshold\": 48.87999890744686, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 370.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303591.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012172614249854423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987827385750145, \"precision\": 1.0, \"recall\": 0.0012172614249854423, \"specificity\": 1.0, \"npv\": 0.999762641769035, \"accuracy\": 0.9997626418376977, \"f1\": 0.0024315630021259746, \"f2\": 0.0015211138829186312, \"f0_5\": 0.006056816210004551, \"p4\": 0.004851328293554119, \"phi\": 0.034885132907400335}, {\"truth_threshold\": 48.91999890655279, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 354.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303607.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011646230930941798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988353769069058, \"precision\": 1.0, \"recall\": 0.0011646230930941798, \"specificity\": 1.0, \"npv\": 0.9997626292626358, \"accuracy\": 0.9997626293283328, \"f1\": 0.0023265366478813073, \"f2\": 0.001455355131319078, \"f0_5\": 0.005796114311162923, \"p4\": 0.004642271598603462, \"phi\": 0.03412252402229092}, {\"truth_threshold\": 48.93999890610576, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 352.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303609.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001158043301607772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988419566983923, \"precision\": 1.0, \"recall\": 0.001158043301607772, \"specificity\": 1.0, \"npv\": 0.9997626276993359, \"accuracy\": 0.9997626277646622, \"f1\": 0.002313407577067033, \"f2\": 0.0014471351657134213, \"f0_5\": 0.005763518890260636, \"p4\": 0.00461613488496393, \"phi\": 0.03402599615301514}, {\"truth_threshold\": 48.95999890565872, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 351.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303610.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011547534058645682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988452465941354, \"precision\": 1.0, \"recall\": 0.0011547534058645682, \"specificity\": 1.0, \"npv\": 0.9997626269176859, \"accuracy\": 0.9997626269828269, \"f1\": 0.0023068429769447147, \"f2\": 0.0014430251727724584, \"f0_5\": 0.005747220539354543, \"p4\": 0.004603066142507879, \"phi\": 0.03397762938301178}, {\"truth_threshold\": 48.99999890476465, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 347.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011415938228917526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988584061771082, \"precision\": 1.0, \"recall\": 0.0011415938228917526, \"specificity\": 1.0, \"npv\": 0.9997626237910863, \"accuracy\": 0.9997626238554856, \"f1\": 0.002280584145010976, \"f2\": 0.0014265851334206551, \"f0_5\": 0.00568202286563899, \"p4\": 0.004550788601598072, \"phi\": 0.0337834698584671}, {\"truth_threshold\": 49.01999890431762, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 344.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011317241356621408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988682758643379, \"precision\": 1.0, \"recall\": 0.0011317241356621408, \"specificity\": 1.0, \"npv\": 0.9997626214461365, \"accuracy\": 0.9997626215099797, \"f1\": 0.002260889568032073, \"f2\": 0.0014142550329389865, \"f0_5\": 0.005633120126286693, \"p4\": 0.004511577746063377, \"phi\": 0.03363711474879266}, {\"truth_threshold\": 49.03999890387058, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 343.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303618.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001128434239918937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988715657600811, \"precision\": 1.0, \"recall\": 0.001128434239918937, \"specificity\": 1.0, \"npv\": 0.9997626206644865, \"accuracy\": 0.9997626207281445, \"f1\": 0.002254324622745675, \"f2\": 0.0014101449859273286, \"f0_5\": 0.0056168183589720075, \"p4\": 0.004498506946587086, \"phi\": 0.03358818799740311}, {\"truth_threshold\": 49.05999890342355, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 341.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303620.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011218544484325292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988781455515675, \"precision\": 1.0, \"recall\": 0.0011218544484325292, \"specificity\": 1.0, \"npv\": 0.9997626191011867, \"accuracy\": 0.9997626191644738, \"f1\": 0.0022411946027301823, \"f2\": 0.0014019248716272607, \"f0_5\": 0.005584213542946041, \"p4\": 0.004472364576141878, \"phi\": 0.03349012005973139}, {\"truth_threshold\": 49.07999890297651, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 339.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011152746569461213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988847253430538, \"precision\": 1.0, \"recall\": 0.0011152746569461213, \"specificity\": 1.0, \"npv\": 0.9997626175378869, \"accuracy\": 0.9997626176008032, \"f1\": 0.0022280644101215904, \"f2\": 0.0013937047302914117, \"f0_5\": 0.0055516070182793625, \"p4\": 0.004446221176989236, \"phi\": 0.033391764108865574}, {\"truth_threshold\": 49.11999890208244, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 338.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303623.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011119847612029174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988880152387971, \"precision\": 1.0, \"recall\": 0.0011119847612029174, \"specificity\": 1.0, \"npv\": 0.9997626167562369, \"accuracy\": 0.9997626168189679, \"f1\": 0.002221499249093819, \"f2\": 0.0013895946494850277, \"f0_5\": 0.005535303115163783, \"p4\": 0.0044331490916286525, \"phi\": 0.03334247733227524}, {\"truth_threshold\": 49.159998901188374, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 335.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011021150739733059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988978849260267, \"precision\": 1.0, \"recall\": 0.0011021150739733059, \"specificity\": 1.0, \"npv\": 0.9997626144112872, \"accuracy\": 0.999762614473462, \"f1\": 0.002201803507111497, \"f2\": 0.0013772643665118374, \"f0_5\": 0.005486388842486595, \"p4\": 0.0043939312923187614, \"phi\": 0.03319417791929243}, {\"truth_threshold\": 49.17999890074134, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 332.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001092245386743694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989077546132563, \"precision\": 1.0, \"recall\": 0.001092245386743694, \"specificity\": 1.0, \"npv\": 0.9997626120663374, \"accuracy\": 0.999762612127956, \"f1\": 0.0021821073767717297, \"f2\": 0.0013649340227072397, \"f0_5\": 0.005437470724461085, \"p4\": 0.0043547111780072355, \"phi\": 0.03304521297961752}, {\"truth_threshold\": 49.199998900294304, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 330.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010856655952572864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989143344047428, \"precision\": 1.0, \"recall\": 0.0010856655952572864, \"specificity\": 1.0, \"npv\": 0.9997626105030376, \"accuracy\": 0.9997626105642855, \"f1\": 0.0021689764074520773, \"f2\": 0.001356713759708726, \"f0_5\": 0.005404856509248856, \"p4\": 0.004328563148919638, \"phi\": 0.032945528826348484}, {\"truth_threshold\": 49.21999889984727, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 327.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303634.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010757959080276746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989242040919724, \"precision\": 1.0, \"recall\": 0.0010757959080276746, \"specificity\": 1.0, \"npv\": 0.9997626081580879, \"accuracy\": 0.9997626082187796, \"f1\": 0.0021492796298243767, \"f2\": 0.0013443833145174485, \"f0_5\": 0.005355931981301737, \"p4\": 0.004289339175816508, \"phi\": 0.032795434481884}, {\"truth_threshold\": 49.239998899400234, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 324.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303637.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010659262207980628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998934073779202, \"precision\": 1.0, \"recall\": 0.0010659262207980628, \"specificity\": 1.0, \"npv\": 0.9997626058131382, \"accuracy\": 0.9997626058732736, \"f1\": 0.0021295824638086006, \"f2\": 0.0013320528084935633, \"f0_5\": 0.005307003606796896, \"p4\": 0.004250112887165047, \"phi\": 0.032644650038093866}, {\"truth_threshold\": 49.2599988989532, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 308.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010132878889068005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989867121110932, \"precision\": 1.0, \"recall\": 0.0010132878889068005, \"specificity\": 1.0, \"npv\": 0.99976259330674, \"accuracy\": 0.9997625933639087, \"f1\": 0.002024524351807118, \"f2\": 0.0012662890822857668, \"f0_5\": 0.0050459872932865435, \"p4\": 0.004040866898852193, \"phi\": 0.031828404414607006}, {\"truth_threshold\": 49.279998898506165, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 307.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303654.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010099979931635966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989900020068364, \"precision\": 1.0, \"recall\": 0.0010099979931635966, \"specificity\": 1.0, \"npv\": 0.99976259252509, \"accuracy\": 0.9997625925820735, \"f1\": 0.0020179578529454295, \"f2\": 0.0012621787919427768, \"f0_5\": 0.005029670138832002, \"p4\": 0.0040277868367719055, \"phi\": 0.03177669290675755}, {\"truth_threshold\": 49.319998897612095, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 304.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303657.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001000128305933985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998999871694066, \"precision\": 1.0, \"recall\": 0.001000128305933985, \"specificity\": 1.0, \"npv\": 0.9997625901801405, \"accuracy\": 0.9997625902365675, \"f1\": 0.001998258097382216, \"f2\": 0.001249847880356667, \"f0_5\": 0.004980716109012147, \"p4\": 0.003988545105890093, \"phi\": 0.031621050989064814}, {\"truth_threshold\": 49.33999889716506, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 300.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303661.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009869687229611694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990130312770388, \"precision\": 1.0, \"recall\": 0.0009869687229611694, \"specificity\": 1.0, \"npv\": 0.9997625870535409, \"accuracy\": 0.9997625871092263, \"f1\": 0.00197199115233303, \"f2\": 0.0012334065702745728, \"f0_5\": 0.004915438080226504, \"p4\": 0.003936219193601693, \"phi\": 0.03141232885044642}, {\"truth_threshold\": 49.359998896718025, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 298.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303663.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009803889314747615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990196110685252, \"precision\": 1.0, \"recall\": 0.0009803889314747615, \"specificity\": 1.0, \"npv\": 0.9997625854902412, \"accuracy\": 0.9997625855455556, \"f1\": 0.001958857420815818, \"f2\": 0.0012251858746758191, \"f0_5\": 0.004882796498805517, \"p4\": 0.003910054692558099, \"phi\": 0.03130744596605131}, {\"truth_threshold\": 49.37999889627099, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 288.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303673.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009474899740427226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990525100259573, \"precision\": 1.0, \"recall\": 0.0009474899740427226, \"specificity\": 1.0, \"npv\": 0.9997625776737425, \"accuracy\": 0.9997625777272027, \"f1\": 0.0018931861731673728, \"f2\": 0.0011840819910996503, \"f0_5\": 0.004719562916034387, \"p4\": 0.0037792167359132246, \"phi\": 0.030777670782061783}, {\"truth_threshold\": 49.399998895823956, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 285.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009376202868131109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990623797131869, \"precision\": 1.0, \"recall\": 0.0009376202868131109, \"specificity\": 1.0, \"npv\": 0.999762575328793, \"accuracy\": 0.9997625753816967, \"f1\": 0.0018734839570610624, \"f2\": 0.0011717506942108937, \"f0_5\": 0.004670584494970518, \"p4\": 0.0037399603264645837, \"phi\": 0.030616950740150424}, {\"truth_threshold\": 49.41999889537692, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 280.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303681.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009211708080970914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990788291919029, \"precision\": 1.0, \"recall\": 0.0009211708080970914, \"specificity\": 1.0, \"npv\": 0.9997625714205438, \"accuracy\": 0.9997625714725201, \"f1\": 0.0018406460667694362, \"f2\": 0.0011511983975318306, \"f0_5\": 0.004588945230938669, \"p4\": 0.003674527825234722, \"phi\": 0.03034719255253587}, {\"truth_threshold\": 49.479998894035816, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 278.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303683.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009145910166106836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990854089833893, \"precision\": 1.0, \"recall\": 0.0009145910166106836, \"specificity\": 1.0, \"npv\": 0.9997625698572441, \"accuracy\": 0.9997625699088496, \"f1\": 0.0018275106084361308, \"f2\": 0.0011429774315405855, \"f0_5\": 0.004556286528142444, \"p4\": 0.003648353021313192, \"phi\": 0.03023861546326231}, {\"truth_threshold\": 49.49999889358878, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 277.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303684.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009113011208674798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990886988791325, \"precision\": 1.0, \"recall\": 0.0009113011208674798, \"specificity\": 1.0, \"npv\": 0.9997625690755942, \"accuracy\": 0.9997625691270142, \"f1\": 0.0018209428145070634, \"f2\": 0.0011388669384049777, \"f0_5\": 0.00453995653442336, \"p4\": 0.0036352652328727974, \"phi\": 0.030184180455992842}, {\"truth_threshold\": 49.51999889314175, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 276.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303685.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009080112251242758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990919887748757, \"precision\": 1.0, \"recall\": 0.0009080112251242758, \"specificity\": 1.0, \"npv\": 0.9997625682939444, \"accuracy\": 0.999762568345179, \"f1\": 0.0018143749774024857, \"f2\": 0.0011347564385093577, \"f0_5\": 0.004523626112467835, \"p4\": 0.0036221771867691707, \"phi\": 0.030129647101650177}, {\"truth_threshold\": 49.53999889269471, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 275.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303686.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009047213293810719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999095278670619, \"precision\": 1.0, \"recall\": 0.0009047213293810719, \"specificity\": 1.0, \"npv\": 0.9997625675122945, \"accuracy\": 0.9997625675633437, \"f1\": 0.001807807097121971, \"f2\": 0.0011306459318537083, \"f0_5\": 0.004507295262259023, \"p4\": 0.0036090888829947033, \"phi\": 0.030075014865252468}, {\"truth_threshold\": 49.57999889180064, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 274.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303687.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000901431433637868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990985685663621, \"precision\": 1.0, \"recall\": 0.000901431433637868, \"specificity\": 1.0, \"npv\": 0.9997625667306447, \"accuracy\": 0.9997625667815083, \"f1\": 0.0018012391736650945, \"f2\": 0.0011265354184380133, \"f0_5\": 0.0044909639837800806, \"p4\": 0.0035960003215417848, \"phi\": 0.030020283206949928}, {\"truth_threshold\": 49.59999889135361, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 271.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008915617464082563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991084382535917, \"precision\": 1.0, \"recall\": 0.0008915617464082563, \"specificity\": 1.0, \"npv\": 0.9997625643856952, \"accuracy\": 0.9997625644360024, \"f1\": 0.0017815351442320335, \"f2\": 0.0011142038376304873, \"f0_5\": 0.004441967578553984, \"p4\": 0.003556733091036224, \"phi\": 0.029855486227782443}, {\"truth_threshold\": 49.61999889090657, \"match_probability\": 0.9999999999999989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 270.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303691.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008882718506650524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991117281493349, \"precision\": 1.0, \"recall\": 0.0008882718506650524, \"specificity\": 1.0, \"npv\": 0.9997625636040454, \"accuracy\": 0.9997625636541672, \"f1\": 0.0017749670480654502, \"f2\": 0.0011100932971744425, \"f0_5\": 0.004425634586826033, \"p4\": 0.0035436434987934006, \"phi\": 0.029800351383804227}, {\"truth_threshold\": 49.63999889045954, \"match_probability\": 0.9999999999999989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 269.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303692.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008849819549218485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991150180450782, \"precision\": 1.0, \"recall\": 0.0008849819549218485, \"specificity\": 1.0, \"npv\": 0.9997625628223955, \"accuracy\": 0.9997625628723318, \"f1\": 0.001768398908720376, \"f2\": 0.0011059827499582686, \"f0_5\": 0.0044093011667437065, \"p4\": 0.0035305536488340734, \"phi\": 0.029745114343438673}, {\"truth_threshold\": 49.69999888911843, \"match_probability\": 0.9999999999999989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 265.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303696.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000871822371949033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999128177628051, \"precision\": 1.0, \"recall\": 0.000871822371949033, \"specificity\": 1.0, \"npv\": 0.9997625596957962, \"accuracy\": 0.9997625597449906, \"f1\": 0.0017421259195466528, \"f2\": 0.0010895404934919484, \"f0_5\": 0.004343963202533596, \"p4\": 0.003478191671679499, \"phi\": 0.029523132729773537}, {\"truth_threshold\": 49.779998887330294, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 264.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000868532476205829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991314675237942, \"precision\": 1.0, \"recall\": 0.000868532476205829, \"specificity\": 1.0, \"npv\": 0.9997625589141463, \"accuracy\": 0.9997625589631552, \"f1\": 0.0017355575643027365, \"f2\": 0.0010854299124748788, \"f0_5\": 0.0043276276404265995, \"p4\": 0.0034651005330234783, \"phi\": 0.029467376043882488}, {\"truth_threshold\": 49.79999888688326, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 260.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008553728932330135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999144627106767, \"precision\": 1.0, \"recall\": 0.0008553728932330135, \"specificity\": 1.0, \"npv\": 0.999762555787547, \"accuracy\": 0.9997625558358141, \"f1\": 0.0017092837115123545, \"f2\": 0.0010689875208041418, \"f0_5\": 0.004262281107275058, \"p4\": 0.003412733400701498, \"phi\": 0.029243286236160702}, {\"truth_threshold\": 49.83999888598919, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 251.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303710.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008257638315441783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991742361684558, \"precision\": 1.0, \"recall\": 0.0008257638315441783, \"specificity\": 1.0, \"npv\": 0.9997625487526988, \"accuracy\": 0.9997625487992963, \"f1\": 0.0016501650165016502, \"f2\": 0.0010319917440660474, \"f0_5\": 0.00411522633744856, \"p4\": 0.0032948922713656507, \"phi\": 0.028732694842155022}, {\"truth_threshold\": 49.899998884648085, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 249.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303712.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008191840400577706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991808159599422, \"precision\": 1.0, \"recall\": 0.0008191840400577706, \"specificity\": 1.0, \"npv\": 0.999762547189399, \"accuracy\": 0.9997625472356257, \"f1\": 0.0016370270536800236, \"f2\": 0.0010237703859819931, \"f0_5\": 0.004082542784720469, \"p4\": 0.00326870251745806, \"phi\": 0.028617992985271686}, {\"truth_threshold\": 49.979998882859945, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 248.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008158941443145666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991841058556854, \"precision\": 1.0, \"recall\": 0.0008158941443145666, \"specificity\": 1.0, \"npv\": 0.9997625464077493, \"accuracy\": 0.9997625464537904, \"f1\": 0.0016304580074882728, \"f2\": 0.0010196596967992552, \"f0_5\": 0.004066200365302194, \"p4\": 0.0032556072536934644, \"phi\": 0.028560469311954644}, {\"truth_threshold\": 49.99999888241291, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 242.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007961547698553433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992038452301446, \"precision\": 1.0, \"recall\": 0.0007961547698553433, \"specificity\": 1.0, \"npv\": 0.9997625417178505, \"accuracy\": 0.9997625417627786, \"f1\": 0.0015910428233778101, \"f2\": 0.000994995419731828, \"f0_5\": 0.003968136844970468, \"p4\": 0.0031770302552747505, \"phi\": 0.028212864376226818}, {\"truth_threshold\": 50.059998881071806, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 236.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007764153953961198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992235846046039, \"precision\": 1.0, \"recall\": 0.0007764153953961198, \"specificity\": 1.0, \"npv\": 0.9997625370279517, \"accuracy\": 0.9997625370717668, \"f1\": 0.001551626084412404, \"f2\": 0.0009703308992829419, \"f0_5\": 0.0038700578868827995, \"p4\": 0.0030984439713854983, \"phi\": 0.027860922911647865}, {\"truth_threshold\": 50.07999888062477, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 235.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303726.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000773125499652916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992268745003471, \"precision\": 1.0, \"recall\": 0.000773125499652916, \"specificity\": 1.0, \"npv\": 0.9997625362463018, \"accuracy\": 0.9997625362899314, \"f1\": 0.0015450564767452563, \"f2\": 0.000966220122212455, \"f0_5\": 0.003853709892719276, \"p4\": 0.0030853453545343036, \"phi\": 0.02780183285989772}, {\"truth_threshold\": 50.099998880177736, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 232.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303729.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007632558124233043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992367441875767, \"precision\": 1.0, \"recall\": 0.0007632558124233043, \"specificity\": 1.0, \"npv\": 0.9997625339013525, \"accuracy\": 0.9997625339444255, \"f1\": 0.0015253473945817293, \"f2\": 0.0009538877504366504, \"f0_5\": 0.003804663336492953, \"p4\": 0.0030460479560517426, \"phi\": 0.027623804318798274}, {\"truth_threshold\": 50.13999887928367, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 226.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303735.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000743516437964081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992564835620359, \"precision\": 1.0, \"recall\": 0.000743516437964081, \"specificity\": 1.0, \"npv\": 0.9997625292114538, \"accuracy\": 0.9997625292534137, \"f1\": 0.0014859280639869553, \"f2\": 0.0009292228243439934, \"f0_5\": 0.0037065586407098224, \"p4\": 0.0029674461927201965, \"phi\": 0.027264260021670504}, {\"truth_threshold\": 50.1799988783896, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 224.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303737.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007369366464776731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992630633535223, \"precision\": 1.0, \"recall\": 0.0007369366464776731, \"specificity\": 1.0, \"npv\": 0.9997625276481542, \"accuracy\": 0.999762527689743, \"f1\": 0.0014727879415487287, \"f2\": 0.0009210011282263821, \"f0_5\": 0.0036738536428555027, \"p4\": 0.002941243540610822, \"phi\": 0.0271433535952924}, {\"truth_threshold\": 50.19999887794256, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 223.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007336467507344692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992663532492655, \"precision\": 1.0, \"recall\": 0.0007336467507344692, \"specificity\": 1.0, \"npv\": 0.9997625268665045, \"accuracy\": 0.9997625269079078, \"f1\": 0.001466217815532704, \"f2\": 0.0009168902700262404, \"f0_5\": 0.0036575005002411, \"p4\": 0.002928141827459539, \"phi\": 0.02708269797013757}, {\"truth_threshold\": 50.23999887704849, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 221.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007270669592480615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992729330407519, \"precision\": 1.0, \"recall\": 0.0007270669592480615, \"specificity\": 1.0, \"npv\": 0.999762525303205, \"accuracy\": 0.9997625253442372, \"f1\": 0.0014530774339047018, \"f2\": 0.0009086685333432013, \"f0_5\": 0.0036247929275533466, \"p4\": 0.002901937626925655, \"phi\": 0.02696097734212104}, {\"truth_threshold\": 50.25999887660146, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 215.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303746.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000707327584788838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992926724152111, \"precision\": 1.0, \"recall\": 0.000707327584788838, \"specificity\": 1.0, \"npv\": 0.9997625206133063, \"accuracy\": 0.9997625206532254, \"f1\": 0.0014136552522223975, \"f2\": 0.0008840031610308381, \"f0_5\": 0.0035266599086020978, \"p4\": 0.002823318830924385, \"phi\": 0.02659247278964126}, {\"truth_threshold\": 50.27999887615442, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 214.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303747.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007040376890456342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992959623109544, \"precision\": 1.0, \"recall\": 0.0007040376890456342, \"specificity\": 1.0, \"npv\": 0.9997625198316565, \"accuracy\": 0.99976251987139, \"f1\": 0.0014070847374044546, \"f2\": 0.0008798922419818792, \"f0_5\": 0.0035103029030533073, \"p4\": 0.002810214794827481, \"phi\": 0.026530557741154245}, {\"truth_threshold\": 50.29999887570739, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 213.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007007477933024302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992992522066976, \"precision\": 1.0, \"recall\": 0.0007007477933024302, \"specificity\": 1.0, \"npv\": 0.9997625190500068, \"accuracy\": 0.9997625190895547, \"f1\": 0.0014005141793841682, \"f2\": 0.0008757813161718571, \"f0_5\": 0.0034939454682050963, \"p4\": 0.0027971105005873726, \"phi\": 0.02646849786162356}, {\"truth_threshold\": 50.31999887526035, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 211.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303750.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006941680018160225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999305831998184, \"precision\": 1.0, \"recall\": 0.0006941680018160225, \"specificity\": 1.0, \"npv\": 0.9997625174867072, \"accuracy\": 0.9997625175258841, \"f1\": 0.0013873729337348605, \"f2\": 0.0008675594442685569, \"f0_5\": 0.003461229310542806, \"p4\": 0.002770901137647029, \"phi\": 0.026343939512804528}, {\"truth_threshold\": 50.33999887481332, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 210.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303751.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006908781060728185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993091218939272, \"precision\": 1.0, \"recall\": 0.0006908781060728185, \"specificity\": 1.0, \"npv\": 0.9997625167050574, \"accuracy\": 0.9997625167440488, \"f1\": 0.001380802246104987, \"f2\": 0.0008634484981752455, \"f0_5\": 0.0034448705876949223, \"p4\": 0.002757796068931536, \"phi\": 0.026281438964862344}, {\"truth_threshold\": 50.37999887391925, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 206.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000677718523100003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993222814768999, \"precision\": 1.0, \"recall\": 0.000677718523100003, \"specificity\": 1.0, \"npv\": 0.9997625135784585, \"accuracy\": 0.9997625136167075, \"f1\": 0.0013545190635407523, \"f2\": 0.0008470046461905349, \"f0_5\": 0.003379431402464032, \"p4\": 0.0027053732122560765, \"phi\": 0.026029936115041456}, {\"truth_threshold\": 50.41999887302518, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 204.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006711387316135952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993288612683864, \"precision\": 1.0, \"recall\": 0.0006711387316135952, \"specificity\": 1.0, \"npv\": 0.999762512015159, \"accuracy\": 0.9997625120530369, \"f1\": 0.0013413772130258248, \"f2\": 0.0008387826796310672, \"f0_5\": 0.003346709233308288, \"p4\": 0.002679160234723434, \"phi\": 0.02590326898730497}, {\"truth_threshold\": 50.45999887213111, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 203.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303758.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006678488358703913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993321511641297, \"precision\": 1.0, \"recall\": 0.0006678488358703913, \"specificity\": 1.0, \"npv\": 0.9997625112335092, \"accuracy\": 0.9997625112712016, \"f1\": 0.001334806222958667, \"f2\": 0.0008346716862094968, \"f0_5\": 0.003330347504536163, \"p4\": 0.002666053358631678, \"phi\": 0.025839702577122637}, {\"truth_threshold\": 50.49999887123704, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 202.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303759.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006645589401271874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993354410598728, \"precision\": 1.0, \"recall\": 0.0006645589401271874, \"specificity\": 1.0, \"npv\": 0.9997625104518595, \"accuracy\": 0.9997625104893664, \"f1\": 0.0013282351896844783, \"f2\": 0.00083056068602668, \"f0_5\": 0.003313985346278657, \"p4\": 0.0026529462243127903, \"phi\": 0.025775979405733236}, {\"truth_threshold\": 50.53999887034297, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 201.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006612690443839835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999338730955616, \"precision\": 1.0, \"recall\": 0.0006612690443839835, \"specificity\": 1.0, \"npv\": 0.9997625096702096, \"accuracy\": 0.999762509707531, \"f1\": 0.0013216641132028327, \"f2\": 0.0008264496790825998, \"f0_5\": 0.003297622758518859, \"p4\": 0.0026398388317591397, \"phi\": 0.025712098307616834}, {\"truth_threshold\": 50.5799988694489, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 200.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006579791486407795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993420208513593, \"precision\": 1.0, \"recall\": 0.0006579791486407795, \"specificity\": 1.0, \"npv\": 0.9997625088885599, \"accuracy\": 0.9997625089256957, \"f1\": 0.0013150929935133039, \"f2\": 0.0008223386653772397, \"f0_5\": 0.0032812597412398567, \"p4\": 0.002626731180963094, \"phi\": 0.02564805810273878}, {\"truth_threshold\": 50.599998869001865, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 188.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303773.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006185003997223328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993814996002777, \"precision\": 1.0, \"recall\": 0.0006185003997223328, \"specificity\": 1.0, \"npv\": 0.9997624995087631, \"accuracy\": 0.999762499543672, \"f1\": 0.001236236186868936, \"f2\": 0.0007730059735270125, \"f0_5\": 0.003084870025236862, \"p4\": 0.0024694192257253447, \"phi\": 0.02486671481264802}, {\"truth_threshold\": 50.61999886855483, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 184.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303777.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006053408167495172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993946591832504, \"precision\": 1.0, \"recall\": 0.0006053408167495172, \"specificity\": 1.0, \"npv\": 0.9997624963821641, \"accuracy\": 0.9997624964163309, \"f1\": 0.0012099492018609545, \"f2\": 0.0007565615265437967, \"f0_5\": 0.0030193930363607126, \"p4\": 0.0024169736410319135, \"phi\": 0.024600752958304252}, {\"truth_threshold\": 50.639998868107796, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 179.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005888913380334977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994111086619665, \"precision\": 1.0, \"recall\": 0.0005888913380334977, \"specificity\": 1.0, \"npv\": 0.9997624924739155, \"accuracy\": 0.9997624925071543, \"f1\": 0.0011770894982573814, \"f2\": 0.0007360058156794732, \"f0_5\": 0.0029375371294846674, \"p4\": 0.0023514108467337386, \"phi\": 0.024264201447990595}, {\"truth_threshold\": 50.65999886766076, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 175.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303786.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005757317550606822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994242682449394, \"precision\": 1.0, \"recall\": 0.0005757317550606822, \"specificity\": 1.0, \"npv\": 0.9997624893473166, \"accuracy\": 0.999762489379813, \"f1\": 0.0011508009574663965, \"f2\": 0.0007195611252784702, \"f0_5\": 0.0028720446660386464, \"p4\": 0.002298955959954338, \"phi\": 0.023991561279661795}, {\"truth_threshold\": 50.719998866319656, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 171.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005625721720878665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994374278279121, \"precision\": 1.0, \"recall\": 0.0005625721720878665, \"specificity\": 1.0, \"npv\": 0.9997624862207177, \"accuracy\": 0.9997624862524719, \"f1\": 0.0011245117251719647, \"f2\": 0.0007031163266900491, \"f0_5\": 0.0028065453232450884, \"p4\": 0.0022464969381200814, \"phi\": 0.023715787008766018}, {\"truth_threshold\": 50.73999886587262, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 169.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005559923806014587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994440076193986, \"precision\": 1.0, \"recall\": 0.0005559923806014587, \"specificity\": 1.0, \"npv\": 0.9997624846574183, \"accuracy\": 0.9997624846888012, \"f1\": 0.0011113668497024299, \"f2\": 0.0006948938868252231, \"f0_5\": 0.002773793071754252, \"p4\": 0.002220265876404577, \"phi\": 0.0235766902656142}, {\"truth_threshold\": 50.77999886497855, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 166.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000546122693371847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994538773066282, \"precision\": 1.0, \"recall\": 0.000546122693371847, \"specificity\": 1.0, \"npv\": 0.9997624823124692, \"accuracy\": 0.9997624823432953, \"f1\": 0.0010916492123356361, \"f2\": 0.0006825601763143396, \"f0_5\": 0.002724661469019286, \"p4\": 0.002180917345161422, \"phi\": 0.023366492667334763}, {\"truth_threshold\": 50.79999886453152, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 165.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303796.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005428327976286432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994571672023713, \"precision\": 1.0, \"recall\": 0.0005428327976286432, \"specificity\": 1.0, \"npv\": 0.9997624815308195, \"accuracy\": 0.99976248156146, \"f1\": 0.0010850765801016684, \"f2\": 0.000678448925953673, \"f0_5\": 0.0027082834079068746, \"p4\": 0.0021678006510711632, \"phi\": 0.023296005340262292}, {\"truth_threshold\": 50.85999886319041, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 159.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005230934231694197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994769065768305, \"precision\": 1.0, \"recall\": 0.0005230934231694197, \"specificity\": 1.0, \"npv\": 0.9997624768409212, \"accuracy\": 0.9997624768704482, \"f1\": 0.0010456398789951335, \"f2\": 0.0006537812817896009, \"f0_5\": 0.002610006007938358, \"p4\": 0.0020890950573979297, \"phi\": 0.022868519330447593}, {\"truth_threshold\": 50.87999886274338, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 157.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000516513631683012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999483486368317, \"precision\": 1.0, \"recall\": 0.000516513631683012, \"specificity\": 1.0, \"npv\": 0.9997624752776219, \"accuracy\": 0.9997624753067775, \"f1\": 0.0010324939661578729, \"f2\": 0.0006455586796392437, \"f0_5\": 0.002577243432953915, \"p4\": 0.0020628577910827605, \"phi\": 0.022724236993264306}, {\"truth_threshold\": 50.91999886184931, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 155.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303806.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005099338401966042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994900661598034, \"precision\": 1.0, \"recall\": 0.0005099338401966042, \"specificity\": 1.0, \"npv\": 0.9997624737143225, \"accuracy\": 0.999762473743107, \"f1\": 0.0010193478804140525, \"f2\": 0.0006373360504408309, \"f0_5\": 0.0025444791369126766, \"p4\": 0.0020366194904536178, \"phi\": 0.022579032696411087}, {\"truth_threshold\": 50.93999886140227, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 154.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005066439444534002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994933560555466, \"precision\": 1.0, \"recall\": 0.0005066439444534002, \"specificity\": 1.0, \"npv\": 0.9997624729326727, \"accuracy\": 0.9997624729612716, \"f1\": 0.0010127747727011163, \"f2\": 0.0006332247256985621, \"f0_5\": 0.0025280963434533795, \"p4\": 0.0020234999522521922, \"phi\": 0.022506079241020528}, {\"truth_threshold\": 50.9799988605082, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 148.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004869045699941769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995130954300058, \"precision\": 1.0, \"recall\": 0.0004869045699941769, \"specificity\": 1.0, \"npv\": 0.9997624682427746, \"accuracy\": 0.9997624682702598, \"f1\": 0.0009733352186222703, \"f2\": 0.0006085566352410214, \"f0_5\": 0.0024297905454879775, \"p4\": 0.0019447772921459706, \"phi\": 0.02206329337828025}, {\"truth_threshold\": 51.019998859614134, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 147.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000483614674250973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999516385325749, \"precision\": 1.0, \"recall\": 0.000483614674250973, \"specificity\": 1.0, \"npv\": 0.999762467461125, \"accuracy\": 0.9997624674884246, \"f1\": 0.0009667618083049443, \"f2\": 0.0006044452631639544, \"f0_5\": 0.0024134047394672124, \"p4\": 0.0019316559435739497, \"phi\": 0.021988628880163515}, {\"truth_threshold\": 51.0399988591671, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 146.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303815.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00048032477850776906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995196752214922, \"precision\": 1.0, \"recall\": 0.00048032477850776906, \"specificity\": 1.0, \"npv\": 0.9997624666794752, \"accuracy\": 0.9997624667065892, \"f1\": 0.000960188354756714, \"f2\": 0.0006003338843247067, \"f0_5\": 0.002397018503012691, \"p4\": 0.001918534336346968, \"phi\": 0.021913709986403483}, {\"truth_threshold\": 51.07999885827303, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 143.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004704550912781574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995295449087218, \"precision\": 1.0, \"recall\": 0.0004704550912781574, \"specificity\": 1.0, \"npv\": 0.9997624643345262, \"accuracy\": 0.9997624643610833, \"f1\": 0.0009404677347223319, \"f2\": 0.0005879997072337122, \"f0_5\": 0.002347857210876982, \"p4\": 0.001879167962659773, \"phi\": 0.021687400522307304}, {\"truth_threshold\": 51.15999885648489, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 142.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004671651955349535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995328348044651, \"precision\": 1.0, \"recall\": 0.0004671651955349535, \"specificity\": 1.0, \"npv\": 0.9997624635528766, \"accuracy\": 0.999762463579248, \"f1\": 0.0009338941082462192, \"f2\": 0.0005838883013455747, \"f0_5\": 0.0023314692525178227, \"p4\": 0.0018660453207364615, \"phi\": 0.021611437406479615}, {\"truth_threshold\": 51.219998855143785, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303828.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004375561338461184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995624438661539, \"precision\": 1.0, \"recall\": 0.0004375561338461184, \"specificity\": 1.0, \"npv\": 0.9997624565180295, \"accuracy\": 0.9997624565427302, \"f1\": 0.0008747295244233691, \"f2\": 0.0005468853440484483, \"f0_5\": 0.002183958251913837, \"p4\": 0.0017479299013143477, \"phi\": 0.020915357879762113}, {\"truth_threshold\": 51.259998854249716, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004342662381029145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995657337618971, \"precision\": 1.0, \"recall\": 0.0004342662381029145, \"specificity\": 1.0, \"npv\": 0.9997624557363798, \"accuracy\": 0.999762455760895, \"f1\": 0.0008681554655976954, \"f2\": 0.0005427738705369185, \"f0_5\": 0.0021675659876054638, \"p4\": 0.001734804672114697, \"phi\": 0.020836580349212038}, {\"truth_threshold\": 51.27999885380268, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00042768644661650673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995723135533835, \"precision\": 1.0, \"recall\": 0.00042768644661650673, \"specificity\": 1.0, \"npv\": 0.9997624541730805, \"accuracy\": 0.9997624541972243, \"f1\": 0.0008550072182340155, \"f2\": 0.0005345509032265493, \"f0_5\": 0.0021347801669069663, \"p4\": 0.0017085534373985879, \"phi\": 0.02067812495092055}, {\"truth_threshold\": 51.299998853355646, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00039478748918446774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996052125108156, \"precision\": 1.0, \"recall\": 0.00039478748918446774, \"specificity\": 1.0, \"npv\": 0.999762446356584, \"accuracy\": 0.9997624463788712, \"f1\": 0.0007892633870580536, \"f2\": 0.0004934356609241721, \"f0_5\": 0.001970825217365598, \"p4\": 0.0015772817354919105, \"phi\": 0.019866899757587667}, {\"truth_threshold\": 51.31999885290861, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00039149759344126383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996085024065587, \"precision\": 1.0, \"recall\": 0.00039149759344126383, \"specificity\": 1.0, \"npv\": 0.9997624455749343, \"accuracy\": 0.999762445597036, \"f1\": 0.0007826887661141805, \"f2\": 0.0004893240994997381, \"f0_5\": 0.001954427352785634, \"p4\": 0.0015641531416889078, \"phi\": 0.019783947822806732}, {\"truth_threshold\": 51.37999885156751, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003882076976980599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996117923023019, \"precision\": 1.0, \"recall\": 0.0003882076976980599, \"specificity\": 1.0, \"npv\": 0.9997624447932846, \"accuracy\": 0.9997624448152006, \"f1\": 0.0007761141019274597, \"f2\": 0.00048521253131265615, \"f0_5\": 0.0019380290572966793, \"p4\": 0.0015510242890166752, \"phi\": 0.019700646612184708}, {\"truth_threshold\": 51.53999884799123, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00038491780195485607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996150821980452, \"precision\": 1.0, \"recall\": 0.00038491780195485607, \"specificity\": 1.0, \"npv\": 0.9997624440116349, \"accuracy\": 0.9997624440333653, \"f1\": 0.0007695393944974645, \"f2\": 0.00048110095636290964, \"f0_5\": 0.0019216303308817492, \"p4\": 0.0015378951774675563, \"phi\": 0.019616991676247746}, {\"truth_threshold\": 51.61999884620309, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303845.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00038162790621165216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996183720937883, \"precision\": 1.0, \"recall\": 0.00038162790621165216, \"specificity\": 1.0, \"npv\": 0.9997624432299853, \"accuracy\": 0.9997624432515301, \"f1\": 0.0007629646438237684, \"f2\": 0.0004769893746504819, \"f0_5\": 0.0019052311735238564, \"p4\": 0.0015247658070338935, \"phi\": 0.01953297847024117}, {\"truth_threshold\": 51.639998845756054, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303846.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00037833801046844825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996216619895315, \"precision\": 1.0, \"recall\": 0.00037833801046844825, \"specificity\": 1.0, \"npv\": 0.9997624424483357, \"accuracy\": 0.9997624424696947, \"f1\": 0.0007563898499059446, \"f2\": 0.0004728777861753562, \"f0_5\": 0.001888831585206014, \"p4\": 0.0015116361777080293, \"phi\": 0.019448602351248272}, {\"truth_threshold\": 51.65999884530902, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303847.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00037504811472524434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996249518852748, \"precision\": 1.0, \"recall\": 0.00037504811472524434, \"specificity\": 1.0, \"npv\": 0.999762441666686, \"accuracy\": 0.9997624416878594, \"f1\": 0.0007498150127435665, \"f2\": 0.0004687661909375159, \"f0_5\": 0.0018724315659112336, \"p4\": 0.0014985062894823063, \"phi\": 0.019363858575196156}, {\"truth_threshold\": 51.73999884352088, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003717582189820405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999628241781018, \"precision\": 1.0, \"recall\": 0.0003717582189820405, \"specificity\": 1.0, \"npv\": 0.9997624408850364, \"accuracy\": 0.9997624409060242, \"f1\": 0.0007432401323362077, \"f2\": 0.0004646545889369443, \"f0_5\": 0.001856031115622526, \"p4\": 0.0014853761423490662, \"phi\": 0.019278742293743094}, {\"truth_threshold\": 51.759998843073845, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303854.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003520188445228171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996479811554771, \"precision\": 1.0, \"recall\": 0.0003520188445228171, \"specificity\": 1.0, \"npv\": 0.9997624361951386, \"accuracy\": 0.9997624362150123, \"f1\": 0.0007037899417235618, \"f2\": 0.0004399848349152227, \"f0_5\": 0.0017576193620663033, \"p4\": 0.0014065898220628798, \"phi\": 0.018759936502737138}, {\"truth_threshold\": 51.799998842179775, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00034872894877961317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996512710512204, \"precision\": 1.0, \"recall\": 0.00034872894877961317, \"specificity\": 1.0, \"npv\": 0.999762435413489, \"accuracy\": 0.999762435433177, \"f1\": 0.0006972147585893898, \"f2\": 0.0004358731855750648, \"f0_5\": 0.0017412158943443336, \"p4\": 0.0013934578623625699, \"phi\": 0.018672067457330264}, {\"truth_threshold\": 51.81999884173274, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00034543905303640926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996545609469636, \"precision\": 1.0, \"recall\": 0.00034543905303640926, \"specificity\": 1.0, \"npv\": 0.9997624346318393, \"accuracy\": 0.9997624346513416, \"f1\": 0.0006906395322068235, \"f2\": 0.000431761529472042, \"f0_5\": 0.0017248119954924913, \"p4\": 0.0013803256436934676, \"phi\": 0.018583782948597888}, {\"truth_threshold\": 51.839998841285706, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003256996785771859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996743003214228, \"precision\": 1.0, \"recall\": 0.0003256996785771859, \"specificity\": 1.0, \"npv\": 0.9997624299419415, \"accuracy\": 0.9997624299603298, \"f1\": 0.0006511872656712491, \"f2\": 0.0004070914508328104, \"f0_5\": 0.001626379547702205, \"p4\": 0.0013015268929051917, \"phi\": 0.018045007677627536}, {\"truth_threshold\": 51.85999884083867, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303863.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000322409782833982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996775902171661, \"precision\": 1.0, \"recall\": 0.000322409782833982, \"specificity\": 1.0, \"npv\": 0.9997624291602919, \"accuracy\": 0.9997624291784946, \"f1\": 0.0006446117365379745, \"f2\": 0.00040297974738926694, \"f0_5\": 0.001609972630465282, \"p4\": 0.001288392861240025, \"phi\": 0.01795363995604078}, {\"truth_threshold\": 51.8999988399446, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303866.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00031254009560437027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996874599043957, \"precision\": 1.0, \"recall\": 0.00031254009560437027, \"specificity\": 1.0, \"npv\": 0.999762426815343, \"accuracy\": 0.9997624268329887, \"f1\": 0.0006248848896255953, \"f2\": 0.00039064459648058004, \"f0_5\": 0.001560749291091243, \"p4\": 0.0012489892120333503, \"phi\": 0.017676703438665384}, {\"truth_threshold\": 52.03999883681536, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003092501998611664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996907498001388, \"precision\": 1.0, \"recall\": 0.0003092501998611664, \"specificity\": 1.0, \"npv\": 0.9997624260336934, \"accuracy\": 0.9997624260511533, \"f1\": 0.0006183091874825278, \"f2\": 0.0003865328659849433, \"f0_5\": 0.001544340648688789, \"p4\": 0.0012358541442018557, \"phi\": 0.017583422023730314}, {\"truth_threshold\": 52.17999883368611, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002993805126315547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997006194873684, \"precision\": 1.0, \"recall\": 0.0002993805126315547, \"specificity\": 1.0, \"npv\": 0.9997624236887446, \"accuracy\": 0.9997624237056474, \"f1\": 0.0005985818215305277, \"f2\": 0.0003741976339195763, \"f0_5\": 0.0014951121334100057, \"p4\": 0.001196447386312265, \"phi\": 0.01730056030635141}, {\"truth_threshold\": 52.19999883323908, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000289510825401943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999710489174598, \"precision\": 1.0, \"recall\": 0.000289510825401943, \"specificity\": 1.0, \"npv\": 0.9997624213437957, \"accuracy\": 0.9997624213601415, \"f1\": 0.0005788540662853684, \"f2\": 0.00036186234098617355, \"f0_5\": 0.0014458797356668956, \"p4\": 0.0011570382966690524, \"phi\": 0.0170129963207275}, {\"truth_threshold\": 52.219998832792044, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00027964113817233134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997203588618276, \"precision\": 1.0, \"recall\": 0.00027964113817233134, \"specificity\": 1.0, \"npv\": 0.9997624189988469, \"accuracy\": 0.9997624190146356, \"f1\": 0.0005591259217355268, \"f2\": 0.00034952698718428464, \"f0_5\": 0.001396643455000148, \"p4\": 0.0011176268750652466, \"phi\": 0.01672048745553672}, {\"truth_threshold\": 52.23999883234501, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303877.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00027635124242912743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997236487575709, \"precision\": 1.0, \"recall\": 0.00027635124242912743, \"specificity\": 1.0, \"npv\": 0.9997624182171972, \"accuracy\": 0.9997624182328002, \"f1\": 0.0005525497870381029, \"f2\": 0.0003454151890572468, \"f0_5\": 0.0013802304984932483, \"p4\": 0.0011044892162814031, \"phi\": 0.016621840644413344}, {\"truth_threshold\": 52.259998831897974, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303878.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002730613466859235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997269386533141, \"precision\": 1.0, \"recall\": 0.0002730613466859235, \"specificity\": 1.0, \"npv\": 0.9997624174355476, \"accuracy\": 0.999762417450965, \"f1\": 0.0005459736090828959, \"f2\": 0.00034130338416697714, \"f0_5\": 0.0013638171104823312, \"p4\": 0.0010913512983601607, \"phi\": 0.01652260488152292}, {\"truth_threshold\": 52.31999883055687, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002697714509427196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997302285490572, \"precision\": 1.0, \"recall\": 0.0002697714509427196, \"specificity\": 1.0, \"npv\": 0.9997624166538981, \"accuracy\": 0.9997624166691297, \"f1\": 0.000539397387869479, \"f2\": 0.00033719157251345887, \"f0_5\": 0.0013474032909503795, \"p4\": 0.0010782131212938519, \"phi\": 0.016422769490519004}, {\"truth_threshold\": 52.3599988296628, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303880.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002664815551995157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997335184448005, \"precision\": 1.0, \"recall\": 0.0002664815551995157, \"specificity\": 1.0, \"npv\": 0.9997624158722485, \"accuracy\": 0.9997624158872943, \"f1\": 0.0005328211233974254, \"f2\": 0.00033307975409667536, \"f0_5\": 0.0013309890398803753, \"p4\": 0.0010650746850748088, \"phi\": 0.01632232346854031}, {\"truth_threshold\": 52.39999882876873, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00026319165945631185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997368083405437, \"precision\": 1.0, \"recall\": 0.00026319165945631185, \"specificity\": 1.0, \"npv\": 0.9997624150905988, \"accuracy\": 0.999762415105459, \"f1\": 0.0005262448156663082, \"f2\": 0.0003289679289166099, \"f0_5\": 0.0013145743572553002, \"p4\": 0.0010519359896953636, \"phi\": 0.01622125547205717}, {\"truth_threshold\": 52.59999882429838, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002533219722267001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997466780277733, \"precision\": 1.0, \"recall\": 0.0002533219722267001, \"specificity\": 1.0, \"npv\": 0.99976241274565, \"accuracy\": 0.9997624127599531, \"f1\": 0.0005065156329143068, \"f2\": 0.00031663241279655504, \"f0_5\": 0.0012653277198794487, \"p4\": 0.0010125183485179298, \"phi\": 0.015914200770219416}, {\"truth_threshold\": 52.63999882340431, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00025003207648349626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997499679235166, \"precision\": 1.0, \"recall\": 0.00025003207648349626, \"specificity\": 1.0, \"npv\": 0.9997624119640004, \"accuracy\": 0.9997624119781178, \"f1\": 0.0004999391521426669, \"f2\": 0.0003125205605631949, \"f0_5\": 0.001248911310863885, \"p4\": 0.0009993786164201894, \"phi\": 0.015810524085352377}, {\"truth_threshold\": 52.71999882161617, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303886.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00024674218074029235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997532578192597, \"precision\": 1.0, \"recall\": 0.00024674218074029235, \"specificity\": 1.0, \"npv\": 0.9997624111823509, \"accuracy\": 0.9997624111962825, \"f1\": 0.0004933626281098291, \"f2\": 0.0003084087015664695, \"f0_5\": 0.0012324944702081437, \"p4\": 0.0009862386251237021, \"phi\": 0.015706163043764258}, {\"truth_threshold\": 52.819998819381, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303887.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00024345228499708844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997565477150029, \"precision\": 1.0, \"recall\": 0.00024345228499708844, \"specificity\": 1.0, \"npv\": 0.9997624104007012, \"accuracy\": 0.9997624104144472, \"f1\": 0.00048678606081536664, \"f2\": 0.00030429683580636196, \"f0_5\": 0.0012160771978952005, \"p4\": 0.0009730983746207983, \"phi\": 0.015601103911782897}, {\"truth_threshold\": 52.879998818039894, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00023358259776747674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997664174022325, \"precision\": 1.0, \"recall\": 0.00023358259776747674, \"specificity\": 1.0, \"npv\": 0.9997624080557524, \"accuracy\": 0.9997624080689412, \"f1\": 0.0004670560993579623, \"f2\": 0.0002919611979455801, \"f0_5\": 0.0011668227908429062, \"p4\": 0.0009336760677968834, \"phi\": 0.015281593517167336}, {\"truth_threshold\": 52.93999881669879, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00022371291053786507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997762870894621, \"precision\": 1.0, \"recall\": 0.00022371291053786507, \"specificity\": 1.0, \"npv\": 0.9997624057108037, \"accuracy\": 0.9997624057234353, \"f1\": 0.0004473257485305678, \"f2\": 0.0002796254992137589, \"f0_5\": 0.0011175644982628445, \"p4\": 0.000894251427839075, \"phi\": 0.014955258527618363}, {\"truth_threshold\": 52.999998815357685, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303897.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00021055332756504945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999789446672435, \"precision\": 1.0, \"recall\": 0.00021055332756504945, \"specificity\": 1.0, \"npv\": 0.9997624025842053, \"accuracy\": 0.9997624025960942, \"f1\": 0.00042101800838746813, \"f2\": 0.00026317780621560184, \"f0_5\": 0.0010518807298737414, \"p4\": 0.0008416816115512596, \"phi\": 0.014508731875616595}, {\"truth_threshold\": 53.05999881401658, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303898.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00020726343182184557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997927365681781, \"precision\": 1.0, \"recall\": 0.00020726343182184557, \"specificity\": 1.0, \"npv\": 0.9997624018025558, \"accuracy\": 0.9997624018142588, \"f1\": 0.0004144409651869589, \"f2\": 0.0002590658660571902, \"f0_5\": 0.0010354587082077361, \"p4\": 0.000828538509271476, \"phi\": 0.014394936137546725}, {\"truth_threshold\": 53.079998813569546, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00020397353607864166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997960264639214, \"precision\": 1.0, \"recall\": 0.00020397353607864166, \"specificity\": 1.0, \"npv\": 0.9997624010209062, \"accuracy\": 0.9997624010324235, \"f1\": 0.00040786387871970215, \"f2\": 0.0002549539191351963, \"f0_5\": 0.0010190362546801705, \"p4\": 0.000815395147693214, \"phi\": 0.014280233617651612}, {\"truth_threshold\": 53.23999880999327, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303900.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00020068364033543778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997993163596646, \"precision\": 1.0, \"recall\": 0.00020068364033543778, \"specificity\": 1.0, \"npv\": 0.9997624002392567, \"accuracy\": 0.9997624002505883, \"f1\": 0.0004012867489852708, \"f2\": 0.00025084196544960337, \"f0_5\": 0.0010026133692740092, \"p4\": 0.0008022515268087998, \"phi\": 0.014164602287057302}, {\"truth_threshold\": 53.2799988090992, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00019739374459223387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998026062554077, \"precision\": 1.0, \"recall\": 0.00019739374459223387, \"specificity\": 1.0, \"npv\": 0.999762399457607, \"accuracy\": 0.9997623994687529, \"f1\": 0.000394709575983238, \"f2\": 0.00024673000500039476, \"f0_5\": 0.0009861900519722157, \"p4\": 0.0007891076466105595, \"phi\": 0.014048019210246468}, {\"truth_threshold\": 53.35999880731106, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00019410384884902996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999805896151151, \"precision\": 1.0, \"recall\": 0.00019410384884902996, \"specificity\": 1.0, \"npv\": 0.9997623986759575, \"accuracy\": 0.9997623986869176, \"f1\": 0.00038813235971317674, \"f2\": 0.00024261803778755377, \"f0_5\": 0.0009697663027577524, \"p4\": 0.0007759635070908185, \"phi\": 0.013930460491941452}, {\"truth_threshold\": 53.659998800605536, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303903.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00019081395310582608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998091860468942, \"precision\": 1.0, \"recall\": 0.00019081395310582608, \"specificity\": 1.0, \"npv\": 0.9997623978943079, \"accuracy\": 0.9997623979050823, \"f1\": 0.0003815551001746601, \"f2\": 0.00023850606381106373, \"f0_5\": 0.0009533421216135809, \"p4\": 0.0007628191082419022, \"phi\": 0.013811901219918012}, {\"truth_threshold\": 53.739998798817396, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00018752405736262217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998124759426373, \"precision\": 1.0, \"recall\": 0.00018752405736262217, \"specificity\": 1.0, \"npv\": 0.9997623971126584, \"accuracy\": 0.999762397123247, \"f1\": 0.00037497779736726116, \"f2\": 0.00023439408307090792, \"f0_5\": 0.0009369175085226619, \"p4\": 0.0007496744500561356, \"phi\": 0.013692315403362092}, {\"truth_threshold\": 53.77999879792333, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00018423416161941829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998157658383806, \"precision\": 1.0, \"recall\": 0.00018423416161941829, \"specificity\": 1.0, \"npv\": 0.9997623963310087, \"accuracy\": 0.9997623963414117, \"f1\": 0.00036840045129055284, \"f2\": 0.00023028209556706967, \"f0_5\": 0.0009204924634679554, \"p4\": 0.0007365295325258434, \"phi\": 0.013571675906337581}, {\"truth_threshold\": 53.87999879568815, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00018094426587621438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998190557341238, \"precision\": 1.0, \"recall\": 0.00018094426587621438, \"specificity\": 1.0, \"npv\": 0.9997623955493592, \"accuracy\": 0.9997623955595764, \"f1\": 0.0003618230619441082, \"f2\": 0.00022617010129953228, \"f0_5\": 0.0009040669864324201, \"p4\": 0.00072338435564335, \"phi\": 0.013449954375882629}, {\"truth_threshold\": 54.01999879255891, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001776543701330105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998223456298669, \"precision\": 1.0, \"recall\": 0.0001776543701330105, \"specificity\": 1.0, \"npv\": 0.9997623947677096, \"accuracy\": 0.9997623947777411, \"f1\": 0.0003552456293275003, \"f2\": 0.00022205810026827908, \"f0_5\": 0.0008876410773990144, \"p4\": 0.0007102389194009796, \"phi\": 0.013327121164194749}, {\"truth_threshold\": 54.05999879166484, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303913.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001579149956737871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998420850043263, \"precision\": 1.0, \"recall\": 0.0001579149956737871, \"specificity\": 1.0, \"npv\": 0.9997623900778122, \"accuracy\": 0.9997623900867293, \"f1\": 0.00031578012493051194, \"f2\": 0.00019738595204179317, \"f0_5\": 0.0007890765502888349, \"p4\": 0.0006313608549594503, \"phi\": 0.012564930302391364}, {\"truth_threshold\": 54.199998788535595, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001546250999305832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998453749000694, \"precision\": 1.0, \"recall\": 0.0001546250999305832, \"specificity\": 1.0, \"npv\": 0.9997623892961627, \"accuracy\": 0.9997623893048939, \"f1\": 0.000309202389410805, \"f2\": 0.000193273903664062, \"f0_5\": 0.0007726476167930849, \"p4\": 0.0006182136029829899, \"phi\": 0.012433356721004903}, {\"truth_threshold\": 54.21999878808856, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00014804530844417542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998519546915559, \"precision\": 1.0, \"recall\": 0.00014804530844417542, \"specificity\": 1.0, \"npv\": 0.9997623877328635, \"accuracy\": 0.9997623877412233, \"f1\": 0.000296046788550226, \"f2\": 0.00018504978661703495, \"f0_5\": 0.0007397884533818196, \"p4\": 0.000591918320758505, \"phi\": 0.012165941437587025}, {\"truth_threshold\": 54.45999878272414, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001447554127009715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999855244587299, \"precision\": 1.0, \"recall\": 0.0001447554127009715, \"specificity\": 1.0, \"npv\": 0.999762386951214, \"accuracy\": 0.999762386959388, \"f1\": 0.00028946892320849986, \"f2\": 0.0001809377179477057, \"f0_5\": 0.0007233582234322033, \"p4\": 0.000578770290495123, \"phi\": 0.01203000485976757}, {\"truth_threshold\": 54.47999878227711, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001414655169577676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998585344830422, \"precision\": 1.0, \"recall\": 0.0001414655169577676, \"specificity\": 1.0, \"npv\": 0.9997623861695644, \"accuracy\": 0.9997623861775528, \"f1\": 0.00028289101459191325, \"f2\": 0.0001768256425144771, \"f0_5\": 0.0007069275612971957, \"p4\": 0.0005656220007874091, \"phi\": 0.011892514569863209}, {\"truth_threshold\": 54.49999878183007, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00013159582972815592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998684041702719, \"precision\": 1.0, \"recall\": 0.00013159582972815592, \"specificity\": 1.0, \"npv\": 0.9997623838246157, \"accuracy\": 0.9997623838320469, \"f1\": 0.0002631570290887201, \"f2\": 0.00016448937563122798, \"f0_5\": 0.0006576329816092936, \"p4\": 0.0005261755749214791, \"phi\": 0.011470159564295495}, {\"truth_threshold\": 54.539998780936, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303922.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000128305933984952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998716940660151, \"precision\": 1.0, \"recall\": 0.000128305933984952, \"specificity\": 1.0, \"npv\": 0.9997623830429662, \"accuracy\": 0.9997623830502115, \"f1\": 0.00025657894736842105, \"f2\": 0.0001603772731422349, \"f0_5\": 0.000641200590562185, \"p4\": 0.0005130262473596392, \"phi\": 0.011325875079628466}, {\"truth_threshold\": 54.55999878048897, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303923.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00012501603824174813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998749839617582, \"precision\": 1.0, \"recall\": 0.00012501603824174813, \"specificity\": 1.0, \"npv\": 0.9997623822613166, \"accuracy\": 0.9997623822683762, \"f1\": 0.0002500008223711262, \"f2\": 0.00015626516388925898, \"f0_5\": 0.0006247677672444125, \"p4\": 0.0004998766603150666, \"phi\": 0.01117972862879247}, {\"truth_threshold\": 54.819998774677515, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00012172614249854422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998782738575015, \"precision\": 1.0, \"recall\": 0.00012172614249854422, \"specificity\": 1.0, \"npv\": 0.9997623814796671, \"accuracy\": 0.9997623814865408, \"f1\": 0.00024342265409640852, \"f2\": 0.00015215304787228356, \"f0_5\": 0.0006083345116389189, \"p4\": 0.0004867268137800805, \"phi\": 0.011031646210456438}, {\"truth_threshold\": 54.95999877154827, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00011843624675534032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998815637532447, \"precision\": 1.0, \"recall\": 0.00011843624675534032, \"specificity\": 1.0, \"npv\": 0.9997623806980175, \"accuracy\": 0.9997623807047056, \"f1\": 0.0002368444425438409, \"f2\": 0.0001480409250912919, \"f0_5\": 0.0005919008237286464, \"p4\": 0.0004735767077469994, \"phi\": 0.010881548787606334}, {\"truth_threshold\": 54.979998771101236, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303926.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00011514635101213643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998848536489878, \"precision\": 1.0, \"recall\": 0.00011514635101213643, \"specificity\": 1.0, \"npv\": 0.999762379916368, \"accuracy\": 0.9997623799228703, \"f1\": 0.00023026618771299624, \"f2\": 0.00014392879554626735, \"f0_5\": 0.0005754667034965357, \"p4\": 0.00046042634220814154, \"phi\": 0.010729351794334036}, {\"truth_threshold\": 55.03999876976013, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00010856655952572862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998914334404743, \"precision\": 1.0, \"recall\": 0.00010856655952572862, \"specificity\": 1.0, \"npv\": 0.9997623783530689, \"accuracy\": 0.9997623783591997, \"f1\": 0.0002171095482147674, \"f2\": 0.00013570451616405277, \"f0_5\": 0.0005425971659985596, \"p4\": 0.00043412483258236794, \"phi\": 0.01041828977140934}, {\"truth_threshold\": 55.19999876618385, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00010527666378252473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998947233362174, \"precision\": 1.0, \"recall\": 0.00010527666378252473, \"specificity\": 1.0, \"npv\": 0.9997623775714194, \"accuracy\": 0.9997623775773643, \"f1\": 0.00021053116354652904, \"f2\": 0.00013159236632682937, \"f0_5\": 0.0005261617486985718, \"p4\": 0.0004209736884800873, \"phi\": 0.010259222567329546}, {\"truth_threshold\": 55.279998764395714, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00010198676803932083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998980132319607, \"precision\": 1.0, \"recall\": 0.00010198676803932083, \"specificity\": 1.0, \"npv\": 0.9997623767897698, \"accuracy\": 0.999762376795529, \"f1\": 0.00020395273559830522, \"f2\": 0.00012748020972550632, \"f0_5\": 0.0005097258990085009, \"p4\": 0.0004078222848413003, \"phi\": 0.010097649905601715}, {\"truth_threshold\": 55.29999876394868, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303931.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 9.869687229611694e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999013031277039, \"precision\": 1.0, \"recall\": 9.869687229611694e-05, \"specificity\": 1.0, \"npv\": 0.9997623760081202, \"accuracy\": 0.9997623760136938, \"f1\": 0.00019737426436966884, \"f2\": 0.0001233680463600669, \"f0_5\": 0.0004932896169112835, \"p4\": 0.00039467062165832385, \"phi\": 0.009933449529309338}, {\"truth_threshold\": 55.33999876305461, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 7.895749783689355e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999210425021631, \"precision\": 1.0, \"recall\": 7.895749783689355e-05, \"specificity\": 1.0, \"npv\": 0.999762371318223, \"accuracy\": 0.9997623713226819, \"f1\": 0.00015790252808526738, \"f2\": 9.869492412005251e-05, \"f0_5\": 0.000394662842822234, \"p4\": 0.00031575519170219093, \"phi\": 0.00888474733860036}, {\"truth_threshold\": 55.399998761713505, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303938.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 7.566760209368965e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999243323979063, \"precision\": 1.0, \"recall\": 7.566760209368965e-05, \"specificity\": 1.0, \"npv\": 0.9997623705365735, \"accuracy\": 0.9997623705408466, \"f1\": 0.00015132375388178325, \"f2\": 9.458271340533133e-05, \"f0_5\": 0.000378223533397138, \"p4\": 0.0003026017114947341, \"phi\": 0.008697679072143635}, {\"truth_threshold\": 55.49999875947833, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 7.237770635048575e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999276222936495, \"precision\": 1.0, \"recall\": 7.237770635048575e-05, \"specificity\": 1.0, \"npv\": 0.9997623697549239, \"accuracy\": 0.9997623697590113, \"f1\": 0.00014474493639446943, \"f2\": 9.04704959263603e-05, \"f0_5\": 0.0003617837914283553, \"p4\": 0.0002894479716816115, \"phi\": 0.008506497940891283}, {\"truth_threshold\": 55.61999875679612, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.908781060728186e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999309121893927, \"precision\": 1.0, \"recall\": 6.908781060728186e-05, \"specificity\": 1.0, \"npv\": 0.9997623689732744, \"accuracy\": 0.999762368977176, \"f1\": 0.00013816607562289874, \"f2\": 8.635827168312271e-05, \"f0_5\": 0.00034534361689881433, \"p4\": 0.0002762939722551373, \"phi\": 0.008310920117526882}, {\"truth_threshold\": 55.71999875456095, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303941.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.579791486407796e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999934202085136, \"precision\": 1.0, \"recall\": 6.579791486407796e-05, \"specificity\": 1.0, \"npv\": 0.9997623681916249, \"accuracy\": 0.9997623681953407, \"f1\": 0.00013158717156664396, \"f2\": 8.224604067560188e-05, \"f0_5\": 0.0003289030097914426, \"p4\": 0.00026313971320762524, \"phi\": 0.008110627545793328}, {\"truth_threshold\": 55.81999875232577, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.250801912087407e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999374919808791, \"precision\": 1.0, \"recall\": 6.250801912087407e-05, \"specificity\": 1.0, \"npv\": 0.9997623674099754, \"accuracy\": 0.9997623674135054, \"f1\": 0.00012500822422527799, \"f2\": 7.81338029037811e-05, \"f0_5\": 0.00031246197008916675, \"p4\": 0.0002499851945313888, \"phi\": 0.007905261866528715}, {\"truth_threshold\": 55.939998749643564, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 5.921812337767016e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999407818766223, \"precision\": 1.0, \"recall\": 5.921812337767016e-05, \"specificity\": 1.0, \"npv\": 0.9997623666283258, \"accuracy\": 0.9997623666316701, \"f1\": 0.00011842923359837357, \"f2\": 7.40215583676437e-05, \"f0_5\": 0.00029602049777491257, \"p4\": 0.00023683041621874127, \"phi\": 0.007694416883386792}, {\"truth_threshold\": 55.979998748749495, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 5.5928227634466266e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999440717723656, \"precision\": 1.0, \"recall\": 5.5928227634466266e-05, \"specificity\": 1.0, \"npv\": 0.9997623658466763, \"accuracy\": 0.9997623658498348, \"f1\": 0.00011185019968550356, \"f2\": 6.990930706717297e-05, \"f0_5\": 0.0002795785928316049, \"p4\": 0.00022367537826199549, \"phi\": 0.007477629114729176}, {\"truth_threshold\": 56.099998746067286, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 5.2638331891262364e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999473616681087, \"precision\": 1.0, \"recall\": 5.2638331891262364e-05, \"specificity\": 1.0, \"npv\": 0.9997623650650268, \"accuracy\": 0.9997623650679994, \"f1\": 0.00010527112248624073, \"f2\": 6.579704900235225e-05, \"f0_5\": 0.0002631362552421676, \"p4\": 0.00021052008065346398, \"phi\": 0.00725436580168703}, {\"truth_threshold\": 56.39999873936176, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303948.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 4.2768644661650676e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999572313553383, \"precision\": 1.0, \"recall\": 4.2768644661650676e-05, \"specificity\": 1.0, \"npv\": 0.9997623627200782, \"accuracy\": 0.9997623627224935, \"f1\": 8.553363116582339e-05, \"f2\": 5.34602342216231e-05, \"f0_5\": 0.00021380664642630415, \"p4\": 0.00017105262984027676, \"phi\": 0.006538996959570125}, {\"truth_threshold\": 56.479998737573624, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303949.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 3.947874891844677e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999605212510816, \"precision\": 1.0, \"recall\": 3.947874891844677e-05, \"specificity\": 1.0, \"npv\": 0.9997623619384287, \"accuracy\": 0.9997623619406583, \"f1\": 7.895438081671727e-05, \"f2\": 4.9347949099235435e-05, \"f0_5\": 0.00019736257808156994, \"p4\": 0.00015789629354772232, \"phi\": 0.006282465062782326}, {\"truth_threshold\": 56.49999873712659, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 1.9739374459223386e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999802606255408, \"precision\": 1.0, \"recall\": 1.9739374459223386e-05, \"specificity\": 1.0, \"npv\": 0.9997623572485316, \"accuracy\": 0.9997623572496465, \"f1\": 3.9477969648021004e-05, \"f2\": 2.4674096311222602e-05, \"f0_5\": 9.868908005329211e-05, \"p4\": 7.89528220284883e-05, \"phi\": 0.004442373638041338}, {\"truth_threshold\": 56.81999872997403, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 1.644947871601949e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999983550521284, \"precision\": 1.0, \"recall\": 1.644947871601949e-05, \"specificity\": 1.0, \"npv\": 0.9997623564668822, \"accuracy\": 0.9997623564678111, \"f1\": 3.289841627024075e-05, \"f2\": 2.056176383745021e-05, \"f0_5\": 8.224198222915248e-05, \"p4\": 6.579466774285809e-05, \"phi\": 0.0040553137491172574}, {\"truth_threshold\": 57.179998721927404, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 1.3159582972815591e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999868404170272, \"precision\": 1.0, \"recall\": 1.3159582972815591e-05, \"specificity\": 1.0, \"npv\": 0.9997623556852326, \"accuracy\": 0.9997623556859758, \"f1\": 2.63188196009409e-05, \"f2\": 1.6449424599127523e-05, \"f0_5\": 6.579445155390046e-05, \"p4\": 5.263625371316953e-05, \"phi\": 0.003627182883828356}, {\"truth_threshold\": 57.19999872148037, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303958.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 9.869687229611693e-06, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999901303127704, \"precision\": 1.0, \"recall\": 9.869687229611693e-06, \"specificity\": 1.0, \"npv\": 0.9997623549035831, \"accuracy\": 0.9997623549041404, \"f1\": 1.9739179639694174e-05, \"f2\": 1.233707859623785e-05, \"f0_5\": 4.9346488010448293e-05, \"p4\": 3.9477579931731253e-05, \"phi\": 0.0031412325203394936}, {\"truth_threshold\": 58.339998695999384, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.5797914864077955e-06, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999934202085136, \"precision\": 1.0, \"recall\": 6.5797914864077955e-06, \"specificity\": 1.0, \"npv\": 0.9997623541219336, \"accuracy\": 0.9997623541223052, \"f1\": 1.3159496386073305e-05, \"f2\": 8.224725828764498e-06, \"f0_5\": 3.289809158170734e-05, \"p4\": 2.631864639085161e-05, \"phi\": 0.0025648056117535526}, {\"truth_threshold\": 59.0199986808002, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 3.2898957432038977e-06, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999967101042568, \"precision\": 1.0, \"recall\": 3.2898957432038977e-06, \"specificity\": 1.0, \"npv\": 0.9997623533402841, \"accuracy\": 0.9997623533404699, \"f1\": 6.579769839651009e-06, \"f2\": 4.112366296690779e-06, \"f0_5\": 1.644926225058806e-05, \"p4\": 1.3159453082838614e-05, \"phi\": 0.0018135914397872834}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.roc_chart_from_labels_column(\"cluster\", match_weight_round_to_nearest=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:44.268428Z",
     "iopub.status.busy": "2024-05-15T16:07:44.268099Z",
     "iopub.status.idle": "2024-05-15T16:07:47.826572Z",
     "shell.execute_reply": "2024-05-15T16:07:47.826055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-653750341bfa44a484a83422bbdc2c81.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-653750341bfa44a484a83422bbdc2c81.vega-embed details,\n",
       "  #altair-viz-653750341bfa44a484a83422bbdc2c81.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-653750341bfa44a484a83422bbdc2c81\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-653750341bfa44a484a83422bbdc2c81\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-653750341bfa44a484a83422bbdc2c81\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-abd50419f89d7e7fe37f99307f30e7a5\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 54, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-abd50419f89d7e7fe37f99307f30e7a5\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.972133924152017, \"bayes_factor\": 1004.4109343684402, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.972133924152017, \"bayes_factor\": 1004.4109343684402, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.972133924152017, \"bayes_factor\": 1004.4109343684402, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.972133924152017, \"bayes_factor\": 1004.4109343684402, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.972133924152017, \"bayes_factor\": 1004.4109343684402, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.972133924152017, \"bayes_factor\": 1004.4109343684402, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 6}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 6}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 7}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 7}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 8}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 8}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 9}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 9}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 9}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 10}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 10}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 10}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 10}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 10}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 10}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 10}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 10}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 10}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 11}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 11}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 11}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 11}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 11}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 11}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 11}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 12}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 12}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 12}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 12}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 12}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 12}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 12}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 13}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 13}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 13}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 13}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 13}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 13}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.157552153406682, \"bayes_factor\": 1142.1624568384611, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 13}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 14}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"georgie\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 14}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 4.704000507643694, \"log2_bayes_factor\": 2.2338882158662416, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 4.70 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"georgie\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 14}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 14}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.0636897328768884, \"log2_bayes_factor\": 0.08907739321065683, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.06 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 14}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-01-01\", \"value_r\": \"1857-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 14}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ip29 5qh\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 14}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 14}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football manager\", \"value_r\": \"rugby union player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 14}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.20380824248877, \"bayes_factor\": 1179.3761771732316, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 14}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 15}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 25.877922195583377, \"log2_bayes_factor\": 4.693649879201223, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"george\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 15}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 15}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 15}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.0636897328768884, \"log2_bayes_factor\": 0.08907739321065683, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.06 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 15}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-01-01\", \"value_r\": \"1857-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 15}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 15}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 15}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"rugby union player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 15}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.426405459452997, \"bayes_factor\": 1376.1342065879128, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 15}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 16}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 16}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 16}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 16}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.6893895757456465, \"log2_bayes_factor\": 0.7565020541237861, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.69 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 16}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1499-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 16}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"essex\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 16}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.143856895885099, \"bayes_factor\": 2262.7428072699345, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 16}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 17}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 17}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 17}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 17}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.6893895757456465, \"log2_bayes_factor\": 0.7565020541237861, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.69 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 17}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1499-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 17}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"essex\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 17}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.143856895885099, \"bayes_factor\": 2262.7428072699345, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 17}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 18}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 18}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 18}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 18}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.6893895757456465, \"log2_bayes_factor\": 0.7565020541237861, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.69 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 18}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1499-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 18}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"essex\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 18}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.143856895885099, \"bayes_factor\": 2262.7428072699345, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 18}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 19}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 19}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 19}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 19}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.1046008764490765, \"log2_bayes_factor\": 0.14352517723303326, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.10 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 19}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 19}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 19}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8137585316807603, \"log2_bayes_factor\": 0.8589824005550517, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.81 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 19}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.49970678032802, \"bayes_factor\": 2895.72077692764, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 19}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 20}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 20}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 20}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 20}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 20}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-81\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 20}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol3 7ne\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 20}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 20}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 20}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.626967688994473, \"bayes_factor\": 3162.7585103180313, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 20}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 21}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 21}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 21}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 21}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 21}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-81\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 21}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol3 7ne\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 21}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 21}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 21}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.626967688994473, \"bayes_factor\": 3162.7585103180313, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 21}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 22}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 22}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 22}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 22}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.6893895757456465, \"log2_bayes_factor\": 0.7565020541237861, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.69 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1544-01-01\", \"value_r\": \"1498-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 22}, {\"sql_condition\": \"levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 2\", \"label_for_charts\": \"Levenshtein distance of postcode_fake <= 2\", \"m_probability\": 0.05611758855446276, \"u_probability\": 0.0005028225272029813, \"bayes_factor\": 111.60515990925164, \"log2_bayes_factor\": 6.802259919481257, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of postcode_fake <= 2` then comparison is 111.61 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4tl\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 22}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 22}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.1559771225639226, \"log2_bayes_factor\": 1.108341869491769, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 2.16 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 22}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 22}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 22}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.919711515469755, \"bayes_factor\": 3874.277334357177, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 22}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 23}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 25.877922195583377, \"log2_bayes_factor\": 4.693649879201223, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"willie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 23}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 23}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 23}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.1046008764490765, \"log2_bayes_factor\": 0.14352517723303326, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.10 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 23}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 23}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 23}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8137585316807603, \"log2_bayes_factor\": 0.8589824005550517, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.81 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 23}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 12.86708903833032, \"bayes_factor\": 7471.017564017691, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 23}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 24}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 25.877922195583377, \"log2_bayes_factor\": 4.693649879201223, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"will\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 24}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 24}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 24}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.1046008764490765, \"log2_bayes_factor\": 0.14352517723303326, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.10 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 24}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 24}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 24}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3616941455096472, \"log2_bayes_factor\": 0.44540269137599076, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 1.36 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 24}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 12.960625155043115, \"bayes_factor\": 7971.442802022406, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 24}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 25}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"ed\", \"value_r\": \"ed\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 25}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 6.749218119662691, \"log2_bayes_factor\": 2.7547203791676824, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 6.75 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"ed\", \"value_r\": \"ed\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thomas\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 25}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 25}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 25}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 25}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.6275170633615206, \"log2_bayes_factor\": 1.8589824005550517, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.63 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 25}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 12.988427410416163, \"bayes_factor\": 8126.550659899482, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 25}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 26}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 26}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 26}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 26}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 26}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 26}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"ch42 0ns\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 26}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.22382393136636, \"bayes_factor\": 9566.821276424358, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 26}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 27}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 27}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 27}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 27}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 27}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 27}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"ch42 0ns\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 27}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 27}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 27}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.22382393136636, \"bayes_factor\": 9566.821276424358, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 27}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 28}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 28}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 28}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 28}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 28}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 28}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 28}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.22382393136636, \"bayes_factor\": 9566.821276424358, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 28}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 29}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 29}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 38.80800418806047, \"log2_bayes_factor\": 5.278282335224695, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 38.81 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 29}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 29}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7004786045774631, \"log2_bayes_factor\": -0.5135871092439582, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.43 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 29}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 29}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 29}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.22382393136636, \"bayes_factor\": 9566.821276424358, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 29}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 30}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 30}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 30}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 30}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 30}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 30}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"oswestry\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 30}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.838127395580912, \"bayes_factor\": 14645.06925950887, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 30}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 31}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 31}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 31}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 31}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 31}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 31}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"oswestry\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 31}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.838127395580912, \"bayes_factor\": 14645.06925950887, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 31}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 32}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 32}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 32}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 32}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 32}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 32}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 32}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 32}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 32}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 15.384902282551003, \"bayes_factor\": 42787.51529662188, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 32}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 33}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 33}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 14.78400159545161, \"log2_bayes_factor\": 3.885964912445935, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 14.78 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 33}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 33}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.6108747988796353, \"log2_bayes_factor\": 1.3845332767368281, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.61 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 33}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 33}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 33}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 33}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.39606694760423106, \"log2_bayes_factor\": -1.336183783740976, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 33}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 15.384902282551003, \"bayes_factor\": 42787.51529662188, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 33}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 34}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 25.877922195583377, \"log2_bayes_factor\": 4.693649879201223, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"will\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 34}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.100457502474888, \"u_probability\": 0.0038819771431275584, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 25.88 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 34}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 34}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.1046008764490765, \"log2_bayes_factor\": 0.14352517723303326, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.10 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 34}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6142808770483297, \"u_probability\": 0.0020903705879473248, \"bayes_factor\": 293.862189120989, \"log2_bayes_factor\": 8.198995930945316, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 293.86 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 34}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 34}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 34}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3616941455096472, \"log2_bayes_factor\": 0.44540269137599076, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 1.36 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 34}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 15.514571348946845, \"bayes_factor\": 46811.36939155456, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 34}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 35}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 35}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 35}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 35}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.6893895757456465, \"log2_bayes_factor\": 0.7565020541237861, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.69 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1544-01-01\", \"value_r\": \"1498-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 35}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 35}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 35}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.1559771225639226, \"log2_bayes_factor\": 1.108341869491769, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 2.16 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 35}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 17.407260495695677, \"bayes_factor\": 173823.1242465994, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 35}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 36}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 36}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 36}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 36}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 36}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 36}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 36}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 36}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 36}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 18.09204959876405, \"bayes_factor\": 279414.93268866907, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 36}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 37}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 37}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 37}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 37}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 37}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 37}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 37}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 37}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 37}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 18.09204959876405, \"bayes_factor\": 279414.93268866907, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 37}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 38}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 38}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 38}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 38}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1680-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 38}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 38}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 38}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 38}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 21.601890944798644, \"bayes_factor\": 3182857.076598171, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 38}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 39}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 39}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 39}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 39}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1680-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 39}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 39}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 39}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 39}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 21.601890944798644, \"bayes_factor\": 3182857.076598171, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 39}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 40}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 40}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 40}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 40}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.6893895757456465, \"log2_bayes_factor\": 0.7565020541237861, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.69 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 40}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1498-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 40}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.1559771225639226, \"log2_bayes_factor\": 1.108341869491769, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 2.16 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 40}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 22.258492296035428, \"bayes_factor\": 5017343.551067133, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 40}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 41}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 41}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.47544262404974547, \"log2_bayes_factor\": -1.0726568463217356, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 41}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 41}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.8974882121148746, \"log2_bayes_factor\": -0.15603510462587458, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.11 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 41}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1655-01-11\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 41}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ec1m 3ln\", \"value_r\": \"ec1m 3ln\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7164061911967893, \"log2_bayes_factor\": -0.4811502897099013, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison  1.40 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.4201937469914163, \"log2_bayes_factor\": -1.250873401823565, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.38 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 41}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.18383497642045, \"bayes_factor\": 19057228.359918725, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 41}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 42}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 42}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.47544262404974547, \"log2_bayes_factor\": -1.0726568463217356, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  2.10 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 42}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 42}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.8974882121148746, \"log2_bayes_factor\": -0.15603510462587458, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.11 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 42}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1655-01-11\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 42}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ec1m 3ln\", \"value_r\": \"ec1m 3ln\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7164061911967893, \"log2_bayes_factor\": -0.4811502897099013, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison  1.40 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.4201937469914163, \"log2_bayes_factor\": -1.250873401823565, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.38 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 42}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.18383497642045, \"bayes_factor\": 19057228.359918725, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 42}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 43}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 43}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 43}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 43}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 43}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 43}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 43}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.27129231415674, \"bayes_factor\": 20248227.89043521, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 43}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 44}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 44}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 44}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 44}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 44}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 44}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 44}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.27129231415674, \"bayes_factor\": 20248227.89043521, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 44}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 45}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 45}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.6815895356849261, \"log2_bayes_factor\": -0.5530249085773554, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.47 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 45}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 45}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.914641519178399, \"log2_bayes_factor\": 0.9370742997656067, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 45}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 45}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.6275170633615206, \"log2_bayes_factor\": 1.8589824005550517, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.63 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 45}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.728002749882187, \"bayes_factor\": 444621585.7227503, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 45}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 46}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 46}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.6815895356849261, \"log2_bayes_factor\": -0.5530249085773554, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.47 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 46}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 46}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.914641519178399, \"log2_bayes_factor\": 0.9370742997656067, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 46}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 46}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.6275170633615206, \"log2_bayes_factor\": 1.8589824005550517, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.63 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 46}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.728002749882187, \"bayes_factor\": 444621585.7227503, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 46}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 47}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 47}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.6815895356849261, \"log2_bayes_factor\": -0.5530249085773554, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.47 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 47}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 47}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.914641519178399, \"log2_bayes_factor\": 0.9370742997656067, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 47}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 47}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.6275170633615206, \"log2_bayes_factor\": 1.8589824005550517, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.63 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 47}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.728002749882187, \"bayes_factor\": 444621585.7227503, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 47}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 48}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 48}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.6815895356849261, \"log2_bayes_factor\": -0.5530249085773554, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.47 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 48}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 48}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.914641519178399, \"log2_bayes_factor\": 0.9370742997656067, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 48}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 48}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.6275170633615206, \"log2_bayes_factor\": 1.8589824005550517, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.63 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 48}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.728002749882187, \"bayes_factor\": 444621585.7227503, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 48}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 49}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 49}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 49}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 49}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 49}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 49}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 49}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.381858498471228, \"bayes_factor\": 1399106364.0769026, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 49}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 50}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 50}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 50}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 50}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 50}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 50}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 50}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 50}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 50}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 50}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 50}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.381858498471228, \"bayes_factor\": 1399106364.0769026, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 50}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 51}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 51}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 51}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 51}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 51}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 51}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 51}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 51}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 51}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 51}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 51}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.381858498471228, \"bayes_factor\": 1399106364.0769026, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 51}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 52}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 52}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 52}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 52}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 52}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 52}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 52}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 52}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 52}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 52}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 52}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.381858498471228, \"bayes_factor\": 1399106364.0769026, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 52}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 53}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 53}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 53}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 53}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 53}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 53}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 53}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 53}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 53}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 53}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 53}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.381858498471228, \"bayes_factor\": 1399106364.0769026, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 53}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 54}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5520331483113572, \"u_probability\": 0.012292927619903934, \"bayes_factor\": 44.90656460203507, \"log2_bayes_factor\": 5.4888544535850965, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 44.91 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 54}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.22335541978739842, \"log2_bayes_factor\": -2.1625868323861748, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  4.48 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 54}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808260580697907, \"u_probability\": 0.0006234857214613896, \"bayes_factor\": 1252.3559581117763, \"log2_bayes_factor\": 10.290428963557149, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,252.36 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 54}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7179905696918997, \"log2_bayes_factor\": -0.47796319951323696, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.39 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 54}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3387321638685843, \"u_probability\": 0.022242783244398753, \"bayes_factor\": 15.228856935153782, \"log2_bayes_factor\": 3.9287357533328375, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 15.23 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 54}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6872360790281722, \"u_probability\": 0.00013724762297795306, \"bayes_factor\": 5007.271267193948, \"log2_bayes_factor\": 12.28980889970718, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 5,007.27 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 54}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8440643138505439, \"u_probability\": 0.005235471695763575, \"bayes_factor\": 161.22029931582702, \"log2_bayes_factor\": 7.332889595417968, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 161.22 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 54}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3443151470104457, \"log2_bayes_factor\": 0.4268713879172663, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 54}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8989343034777655, \"u_probability\": 0.03736864790951383, \"bayes_factor\": 24.055842364285873, \"log2_bayes_factor\": 4.58831541409548, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.06 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 54}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.8723882583091043, \"log2_bayes_factor\": 1.5222507702190105, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.87 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 54}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.381858498471228, \"bayes_factor\": 1399106364.0769026, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 54}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.999,\n",
    "    include_false_negatives=False,\n",
    "    include_false_positives=True,\n",
    ").as_record_dict()\n",
    "linker.waterfall_chart(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:07:47.834324Z",
     "iopub.status.busy": "2024-05-15T16:07:47.834092Z",
     "iopub.status.idle": "2024-05-15T16:07:51.080047Z",
     "shell.execute_reply": "2024-05-15T16:07:51.079464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2d2a1a64c2944c6188676a4e65fbe399.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2d2a1a64c2944c6188676a4e65fbe399.vega-embed details,\n",
       "  #altair-viz-2d2a1a64c2944c6188676a4e65fbe399.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2d2a1a64c2944c6188676a4e65fbe399\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2d2a1a64c2944c6188676a4e65fbe399\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2d2a1a64c2944c6188676a4e65fbe399\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-f0af9a4ddf349e0548f02c48a0f89a37\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 49, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-f0af9a4ddf349e0548f02c48a0f89a37\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"rt.\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"spicer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1817-03-16\", \"value_r\": \"1847-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"se5 7aq\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"southwark\", \"value_r\": \"brixton\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"businessperson\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -29.57317267573071, \"bayes_factor\": 1.2519528053389664e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"joseph\", \"value_r\": \"jozef\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"conrad\", \"value_r\": \"korzeniowski\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-12-08\", \"value_r\": \"1857-42-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"fy6 8jx\", \"value_r\": \"fy3 9dl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"berdychiv\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"science fiction writer\", \"value_r\": \"autobiographer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -29.453714934393847, \"bayes_factor\": 1.3600294761529441e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"morfudd\", \"value_r\": \"anna\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thomas\", \"value_r\": \"fison\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1889-02-14\", \"value_r\": \"1839-82-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ip6 8ru\", \"value_r\": \"ip14 2ae\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"mid suffolk\", \"value_r\": \"suffolk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.875428862420097, \"bayes_factor\": 2.0306252153669294e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"thomas\", \"value_r\": \"t.\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"whittaker\", \"value_r\": \"w-r\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1856-01-81\", \"value_r\": \"1856-04-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"pe15 0ds\", \"value_r\": \"pe14 9pa\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"fenland\", \"value_r\": \"march\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.875428862420097, \"bayes_factor\": 2.0306252153669294e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"henfy\", \"value_r\": \"real\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stubbe\", \"value_r\": \"societies,\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1632-05-28\", \"value_r\": \"1622-02-28\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ln4 4qa\", \"value_r\": \"ln4 3lh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"lincolnshire\", \"value_r\": \"east lindsey\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"writer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.875428862420097, \"bayes_factor\": 2.0306252153669294e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"c.\", \"value_r\": \"charlotte\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"m.\", \"value_r\": \"duffield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1831-01-07\", \"value_r\": \"1831-21-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"se11 6ez\", \"value_r\": \"ba2 4ll\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"bath and north east somerset\", \"value_r\": \"bath\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 5}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 5}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.875428862420097, \"bayes_factor\": 2.0306252153669294e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-00-27\", \"value_r\": \"1851-02-27\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"bo0 8au\", \"value_r\": \"b14 6ph\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"solihull\", \"value_r\": \"cheswick green\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 6}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"military personnel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 6}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.875428862420097, \"bayes_factor\": 2.0306252153669294e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"jack\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"seigne\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1844-12-74\", \"value_r\": \"1844-02-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"yo17 6sb\", \"value_r\": \"yo60 7pl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"malton\", \"value_r\": \"ryedale\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 7}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"land agent\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 7}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.875428862420097, \"bayes_factor\": 2.0306252153669294e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"harry\", \"value_r\": \"real\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stubbe\", \"value_r\": \"societies,\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 10 year'\", \"m_probability\": 0.013865806714415225, \"u_probability\": 0.19440936016057178, \"bayes_factor\": 0.07132273211003218, \"log2_bayes_factor\": -3.809494221443063, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 10 year'` then comparison is  14.02 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1632-02-26\", \"value_r\": \"1622-02-28\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ln4 4xt\", \"value_r\": \"ln4 3lh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"lincolnshire\", \"value_r\": \"east lindsey\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 8}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"classical philologist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 8}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.83369128352341, \"bayes_factor\": 4.18045962738516e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"elizabeth\", \"value_r\": \"gabriel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"siddal\", \"value_r\": \"dante\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1829-07-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"nw1 3jn\", \"value_r\": \"wc1r 4th\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"holborn\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"visual artist\", \"value_r\": \"model\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.27588706929469, \"bayes_factor\": 6.153749787714421e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 9}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"lord\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"mcauley\", \"value_r\": \"babington\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1800-11-25\", \"value_r\": \"1880-10-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 10}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 10}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"rothley court\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 10}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 0.10498899324518825, \"log2_bayes_factor\": -3.251690007214343, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"historian\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10106569652223449, \"u_probability\": 0.9626313520904862, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 10}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.899768740490117, \"bayes_factor\": 7.98661469106267e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 10}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"john\", \"value_r\": \"jack\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bond\", \"value_r\": \"pearce\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1855-01-01\", \"value_r\": \"1845-00-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 11}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"tf2 9tu\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"telford and wrekin\", \"value_r\": \"oakengates\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 11}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 11}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"5th\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"fletcher-vane\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-10-16\", \"value_r\": \"1861-70-16\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 12}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ch3 7ah\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"dublin\", \"value_r\": \"ireland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 12}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 12}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"5th\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"fletcher-vane\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1864-10-16\", \"value_r\": \"1861-70-16\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 13}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"bb1 4ah\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"dublin\", \"value_r\": \"ireland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 13}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 13}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"george\", \"value_r\": \"1st\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"jeffreys\", \"value_r\": \"wem\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1675-05-15\", \"value_r\": \"1645-05-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 14}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ll13 7jb\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wrexham\", \"value_r\": \"offa\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 14}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"judge\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 14}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 14}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 14}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"flinders\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"petrie\", \"value_r\": \"flinders\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-08-03\", \"value_r\": \"1853-86-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 15}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"se7 8uq\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"charlton\", \"value_r\": \"greenwich\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"egyptologist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 15}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 15}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"andrew\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"taylor\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-10-18\", \"value_r\": \"1850-00-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 16}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"city of edinburgh\", \"value_r\": \"edinburgh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 16}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 16}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bobby\", \"value_r\": \"robert\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baron\", \"value_r\": \"chalmers\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1858-08-48\", \"value_r\": \"1858-09-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 17}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"rm2 6gp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"stoke newington\", \"value_r\": \"hackney\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 17}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 17}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"anne\", \"value_r\": \"julia\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cobden-sanderson\", \"value_r\": \"sarah\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-01-81\", \"value_r\": \"1883-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 18}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"n1 8sy\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"london\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 18}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 18}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"francesca\", \"value_r\": \"darley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"steele\", \"value_r\": \"dale\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1878-01-01\", \"value_r\": \"1849-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 19}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"pe19 6ry\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"huntingdonshire\", \"value_r\": \"yelling\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 19}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 19}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 19}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 19}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bobby\", \"value_r\": \"robert\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baron\", \"value_r\": \"chalmers\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1858-08-48\", \"value_r\": \"1859-08-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 20}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"stoke newington\", \"value_r\": \"hackney\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 20}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 20}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"1st\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"john\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-23-07\", \"value_r\": \"1853-03-87\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 21}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sk10 2ly\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"macclesfield\", \"value_r\": \"cheshire east\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 21}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 21}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"alexander\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"sprot\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-05-24\", \"value_r\": \"1853-24-24\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 22}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl7 6ew\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"cotswold\", \"value_r\": \"somerford keynes\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 22}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 22}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 22}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 22}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"thompson\", \"value_r\": \"ernest\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"meysey-thompson\", \"value_r\": \"thompson\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1829-02-18\", \"value_r\": \"1859-82-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 23}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sa14 7aq\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"carmarthenshire\", \"value_r\": \"gorslas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 23}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 23}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 23}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 23}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1868-11-08\", \"value_r\": \"1860-71-08\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 24}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"renfrewshire\", \"value_r\": \"paisley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 24}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 24}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"frank\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"adam\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1846-86-17\", \"value_r\": \"1846-06-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 25}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ne5 1ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"woolsington\", \"value_r\": \"newcastle upon tyne\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 25}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 25}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"arthur\", \"value_r\": \"young\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"perigal\", \"value_r\": \"artie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1816-88-17\", \"value_r\": \"1816-06-17\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 26}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"wc2r 0bp\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"westminster\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 26}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 26}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"2nd\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"bonham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-08-28\", \"value_r\": \"1847-28-28\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 27}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"rhondda cynon taf\", \"value_r\": \"pont-y-clun\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 27}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"diplomat\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 27}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 27}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 27}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"dame\", \"value_r\": \"mary\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stewart-mackenzie\", \"value_r\": \"helier\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1842-05-18\", \"value_r\": \"1845-05-48\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 28}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"pe34 4px\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"germany\", \"value_r\": \"munich\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"essayist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 28}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 28}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"dame\", \"value_r\": \"mary\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stewart-mackenzie\", \"value_r\": \"helier\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1842-05-18\", \"value_r\": \"1855-05-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 29}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"pe34 4px\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"germany\", \"value_r\": \"munich\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"essayist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 29}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 29}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"baron\", \"value_r\": \"6th\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"robartes\", \"value_r\": \"gowran\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1844-01-04\", \"value_r\": \"1844-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 30}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"w1h 7as\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"westminster\", \"value_r\": \"grosvenor place\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 30}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 30}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"james\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"morrow\", \"value_r\": \"wolfe-murray\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-03-18\", \"value_r\": \"1823-03-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 31}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"bl6 6bw\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"ireland\", \"value_r\": \"ireland | united kingdom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"military personnel\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 31}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 31}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"james\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"murray\", \"value_r\": \"wolfe-murray\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-03-43\", \"value_r\": \"1823-03-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 32}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"bl6 6bw\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"ireland\", \"value_r\": \"ireland | united kingdom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"military personnel\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 32}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 32}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"eddie\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"jack\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1805-12-07\", \"value_r\": \"1805-12-88\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 33}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"s43 3dt\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"staveley\", \"value_r\": \"chesterfield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 33}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 33}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"franciscus\", \"value_r\": \"the\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"junius\", \"value_r\": \"jon\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1581-01-29\", \"value_r\": \"1591-01-59\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 34}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"heidelberg\", \"value_r\": \"germany\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 34}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 34}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bert\", \"value_r\": \"herbie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"wight\", \"value_r\": \"white\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1838-01-01\", \"value_r\": \"1830-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 35}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sr8 2pp\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"easington village\", \"value_r\": \"county durham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"cricketer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 35}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 35}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"david\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"morrow\", \"value_r\": \"murray\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1848-01-29\", \"value_r\": \"1849-01-59\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 36}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"g5 9ne\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"glasgow city\", \"value_r\": \"glasgow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 36}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 36}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"trader\", \"value_r\": \"fred\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"horn\", \"value_r\": \"smythe\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1831-01-01\", \"value_r\": \"1861-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 37}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"ex20 1qt\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"west devon\", \"value_r\": \"belstone\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"adventurer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 37}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 37}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"martin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"martin\", \"value_r\": \"allington\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1856-04-15\", \"value_r\": \"1856-04-72\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 38}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"me2 4sn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"rochester\", \"value_r\": \"medway\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 38}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 38}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"fuller\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"fuller-maitland\", \"value_r\": \"maitland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1874-05-06\", \"value_r\": \"1844-05-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 39}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"bd20 9fa\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 0.15675637973870843, \"log2_bayes_factor\": -2.673403935240592, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"bradford\", \"value_r\": \"silsden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.15593568614945605, \"u_probability\": 0.9947645283042365, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.38 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 39}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.321482668516367, \"bayes_factor\": 1.192461006283956e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 39}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"owen\", \"value_r\": \"hugh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"hall\", \"value_r\": \"lusk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1887-01-01\", \"value_r\": \"1837-00-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"de45 1qs\", \"value_r\": \"ol6 8ug\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"tameside\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 40}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 40}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"owen\", \"value_r\": \"hugh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"hall\", \"value_r\": \"lusk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1887-01-01\", \"value_r\": \"1837-81-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"de45 1qs\", \"value_r\": \"ol14 7aq\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"tameside\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 41}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 41}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"owen\", \"value_r\": \"hugh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"hall\", \"value_r\": \"lusk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1887-01-01\", \"value_r\": \"1837-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"de45 1qs\", \"value_r\": \"ol6 8ug\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"tameside\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 42}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 42}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"hughes\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"lusk\", \"value_r\": \"hall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1837-00-01\", \"value_r\": \"1887-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol6 8ug\", \"value_r\": \"de45 1qs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tameside\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 43}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 43}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"hugh\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"lusk\", \"value_r\": \"hall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1831-01-01\", \"value_r\": \"1887-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol6 8ug\", \"value_r\": \"de45 1qs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tameside\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 44}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 44}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bob\", \"value_r\": \"robert\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stephenson\", \"value_r\": \"sitivensin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-11-03\", \"value_r\": \"1850-17-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"e5 0ry\", \"value_r\": \"bh4 8an\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"edinburgh\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"short story writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 45}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 45}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"georgie\", \"value_r\": \"clift\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"rey\", \"value_r\": \"king\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1848-14-23\", \"value_r\": \"1848-07-23\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ss3 0qh\", \"value_r\": \"cm2 6dh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 46}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 46}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"mr.\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cousins\", \"value_r\": \"cozens\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1762-01-01\", \"value_r\": \"1752-81-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"w10 5az\", \"value_r\": \"w1t 2rf\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"london\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 47}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 47}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"mrs.\", \"value_r\": \"annie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"smyth\", \"value_r\": \"burnett-smith\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1849-07-08\", \"value_r\": \"1859-87-08\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"wf2 0xg\", \"value_r\": \"hg3 1tl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"leeds\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"autobiographer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 48}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 48}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 0.23981293553411973, \"log2_bayes_factor\": -2.0600186149192092, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"prince\", \"value_r\": \"fred\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23430378048458858, \"u_probability\": 0.9770272815465064, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.17 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 0.06740121411265958, \"log2_bayes_factor\": -3.8910816105554686, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"britain\", \"value_r\": \"ireland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06710362536524198, \"u_probability\": 0.9955848162182925, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.84 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026090511008549776, \"u_probability\": 0.7530934547412738, \"bayes_factor\": 0.03464445328038763, \"log2_bayes_factor\": -4.851231800339749, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.86 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1760-09-22\", \"value_r\": \"1780-09-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17016757507745223, \"u_probability\": 0.9992892645977137, \"bayes_factor\": 0.17028860521778647, \"log2_bayes_factor\": -2.55394619390373, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.87 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sl4 3dn\", \"value_r\": \"sl4 2jg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"windsor castle\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 49}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.202024927179504, \"bayes_factor\": 1.2954019598766614e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 49}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the false negatives will be because they weren't detected by the blocking rules\n",
    "records = linker.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.5,\n",
    "    include_false_negatives=True,\n",
    "    include_false_positives=False,\n",
    ").as_record_dict(limit=50)\n",
    "\n",
    "linker.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06545e908438426c8185e5bc9b35b182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fe1cfa86b4f4e9bbecf34be2378fbe7",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_40efa7951ddc4ca8bb74e0c91d1abf66",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "1e58ea15a76f4887b75ee41c6210f8bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "40efa7951ddc4ca8bb74e0c91d1abf66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "4816c47151d145b994566568e51c630c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a5007a2aafc44df2b5a0932cc17d4a0c",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e58ea15a76f4887b75ee41c6210f8bd",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "5fcb5354d9c746bcbbd42fb211dc84ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "5fe1cfa86b4f4e9bbecf34be2378fbe7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "8d093bba3d464dafaebcaeb55dcbef47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f0a6693a457e40b68664a1569829e678",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ef73e739ae9e4d9e942ff4eb0ec2338c",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "9fe5f6a7b06a455fa9fb04d4088d3a78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fcb5354d9c746bcbbd42fb211dc84ec",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ad735d4f18bb437fb01e563f9175ba97",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "a5007a2aafc44df2b5a0932cc17d4a0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "ad735d4f18bb437fb01e563f9175ba97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "ef73e739ae9e4d9e942ff4eb0ec2338c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "f0a6693a457e40b68664a1569829e678": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
