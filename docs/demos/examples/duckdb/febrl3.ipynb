{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplicating the febrl3 dataset\n",
    "\n",
    "See A.2 [here](https://arxiv.org/pdf/2008.04443.pdf) and [here](https://recordlinkage.readthedocs.io/en/latest/ref-datasets.html) for the source of this data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/moj-analytical-services/splink/blob/splink4_dev/docs/demos/examples/duckdb/febrl3.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:53.970752Z",
     "iopub.status.busy": "2024-05-15T15:50:53.970419Z",
     "iopub.status.idle": "2024-05-15T15:50:53.975673Z",
     "shell.execute_reply": "2024-05-15T15:50:53.974958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're running in Google Colab.\n",
    "# !pip install git+https://github.com/moj-analytical-services/splink.git@splink4_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:53.979321Z",
     "iopub.status.busy": "2024-05-15T15:50:53.979040Z",
     "iopub.status.idle": "2024-05-15T15:50:55.403280Z",
     "shell.execute_reply": "2024-05-15T15:50:55.402512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec-1496-org</td>\n",
       "      <td>mitchell</td>\n",
       "      <td>green</td>\n",
       "      <td>7</td>\n",
       "      <td>wallaby place</td>\n",
       "      <td>delmar</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>2119</td>\n",
       "      <td>sa</td>\n",
       "      <td>19560409</td>\n",
       "      <td>1804974</td>\n",
       "      <td>rec-1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec-552-dup-3</td>\n",
       "      <td>harley</td>\n",
       "      <td>mccarthy</td>\n",
       "      <td>177</td>\n",
       "      <td>pridhamstreet</td>\n",
       "      <td>milton</td>\n",
       "      <td>marsden</td>\n",
       "      <td>3165</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19080419</td>\n",
       "      <td>6089216</td>\n",
       "      <td>rec-552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rec_id given_name    surname street_number       address_1  \\\n",
       "0   rec-1496-org   mitchell      green             7   wallaby place   \n",
       "1  rec-552-dup-3     harley   mccarthy           177   pridhamstreet   \n",
       "\n",
       "  address_2      suburb  postcode state date_of_birth soc_sec_id   cluster  \n",
       "0    delmar   cleveland      2119    sa      19560409    1804974  rec-1496  \n",
       "1    milton     marsden      3165   nsw      19080419    6089216   rec-552  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "\n",
    "df = splink_datasets.febrl3\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "\n",
    "df[\"cluster\"] = df[\"rec_id\"].apply(lambda x: \"-\".join(x.split(\"-\")[:2]))\n",
    "\n",
    "df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\n",
    "df[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:55.445888Z",
     "iopub.status.busy": "2024-05-15T15:50:55.445564Z",
     "iopub.status.idle": "2024-05-15T15:50:55.453559Z",
     "shell.execute_reply": "2024-05-15T15:50:55.452728Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\n",
    "df[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:55.457023Z",
     "iopub.status.busy": "2024-05-15T15:50:55.456741Z",
     "iopub.status.idle": "2024-05-15T15:50:55.464209Z",
     "shell.execute_reply": "2024-05-15T15:50:55.463386Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\n",
    "df[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:55.467779Z",
     "iopub.status.busy": "2024-05-15T15:50:55.467486Z",
     "iopub.status.idle": "2024-05-15T15:50:55.617978Z",
     "shell.execute_reply": "2024-05-15T15:50:55.617331Z"
    }
   },
   "outputs": [],
   "source": [
    "from splink import DuckDBAPI, Linker, SettingsCreator\n",
    "\n",
    "# TODO:  Allow missingness to be analysed without a linker\n",
    "settings = SettingsCreator(\n",
    "    unique_id_column_name=\"rec_id\",\n",
    "    link_type=\"dedupe_only\",\n",
    ")\n",
    "\n",
    "linker = Linker(df, settings, database_api=DuckDBAPI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually a good idea to perform exploratory analysis on your data so you understand what's in each column and how often it's missing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:55.621604Z",
     "iopub.status.busy": "2024-05-15T15:50:55.621314Z",
     "iopub.status.idle": "2024-05-15T15:50:55.930689Z",
     "shell.execute_reply": "2024-05-15T15:50:55.929809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2cbeededfbd0430ba92f22a175bb89e1.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2cbeededfbd0430ba92f22a175bb89e1.vega-embed details,\n",
       "  #altair-viz-2cbeededfbd0430ba92f22a175bb89e1.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2cbeededfbd0430ba92f22a175bb89e1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2cbeededfbd0430ba92f22a175bb89e1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2cbeededfbd0430ba92f22a175bb89e1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"rect\", \"encoding\": {\"color\": {\"field\": \"completeness\", \"legend\": null, \"scale\": {\"scheme\": \"darkred\", \"zero\": true}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"source_dataset\", \"title\": \"Source dataset\", \"type\": \"nominal\"}, {\"field\": \"total_rows_inc_nulls\", \"format\": \",\", \"title\": \"# of records\", \"type\": \"quantitative\"}, {\"field\": \"column_name\", \"title\": \"Column name\", \"type\": \"nominal\"}, {\"field\": \"total_null_rows\", \"format\": \",\", \"title\": \"# of nulls\", \"type\": \"quantitative\"}, {\"field\": \"completeness\", \"format\": \".1%\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labelAngle\": 20}, \"field\": \"column_name\", \"sort\": {\"field\": \"mean_comp\", \"order\": \"descending\"}, \"title\": \"Column name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"source_dataset\", \"title\": \"Source dataset\", \"type\": \"nominal\"}}, \"title\": \"Column completeness by source dataset\", \"transform\": [{\"joinaggregate\": [{\"op\": \"mean\", \"field\": \"completeness\", \"as\": \"mean_comp\"}], \"groupby\": [\"column_name\"]}]}, {\"mark\": {\"type\": \"text\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"datum['completeness'] < 0.5\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"completeness\", \"format\": \".0%\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"column_name\", \"sort\": {\"field\": \"mean_comp\", \"order\": \"descending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"source_dataset\", \"type\": \"nominal\"}}, \"transform\": [{\"joinaggregate\": [{\"op\": \"mean\", \"field\": \"completeness\", \"as\": \"mean_comp\"}], \"groupby\": [\"column_name\"]}]}], \"data\": {\"name\": \"data-f284bee0b7d37d94cca34fa76f5ff473\"}, \"height\": {\"step\": 40}, \"width\": {\"step\": 40}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-f284bee0b7d37d94cca34fa76f5ff473\": [{\"source_dataset\": \"input_data_1\", \"column_name\": \"rec_id\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"given_name\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"surname\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"street_number\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"address_1\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"address_2\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"suburb\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"postcode\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"state\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"date_of_birth\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"soc_sec_id\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"cluster\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.exploratory import completeness_chart\n",
    "\n",
    "completeness_chart(df, db_api=DuckDBAPI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:55.933815Z",
     "iopub.status.busy": "2024-05-15T15:50:55.933588Z",
     "iopub.status.idle": "2024-05-15T15:50:56.393881Z",
     "shell.execute_reply": "2024-05-15T15:50:56.393363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-197fb936f0184ca9a8215bd3fa2dba0e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-197fb936f0184ca9a8215bd3fa2dba0e.vega-embed details,\n",
       "  #altair-viz-197fb936f0184ca9a8215bd3fa2dba0e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-197fb936f0184ca9a8215bd3fa2dba0e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-197fb936f0184ca9a8215bd3fa2dba0e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-197fb936f0184ca9a8215bd3fa2dba0e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.7373999953269958, \"percentile_inc_nulls\": 0.7373999953269958, \"value_count\": 26, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 26.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.727400004863739, \"percentile_inc_nulls\": 0.727400004863739, \"value_count\": 25, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7081999778747559, \"percentile_inc_nulls\": 0.7081999778747559, \"value_count\": 24, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6759999990463257, \"percentile_inc_nulls\": 0.6759999990463257, \"value_count\": 23, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6540000438690186, \"percentile_inc_nulls\": 0.6540000438690186, \"value_count\": 22, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 110.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6288000345230103, \"percentile_inc_nulls\": 0.6288000345230103, \"value_count\": 21, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6208000183105469, \"percentile_inc_nulls\": 0.6208000183105469, \"value_count\": 20, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6094000339508057, \"percentile_inc_nulls\": 0.6094000339508057, \"value_count\": 19, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5914000272750854, \"percentile_inc_nulls\": 0.5914000272750854, \"value_count\": 18, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5845999717712402, \"percentile_inc_nulls\": 0.5845999717712402, \"value_count\": 17, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5717999935150146, \"percentile_inc_nulls\": 0.5717999935150146, \"value_count\": 16, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5478000044822693, \"percentile_inc_nulls\": 0.5478000044822693, \"value_count\": 15, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.522599995136261, \"percentile_inc_nulls\": 0.522599995136261, \"value_count\": 14, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.509600043296814, \"percentile_inc_nulls\": 0.509600043296814, \"value_count\": 13, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5024000406265259, \"percentile_inc_nulls\": 0.5024000406265259, \"value_count\": 12, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.48919999599456787, \"percentile_inc_nulls\": 0.48919999599456787, \"value_count\": 11, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 66.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.4631999731063843, \"percentile_inc_nulls\": 0.4631999731063843, \"value_count\": 10, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 130.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.4326000213623047, \"percentile_inc_nulls\": 0.4326000213623047, \"value_count\": 9, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 153.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.40380001068115234, \"percentile_inc_nulls\": 0.40380001068115234, \"value_count\": 8, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.3659999966621399, \"percentile_inc_nulls\": 0.3659999966621399, \"value_count\": 7, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 189.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.33240002393722534, \"percentile_inc_nulls\": 0.33240002393722534, \"value_count\": 6, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 168.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.2784000039100647, \"percentile_inc_nulls\": 0.2784000039100647, \"value_count\": 5, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 270.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.23680001497268677, \"percentile_inc_nulls\": 0.23680001497268677, \"value_count\": 4, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 208.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.1905999779701233, \"percentile_inc_nulls\": 0.1905999779701233, \"value_count\": 3, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 231.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.14020001888275146, \"percentile_inc_nulls\": 0.14020001888275146, \"value_count\": 2, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 252.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 701.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9688000082969666, \"percentile_inc_nulls\": 0.9688000082969666, \"value_count\": 156, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9526000022888184, \"percentile_inc_nulls\": 0.9526000022888184, \"value_count\": 81, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9387999773025513, \"percentile_inc_nulls\": 0.9387999773025513, \"value_count\": 69, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9265999794006348, \"percentile_inc_nulls\": 0.9265999794006348, \"value_count\": 61, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 61.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9157999753952026, \"percentile_inc_nulls\": 0.9157999753952026, \"value_count\": 54, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9056000113487244, \"percentile_inc_nulls\": 0.9056000113487244, \"value_count\": 51, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 51.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.895799994468689, \"percentile_inc_nulls\": 0.895799994468689, \"value_count\": 49, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 49.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8863999843597412, \"percentile_inc_nulls\": 0.8863999843597412, \"value_count\": 47, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8772000074386597, \"percentile_inc_nulls\": 0.8772000074386597, \"value_count\": 46, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8682000041007996, \"percentile_inc_nulls\": 0.8682000041007996, \"value_count\": 45, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8597999811172485, \"percentile_inc_nulls\": 0.8597999811172485, \"value_count\": 42, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.836400032043457, \"percentile_inc_nulls\": 0.836400032043457, \"value_count\": 39, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 117.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8141999840736389, \"percentile_inc_nulls\": 0.8141999840736389, \"value_count\": 37, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8073999881744385, \"percentile_inc_nulls\": 0.8073999881744385, \"value_count\": 34, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7946000099182129, \"percentile_inc_nulls\": 0.7946000099182129, \"value_count\": 32, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7821999788284302, \"percentile_inc_nulls\": 0.7821999788284302, \"value_count\": 31, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7702000141143799, \"percentile_inc_nulls\": 0.7702000141143799, \"value_count\": 30, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7644000053405762, \"percentile_inc_nulls\": 0.7644000053405762, \"value_count\": 29, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7588000297546387, \"percentile_inc_nulls\": 0.7588000297546387, \"value_count\": 28, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7425999641418457, \"percentile_inc_nulls\": 0.7425999641418457, \"value_count\": 27, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 26, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 26.0, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column given_name\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1214 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 156, \"group_name\": \"given_name\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 81, \"group_name\": \"given_name\", \"value\": \" joshua\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 69, \"group_name\": \"given_name\", \"value\": \" emiily\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 61, \"group_name\": \"given_name\", \"value\": \" jack\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 54, \"group_name\": \"given_name\", \"value\": \" benjamin\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 51, \"group_name\": \"given_name\", \"value\": \" isabella\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 49, \"group_name\": \"given_name\", \"value\": \" samuel\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 47, \"group_name\": \"given_name\", \"value\": \" thomas\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 46, \"group_name\": \"given_name\", \"value\": \" sophie\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 45, \"group_name\": \"given_name\", \"value\": \" james\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" lary\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" wanders\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" trentk\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" joh\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" eri n\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" olier\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" harvey\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" diaond\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" willian\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" paris\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 156]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.5839999914169312, \"percentile_inc_nulls\": 0.5839999914169312, \"value_count\": 7, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.5371999740600586, \"percentile_inc_nulls\": 0.5371999740600586, \"value_count\": 6, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 234.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.46219998598098755, \"percentile_inc_nulls\": 0.46219998598098755, \"value_count\": 5, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 375.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.3845999836921692, \"percentile_inc_nulls\": 0.3845999836921692, \"value_count\": 4, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 388.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.3011999726295471, \"percentile_inc_nulls\": 0.3011999726295471, \"value_count\": 3, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 417.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.20959997177124023, \"percentile_inc_nulls\": 0.20959997177124023, \"value_count\": 2, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 458.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1048.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9753999710083008, \"percentile_inc_nulls\": 0.9753999710083008, \"value_count\": 123, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9581999778747559, \"percentile_inc_nulls\": 0.9581999778747559, \"value_count\": 86, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9423999786376953, \"percentile_inc_nulls\": 0.9423999786376953, \"value_count\": 79, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 79.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9277999997138977, \"percentile_inc_nulls\": 0.9277999997138977, \"value_count\": 73, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 73.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9139999747276306, \"percentile_inc_nulls\": 0.9139999747276306, \"value_count\": 69, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9025999903678894, \"percentile_inc_nulls\": 0.9025999903678894, \"value_count\": 57, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8925999999046326, \"percentile_inc_nulls\": 0.8925999999046326, \"value_count\": 50, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8831999897956848, \"percentile_inc_nulls\": 0.8831999897956848, \"value_count\": 47, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8740000128746033, \"percentile_inc_nulls\": 0.8740000128746033, \"value_count\": 46, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.847599983215332, \"percentile_inc_nulls\": 0.847599983215332, \"value_count\": 44, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 132.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8395999670028687, \"percentile_inc_nulls\": 0.8395999670028687, \"value_count\": 40, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8317999839782715, \"percentile_inc_nulls\": 0.8317999839782715, \"value_count\": 39, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 39.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8242000341415405, \"percentile_inc_nulls\": 0.8242000341415405, \"value_count\": 38, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8181999921798706, \"percentile_inc_nulls\": 0.8181999921798706, \"value_count\": 30, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 30.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8123999834060669, \"percentile_inc_nulls\": 0.8123999834060669, \"value_count\": 29, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8068000078201294, \"percentile_inc_nulls\": 0.8068000078201294, \"value_count\": 28, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7906000018119812, \"percentile_inc_nulls\": 0.7906000018119812, \"value_count\": 27, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7802000045776367, \"percentile_inc_nulls\": 0.7802000045776367, \"value_count\": 26, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7752000093460083, \"percentile_inc_nulls\": 0.7752000093460083, \"value_count\": 25, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 25.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7703999876976013, \"percentile_inc_nulls\": 0.7703999876976013, \"value_count\": 24, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 24.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7660000324249268, \"percentile_inc_nulls\": 0.7660000324249268, \"value_count\": 22, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 22.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7576000094413757, \"percentile_inc_nulls\": 0.7576000094413757, \"value_count\": 21, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.75, \"percentile_inc_nulls\": 0.75, \"value_count\": 19, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7427999973297119, \"percentile_inc_nulls\": 0.7427999973297119, \"value_count\": 18, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7394000291824341, \"percentile_inc_nulls\": 0.7394000291824341, \"value_count\": 17, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 17.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7265999913215637, \"percentile_inc_nulls\": 0.7265999913215637, \"value_count\": 16, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7175999879837036, \"percentile_inc_nulls\": 0.7175999879837036, \"value_count\": 15, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7120000123977661, \"percentile_inc_nulls\": 0.7120000123977661, \"value_count\": 14, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7015999555587769, \"percentile_inc_nulls\": 0.7015999555587769, \"value_count\": 13, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6872000098228455, \"percentile_inc_nulls\": 0.6872000098228455, \"value_count\": 12, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 72.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6762000322341919, \"percentile_inc_nulls\": 0.6762000322341919, \"value_count\": 11, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 55.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6582000255584717, \"percentile_inc_nulls\": 0.6582000255584717, \"value_count\": 10, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6402000188827515, \"percentile_inc_nulls\": 0.6402000188827515, \"value_count\": 9, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6161999702453613, \"percentile_inc_nulls\": 0.6161999702453613, \"value_count\": 8, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 7, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column surname\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1741 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 123, \"group_name\": \"surname\", \"value\": \" white\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 86, \"group_name\": \"surname\", \"value\": \" clarke\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 79, \"group_name\": \"surname\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 73, \"group_name\": \"surname\", \"value\": \" campbell\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 69, \"group_name\": \"surname\", \"value\": \" ryan\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 57, \"group_name\": \"surname\", \"value\": \" green\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 50, \"group_name\": \"surname\", \"value\": \" reid\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 47, \"group_name\": \"surname\", \"value\": \" dixon\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 46, \"group_name\": \"surname\", \"value\": \" nguyen\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 44, \"group_name\": \"surname\", \"value\": \" morrison\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" jennion\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" hathaway\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" matthiessen\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" hylnand\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" liberts\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" whiteley\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" colemn\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" poyntz\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" mazurek\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" bullvck\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 123]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.exploratory import profile_columns\n",
    "\n",
    "profile_columns(df, db_api=DuckDBAPI(), column_expressions=[\"given_name\", \"surname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:56.397337Z",
     "iopub.status.busy": "2024-05-15T15:50:56.396993Z",
     "iopub.status.idle": "2024-05-15T15:50:56.749566Z",
     "shell.execute_reply": "2024-05-15T15:50:56.748922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-8fbec16d73424e4684a6927f26daf145.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-8fbec16d73424e4684a6927f26daf145.vega-embed details,\n",
       "  #altair-viz-8fbec16d73424e4684a6927f26daf145.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-8fbec16d73424e4684a6927f26daf145\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8fbec16d73424e4684a6927f26daf145\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8fbec16d73424e4684a6927f26daf145\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-4ab5b177c099ba5baa7c18ee8b59ed20\"}, \"mark\": \"bar\", \"encoding\": {\"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"blocking_rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Total comparisons in Cartesian product\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"blocking_rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-4ab5b177c099ba5baa7c18ee8b59ed20\": [{\"blocking_rule\": \"l.\\\"soc_sec_id\\\" = r.\\\"soc_sec_id\\\"\", \"row_count\": 5601, \"cumulative_rows\": 5601, \"cartesian\": 12497500, \"match_key\": \"0\", \"start\": 0}, {\"blocking_rule\": \"l.\\\"given_name\\\" = r.\\\"given_name\\\"\", \"row_count\": 48681, \"cumulative_rows\": 54282, \"cartesian\": 12497500, \"match_key\": \"1\", \"start\": 5601}, {\"blocking_rule\": \"l.\\\"surname\\\" = r.\\\"surname\\\"\", \"row_count\": 36675, \"cumulative_rows\": 90957, \"cartesian\": 12497500, \"match_key\": \"2\", \"start\": 54282}, {\"blocking_rule\": \"l.\\\"date_of_birth\\\" = r.\\\"date_of_birth\\\"\", \"row_count\": 12256, \"cumulative_rows\": 103213, \"cartesian\": 12497500, \"match_key\": \"3\", \"start\": 90957}, {\"blocking_rule\": \"l.\\\"postcode\\\" = r.\\\"postcode\\\"\", \"row_count\": 11037, \"cumulative_rows\": 114250, \"cartesian\": 12497500, \"match_key\": \"4\", \"start\": 103213}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import DuckDBAPI, block_on\n",
    "from splink.blocking_analysis import (\n",
    "    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n",
    ")\n",
    "\n",
    "blocking_rules = [\n",
    "    block_on(\"soc_sec_id\"),\n",
    "    block_on(\"given_name\"),\n",
    "    block_on(\"surname\"),\n",
    "    block_on(\"date_of_birth\"),\n",
    "    block_on(\"postcode\"),\n",
    "]\n",
    "\n",
    "db_api = DuckDBAPI()\n",
    "cumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n",
    "    table_or_tables=df,\n",
    "    blocking_rules=blocking_rules,\n",
    "    db_api=db_api,\n",
    "    link_type=\"dedupe_only\",\n",
    "    unique_id_column_name=\"rec_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:56.752854Z",
     "iopub.status.busy": "2024-05-15T15:50:56.752596Z",
     "iopub.status.idle": "2024-05-15T15:50:56.907514Z",
     "shell.execute_reply": "2024-05-15T15:50:56.906772Z"
    }
   },
   "outputs": [],
   "source": [
    "import splink.comparison_library as cl\n",
    "import splink.comparison_template_library as ctl\n",
    "from splink.linker import Linker\n",
    "\n",
    "settings = SettingsCreator(\n",
    "    unique_id_column_name=\"rec_id\",\n",
    "    link_type=\"dedupe_only\",\n",
    "    blocking_rules_to_generate_predictions=blocking_rules,\n",
    "    comparisons=[\n",
    "        ctl.NameComparison(\"given_name\").configure(term_frequency_adjustments=True),\n",
    "        ctl.NameComparison(\"surname\").configure(term_frequency_adjustments=True),\n",
    "        ctl.DateComparison(\n",
    "            \"date_of_birth\",\n",
    "            input_is_string=True,\n",
    "            datetime_format=\"%Y%m%d\",\n",
    "            invalid_dates_as_null=True,\n",
    "            datetime_metrics=[\"month\", \"year\", \"year\"],\n",
    "            datetime_thresholds=[1, 1, 10],\n",
    "        ),\n",
    "        cl.LevenshteinAtThresholds(\"soc_sec_id\", [2]),\n",
    "        cl.ExactMatch(\"street_number\").configure(term_frequency_adjustments=True),\n",
    "        cl.ExactMatch(\"postcode\").configure(term_frequency_adjustments=True),\n",
    "    ],\n",
    "    retain_intermediate_calculation_columns=True,\n",
    ")\n",
    "\n",
    "linker = Linker(df, settings, database_api=DuckDBAPI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:56.910709Z",
     "iopub.status.busy": "2024-05-15T15:50:56.910470Z",
     "iopub.status.idle": "2024-05-15T15:50:57.119744Z",
     "shell.execute_reply": "2024-05-15T15:50:57.119133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.000528.\n",
      "This means that amongst all possible pairwise record comparisons, one in 1,893.56 are expected to match.  With 12,497,500 total possible comparisons, we expect a total of around 6,600.00 matching pairs\n"
     ]
    }
   ],
   "source": [
    "from splink.blocking_rule_library import block_on\n",
    "\n",
    "deterministic_rules = [\n",
    "    block_on(\"soc_sec_id\"),\n",
    "    block_on(\"given_name\", \"surname\", \"date_of_birth\"),\n",
    "    \"l.given_name = r.surname and l.surname = r.given_name and l.date_of_birth = r.date_of_birth\",\n",
    "]\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:50:57.122905Z",
     "iopub.status.busy": "2024-05-15T15:50:57.122623Z",
     "iopub.status.idle": "2024-05-15T15:51:01.161828Z",
     "shell.execute_reply": "2024-05-15T15:51:01.161251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated u probabilities using random sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - given_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - date_of_birth (some u values are not trained, no m values are trained).\n",
      "    - soc_sec_id (no m values are trained).\n",
      "    - street_number (no m values are trained).\n",
      "    - postcode (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:51:01.165539Z",
     "iopub.status.busy": "2024-05-15T15:51:01.165298Z",
     "iopub.status.idle": "2024-05-15T15:51:01.704281Z",
     "shell.execute_reply": "2024-05-15T15:51:01.703690Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"date_of_birth\" = r.\"date_of_birth\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - given_name\n",
      "    - surname\n",
      "    - soc_sec_id\n",
      "    - street_number\n",
      "    - postcode\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - date_of_birth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.377 in the m_probability of surname, level `Exact match on surname`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was 0.0152 in the m_probability of given_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 0.000666 in the m_probability of postcode, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was 3.54e-05 in the m_probability of postcode, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 4 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - date_of_birth (some u values are not trained, no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "em_blocking_rule_1 = block_on(\"date_of_birth\")\n",
    "session_dob = linker.estimate_parameters_using_expectation_maximisation(\n",
    "    em_blocking_rule_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:51:01.707325Z",
     "iopub.status.busy": "2024-05-15T15:51:01.707114Z",
     "iopub.status.idle": "2024-05-15T15:51:02.290513Z",
     "shell.execute_reply": "2024-05-15T15:51:02.290020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"postcode\" = r.\"postcode\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - given_name\n",
      "    - surname\n",
      "    - date_of_birth\n",
      "    - soc_sec_id\n",
      "    - street_number\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - postcode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "Level Abs difference of 'transformed date_of_birth <= 1 month' on comparison date_of_birth not observed in dataset, unable to train m value\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "Level Abs difference of 'transformed date_of_birth <= 1 year' on comparison date_of_birth not observed in dataset, unable to train m value\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "Level Abs difference of 'transformed date_of_birth <= 10 year' on comparison date_of_birth not observed in dataset, unable to train m value\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was 0.0681 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was -0.00191 in the m_probability of date_of_birth, level `Exact match on date_of_birth`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 5.43e-05 in the m_probability of soc_sec_id, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - date_of_birth (some u values are not trained, some m values are not trained).\n"
     ]
    }
   ],
   "source": [
    "em_blocking_rule_2 = block_on(\"postcode\")\n",
    "session_postcode = linker.estimate_parameters_using_expectation_maximisation(\n",
    "    em_blocking_rule_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:51:02.294783Z",
     "iopub.status.busy": "2024-05-15T15:51:02.294498Z",
     "iopub.status.idle": "2024-05-15T15:51:02.665651Z",
     "shell.execute_reply": "2024-05-15T15:51:02.665073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b16159b6a3a5450589158cb01859bf87.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b16159b6a3a5450589158cb01859bf87.vega-embed details,\n",
       "  #altair-viz-b16159b6a3a5450589158cb01859bf87.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b16159b6a3a5450589158cb01859bf87\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b16159b6a3a5450589158cb01859bf87\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b16159b6a3a5450589158cb01859bf87\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": 60, \"discreteWidth\": 400}, \"header\": {\"title\": null}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}}, \"vconcat\": [{\"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\", \"type\": \"nominal\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Equivalent match weight\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"domain\": false, \"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-11, 11]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAlign\": \"right\", \"titleAngle\": 0, \"titleFontWeight\": \"normal\"}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": 20, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}]}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"row\": {\"field\": \"comparison_name\", \"header\": {\"labelAlign\": \"left\", \"labelAnchor\": \"middle\", \"labelAngle\": 0}, \"sort\": {\"field\": \"comparison_sort_order\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\", \"type\": \"quantitative\"}, {\"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-11, 11]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": {\"step\": 12}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}]}], \"data\": {\"name\": \"data-ac702d7497e8fa17aab008ac4cfe0396\"}, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\", \"views\": []}], \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-ac702d7497e8fa17aab008ac4cfe0396\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.0005283846640354178, \"log2_bayes_factor\": -10.886123785487664, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.001 or one in  1,893.6 records.This is equivalent to a starting match weight of -10.886.\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": -1}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"\\\"given_name_l\\\" = \\\"given_name_r\\\"\", \"label_for_charts\": \"Exact match on given_name\", \"m_probability\": 0.5748627388410512, \"u_probability\": 0.004655147553337382, \"m_probability_description\": \"Amongst matching record comparisons, 57.49% of records are in the exact match on given_name comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.47% of records are in the exact match on given_name comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"given_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 123.48969227171305, \"log2_bayes_factor\": 6.94824681434496, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on given_name` then comparison is 123.49 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"given_name_l\\\", \\\"given_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of given_name >= 0.9\", \"m_probability\": 0.17033828534998488, \"u_probability\": 0.002885917836593059, \"m_probability_description\": \"Amongst matching record comparisons, 17.03% of records are in the jaro-winkler distance of given_name >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.29% of records are in the jaro-winkler distance of given_name >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 59.02395528733278, \"log2_bayes_factor\": 5.883228696142251, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of given_name >= 0.9` then comparison is 59.02 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"given_name_l\\\", \\\"given_name_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of given_name >= 0.8\", \"m_probability\": 0.009081841411820668, \"u_probability\": 0.014744282630500425, \"m_probability_description\": \"Amongst matching record comparisons, 0.91% of records are in the jaro-winkler distance of given_name >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.47% of records are in the jaro-winkler distance of given_name >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.6159568179352262, \"log2_bayes_factor\": -0.6990988815230206, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of given_name >= 0.8` then comparison is  1.62 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"m_probability_description\": \"Amongst matching record comparisons, 24.57% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 97.77% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.5618944210496456, \"u_probability\": 0.0029364371860301367, \"m_probability_description\": \"Amongst matching record comparisons, 56.19% of records are in the exact match on surname comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.29% of records are in the exact match on surname comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 191.3524402029824, \"log2_bayes_factor\": 7.580088488723616, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 191.35 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.9\", \"m_probability\": 0.23310749418305604, \"u_probability\": 0.0014913732948403956, \"m_probability_description\": \"Amongst matching record comparisons, 23.31% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.15% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 156.30392135189925, \"log2_bayes_factor\": 7.288210162891398, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.9` then comparison is 156.30 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.8\", \"m_probability\": 0.0055732777225956705, \"u_probability\": 0.009360814456111841, \"m_probability_description\": \"Amongst matching record comparisons, 0.56% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.94% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.5953838470707834, \"log2_bayes_factor\": -0.7481080134978297, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.8` then comparison is  1.68 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"m_probability_description\": \"Amongst matching record comparisons, 19.94% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.62% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9294024247696142, \"u_probability\": 0.00048151626398019293, \"m_probability_description\": \"Amongst matching record comparisons, 92.94% of records are in the exact match on date_of_birth comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the exact match on date_of_birth comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1930.157908036612, \"log2_bayes_factor\": 10.91450316522398, \"comparison_vector_value\": 5, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,930.16 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"damerau_levenshtein(\\\"date_of_birth_l\\\", \\\"date_of_birth_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of date_of_birth <= 1\", \"m_probability\": 0.012215290539268037, \"u_probability\": 0.0010461310794274167, \"m_probability_description\": \"Amongst matching record comparisons, 1.22% of records are in the damerau-levenshtein distance of date_of_birth <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.10% of records are in the damerau-levenshtein distance of date_of_birth <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 11.676634773104993, \"log2_bayes_factor\": 3.545552641734149, \"comparison_vector_value\": 4, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of date_of_birth <= 1` then comparison is 11.68 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"date_of_birth_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"date_of_birth_r\\\", '%Y-%m-%d'))) <= 2629800.0\", \"label_for_charts\": \"Abs difference of 'transformed date_of_birth <= 1 month'\", \"m_probability\": 0.010000000000000009, \"u_probability\": 0.0050000000000000044, \"m_probability_description\": \"Amongst matching record comparisons, 1.00% of records are in the abs difference of 'transformed date_of_birth <= 1 month' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.50% of records are in the abs difference of 'transformed date_of_birth <= 1 month' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 2.0, \"log2_bayes_factor\": 1.0, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed date_of_birth <= 1 month'` then comparison is 2.00 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"date_of_birth_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"date_of_birth_r\\\", '%Y-%m-%d'))) <= 31557600.0\", \"label_for_charts\": \"Abs difference of 'transformed date_of_birth <= 1 year'\", \"m_probability\": 0.010000000000000009, \"u_probability\": 0.020000000000000018, \"m_probability_description\": \"Amongst matching record comparisons, 1.00% of records are in the abs difference of 'transformed date_of_birth <= 1 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 2.00% of records are in the abs difference of 'transformed date_of_birth <= 1 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.5, \"log2_bayes_factor\": -1.0, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed date_of_birth <= 1 year'` then comparison is  2.00 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"date_of_birth_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"date_of_birth_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed date_of_birth <= 10 year'\", \"m_probability\": 0.010000000000000009, \"u_probability\": 0.08000000000000007, \"m_probability_description\": \"Amongst matching record comparisons, 1.00% of records are in the abs difference of 'transformed date_of_birth <= 10 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 8.00% of records are in the abs difference of 'transformed date_of_birth <= 10 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.125, \"log2_bayes_factor\": -3.0, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed date_of_birth <= 10 year'` then comparison is  8.00 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.058382284691117774, \"u_probability\": 0.9984723526565924, \"m_probability_description\": \"Amongst matching record comparisons, 5.84% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.85% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.05847160868879598, \"log2_bayes_factor\": -4.096119906044184, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"label_for_charts\": \"Exact match on soc_sec_id\", \"m_probability\": 0.8589356345410205, \"u_probability\": 0.0004441492804676408, \"m_probability_description\": \"Amongst matching record comparisons, 85.89% of records are in the exact match on soc_sec_id comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.04% of records are in the exact match on soc_sec_id comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1933.8895103841098, \"log2_bayes_factor\": 10.917289655808569, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match on soc_sec_id` then comparison is 1,933.89 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"levenshtein(\\\"soc_sec_id_l\\\", \\\"soc_sec_id_r\\\") <= 2\", \"label_for_charts\": \"Levenshtein distance of soc_sec_id <= 2\", \"m_probability\": 0.07681338528309826, \"u_probability\": 0.00031364096108852356, \"m_probability_description\": \"Amongst matching record comparisons, 7.68% of records are in the levenshtein distance of soc_sec_id <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.03% of records are in the levenshtein distance of soc_sec_id <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 244.9086529275686, \"log2_bayes_factor\": 7.936099936788745, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of soc_sec_id <= 2` then comparison is 244.91 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"m_probability_description\": \"Amongst matching record comparisons, 6.43% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.92% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"street_number\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"label_for_charts\": \"Exact match on street_number\", \"m_probability\": 0.768128872117923, \"u_probability\": 0.014484318478188797, \"m_probability_description\": \"Amongst matching record comparisons, 76.81% of records are in the exact match on street_number comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.45% of records are in the exact match on street_number comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"street_number\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 53.031757985341834, \"log2_bayes_factor\": 5.728784669025015, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on street_number` then comparison is 53.03 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 4}, {\"comparison_name\": \"street_number\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"m_probability_description\": \"Amongst matching record comparisons, 23.19% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.55% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 4}, {\"comparison_name\": \"postcode\", \"sql_condition\": \"\\\"postcode_l\\\" = \\\"postcode_r\\\"\", \"label_for_charts\": \"Exact match on postcode\", \"m_probability\": 0.7702238580448146, \"u_probability\": 0.0012871909241988736, \"m_probability_description\": \"Amongst matching record comparisons, 77.02% of records are in the exact match on postcode comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.13% of records are in the exact match on postcode comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"postcode\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 598.3757681667848, \"log2_bayes_factor\": 9.224907942785277, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on postcode` then comparison is 598.38 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 5}, {\"comparison_name\": \"postcode\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"m_probability_description\": \"Amongst matching record comparisons, 22.98% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.87% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:51:02.668752Z",
     "iopub.status.busy": "2024-05-15T15:51:02.668512Z",
     "iopub.status.idle": "2024-05-15T15:51:09.240685Z",
     "shell.execute_reply": "2024-05-15T15:51:09.240109Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    }
   ],
   "source": [
    "results = linker.predict(threshold_match_probability=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:51:09.243955Z",
     "iopub.status.busy": "2024-05-15T15:51:09.243667Z",
     "iopub.status.idle": "2024-05-15T15:51:11.811265Z",
     "shell.execute_reply": "2024-05-15T15:51:11.810638Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7dc2fb7f57a0497fa7e9a926b992c586.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7dc2fb7f57a0497fa7e9a926b992c586.vega-embed details,\n",
       "  #altair-viz-7dc2fb7f57a0497fa7e9a926b992c586.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7dc2fb7f57a0497fa7e9a926b992c586\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7dc2fb7f57a0497fa7e9a926b992c586\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7dc2fb7f57a0497fa7e9a926b992c586\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0d4be6e7219da794280f37bed4116920\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-0d4be6e7219da794280f37bed4116920\": [{\"truth_threshold\": -23.400000348687172, \"match_probability\": 9.034371752972305e-08, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12383243.0, \"fp\": 107719.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9913762446799534, \"fp_rate\": 0.008623755320046606, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.05716411378555799, \"recall\": 0.9989293361884368, \"specificity\": 0.9913762446799534, \"npv\": 0.9999994347202875, \"accuracy\": 0.9913801960392078, \"f1\": 0.10813988144517667, \"f2\": 0.2325821569493312, \"f0_5\": 0.0704472988190828, \"p4\": 0.19509089158934365, \"phi\": 0.23792726011867513}, {\"truth_threshold\": -22.100000329315662, \"match_probability\": 2.2245229983413064e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12394452.0, \"fp\": 96510.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9922736135135148, \"fp_rate\": 0.007726386486485188, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.06338253704835939, \"recall\": 0.9989293361884368, \"specificity\": 0.9922736135135148, \"npv\": 0.9999994352315015, \"accuracy\": 0.9922770954190838, \"f1\": 0.11920167185318355, \"f2\": 0.252761372520183, \"f0_5\": 0.07799102941949167, \"p4\": 0.21292366505302607, \"phi\": 0.2506479560693152}, {\"truth_threshold\": -21.800000324845314, \"match_probability\": 2.738708929430773e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12394606.0, \"fp\": 96356.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.992285942427813, \"fp_rate\": 0.007714057572186994, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.06347740725261695, \"recall\": 0.9989293361884368, \"specificity\": 0.992285942427813, \"npv\": 0.9999994352385185, \"accuracy\": 0.9922894178835767, \"f1\": 0.11936943111720356, \"f2\": 0.25306302745681536, \"f0_5\": 0.07810593992623527, \"p4\": 0.21319140009766618, \"phi\": 0.2508370309893072}, {\"truth_threshold\": -21.300000317394733, \"match_probability\": 3.873118892024803e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12394730.0, \"fp\": 96232.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9922958696055596, \"fp_rate\": 0.007704130394440396, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.06355400289987641, \"recall\": 0.9989293361884368, \"specificity\": 0.9922958696055596, \"npv\": 0.9999994352441686, \"accuracy\": 0.9922993398679736, \"f1\": 0.11950485356950073, \"f2\": 0.2533064422293759, \"f0_5\": 0.07819871165497258, \"p4\": 0.21340746879908556, \"phi\": 0.2509895810651251}, {\"truth_threshold\": -20.60000030696392, \"match_probability\": 6.29189872645777e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12405730.0, \"fp\": 85232.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9931765063411448, \"fp_rate\": 0.006823493658855099, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.07117247692425052, \"recall\": 0.9989293361884368, \"specificity\": 0.9931765063411448, \"npv\": 0.99999943574493, \"accuracy\": 0.9931795159031807, \"f1\": 0.13287759025849177, \"f2\": 0.2769367764915405, \"f0_5\": 0.08740865654862282, \"p4\": 0.23448970920742496, \"phi\": 0.26572555462939407}, {\"truth_threshold\": -20.300000302493572, \"match_probability\": 7.746234863849234e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12412635.0, \"fp\": 78327.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9937293060374373, \"fp_rate\": 0.006270693962562691, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.07696386905182775, \"recall\": 0.9989293361884368, \"specificity\": 0.9937293060374373, \"npv\": 0.9999994360588181, \"accuracy\": 0.993732026405281, \"f1\": 0.1429165390170248, \"f2\": 0.29416268804612195, \"f0_5\": 0.09438679654305286, \"p4\": 0.24999230612578563, \"phi\": 0.27640240583676073}, {\"truth_threshold\": -20.10000029951334, \"match_probability\": 8.898086238977229e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12415479.0, \"fp\": 75483.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9939569906625286, \"fp_rate\": 0.006043009337471365, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.07963274562879509, \"recall\": 0.9989293361884368, \"specificity\": 0.9939569906625286, \"npv\": 0.9999994361879994, \"accuracy\": 0.9939595919183837, \"f1\": 0.14750654982383232, \"f2\": 0.3018970841114583, \"f0_5\": 0.09759589233518831, \"p4\": 0.25699012721782577, \"phi\": 0.28118624522406016}, {\"truth_threshold\": -20.000000298023224, \"match_probability\": 9.53673209908534e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12420875.0, \"fp\": 70087.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9943889830102758, \"fp_rate\": 0.00561101698972425, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.08524106606802578, \"recall\": 0.9989293361884368, \"specificity\": 0.9943889830102758, \"npv\": 0.9999994364329361, \"accuracy\": 0.9943913582716544, \"f1\": 0.15707826254269083, \"f2\": 0.31774837014693, \"f0_5\": 0.10432574039168077, \"p4\": 0.2714044889000889, \"phi\": 0.2909827360375682}, {\"truth_threshold\": -19.900000296533108, \"match_probability\": 1.0221215694048732e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12423674.0, \"fp\": 67288.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9946130650305397, \"fp_rate\": 0.005386934969460319, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.08847315731722186, \"recall\": 0.9989293361884368, \"specificity\": 0.9946130650305397, \"npv\": 0.9999994365599052, \"accuracy\": 0.994615323064613, \"f1\": 0.16254962231043965, \"f2\": 0.32664472697082153, \"f0_5\": 0.10819577620653781, \"p4\": 0.2795374709424317, \"phi\": 0.29648148907267746}, {\"truth_threshold\": -19.80000029504299, \"match_probability\": 1.095482694339651e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12427835.0, \"fp\": 63127.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9949461858902461, \"fp_rate\": 0.005053814109753916, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.09375807516724569, \"recall\": 0.9989293361884368, \"specificity\": 0.9949461858902461, \"npv\": 0.9999994367485522, \"accuracy\": 0.9949482696539308, \"f1\": 0.1714263215916846, \"f2\": 0.34083081098006474, \"f0_5\": 0.11451064277448539, \"p4\": 0.29257089720737667, \"phi\": 0.3052593915084545}, {\"truth_threshold\": -19.700000293552876, \"match_probability\": 1.174109189357499e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12429684.0, \"fp\": 61278.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9950942129197095, \"fp_rate\": 0.004905787080290533, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.09631464849798699, \"recall\": 0.9989293361884368, \"specificity\": 0.9950942129197095, \"npv\": 0.9999994368323396, \"accuracy\": 0.9950962192438487, \"f1\": 0.17568967140570568, \"f2\": 0.34753780823958874, \"f0_5\": 0.11755959881054383, \"p4\": 0.2987607626972144, \"phi\": 0.30941633591191675}, {\"truth_threshold\": -19.60000029206276, \"match_probability\": 1.2583789665296601e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12430959.0, \"fp\": 60003.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9951962867231523, \"fp_rate\": 0.004803713276847692, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.09816033907475877, \"recall\": 0.9989293361884368, \"specificity\": 0.9951962867231523, \"npv\": 0.9999994368901017, \"accuracy\": 0.9951982396479296, \"f1\": 0.1787552003503394, \"f2\": 0.3523185810154716, \"f0_5\": 0.11975839280606144, \"p4\": 0.30318388985414346, \"phi\": 0.31238301558492093}, {\"truth_threshold\": -19.500000290572643, \"match_probability\": 1.3486970617214505e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12432902.0, \"fp\": 58060.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9953518391938107, \"fp_rate\": 0.004648160806189307, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.10111315817993219, \"recall\": 0.9989293361884368, \"specificity\": 0.9953518391938107, \"npv\": 0.9999994369781038, \"accuracy\": 0.9953537107421484, \"f1\": 0.18363817852071587, \"f2\": 0.35986246873037037, \"f0_5\": 0.12327200247638749, \"p4\": 0.31018206989903857, \"phi\": 0.31707152183644843}, {\"truth_threshold\": -19.400000289082527, \"match_probability\": 1.4454975813216156e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12436868.0, \"fp\": 54094.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9956693487659317, \"fp_rate\": 0.004330651234068281, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.10772783505154639, \"recall\": 0.9989293361884368, \"specificity\": 0.9956693487659317, \"npv\": 0.9999994371576462, \"accuracy\": 0.9956710542108421, \"f1\": 0.1944820809076426, \"f2\": 0.3763093907371769, \"f0_5\": 0.1311245673351055, \"p4\": 0.32551887754211073, \"phi\": 0.32733072460889484}, {\"truth_threshold\": -19.30000028759241, \"match_probability\": 1.549245788689352e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12437644.0, \"fp\": 53318.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.995731473684733, \"fp_rate\": 0.00426852631526699, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.10912463031963776, \"recall\": 0.9989293361884368, \"specificity\": 0.995731473684733, \"npv\": 0.9999994371927625, \"accuracy\": 0.9957331466293259, \"f1\": 0.196755388856252, \"f2\": 0.37970488715247497, \"f0_5\": 0.13277952621435019, \"p4\": 0.32869886501685464, \"phi\": 0.3294562692809753}, {\"truth_threshold\": -19.200000286102295, \"match_probability\": 1.66044034034615e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12440686.0, \"fp\": 50276.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9959750097710649, \"fp_rate\": 0.0040249902289351295, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.11496822574682698, \"recall\": 0.9989293361884368, \"specificity\": 0.9959750097710649, \"npv\": 0.9999994373303802, \"accuracy\": 0.9959765553110622, \"f1\": 0.2062041202936301, \"f2\": 0.3936281777745633, \"f0_5\": 0.13969097302430636, \"p4\": 0.3417877653561756, \"phi\": 0.3382038255849883}, {\"truth_threshold\": -19.10000028461218, \"match_probability\": 1.7796156826591604e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12444256.0, \"fp\": 46706.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9962608164207049, \"fp_rate\": 0.0037391835792951736, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.1226778368427973, \"recall\": 0.9989293361884368, \"specificity\": 0.9962608164207049, \"npv\": 0.9999994374917984, \"accuracy\": 0.9962622124424885, \"f1\": 0.21851944792973652, \"f2\": 0.4113290254317349, \"f0_5\": 0.1487794210109073, \"p4\": 0.3585431851622418, \"phi\": 0.3494098100607936}, {\"truth_threshold\": -19.000000283122063, \"match_probability\": 1.907344620533969e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12447111.0, \"fp\": 43851.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9964893816825318, \"fp_rate\": 0.0035106183174682623, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.12962962962962962, \"recall\": 0.9989293361884368, \"specificity\": 0.9964893816825318, \"npv\": 0.9999994376208211, \"accuracy\": 0.9964906581316263, \"f1\": 0.22947997189037245, \"f2\": 0.42667311260354873, \"f0_5\": 0.15694539232743457, \"p4\": 0.37317327921722127, \"phi\": 0.3592146989214852}, {\"truth_threshold\": -18.900000281631947, \"match_probability\": 2.0442410704611823e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12449081.0, \"fp\": 41881.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9966470957160866, \"fp_rate\": 0.003352904283913441, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.13490456911509544, \"recall\": 0.9989293361884368, \"specificity\": 0.9966470957160866, \"npv\": 0.9999994377098146, \"accuracy\": 0.9966482896579316, \"f1\": 0.23770700636942677, \"f2\": 0.4379459256477657, \"f0_5\": 0.16312329533533815, \"p4\": 0.3839846185548206, \"phi\": 0.3664795352599752}, {\"truth_threshold\": -18.80000028014183, \"match_probability\": 2.1909630111470102e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12451068.0, \"fp\": 39894.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9968061707336873, \"fp_rate\": 0.003193829266312715, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.14067851373182552, \"recall\": 0.9989293361884368, \"specificity\": 0.9968061707336873, \"npv\": 0.9999994377995475, \"accuracy\": 0.9968072814562913, \"f1\": 0.2466250023601382, \"f2\": 0.44993593011560135, \"f0_5\": 0.16986756000374537, \"p4\": 0.3955429234744392, \"phi\": 0.3742699979705262}, {\"truth_threshold\": -18.700000278651714, \"match_probability\": 2.348215645907411e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12451815.0, \"fp\": 39147.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.996865973973822, \"fp_rate\": 0.0031340260261779676, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.14297911467227112, \"recall\": 0.9989293361884368, \"specificity\": 0.996865973973822, \"npv\": 0.9999994378332745, \"accuracy\": 0.9968670534106822, \"f1\": 0.25015320974413974, \"f2\": 0.4546150633440067, \"f0_5\": 0.17254953764861294, \"p4\": 0.40007022304153966, \"phi\": 0.3773292621024914}, {\"truth_threshold\": -18.600000277161598, \"match_probability\": 2.516754792022793e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12452901.0, \"fp\": 38061.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9969529168369898, \"fp_rate\": 0.003047083163010183, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.14646124865446716, \"recall\": 0.9989293361884368, \"specificity\": 0.9969529168369898, \"npv\": 0.9999994378823003, \"accuracy\": 0.996953950790158, \"f1\": 0.25546645804811263, \"f2\": 0.46159391609182404, \"f0_5\": 0.1766032470552605, \"p4\": 0.40684006480685353, \"phi\": 0.3819130771365216}, {\"truth_threshold\": -18.500000275671482, \"match_probability\": 2.6973905133407355e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12454763.0, \"fp\": 36199.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9971019846189589, \"fp_rate\": 0.002898015381041108, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.152843435525392, \"recall\": 0.9989293361884368, \"specificity\": 0.9971019846189589, \"npv\": 0.9999994379663374, \"accuracy\": 0.9971029405881177, \"f1\": 0.265121376958675, \"f2\": 0.47407160070845794, \"f0_5\": 0.18401537265155699, \"p4\": 0.4189963916912101, \"phi\": 0.39017469056816706}, {\"truth_threshold\": -18.400000274181366, \"match_probability\": 2.8909910135828424e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12456966.0, \"fp\": 33996.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9972783521397312, \"fp_rate\": 0.002721647860268889, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.16115182470945297, \"recall\": 0.9989293361884368, \"specificity\": 0.9972783521397312, \"npv\": 0.9999994380657323, \"accuracy\": 0.9972792158431686, \"f1\": 0.2775310740465314, \"f2\": 0.4897343991361598, \"f0_5\": 0.19363044483711442, \"p4\": 0.43435156753091436, \"phi\": 0.4006745898611896}, {\"truth_threshold\": -18.30000027269125, \"match_probability\": 3.098486809064348e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12460316.0, \"fp\": 30646.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9975465460546593, \"fp_rate\": 0.002453453945340639, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.17567313123705516, \"recall\": 0.9989293361884368, \"specificity\": 0.9975465460546593, \"npv\": 0.9999994382168103, \"accuracy\": 0.9975472694538908, \"f1\": 0.2987990392313851, \"f2\": 0.5156405438266829, \"f0_5\": 0.21034358373162593, \"p4\": 0.4599857266076457, \"phi\": 0.4183939275759773}, {\"truth_threshold\": -18.200000271201134, \"match_probability\": 3.3208752008774106e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12461811.0, \"fp\": 29151.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.997666232592814, \"fp_rate\": 0.0023337674071860917, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.18303346224987388, \"recall\": 0.9989293361884368, \"specificity\": 0.997666232592814, \"npv\": 0.9999994382842055, \"accuracy\": 0.9976668933786758, \"f1\": 0.30937944102321174, \"f2\": 0.5281075136656208, \"f0_5\": 0.21877051706349737, \"p4\": 0.4724282903808682, \"phi\": 0.427094576895379}, {\"truth_threshold\": -18.100000269711018, \"match_probability\": 3.5592250680276667e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12462307.0, \"fp\": 28655.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9977059413038003, \"fp_rate\": 0.0022940586961997, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.18561359631671687, \"recall\": 0.9989293361884368, \"specificity\": 0.9977059413038003, \"npv\": 0.9999994383065617, \"accuracy\": 0.9977065813162632, \"f1\": 0.31305723324705204, \"f2\": 0.5323779712413186, \"f0_5\": 0.2217175214893877, \"p4\": 0.47670645010941987, \"phi\": 0.43010289265238316}, {\"truth_threshold\": -18.0000002682209, \"match_probability\": 3.8146820045553597e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12463768.0, \"fp\": 27194.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.997822905873863, \"fp_rate\": 0.002177094126136962, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.19365455893254263, \"recall\": 0.9989293361884368, \"specificity\": 0.997822905873863, \"npv\": 0.9999994383724032, \"accuracy\": 0.9978234846969394, \"f1\": 0.32441695849787644, \"f2\": 0.5453680044090385, \"f0_5\": 0.23087854749077336, \"p4\": 0.4897706358343707, \"phi\": 0.43934616875310445}, {\"truth_threshold\": -17.900000266730785, \"match_probability\": 4.088473825324779e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12464198.0, \"fp\": 26764.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.997857330764436, \"fp_rate\": 0.0021426692355640824, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.1961555789157531, \"recall\": 0.9989293361884368, \"specificity\": 0.997857330764436, \"npv\": 0.9999994383917787, \"accuracy\": 0.9978578915783156, \"f1\": 0.3279190620842015, \"f2\": 0.5493128332800646, \"f0_5\": 0.23372078042915015, \"p4\": 0.4937531691620129, \"phi\": 0.4421817566431904}, {\"truth_threshold\": -17.80000026524067, \"match_probability\": 4.381916466936514e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12465863.0, \"fp\": 25099.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9979906271430495, \"fp_rate\": 0.0020093728569504895, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.20648118874486246, \"recall\": 0.9989293361884368, \"specificity\": 0.9979906271430495, \"npv\": 0.9999994384667897, \"accuracy\": 0.9979911182236447, \"f1\": 0.3422238524418361, \"f2\": 0.565141393513551, \"f0_5\": 0.24541929083557545, \"p4\": 0.5098046922484556, \"phi\": 0.4537010682249961}, {\"truth_threshold\": -17.700000263750553, \"match_probability\": 4.696420312114957e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12466872.0, \"fp\": 24090.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9980714055490681, \"fp_rate\": 0.0019285944509318017, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2132850004898599, \"recall\": 0.9989293361884368, \"specificity\": 0.9980714055490681, \"npv\": 0.9999994385122372, \"accuracy\": 0.9980718543708742, \"f1\": 0.3515164563093732, \"f2\": 0.5751853874200764, \"f0_5\": 0.25309637116150735, \"p4\": 0.520050079977352, \"phi\": 0.4611341929266993}, {\"truth_threshold\": -17.600000262260437, \"match_probability\": 5.03349696795731e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12467821.0, \"fp\": 23141.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9981473804819837, \"fp_rate\": 0.0018526195180163065, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.22010649770827717, \"recall\": 0.9989293361884368, \"specificity\": 0.9981473804819837, \"npv\": 0.9999994385549753, \"accuracy\": 0.9981477895579116, \"f1\": 0.36072908036454016, \"f2\": 0.584963456577816, \"f0_5\": 0.26076853049686166, \"p4\": 0.5300692604649119, \"phi\": 0.4684682531922868}, {\"truth_threshold\": -17.50000026077032, \"match_probability\": 5.394766530610173e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12468621.0, \"fp\": 22341.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9982114267900263, \"fp_rate\": 0.0017885732099737395, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2262053200332502, \"recall\": 0.9989293361884368, \"specificity\": 0.9982114267900263, \"npv\": 0.9999994385909982, \"accuracy\": 0.9982118023604721, \"f1\": 0.36887884778311214, \"f2\": 0.5934683047397499, \"f0_5\": 0.26760690344680643, \"p4\": 0.5388201991997875, \"phi\": 0.47492945329168845}, {\"truth_threshold\": -17.400000259280205, \"match_probability\": 5.781965371275756e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12469200.0, \"fp\": 21762.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9982577803054721, \"fp_rate\": 0.0017422196945279314, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2308344820273566, \"recall\": 0.9989293361884368, \"specificity\": 0.9982577803054721, \"npv\": 0.9999994386170669, \"accuracy\": 0.9982581316263253, \"f1\": 0.3750107662714249, \"f2\": 0.5997795940857746, \"f0_5\": 0.2727842285523348, \"p4\": 0.5453361054578323, \"phi\": 0.47977558474394716}, {\"truth_threshold\": -17.30000025779009, \"match_probability\": 6.196954480953251e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12470229.0, \"fp\": 20733.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9983401598691918, \"fp_rate\": 0.0016598401308081795, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.23954665492957747, \"recall\": 0.9989293361884368, \"specificity\": 0.9983401598691918, \"npv\": 0.9999994386633901, \"accuracy\": 0.9983404680936188, \"f1\": 0.38642683864860067, \"f2\": 0.6113336827916729, \"f0_5\": 0.2824973614547468, \"p4\": 0.5573136394798944, \"phi\": 0.48876580490049876}, {\"truth_threshold\": -17.200000256299973, \"match_probability\": 6.6417284140038195e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12471205.0, \"fp\": 19757.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9984182963650038, \"fp_rate\": 0.0015817036349962477, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2484403530127815, \"recall\": 0.9989293361884368, \"specificity\": 0.9984182963650038, \"npv\": 0.9999994387073206, \"accuracy\": 0.9984185637127425, \"f1\": 0.39791628587095595, \"f2\": 0.6227116704805492, \"f0_5\": 0.2923717432178351, \"p4\": 0.5691707854825929, \"phi\": 0.4977758914452503}, {\"truth_threshold\": -17.100000254809856, \"match_probability\": 7.118424873502875e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12472509.0, \"fp\": 18453.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9985226918471132, \"fp_rate\": 0.0014773081528868634, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.26140730067243034, \"recall\": 0.9989293361884368, \"specificity\": 0.9985226918471132, \"npv\": 0.9999994387660036, \"accuracy\": 0.9985229045809162, \"f1\": 0.41437726032612143, \"f2\": 0.6385912077596996, \"f0_5\": 0.30669459210699324, \"p4\": 0.5858231045560576, \"phi\": 0.5106277336720231}, {\"truth_threshold\": -17.00000025331974, \"match_probability\": 7.629334984424643e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12473514.0, \"fp\": 17448.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9986031500215916, \"fp_rate\": 0.0013968499784083883, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.27236331790316526, \"recall\": 0.9989293361884368, \"specificity\": 0.9986031500215916, \"npv\": 0.9999994388112226, \"accuracy\": 0.9986033206641328, \"f1\": 0.42802372448143655, \"f2\": 0.6513933494245078, \"f0_5\": 0.318728404942706, \"p4\": 0.5993373529468459, \"phi\": 0.5212395781752576}, {\"truth_threshold\": -16.900000251829624, \"match_probability\": 8.176914304005986e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12474688.0, \"fp\": 16274.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9986971379786441, \"fp_rate\": 0.0013028620213559213, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2863845647884236, \"recall\": 0.9989293361884368, \"specificity\": 0.9986971379786441, \"npv\": 0.9999994388640363, \"accuracy\": 0.9986972594518904, \"f1\": 0.44514875779572644, \"f2\": 0.6670139101660642, \"f0_5\": 0.33403915792057937, \"p4\": 0.6159356187800298, \"phi\": 0.534513109120493}, {\"truth_threshold\": -16.800000250339508, \"match_probability\": 8.76379462217525e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12475885.0, \"fp\": 15077.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9987929672670528, \"fp_rate\": 0.00120703273294723, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.3022491669751944, \"recall\": 0.9989293361884368, \"specificity\": 0.9987929672670528, \"npv\": 0.9999994389178746, \"accuracy\": 0.9987930386077215, \"f1\": 0.46408015348539755, \"f2\": 0.6837311557788944, \"f0_5\": 0.35124233623749596, \"p4\": 0.6338331161347662, \"phi\": 0.5491449492509635}, {\"truth_threshold\": -16.700000248849392, \"match_probability\": 9.392796608724036e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12476256.0, \"fp\": 14706.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9988226687424075, \"fp_rate\": 0.0011773312575924897, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.30752931204972456, \"recall\": 0.9989293361884368, \"specificity\": 0.9988226687424075, \"npv\": 0.9999994389345591, \"accuracy\": 0.998822724544909, \"f1\": 0.4702790279027903, \"f2\": 0.6890839646331427, \"f0_5\": 0.35693985965065694, \"p4\": 0.639593357247632, \"phi\": 0.5539290819847316}, {\"truth_threshold\": -16.600000247359276, \"match_probability\": 1.0066943367963594e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12477140.0, \"fp\": 13822.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9988934399127946, \"fp_rate\": 0.001106560087205453, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.32088635581978087, \"recall\": 0.9989293361884368, \"specificity\": 0.9988934399127946, \"npv\": 0.9999994389743104, \"accuracy\": 0.9988934586917384, \"f1\": 0.4857387229928229, \"f2\": 0.7021825610149446, \"f0_5\": 0.37129050596930074, \"p4\": 0.6537498500050192, \"phi\": 0.5658508236036157}, {\"truth_threshold\": -16.50000024586916, \"match_probability\": 1.0789474965962542e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12478166.0, \"fp\": 12796.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9989755793028592, \"fp_rate\": 0.0010244206971408607, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.33792104310032595, \"recall\": 0.9989293361884368, \"specificity\": 0.9989755793028592, \"npv\": 0.99999943902044, \"accuracy\": 0.9989755551110222, \"f1\": 0.5050067658998647, \"f2\": 0.7180237032476527, \"f0_5\": 0.3894640173651695, \"p4\": 0.6709868139456814, \"phi\": 0.5807000173527644}, {\"truth_threshold\": -16.400000244379044, \"match_probability\": 1.1563864000129272e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12478680.0, \"fp\": 12282.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9990167290557765, \"fp_rate\": 0.0009832709442235113, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.3471535640248764, \"recall\": 0.9989293361884368, \"specificity\": 0.9990167290557765, \"npv\": 0.9999994390435468, \"accuracy\": 0.9990166833366674, \"f1\": 0.5152459469054476, \"f2\": 0.7262315133993106, \"f0_5\": 0.3992541875534906, \"p4\": 0.6799684124912028, \"phi\": 0.5885915166308849}, {\"truth_threshold\": -16.300000242888927, \"match_probability\": 1.239383228590334e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12479370.0, \"fp\": 11592.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9990719689964632, \"fp_rate\": 0.0009280310035367972, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.3603707995365006, \"recall\": 0.9989293361884368, \"specificity\": 0.9990719689964632, \"npv\": 0.9999994390745628, \"accuracy\": 0.9990718943788758, \"f1\": 0.5296622196991201, \"f2\": 0.7375494071146245, \"f0_5\": 0.41319751992914083, \"p4\": 0.6924103832213282, \"phi\": 0.5997082361312333}, {\"truth_threshold\": -16.20000024139881, \"match_probability\": 1.328336874067903e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12479881.0, \"fp\": 11081.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9991128785757254, \"fp_rate\": 0.0008871214242746075, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.37082670906200316, \"recall\": 0.9989293361884368, \"specificity\": 0.9991128785757254, \"npv\": 0.9999994390975303, \"accuracy\": 0.9991127825565113, \"f1\": 0.5408695652173913, \"f2\": 0.7461612284069098, \"f0_5\": 0.42416803055100927, \"p4\": 0.7019221495268686, \"phi\": 0.6083585704184697}, {\"truth_threshold\": -16.100000239908695, \"match_probability\": 1.4236748550826774e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12480639.0, \"fp\": 10323.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9991735624525957, \"fp_rate\": 0.0008264375474042752, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.38750444998220007, \"recall\": 0.9989293361884368, \"specificity\": 0.9991735624525957, \"npv\": 0.9999994391315963, \"accuracy\": 0.9991734346869374, \"f1\": 0.5583960328317373, \"f2\": 0.7593126540482723, \"f0_5\": 0.4415582659491035, \"p4\": 0.7165229267050982, \"phi\": 0.6219073523919406}, {\"truth_threshold\": -16.00000023841858, \"match_probability\": 1.5258553713831415e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12480668.0, \"fp\": 10294.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9991758841312622, \"fp_rate\": 0.0008241158687377321, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.38817236255572063, \"recall\": 0.9989293361884368, \"specificity\": 0.9991758841312622, \"npv\": 0.9999994391328995, \"accuracy\": 0.9991757551510302, \"f1\": 0.5590891580704532, \"f2\": 0.7598250226865533, \"f0_5\": 0.4422519569869173, \"p4\": 0.7170936053928325, \"phi\": 0.6224438140477538}, {\"truth_threshold\": -15.900000236928463, \"match_probability\": 1.6353695054159956e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12481832.0, \"fp\": 9130.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9992690715094642, \"fp_rate\": 0.000730928490535797, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.4170231785965136, \"recall\": 0.9989293361884368, \"specificity\": 0.9992690715094642, \"npv\": 0.9999994391852034, \"accuracy\": 0.9992688937787557, \"f1\": 0.5884048831028424, \"f2\": 0.7809772080453448, \"f0_5\": 0.472015842271111, \"p4\": 0.7407747502394608, \"phi\": 0.6451909120901506}, {\"truth_threshold\": -15.70000023394823, \"match_probability\": 1.8785416963874395e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12482009.0, \"fp\": 8953.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9992832417551186, \"fp_rate\": 0.000716758244881379, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.4217902350813743, \"recall\": 0.9989293361884368, \"specificity\": 0.9992832417551186, \"npv\": 0.9999994391931559, \"accuracy\": 0.9992830566113222, \"f1\": 0.593134138588684, \"f2\": 0.7842972427706792, \"f0_5\": 0.4768963402167246, \"p4\": 0.7445134418999542, \"phi\": 0.6488726825098676}, {\"truth_threshold\": -15.600000232458115, \"match_probability\": 2.0133684259220603e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12482920.0, \"fp\": 8042.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9993561744884021, \"fp_rate\": 0.0006438255115979057, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.4481575516365882, \"recall\": 0.9989293361884368, \"specificity\": 0.9993561744884021, \"npv\": 0.9999994392340835, \"accuracy\": 0.999355951190238, \"f1\": 0.6187295722609066, \"f2\": 0.801841620626151, \"f0_5\": 0.503701989819528, \"p4\": 0.7643689782181077, \"phi\": 0.6688711613567474}, {\"truth_threshold\": -15.500000230967999, \"match_probability\": 2.1578717331772276e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12483153.0, \"fp\": 7809.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9993748279756195, \"fp_rate\": 0.000625172024380508, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.45543933054393304, \"recall\": 0.9989293361884368, \"specificity\": 0.9993748279756195, \"npv\": 0.9999994392445503, \"accuracy\": 0.9993745949189838, \"f1\": 0.6256346393332695, \"f2\": 0.8064555961671441, \"f0_5\": 0.5110488591192213, \"p4\": 0.7696185287094471, \"phi\": 0.6742895671754072}, {\"truth_threshold\": -15.400000229477882, \"match_probability\": 2.312746079632102e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12483527.0, \"fp\": 7435.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9994047696246294, \"fp_rate\": 0.000595230375370608, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.46763568666762134, \"recall\": 0.9989293361884368, \"specificity\": 0.9994047696246294, \"npv\": 0.9999994392613502, \"accuracy\": 0.9994045209041809, \"f1\": 0.6370464299648849, \"f2\": 0.8139737773567974, \"f0_5\": 0.5233005352392551, \"p4\": 0.7781972873030075, \"phi\": 0.6832686845532148}, {\"truth_threshold\": -15.300000227987766, \"match_probability\": 2.478735761747151e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12484331.0, \"fp\": 6631.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9994691361642122, \"fp_rate\": 0.0005308638357878281, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.4962011852302082, \"recall\": 0.9989293361884368, \"specificity\": 0.9994691361642122, \"npv\": 0.9999994392974622, \"accuracy\": 0.9994688537707541, \"f1\": 0.6630456852791878, \"f2\": 0.8306201353207509, \"f0_5\": 0.5517352076504579, \"p4\": 0.7973027076004119, \"phi\": 0.7038507977610429}, {\"truth_threshold\": -15.20000022649765, \"match_probability\": 2.6566384864664307e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12484475.0, \"fp\": 6487.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9994806644996599, \"fp_rate\": 0.000519335500340166, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.5016899677369796, \"recall\": 0.9989293361884368, \"specificity\": 0.9994806644996599, \"npv\": 0.9999994393039294, \"accuracy\": 0.999480376075215, \"f1\": 0.6679280016363265, \"f2\": 0.8336737298953281, \"f0_5\": 0.55715748165842, \"p4\": 0.8008240675981222, \"phi\": 0.7077370424309617}, {\"truth_threshold\": -15.100000225007534, \"match_probability\": 2.8473092031487608e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12484738.0, \"fp\": 6224.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995017197234288, \"fp_rate\": 0.000498280276571172, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5119962364748314, \"recall\": 0.9987763842153564, \"specificity\": 0.9995017197234288, \"npv\": 0.999999359218041, \"accuracy\": 0.9995013402680536, \"f1\": 0.6769645448890732, \"f2\": 0.8392021796123991, \"f0_5\": 0.5672933245300066, \"p4\": 0.8072876046057226, \"phi\": 0.7149223681584522}, {\"truth_threshold\": -15.000000223517418, \"match_probability\": 3.0516642103032495e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12484998.0, \"fp\": 5964.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995225347735427, \"fp_rate\": 0.0004774652264573377, \"fn_rate\": 0.001223615784643622, \"precision\": 0.522650872418761, \"recall\": 0.9987763842153564, \"specificity\": 0.9995225347735427, \"npv\": 0.9999993592313853, \"accuracy\": 0.9995221444288858, \"f1\": 0.6862126944094157, \"f2\": 0.8448481084717694, \"f0_5\": 0.5777329511271543, \"p4\": 0.8138307983915939, \"phi\": 0.7223303685057404}, {\"truth_threshold\": -14.900000222027302, \"match_probability\": 3.270685556819147e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12485460.0, \"fp\": 5502.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995595215164372, \"fp_rate\": 0.0004404784835627552, \"fn_rate\": 0.001223615784643622, \"precision\": 0.542719414893617, \"recall\": 0.9987763842153564, \"specificity\": 0.9995595215164372, \"npv\": 0.9999993592550956, \"accuracy\": 0.9995591118223645, \"f1\": 0.7032848680667744, \"f2\": 0.8550701864655353, \"f0_5\": 0.5972633812607471, \"p4\": 0.8257230619990397, \"phi\": 0.7360812719716511}, {\"truth_threshold\": -14.800000220537186, \"match_probability\": 3.505425758788192e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12485745.0, \"fp\": 5217.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995823380136775, \"fp_rate\": 0.0004176619863225907, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5558866093470674, \"recall\": 0.9987763842153564, \"specificity\": 0.9995823380136775, \"npv\": 0.9999993592697213, \"accuracy\": 0.9995819163832766, \"f1\": 0.7142466502597757, \"f2\": 0.8615003034380855, \"f0_5\": 0.6099839330418861, \"p4\": 0.8332341061589634, \"phi\": 0.7449655061365633}, {\"truth_threshold\": -14.70000021904707, \"match_probability\": 3.757012854526189e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12485974.0, \"fp\": 4988.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996006712693546, \"fp_rate\": 0.00039932873064540584, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5669387046362215, \"recall\": 0.9987763842153564, \"specificity\": 0.9996006712693546, \"npv\": 0.9999993592814727, \"accuracy\": 0.9996002400480096, \"f1\": 0.7233052724856004, \"f2\": 0.8667374568622246, \"f0_5\": 0.6206044478236077, \"p4\": 0.8393690339745324, \"phi\": 0.7523416477215324}, {\"truth_threshold\": -14.600000217556953, \"match_probability\": 4.026655822016454e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486075.0, \"fp\": 4887.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996087571157449, \"fp_rate\": 0.00039124288425503175, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5719541035298239, \"recall\": 0.9987763842153564, \"specificity\": 0.9996087571157449, \"npv\": 0.9999993592866554, \"accuracy\": 0.9996083216643329, \"f1\": 0.7273739905318852, \"f2\": 0.8690675823152066, \"f0_5\": 0.6254070413362449, \"p4\": 0.8421036342038151, \"phi\": 0.7556651631568334}, {\"truth_threshold\": -14.500000216066837, \"match_probability\": 4.315650384728788e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486308.0, \"fp\": 4654.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996274106029623, \"fp_rate\": 0.0003725893970376341, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5838698140200286, \"recall\": 0.9987763842153564, \"specificity\": 0.9996274106029623, \"npv\": 0.9999993592986114, \"accuracy\": 0.9996269653930786, \"f1\": 0.736937140277621, \"f2\": 0.8744911077780159, \"f0_5\": 0.6367749736708663, \"p4\": 0.8484806484258035, \"phi\": 0.7635032405424124}, {\"truth_threshold\": -14.400000214576721, \"match_probability\": 4.625385233621647e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486458.0, \"fp\": 4504.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996394192857203, \"fp_rate\": 0.0003605807142796528, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5918071415624434, \"recall\": 0.9987763842153564, \"specificity\": 0.9996394192857203, \"npv\": 0.9999993593063081, \"accuracy\": 0.9996389677935588, \"f1\": 0.7432278625085363, \"f2\": 0.8780186091539827, \"f0_5\": 0.6443146386707187, \"p4\": 0.8526373757974294, \"phi\": 0.7686800134529551}, {\"truth_threshold\": -14.300000213086605, \"match_probability\": 4.957348695121048e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486707.0, \"fp\": 4255.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996593536990986, \"fp_rate\": 0.00034064630090140373, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6054705609643023, \"recall\": 0.9987763842153564, \"specificity\": 0.9996593536990986, \"npv\": 0.9999993593190843, \"accuracy\": 0.9996588917783557, \"f1\": 0.7539109853951395, \"f2\": 0.8839375152286325, \"f0_5\": 0.6572325778010387, \"p4\": 0.8596281992418373, \"phi\": 0.7775106472860351}, {\"truth_threshold\": -14.200000211596489, \"match_probability\": 5.313135876996633e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486978.0, \"fp\": 3984.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.999681049385948, \"fp_rate\": 0.00031895061405198415, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6210766596918394, \"recall\": 0.9987763842153564, \"specificity\": 0.999681049385948, \"npv\": 0.9999993593329888, \"accuracy\": 0.9996805761152231, \"f1\": 0.7658925639221206, \"f2\": 0.8904707358315606, \"f0_5\": 0.6718936494217393, \"p4\": 0.8673681351660593, \"phi\": 0.7874756936101868}, {\"truth_threshold\": -14.100000210106373, \"match_probability\": 5.694456326333118e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487064.0, \"fp\": 3898.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996879343640626, \"fp_rate\": 0.0003120656359374082, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6261986958189489, \"recall\": 0.9987763842153564, \"specificity\": 0.9996879343640626, \"npv\": 0.9999993593374011, \"accuracy\": 0.9996874574914983, \"f1\": 0.7697748438052576, \"f2\": 0.8925642427556042, \"f0_5\": 0.6766839378238342, \"p4\": 0.8698535679052172, \"phi\": 0.7907189225239538}, {\"truth_threshold\": -14.000000208616257, \"match_probability\": 6.103142236234761e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487107.0, \"fp\": 3855.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996913768531199, \"fp_rate\": 0.0003086231468801202, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6287915262397689, \"recall\": 0.9987763842153564, \"specificity\": 0.9996913768531199, \"npv\": 0.9999993593396073, \"accuracy\": 0.999690898179636, \"f1\": 0.7717307805944572, \"f2\": 0.8936146919560993, \"f0_5\": 0.6791047880527477, \"p4\": 0.8711016334147453, \"phi\": 0.7923556194693795}, {\"truth_threshold\": -13.90000020712614, \"match_probability\": 6.541157240512605e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487340.0, \"fp\": 3622.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997100303403372, \"fp_rate\": 0.00028996965966272256, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6432230102442869, \"recall\": 0.9987763842153564, \"specificity\": 0.9997100303403372, \"npv\": 0.9999993593515613, \"accuracy\": 0.9997095419083817, \"f1\": 0.7825044937088077, \"f2\": 0.8993499338915822, \"f0_5\": 0.6925295889364952, \"p4\": 0.8779271760779108, \"phi\": 0.8014042660104671}, {\"truth_threshold\": -13.800000205636024, \"match_probability\": 7.010605838401368e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487375.0, \"fp\": 3587.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997128323663141, \"fp_rate\": 0.0002871676336858602, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6454482554116833, \"recall\": 0.9987763842153564, \"specificity\": 0.9997128323663141, \"npv\": 0.9999993593533569, \"accuracy\": 0.9997123424684937, \"f1\": 0.7841489042329631, \"f2\": 0.9002178168684, \"f0_5\": 0.6945921797217377, \"p4\": 0.878961723586226, \"phi\": 0.8027904354258668}, {\"truth_threshold\": -13.700000204145908, \"match_probability\": 7.51374349434771e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487522.0, \"fp\": 3440.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997246008754169, \"fp_rate\": 0.0002753991245830385, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6549648946840522, \"recall\": 0.9987763842153564, \"specificity\": 0.9997246008754169, \"npv\": 0.9999993593608985, \"accuracy\": 0.9997241048209642, \"f1\": 0.7911315725708747, \"f2\": 0.9038812911798904, \"f0_5\": 0.703390925933905, \"p4\": 0.8833335808503291, \"phi\": 0.8086918157512951}, {\"truth_threshold\": -13.600000202655792, \"match_probability\": 8.052987461117984e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487674.0, \"fp\": 3288.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997367696739451, \"fp_rate\": 0.00026323032605495077, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6651049093501732, \"recall\": 0.9987763842153564, \"specificity\": 0.9997367696739451, \"npv\": 0.9999993593686963, \"accuracy\": 0.9997362672534507, \"f1\": 0.7984837368549768, \"f2\": 0.9077008618293022, \"f0_5\": 0.7127264789347304, \"p4\": 0.8879001114215276, \"phi\": 0.8149327340484709}, {\"truth_threshold\": -13.500000201165676, \"match_probability\": 8.630928377906233e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487785.0, \"fp\": 3177.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.999745656099186, \"fp_rate\": 0.0002543439008140446, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6727104151643144, \"recall\": 0.9987763842153564, \"specificity\": 0.999745656099186, \"npv\": 0.9999993593743907, \"accuracy\": 0.9997451490298059, \"f1\": 0.8039396737457679, \"f2\": 0.9105106110042109, \"f0_5\": 0.7197019794559802, \"p4\": 0.8912648225163031, \"phi\": 0.8195825380106165}, {\"truth_threshold\": -13.40000019967556, \"match_probability\": 9.25034269879762e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487821.0, \"fp\": 3141.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997485381830479, \"fp_rate\": 0.00025146181695212907, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6752145589907972, \"recall\": 0.9987763842153564, \"specificity\": 0.9997485381830479, \"npv\": 0.9999993593762374, \"accuracy\": 0.9997480296059211, \"f1\": 0.8057252143870689, \"f2\": 0.9114256204114675, \"f0_5\": 0.7219937198708594, \"p4\": 0.8923615634292106, \"phi\": 0.8211077428935656}, {\"truth_threshold\": -13.300000198185444, \"match_probability\": 9.914206010875549e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487923.0, \"fp\": 3039.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997567040873233, \"fp_rate\": 0.00024329591267670177, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6824119552722333, \"recall\": 0.9987763842153564, \"specificity\": 0.9997567040873233, \"npv\": 0.99999935938147, \"accuracy\": 0.9997561912382477, \"f1\": 0.8108275904886074, \"f2\": 0.9140281627054114, \"f0_5\": 0.7285669656803677, \"p4\": 0.8954837053114594, \"phi\": 0.8254757885691464}, {\"truth_threshold\": -13.200000196695328, \"match_probability\": 0.00010625707305470121, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488028.0, \"fp\": 2934.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997651101652539, \"fp_rate\": 0.00023488983474611482, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6899830938292477, \"recall\": 0.9987763842153564, \"specificity\": 0.9997651101652539, \"npv\": 0.9999993593868564, \"accuracy\": 0.9997645929185838, \"f1\": 0.8161479815023122, \"f2\": 0.9167228212039533, \"f0_5\": 0.7354597468126324, \"p4\": 0.8987205777804756, \"phi\": 0.8300458480896148}, {\"truth_threshold\": -13.100000195205212, \"match_probability\": 0.00011388264270550263, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488126.0, \"fp\": 2836.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997729558379891, \"fp_rate\": 0.00022704416201090036, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6972026478752936, \"recall\": 0.9987763842153564, \"specificity\": 0.9997729558379891, \"npv\": 0.9999993593918836, \"accuracy\": 0.9997724344868973, \"f1\": 0.8211770623742455, \"f2\": 0.9192522101469678, \"f0_5\": 0.7420117267396936, \"p4\": 0.901762842564067, \"phi\": 0.834380371437696}, {\"truth_threshold\": -13.000000193715096, \"match_probability\": 0.00012205539677081966, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488209.0, \"fp\": 2753.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997796006424485, \"fp_rate\": 0.00022039935755148403, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7034363890983518, \"recall\": 0.9987763842153564, \"specificity\": 0.9997796006424485, \"npv\": 0.9999993593961412, \"accuracy\": 0.999779075815163, \"f1\": 0.8254851147209405, \"f2\": 0.9214053901509807, \"f0_5\": 0.7476528509274101, \"p4\": 0.9043556100678978, \"phi\": 0.8381049914074641}, {\"truth_threshold\": -12.90000019222498, \"match_probability\": 0.00013081458937332365, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488304.0, \"fp\": 2658.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997872061415286, \"fp_rate\": 0.0002127938584714292, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7107096212451023, \"recall\": 0.9987763842153564, \"specificity\": 0.9997872061415286, \"npv\": 0.9999993594010144, \"accuracy\": 0.9997866773354671, \"f1\": 0.8304718300902963, \"f2\": 0.923882286361064, \"f0_5\": 0.7542157542157543, \"p4\": 0.9073415947045994, \"phi\": 0.8424298851612922}, {\"truth_threshold\": -12.800000190734863, \"match_probability\": 0.00014020228918616167, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488443.0, \"fp\": 2519.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997983341875509, \"fp_rate\": 0.00020166581244903314, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7216266990827715, \"recall\": 0.9987763842153564, \"specificity\": 0.9997983341875509, \"npv\": 0.9999993594081443, \"accuracy\": 0.999797799559912, \"f1\": 0.8378777186116636, \"f2\": 0.927530467884435, \"f0_5\": 0.7640286422988721, \"p4\": 0.911746266120254, \"phi\": 0.8488801671318317}, {\"truth_threshold\": -12.700000189244747, \"match_probability\": 0.00015026358101882152, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488534.0, \"fp\": 2428.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9998056194550908, \"fp_rate\": 0.00019438054490919114, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7289573565528019, \"recall\": 0.9987763842153564, \"specificity\": 0.9998056194550908, \"npv\": 0.9999993594128121, \"accuracy\": 0.9998050810162032, \"f1\": 0.8427981414558596, \"f2\": 0.9299344915978354, \"f0_5\": 0.7705924002832193, \"p4\": 0.9146531368012277, \"phi\": 0.853184070419726}, {\"truth_threshold\": -12.600000187754631, \"match_probability\": 0.0001610467818084837, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488616.0, \"fp\": 2346.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9998121842016652, \"fp_rate\": 0.00018781579833482802, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7356917530419108, \"recall\": 0.9987763842153564, \"specificity\": 0.9998121842016652, \"npv\": 0.9999993594170182, \"accuracy\": 0.9998116423284656, \"f1\": 0.8472816919683405, \"f2\": 0.9321114536941875, \"f0_5\": 0.7766043480329194, \"p4\": 0.9172884369956255, \"phi\": 0.8571188568614553}, {\"truth_threshold\": -12.500000186264515, \"match_probability\": 0.00017260367204143044, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6528.0, \"tn\": 12488679.0, \"fp\": 2283.0, \"fn\": 10.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9984704802691955, \"tn_rate\": 0.9998172278484235, \"fp_rate\": 0.00018277215157647586, \"fn_rate\": 0.0015295197308045274, \"precision\": 0.7408920667347634, \"recall\": 0.9984704802691955, \"specificity\": 0.9998172278484235, \"npv\": 0.9999991992754403, \"accuracy\": 0.999816523304661, \"f1\": 0.8506091602058766, \"f2\": 0.9335583330949861, \"f0_5\": 0.7811976449188646, \"p4\": 0.9192359873412507, \"phi\": 0.8600131649630065}, {\"truth_threshold\": -12.400000184774399, \"match_probability\": 0.00018498974370122882, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6528.0, \"tn\": 12488801.0, \"fp\": 2161.0, \"fn\": 10.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9984704802691955, \"tn_rate\": 0.9998269949104001, \"fp_rate\": 0.00017300508959998436, \"fn_rate\": 0.0015295197308045274, \"precision\": 0.7512947404764645, \"recall\": 0.9984704802691955, \"specificity\": 0.9998269949104001, \"npv\": 0.9999991992832624, \"accuracy\": 0.9998262852570514, \"f1\": 0.8574243120772312, \"f2\": 0.9368273011681639, \"f0_5\": 0.7904296023635395, \"p4\": 0.9232030671926184, \"phi\": 0.86603397345593}, {\"truth_threshold\": -12.300000183284283, \"match_probability\": 0.00019826446591752426, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489164.0, \"fp\": 1798.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998560559226743, \"fp_rate\": 0.00014394407732566957, \"fn_rate\": 0.002906087488528602, \"precision\": 0.7838162799086209, \"recall\": 0.9970939125114714, \"specificity\": 0.9998560559226743, \"npv\": 0.9999984786835135, \"accuracy\": 0.9998546109221844, \"f1\": 0.8776842813867385, \"f2\": 0.945632307290609, \"f0_5\": 0.8188464050645631, \"p4\": 0.9348264219759939, \"phi\": 0.8839819561714175}, {\"truth_threshold\": -12.200000181794167, \"match_probability\": 0.00021249156957169895, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489326.0, \"fp\": 1636.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.999869025300053, \"fp_rate\": 0.0001309746999470497, \"fn_rate\": 0.002906087488528602, \"precision\": 0.7993868792152053, \"recall\": 0.9970939125114714, \"specificity\": 0.999869025300053, \"npv\": 0.9999984787032467, \"accuracy\": 0.9998675735147029, \"f1\": 0.8873613285237868, \"f2\": 0.9500976477103799, \"f0_5\": 0.8323969559221615, \"p4\": 0.9402902068889673, \"phi\": 0.8927248035502859}, {\"truth_threshold\": -12.10000018030405, \"match_probability\": 0.0002277393522037113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489390.0, \"fp\": 1572.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998741490046964, \"fp_rate\": 0.00012585099530364435, \"fn_rate\": 0.002906087488528602, \"precision\": 0.8057100482017056, \"recall\": 0.9970939125114714, \"specificity\": 0.9998741490046964, \"npv\": 0.9999984787110423, \"accuracy\": 0.9998726945389078, \"f1\": 0.8912434206029121, \"f2\": 0.9518733755804106, \"f0_5\": 0.837874659400545, \"p4\": 0.9424663799907229, \"phi\": 0.8962508958005283}, {\"truth_threshold\": -12.000000178813934, \"match_probability\": 0.00024408100465850272, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489462.0, \"fp\": 1500.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998799131724202, \"fp_rate\": 0.00012008682757981331, \"fn_rate\": 0.002906087488528602, \"precision\": 0.8129442573887018, \"recall\": 0.9970939125114714, \"specificity\": 0.9998799131724202, \"npv\": 0.9999984787198123, \"accuracy\": 0.9998784556911382, \"f1\": 0.8956515765611046, \"f2\": 0.9538790202218256, \"f0_5\": 0.8441238928885896, \"p4\": 0.9449266464221592, \"phi\": 0.9002680876716866}, {\"truth_threshold\": -11.900000177323818, \"match_probability\": 0.0002615949610108224, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489502.0, \"fp\": 1460.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998831154878223, \"fp_rate\": 0.00011688451217768495, \"fn_rate\": 0.002906087488528602, \"precision\": 0.8170196766512094, \"recall\": 0.9970939125114714, \"specificity\": 0.9998831154878223, \"npv\": 0.9999984787246845, \"accuracy\": 0.9998816563312662, \"f1\": 0.8981194461665634, \"f2\": 0.9549969236178254, \"f0_5\": 0.8476361366827898, \"p4\": 0.9462990193966214, \"phi\": 0.9025233140302381}, {\"truth_threshold\": -11.800000175833702, \"match_probability\": 0.0002803652734145845, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489597.0, \"fp\": 1365.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9998907209869023, \"fp_rate\": 0.00010927901309763011, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8268425726246353, \"recall\": 0.996940960538391, \"specificity\": 0.9998907209869023, \"npv\": 0.9999983986698712, \"accuracy\": 0.9998891778355671, \"f1\": 0.9039595035018376, \"f2\": 0.957543705009549, \"f0_5\": 0.8560546361964801, \"p4\": 0.949532493781873, \"phi\": 0.9078663314439575}, {\"truth_threshold\": -11.700000174343586, \"match_probability\": 0.0003004820136373637, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489637.0, \"fp\": 1325.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9998939233023045, \"fp_rate\": 0.00010607669769550176, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.831059543542012, \"recall\": 0.996940960538391, \"specificity\": 0.9998939233023045, \"npv\": 0.9999983986749996, \"accuracy\": 0.9998923784756951, \"f1\": 0.9064738196231138, \"f2\": 0.9586703927048096, \"f0_5\": 0.8596676338696914, \"p4\": 0.9509185006566888, \"phi\": 0.9101799532481376}, {\"truth_threshold\": -11.60000017285347, \"match_probability\": 0.0003220417031628006, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489670.0, \"fp\": 1292.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9998965652125112, \"fp_rate\": 0.00010343478748874586, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8345710627400769, \"recall\": 0.996940960538391, \"specificity\": 0.9998965652125112, \"npv\": 0.9999983986792307, \"accuracy\": 0.9998950190038007, \"f1\": 0.908558684137162, \"f2\": 0.9596019080148401, \"f0_5\": 0.8626713960506115, \"p4\": 0.9520650060525858, \"phi\": 0.9121020540424659}, {\"truth_threshold\": -11.500000171363354, \"match_probability\": 0.00034514777387400505, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489730.0, \"fp\": 1232.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999013686856144, \"fp_rate\": 9.863131438555333e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8410322580645161, \"recall\": 0.996940960538391, \"specificity\": 0.9999013686856144, \"npv\": 0.9999983986869233, \"accuracy\": 0.9998998199639928, \"f1\": 0.9123740201567749, \"f2\": 0.9613002182762079, \"f0_5\": 0.8681869039373435, \"p4\": 0.9541566598379057, \"phi\": 0.9156281771684944}, {\"truth_threshold\": -11.400000169873238, \"match_probability\": 0.0003699110614699968, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489776.0, \"fp\": 1186.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999050513483269, \"fp_rate\": 9.494865167310572e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8460539979231568, \"recall\": 0.996940960538391, \"specificity\": 0.9999050513483269, \"npv\": 0.9999983986928209, \"accuracy\": 0.99990350070014, \"f1\": 0.9153208818986097, \"f2\": 0.9626063327032136, \"f0_5\": 0.8724634577287573, \"p4\": 0.9557664956333963, \"phi\": 0.9183593835823952}, {\"truth_threshold\": -11.300000168383121, \"match_probability\": 0.00039645033391533577, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489828.0, \"fp\": 1134.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999092143583497, \"fp_rate\": 9.078564165033887e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8518034500784109, \"recall\": 0.996940960538391, \"specificity\": 0.9999092143583497, \"npv\": 0.9999983986994878, \"accuracy\": 0.9999076615323065, \"f1\": 0.9186751233262861, \"f2\": 0.9640870902851734, \"f0_5\": 0.8773488397135627, \"p4\": 0.9575928636999639, \"phi\": 0.9214764359068631}, {\"truth_threshold\": -11.200000166893005, \"match_probability\": 0.00042489285738089063, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489926.0, \"fp\": 1036.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999170600310848, \"fp_rate\": 8.293996891512439e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8628541170240932, \"recall\": 0.996940960538391, \"specificity\": 0.9999170600310848, \"npv\": 0.9999983987120521, \"accuracy\": 0.9999155031006202, \"f1\": 0.9250638660232756, \"f2\": 0.966890167922625, \"f0_5\": 0.8867062088480165, \"p4\": 0.9610539065846617, \"phi\": 0.927438111617226}, {\"truth_threshold\": -11.10000016540289, \"match_probability\": 0.00045537500230174836, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489983.0, \"fp\": 979.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999216233305329, \"fp_rate\": 7.837666946709149e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8694144324396426, \"recall\": 0.996940960538391, \"specificity\": 0.9999216233305329, \"npv\": 0.9999983987193598, \"accuracy\": 0.9999200640128025, \"f1\": 0.9288208051300321, \"f2\": 0.9685280394662545, \"f0_5\": 0.892241143295187, \"p4\": 0.9630784940410264, \"phi\": 0.9309592479362132}, {\"truth_threshold\": -11.000000163912773, \"match_probability\": 0.00048804289235713973, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490033.0, \"fp\": 929.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999256262247855, \"fp_rate\": 7.437377521443105e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8752517792399624, \"recall\": 0.996940960538391, \"specificity\": 0.9999256262247855, \"npv\": 0.99999839872577, \"accuracy\": 0.9999240648129626, \"f1\": 0.9321415802645692, \"f2\": 0.969969344325724, \"f0_5\": 0.8971535539283159, \"p4\": 0.9648614840532814, \"phi\": 0.9340811835555637}, {\"truth_threshold\": -10.900000162422657, \"match_probability\": 0.0005230530993675534, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490053.0, \"fp\": 909.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999272273824866, \"fp_rate\": 7.277261751336687e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8776087249225798, \"recall\": 0.996940960538391, \"specificity\": 0.9999272273824866, \"npv\": 0.9999983987283341, \"accuracy\": 0.9999256651330266, \"f1\": 0.9334765485141425, \"f2\": 0.9705470681080437, \"f0_5\": 0.8991336975114496, \"p4\": 0.9655765299460435, \"phi\": 0.9353387744878003}, {\"truth_threshold\": -10.800000160932541, \"match_probability\": 0.0005605733873065377, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490090.0, \"fp\": 872.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999301895242336, \"fp_rate\": 6.981047576639813e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8820027063599458, \"recall\": 0.996940960538391, \"specificity\": 0.9999301895242336, \"npv\": 0.9999983987330776, \"accuracy\": 0.9999286257251451, \"f1\": 0.9359563469270534, \"f2\": 0.9716176733647367, \"f0_5\": 0.9028201008366115, \"p4\": 0.9669021626355756, \"phi\": 0.9376787594856717}, {\"truth_threshold\": -10.700000159442425, \"match_probability\": 0.0006007835088396779, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490138.0, \"fp\": 824.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999340323027162, \"fp_rate\": 6.596769728384411e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8877690002724054, \"recall\": 0.996940960538391, \"specificity\": 0.9999340323027162, \"npv\": 0.9999983987392314, \"accuracy\": 0.9999324664932987, \"f1\": 0.9391930835734871, \"f2\": 0.9730100913596466, \"f0_5\": 0.9076477468946694, \"p4\": 0.968627335971683, \"phi\": 0.9407407291779672}, {\"truth_threshold\": -10.600000157952309, \"match_probability\": 0.0006438760580315065, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490168.0, \"fp\": 794.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999364340392678, \"fp_rate\": 6.356596073224784e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8914113785557987, \"recall\": 0.996940960538391, \"specificity\": 0.9999364340392678, \"npv\": 0.9999983987430774, \"accuracy\": 0.9999348669733947, \"f1\": 0.9412274368231047, \"f2\": 0.9738823810662204, \"f0_5\": 0.9106913318057341, \"p4\": 0.96970869899015, \"phi\": 0.9426697493262179}, {\"truth_threshold\": -10.500000156462193, \"match_probability\": 0.0006900573831033208, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490218.0, \"fp\": 744.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999404369335204, \"fp_rate\": 5.95630664795874e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8975488846047921, \"recall\": 0.996940960538391, \"specificity\": 0.9999404369335204, \"npv\": 0.9999983987494874, \"accuracy\": 0.9999388677735547, \"f1\": 0.9446376811594203, \"f2\": 0.9753396779792901, \"f0_5\": 0.9158095880402406, \"p4\": 0.9715163461040757, \"phi\": 0.9459113014058622}, {\"truth_threshold\": -10.400000154972076, \"match_probability\": 0.0007395485633816526, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490241.0, \"fp\": 721.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999422782648766, \"fp_rate\": 5.7721735123363595e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9004006078187595, \"recall\": 0.996940960538391, \"specificity\": 0.9999422782648766, \"npv\": 0.999998398752436, \"accuracy\": 0.9999407081416283, \"f1\": 0.9462147056688684, \"f2\": 0.9760115001048186, \"f0_5\": 0.9181833549332281, \"p4\": 0.9723501287794537, \"phi\": 0.9474136783295553}, {\"truth_threshold\": -10.30000015348196, \"match_probability\": 0.0007925864548491303, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490296.0, \"fp\": 666.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999466814485546, \"fp_rate\": 5.331855144543711e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.907293986636971, \"recall\": 0.996940960538391, \"specificity\": 0.9999466814485546, \"npv\": 0.9999983987594869, \"accuracy\": 0.9999451090218043, \"f1\": 0.95000728756741, \"f2\": 0.9776217902567794, \"f0_5\": 0.92390996201168, \"p4\": 0.974349771906147, \"phi\": 0.951035523348411}, {\"truth_threshold\": -10.200000151991844, \"match_probability\": 0.0008494248089972806, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490325.0, \"fp\": 637.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999490031272211, \"fp_rate\": 5.099687277889405e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9109713487071978, \"recall\": 0.996940960538391, \"specificity\": 0.9999490031272211, \"npv\": 0.9999983987632047, \"accuracy\": 0.9999474294858972, \"f1\": 0.9520192799240488, \"f2\": 0.9784729936649953, \"f0_5\": 0.9269583025200523, \"p4\": 0.9754074443543069, \"phi\": 0.95296201312342}, {\"truth_threshold\": -10.100000150501728, \"match_probability\": 0.0009103354699850551, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490356.0, \"fp\": 606.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999514849216578, \"fp_rate\": 4.8515078342244576e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9149354295339697, \"recall\": 0.996940960538391, \"specificity\": 0.9999514849216578, \"npv\": 0.9999983987671788, \"accuracy\": 0.9999499099819964, \"f1\": 0.9541794759186063, \"f2\": 0.9793845414112273, \"f0_5\": 0.9302391962093965, \"p4\": 0.9765406019210419, \"phi\": 0.9550343562036164}, {\"truth_threshold\": -10.000000149011612, \"match_probability\": 0.0009756096554280922, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490371.0, \"fp\": 591.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999526857899336, \"fp_rate\": 4.7314210066446444e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9168659445772964, \"recall\": 0.996940960538391, \"specificity\": 0.9999526857899336, \"npv\": 0.9999983987691018, \"accuracy\": 0.9999511102220444, \"f1\": 0.9552282552942039, \"f2\": 0.979826222903701, \"f0_5\": 0.9318350774861326, \"p4\": 0.9770898496924718, \"phi\": 0.9560419647834585}, {\"truth_threshold\": -9.900000147521496, \"match_probability\": 0.0010455593264824352, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490412.0, \"fp\": 550.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999559681632207, \"fp_rate\": 4.403183677926488e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.922184493491794, \"recall\": 0.996940960538391, \"specificity\": 0.9999559681632207, \"npv\": 0.9999983987743578, \"accuracy\": 0.9999543908781756, \"f1\": 0.9581067176245774, \"f2\": 0.9810355207706201, \"f0_5\": 0.9362252226371732, \"p4\": 0.9785942841435542, \"phi\": 0.9588124389062211}, {\"truth_threshold\": -9.80000014603138, \"match_probability\": 0.0011205186532430977, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490453.0, \"fp\": 509.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999592505365079, \"fp_rate\": 4.0749463492083315e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9275651060196385, \"recall\": 0.996940960538391, \"specificity\": 0.9999592505365079, \"npv\": 0.9999983987796138, \"accuracy\": 0.9999576715343068, \"f1\": 0.961002580169554, \"f2\": 0.9822478073480213, \"f0_5\": 0.94065693009294, \"p4\": 0.9801033585174106, \"phi\": 0.9616071202522097}, {\"truth_threshold\": -9.700000144541264, \"match_probability\": 0.001200845581852835, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490492.0, \"fp\": 470.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.999962372794025, \"fp_rate\": 3.762720597500817e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9327418431597023, \"recall\": 0.996940960538391, \"specificity\": 0.999962372794025, \"npv\": 0.9999983987846135, \"accuracy\": 0.9999607921584317, \"f1\": 0.963773473310661, \"f2\": 0.9834037417018708, \"f0_5\": 0.9449115685706002, \"p4\": 0.9815431450690404, \"phi\": 0.9642882641241531}, {\"truth_threshold\": -9.600000143051147, \"match_probability\": 0.001286923510110021, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490542.0, \"fp\": 420.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999663756882776, \"fp_rate\": 3.3624311722347725e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9394638224272125, \"recall\": 0.996940960538391, \"specificity\": 0.9999663756882776, \"npv\": 0.9999983987910231, \"accuracy\": 0.9999647929585918, \"f1\": 0.9673493618284358, \"f2\": 0.9848896947718344, \"f0_5\": 0.9504228638086906, \"p4\": 0.9833952250018091, \"phi\": 0.9677586374919421}, {\"truth_threshold\": -9.500000141561031, \"match_probability\": 0.0013791630787767571, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490555.0, \"fp\": 407.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999674164407834, \"fp_rate\": 3.258355921665601e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9412274368231047, \"recall\": 0.996940960538391, \"specificity\": 0.9999674164407834, \"npv\": 0.9999983987926897, \"accuracy\": 0.9999658331666333, \"f1\": 0.9682834435118473, \"f2\": 0.9852767784260967, \"f0_5\": 0.9518663473333723, \"p4\": 0.9838779112091363, \"phi\": 0.9686670842733373}, {\"truth_threshold\": -9.400000140070915, \"match_probability\": 0.001478004086219237, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490574.0, \"fp\": 388.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999689375405993, \"fp_rate\": 3.106245940064504e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9438169707500724, \"recall\": 0.996940960538391, \"specificity\": 0.9999689375405993, \"npv\": 0.9999983987951253, \"accuracy\": 0.9999673534706941, \"f1\": 0.9696518893186552, \"f2\": 0.9858430637062133, \"f0_5\": 0.9539839587846145, \"p4\": 0.9845842286281121, \"phi\": 0.969999424669256}, {\"truth_threshold\": -9.300000138580799, \"match_probability\": 0.0015839175344616876, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490620.0, \"fp\": 342.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999726202033118, \"fp_rate\": 2.7379796688197435e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9501457725947522, \"recall\": 0.996940960538391, \"specificity\": 0.9999726202033118, \"npv\": 0.9999983988010223, \"accuracy\": 0.9999710342068414, \"f1\": 0.9729810419465592, \"f2\": 0.9872167696595178, \"f0_5\": 0.9591500382600506, \"p4\": 0.9862984673234562, \"phi\": 0.9732479787428381}, {\"truth_threshold\": -9.200000137090683, \"match_probability\": 0.0016974078152024628, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490631.0, \"fp\": 331.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999735008400474, \"fp_rate\": 2.6499159952612138e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9516717769017374, \"recall\": 0.996940960538391, \"specificity\": 0.9999735008400474, \"npv\": 0.9999983988024324, \"accuracy\": 0.9999719143828766, \"f1\": 0.9737805333532532, \"f2\": 0.9875458319444865, \"f0_5\": 0.9603937054281841, \"p4\": 0.9867092787208337, \"phi\": 0.9740296507920312}, {\"truth_threshold\": -9.100000135600567, \"match_probability\": 0.0018190150448253225, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490640.0, \"fp\": 322.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999742213610129, \"fp_rate\": 2.5778638987133255e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9529170931422722, \"recall\": 0.9967880085653105, \"specificity\": 0.9999742213610129, \"npv\": 0.9999983187439, \"accuracy\": 0.9999725545109022, \"f1\": 0.9743589743589743, \"f2\": 0.9876936134097178, \"f0_5\": 0.9613795952085915, \"p4\": 0.9870062990751359, \"phi\": 0.9745922690452772}, {\"truth_threshold\": -9.00000013411045, \"match_probability\": 0.0019493175579394322, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490663.0, \"fp\": 299.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.999976062692369, \"fp_rate\": 2.3937307630909453e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9561326291079812, \"recall\": 0.9967880085653105, \"specificity\": 0.999976062692369, \"npv\": 0.9999983187469957, \"accuracy\": 0.9999743948789758, \"f1\": 0.9760371424292347, \"f2\": 0.9883826741082261, \"f0_5\": 0.96399621324182, \"p4\": 0.987867025383053, \"phi\": 0.9762361272967678}, {\"truth_threshold\": -8.900000132620335, \"match_probability\": 0.002088934569496736, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490666.0, \"fp\": 296.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999763028660242, \"fp_rate\": 2.3697133975749826e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9565536474387201, \"recall\": 0.9967880085653105, \"specificity\": 0.9999763028660242, \"npv\": 0.9999983187473995, \"accuracy\": 0.9999746349269854, \"f1\": 0.9762564601902479, \"f2\": 0.9884726224783862, \"f0_5\": 0.9643385617046464, \"p4\": 0.9879794047192858, \"phi\": 0.9764511569575802}, {\"truth_threshold\": -8.800000131130219, \"match_probability\": 0.0022385290160630528, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490676.0, \"fp\": 286.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999771034448748, \"fp_rate\": 2.289655512521774e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9579597236513303, \"recall\": 0.9967880085653105, \"specificity\": 0.9999771034448748, \"npv\": 0.9999983187487456, \"accuracy\": 0.9999754350870174, \"f1\": 0.9769882317667341, \"f2\": 0.9887725686542255, \"f0_5\": 0.9654814814814815, \"p4\": 0.9883541872376157, \"phi\": 0.9771689492784599}, {\"truth_threshold\": -8.700000129640102, \"match_probability\": 0.002398810587356977, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490682.0, \"fp\": 280.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999775837921852, \"fp_rate\": 2.2416207814898486e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9588053553038105, \"recall\": 0.9967880085653105, \"specificity\": 0.9999775837921852, \"npv\": 0.9999983187495531, \"accuracy\": 0.9999759151830366, \"f1\": 0.9774278215223097, \"f2\": 0.9889526237518589, \"f0_5\": 0.9661685346616854, \"p4\": 0.9885791932636133, \"phi\": 0.9776003846778827}, {\"truth_threshold\": -8.600000128149986, \"match_probability\": 0.0025705389597152823, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490688.0, \"fp\": 274.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999780641394954, \"fp_rate\": 2.193586050457923e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9596524812251509, \"recall\": 0.9967880085653105, \"specificity\": 0.9999780641394954, \"npv\": 0.9999983187503607, \"accuracy\": 0.9999763952790558, \"f1\": 0.9778678070372872, \"f2\": 0.9891327444373615, \"f0_5\": 0.9668565663758827, \"p4\": 0.9888043017613464, \"phi\": 0.9780323916208583}, {\"truth_threshold\": -8.50000012665987, \"match_probability\": 0.0027545272436909716, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490703.0, \"fp\": 259.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999792650077712, \"fp_rate\": 2.0734992228781097e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9617768595041323, \"recall\": 0.9967880085653105, \"specificity\": 0.9999792650077712, \"npv\": 0.9999983187523798, \"accuracy\": 0.9999775955191038, \"f1\": 0.9789695057833859, \"f2\": 0.9895833333333334, \"f0_5\": 0.9685809404910528, \"p4\": 0.9893675217791658, \"phi\": 0.9791149177808539}, {\"truth_threshold\": -8.400000125169754, \"match_probability\": 0.0029516456585356845, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490713.0, \"fp\": 249.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999800655866218, \"fp_rate\": 1.993441337824901e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9631765749778172, \"recall\": 0.9961762006729887, \"specificity\": 0.9999800655866218, \"npv\": 0.9999979985169811, \"accuracy\": 0.999978075615123, \"f1\": 0.9793984962406015, \"f2\": 0.9893966093455673, \"f0_5\": 0.9696004287500745, \"p4\": 0.9895866678058491, \"phi\": 0.9795266136704868}, {\"truth_threshold\": -8.300000123679638, \"match_probability\": 0.0031628254468557835, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490717.0, \"fp\": 245.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.999980385818162, \"fp_rate\": 1.9614181838036174e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9637466706126073, \"recall\": 0.9961762006729887, \"specificity\": 0.999980385818162, \"npv\": 0.999997998517622, \"accuracy\": 0.9999783956791358, \"f1\": 0.9796931407942239, \"f2\": 0.9895168641750228, \"f0_5\": 0.9700625558534406, \"p4\": 0.9897371270993598, \"phi\": 0.9798166154183204}, {\"truth_threshold\": -8.200000122189522, \"match_probability\": 0.0033890630432542824, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490731.0, \"fp\": 231.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999815066285527, \"fp_rate\": 1.849337144729125e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9657473309608541, \"recall\": 0.9961762006729887, \"specificity\": 0.9999815066285527, \"npv\": 0.9999979985198654, \"accuracy\": 0.9999795159031807, \"f1\": 0.9807257943080862, \"f2\": 0.9899379863813229, \"f0_5\": 0.9716834755624515, \"p4\": 0.9902640951184987, \"phi\": 0.9808336521820024}, {\"truth_threshold\": -8.100000120699406, \"match_probability\": 0.003631424511270156, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490742.0, \"fp\": 220.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999823872652883, \"fp_rate\": 1.761273471170595e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9673251151047082, \"recall\": 0.9961762006729887, \"specificity\": 0.9999823872652883, \"npv\": 0.999997998521628, \"accuracy\": 0.9999803960792158, \"f1\": 0.9815386933916057, \"f2\": 0.9902691196594192, \"f0_5\": 0.9729608604720645, \"p4\": 0.99067853524719, \"phi\": 0.9816349764296647}, {\"truth_threshold\": -8.00000011920929, \"match_probability\": 0.0038910502633927486, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490761.0, \"fp\": 201.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999839083651043, \"fp_rate\": 1.6091634895694983e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9700625558534406, \"recall\": 0.9961762006729887, \"specificity\": 0.9999839083651043, \"npv\": 0.9999979985246725, \"accuracy\": 0.9999819163832766, \"f1\": 0.9829459704195593, \"f2\": 0.9908415992210795, \"f0_5\": 0.9751751811702701, \"p4\": 0.9913952040439943, \"phi\": 0.9830237167143293}, {\"truth_threshold\": -7.900000117719173, \"match_probability\": 0.004169160079349993, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490763.0, \"fp\": 199.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999840684808744, \"fp_rate\": 1.5931519125588566e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9703516090584029, \"recall\": 0.9961762006729887, \"specificity\": 0.9999840684808744, \"npv\": 0.9999979985249929, \"accuracy\": 0.999982076415283, \"f1\": 0.9830943396226415, \"f2\": 0.9909018987341772, \"f0_5\": 0.9754088540106631, \"p4\": 0.9914707031871538, \"phi\": 0.9831702427675592}, {\"truth_threshold\": -7.800000116229057, \"match_probability\": 0.004467058438231288, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490771.0, \"fp\": 191.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999847089439549, \"fp_rate\": 1.5291056045162895e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9715095465393795, \"recall\": 0.9961762006729887, \"specificity\": 0.9999847089439549, \"npv\": 0.9999979985262749, \"accuracy\": 0.9999827165433086, \"f1\": 0.9836882646125963, \"f2\": 0.9911431701972242, \"f0_5\": 0.9763446663068898, \"p4\": 0.9917728147865988, \"phi\": 0.9837570024108219}, {\"truth_threshold\": -7.700000114738941, \"match_probability\": 0.004786140180292905, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490777.0, \"fp\": 185.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999851892912651, \"fp_rate\": 1.481070873484364e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9723798148701105, \"recall\": 0.9961762006729887, \"specificity\": 0.9999851892912651, \"npv\": 0.9999979985272363, \"accuracy\": 0.9999831966393279, \"f1\": 0.9841341795104261, \"f2\": 0.991324200913242, \"f0_5\": 0.9770477047704771, \"p4\": 0.9919995193379518, \"phi\": 0.9841977617147393}, {\"truth_threshold\": -7.600000113248825, \"match_probability\": 0.0051278965144870335, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490794.0, \"fp\": 168.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.999986550275311, \"fp_rate\": 1.3449724688939091e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9748540637629097, \"recall\": 0.9961762006729887, \"specificity\": 0.999986550275311, \"npv\": 0.9999979985299603, \"accuracy\": 0.9999845569113823, \"f1\": 0.9853998033134125, \"f2\": 0.9918374805835593, \"f0_5\": 0.9790451566351993, \"p4\": 0.992642412101128, \"phi\": 0.9854498019388348}, {\"truth_threshold\": -7.500000111758709, \"match_probability\": 0.005493921387833209, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490796.0, \"fp\": 166.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999867103910811, \"fp_rate\": 1.3289608918832673e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9751459799371164, \"recall\": 0.9961762006729887, \"specificity\": 0.9999867103910811, \"npv\": 0.9999979985302807, \"accuracy\": 0.9999847169433886, \"f1\": 0.9855489142770674, \"f2\": 0.9918979013737017, \"f0_5\": 0.9792806880375293, \"p4\": 0.9927181013316726, \"phi\": 0.985597414919845}, {\"truth_threshold\": -7.400000110268593, \"match_probability\": 0.005885918232687788, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490801.0, \"fp\": 161.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999871106805064, \"fp_rate\": 1.2889319493566628e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9758765358106083, \"recall\": 0.9961762006729887, \"specificity\": 0.9999871106805064, \"npv\": 0.999997998531082, \"accuracy\": 0.9999851170234046, \"f1\": 0.9859218891916439, \"f2\": 0.9920489855602267, \"f0_5\": 0.9798700126376603, \"p4\": 0.9929073749166801, \"phi\": 0.9859667375704761}, {\"truth_threshold\": -7.300000108778477, \"match_probability\": 0.006305707107734554, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490805.0, \"fp\": 157.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999874309120467, \"fp_rate\": 1.2569087953353792e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9764617691154422, \"recall\": 0.9961762006729887, \"specificity\": 0.9999874309120467, \"npv\": 0.9999979985317229, \"accuracy\": 0.9999854370874175, \"f1\": 0.9862204724409449, \"f2\": 0.9921698860520383, \"f0_5\": 0.9803419832620868, \"p4\": 0.9930588457582312, \"phi\": 0.9862624945906032}, {\"truth_threshold\": -7.200000107288361, \"match_probability\": 0.006755232248084272, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490815.0, \"fp\": 147.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999882314908972, \"fp_rate\": 1.1768509102821704e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9779279279279279, \"recall\": 0.9961762006729887, \"specificity\": 0.9999882314908972, \"npv\": 0.9999979985333253, \"accuracy\": 0.9999862372474495, \"f1\": 0.9869677223821791, \"f2\": 0.992472266244057, \"f0_5\": 0.9815239013804328, \"p4\": 0.9934377251279669, \"phi\": 0.987003052290932}, {\"truth_threshold\": -7.1000001057982445, \"match_probability\": 0.007236570039195372, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490816.0, \"fp\": 146.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999883115487822, \"fp_rate\": 1.1688451217768496e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9780747860039045, \"recall\": 0.9961762006729887, \"specificity\": 0.9999883115487822, \"npv\": 0.9999979985334855, \"accuracy\": 0.9999863172634527, \"f1\": 0.9870425096612867, \"f2\": 0.9925025144006583, \"f0_5\": 0.9816422499547839, \"p4\": 0.9934756289663533, \"phi\": 0.9870771997802797}, {\"truth_threshold\": -7.000000104308128, \"match_probability\": 0.00775193742836891, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490823.0, \"fp\": 139.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999888719539776, \"fp_rate\": 1.1128046022396034e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9791040288634997, \"recall\": 0.9961762006729887, \"specificity\": 0.9999888719539776, \"npv\": 0.9999979985346071, \"accuracy\": 0.9999868773754751, \"f1\": 0.9875663381349508, \"f2\": 0.9927143031337642, \"f0_5\": 0.9824714897725215, \"p4\": 0.993741036843316, \"phi\": 0.9875967001930721}, {\"truth_threshold\": -6.900000102818012, \"match_probability\": 0.008303700786279804, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490825.0, \"fp\": 137.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999890320697478, \"fp_rate\": 1.0967930252289615e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9793984962406015, \"recall\": 0.9961762006729887, \"specificity\": 0.9999890320697478, \"npv\": 0.9999979985349275, \"accuracy\": 0.9999870374074815, \"f1\": 0.9877161055505005, \"f2\": 0.9927748308029998, \"f0_5\": 0.9827086728227412, \"p4\": 0.9938168937136123, \"phi\": 0.9877452794954199}, {\"truth_threshold\": -6.800000101327896, \"match_probability\": 0.00889438522932807, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490828.0, \"fp\": 134.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999892722434028, \"fp_rate\": 1.0727756597129988e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9798405295622085, \"recall\": 0.9961762006729887, \"specificity\": 0.9999892722434028, \"npv\": 0.9999979985354083, \"accuracy\": 0.9999872774554911, \"f1\": 0.9879408418657566, \"f2\": 0.9928656361474435, \"f0_5\": 0.983064662198877, \"p4\": 0.9939307007359219, \"phi\": 0.9879682741485495}, {\"truth_threshold\": -6.70000009983778, \"match_probability\": 0.009526684411466419, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490830.0, \"fp\": 132.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999894323591729, \"fp_rate\": 1.056764082702357e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.980135440180587, \"recall\": 0.9961762006729887, \"specificity\": 0.9999894323591729, \"npv\": 0.9999979985357288, \"accuracy\": 0.9999874374874975, \"f1\": 0.9880907229007054, \"f2\": 0.9929261822727689, \"f0_5\": 0.9833021317712423, \"p4\": 0.9940065865659075, \"phi\": 0.9881170211239295}, {\"truth_threshold\": -6.600000098347664, \"match_probability\": 0.010203470791514735, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490849.0, \"fp\": 113.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.999990953458989, \"fp_rate\": 9.046541011012603e-06, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9829459704195593, \"recall\": 0.9961762006729887, \"specificity\": 0.999990953458989, \"npv\": 0.9999979985387731, \"accuracy\": 0.9999889577915583, \"f1\": 0.9895168641750228, \"f2\": 0.9935017389712613, \"f0_5\": 0.9855638278554567, \"p4\": 0.9947280803035358, \"phi\": 0.9895334740312796}, {\"truth_threshold\": -6.500000096857548, \"match_probability\": 0.010927806378730125, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490853.0, \"fp\": 109.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999912736905292, \"fp_rate\": 8.726309470799766e-06, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9835397160978556, \"recall\": 0.9961762006729887, \"specificity\": 0.9999912736905292, \"npv\": 0.9999979985394141, \"accuracy\": 0.9999892778555711, \"f1\": 0.9898176291793314, \"f2\": 0.9936229938365778, \"f0_5\": 0.9860413007933143, \"p4\": 0.9948801072038869, \"phi\": 0.9898324510398088}, {\"truth_threshold\": -6.400000095367432, \"match_probability\": 0.011702953955477532, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6512.0, \"tn\": 12490865.0, \"fp\": 97.0, \"fn\": 26.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9960232486999082, \"tn_rate\": 0.9999922343851498, \"fp_rate\": 7.76561485016126e-06, \"fn_rate\": 0.0039767513000917715, \"precision\": 0.9853230443334846, \"recall\": 0.9960232486999082, \"specificity\": 0.9999922343851498, \"npv\": 0.999997918483157, \"accuracy\": 0.9999901580316063, \"f1\": 0.9906442534418498, \"f2\": 0.9938646561460273, \"f0_5\": 0.9874446533632559, \"p4\": 0.995297702670591, \"phi\": 0.9906537915809195}, {\"truth_threshold\": -6.3000000938773155, \"match_probability\": 0.012532388771145032, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6512.0, \"tn\": 12490868.0, \"fp\": 94.0, \"fn\": 26.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9960232486999082, \"tn_rate\": 0.999992474558805, \"fp_rate\": 7.525441195001634e-06, \"fn_rate\": 0.0039767513000917715, \"precision\": 0.9857705116560702, \"recall\": 0.9960232486999082, \"specificity\": 0.999992474558805, \"npv\": 0.9999979184836569, \"accuracy\": 0.9999903980796159, \"f1\": 0.9908703590992087, \"f2\": 0.9939556749496307, \"f0_5\": 0.9878041380984164, \"p4\": 0.9954118666360929, \"phi\": 0.990878830085307}, {\"truth_threshold\": -6.200000092387199, \"match_probability\": 0.013419810695865477, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6511.0, \"tn\": 12490868.0, \"fp\": 94.0, \"fn\": 27.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9958702967268278, \"tn_rate\": 0.999992474558805, \"fp_rate\": 7.525441195001634e-06, \"fn_rate\": 0.004129703273172224, \"precision\": 0.985768357305072, \"recall\": 0.9958702967268278, \"specificity\": 0.999992474558805, \"npv\": 0.9999978384255092, \"accuracy\": 0.9999903180636127, \"f1\": 0.9907935783306703, \"f2\": 0.9938333791250725, \"f0_5\": 0.9877723162813278, \"p4\": 0.9953731022079875, \"phi\": 0.9908016226873835}, {\"truth_threshold\": -6.100000090897083, \"match_probability\": 0.014369156816028038, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6510.0, \"tn\": 12490869.0, \"fp\": 93.0, \"fn\": 28.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9957173447537473, \"tn_rate\": 0.99999255461669, \"fp_rate\": 7.445383309948425e-06, \"fn_rate\": 0.004282655246252677, \"precision\": 0.9859154929577465, \"recall\": 0.9957173447537473, \"specificity\": 0.99999255461669, \"npv\": 0.9999977583675536, \"accuracy\": 0.9999903180636127, \"f1\": 0.9907921771554676, \"f2\": 0.9937414135246527, \"f0_5\": 0.9878603945371776, \"p4\": 0.9953723951287743, \"phi\": 0.9907994672309304}, {\"truth_threshold\": -6.000000089406967, \"match_probability\": 0.015384614445865122, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6510.0, \"tn\": 12490874.0, \"fp\": 88.0, \"fn\": 28.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9957173447537473, \"tn_rate\": 0.9999929549061153, \"fp_rate\": 7.045093884682381e-06, \"fn_rate\": 0.004282655246252677, \"precision\": 0.9866626250378903, \"recall\": 0.9957173447537473, \"specificity\": 0.9999929549061153, \"npv\": 0.9999977583684508, \"accuracy\": 0.9999907181436287, \"f1\": 0.991169305724726, \"f2\": 0.9938931297709923, \"f0_5\": 0.9884603704828424, \"p4\": 0.9955627699695268, \"phi\": 0.9911750128125926}, {\"truth_threshold\": -5.900000087916851, \"match_probability\": 0.016470634520449206, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6510.0, \"tn\": 12490880.0, \"fp\": 82.0, \"fn\": 28.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9957173447537473, \"tn_rate\": 0.9999934352534257, \"fp_rate\": 6.564746574363128e-06, \"fn_rate\": 0.004282655246252677, \"precision\": 0.9875606796116505, \"recall\": 0.9957173447537473, \"specificity\": 0.9999934352534257, \"npv\": 0.9999977583695276, \"accuracy\": 0.9999911982396479, \"f1\": 0.9916222391469917, \"f2\": 0.9940752504275593, \"f0_5\": 0.9891813043214004, \"p4\": 0.9957913159256325, \"phi\": 0.9916262312912583}, {\"truth_threshold\": -5.800000086426735, \"match_probability\": 0.017631945325087592, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6506.0, \"tn\": 12490884.0, \"fp\": 78.0, \"fn\": 32.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9951055368614256, \"tn_rate\": 0.9999937554849658, \"fp_rate\": 6.244515034150292e-06, \"fn_rate\": 0.004894463138574488, \"precision\": 0.9881530984204131, \"recall\": 0.9951055368614256, \"specificity\": 0.9999937554849658, \"npv\": 0.9999974381382438, \"accuracy\": 0.9999911982396479, \"f1\": 0.991617131534827, \"f2\": 0.9937072336265884, \"f0_5\": 0.9895358033704448, \"p4\": 0.9957887405945726, \"phi\": 0.9916188278069484}, {\"truth_threshold\": -5.700000084936619, \"match_probability\": 0.01887356650421064, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6506.0, \"tn\": 12490887.0, \"fp\": 75.0, \"fn\": 32.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9951055368614256, \"tn_rate\": 0.999993995658621, \"fp_rate\": 6.004341378990665e-06, \"fn_rate\": 0.004894463138574488, \"precision\": 0.9886035556906245, \"recall\": 0.9951055368614256, \"specificity\": 0.999993995658621, \"npv\": 0.9999974381388591, \"accuracy\": 0.9999914382876576, \"f1\": 0.9918438905404375, \"f2\": 0.9937983075184065, \"f0_5\": 0.9898971456393403, \"p4\": 0.9959031225875888, \"phi\": 0.9918449409099048}, {\"truth_threshold\": -5.600000083446503, \"match_probability\": 0.02020082327925431, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6506.0, \"tn\": 12490888.0, \"fp\": 74.0, \"fn\": 32.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9951055368614256, \"tn_rate\": 0.9999940757165061, \"fp_rate\": 5.924283493937457e-06, \"fn_rate\": 0.004894463138574488, \"precision\": 0.9887537993920973, \"recall\": 0.9951055368614256, \"specificity\": 0.9999940757165061, \"npv\": 0.9999974381390642, \"accuracy\": 0.9999915183036607, \"f1\": 0.9919194999237688, \"f2\": 0.9938286691922278, \"f0_5\": 0.9900176517134336, \"p4\": 0.995941255758176, \"phi\": 0.9919203462996456}, {\"truth_threshold\": -5.500000081956387, \"match_probability\": 0.02161936078957948, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6504.0, \"tn\": 12490888.0, \"fp\": 74.0, \"fn\": 34.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9947996329152646, \"tn_rate\": 0.9999940757165061, \"fp_rate\": 5.924283493937457e-06, \"fn_rate\": 0.005200367084735393, \"precision\": 0.9887503800547279, \"recall\": 0.9947996329152646, \"specificity\": 0.9999940757165061, \"npv\": 0.9999972780231916, \"accuracy\": 0.9999913582716543, \"f1\": 0.9917657822506862, \"f2\": 0.9935838680109991, \"f0_5\": 0.9899543378995433, \"p4\": 0.9958637267283781, \"phi\": 0.991766076088667}, {\"truth_threshold\": -5.4000000804662704, \"match_probability\": 0.023135158452986655, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6504.0, \"tn\": 12490923.0, \"fp\": 39.0, \"fn\": 34.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9947996329152646, \"tn_rate\": 0.9999968777424829, \"fp_rate\": 3.122257517075146e-06, \"fn_rate\": 0.005200367084735393, \"precision\": 0.9940394314534617, \"recall\": 0.9947996329152646, \"specificity\": 0.9999968777424829, \"npv\": 0.9999972780308186, \"accuracy\": 0.9999941588317663, \"f1\": 0.9944193868970262, \"f2\": 0.9946474996176785, \"f0_5\": 0.9941913787832467, \"p4\": 0.9972004329584191, \"phi\": 0.9944165375036114}, {\"truth_threshold\": -5.300000078976154, \"match_probability\": 0.024754544222716376, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6502.0, \"tn\": 12490925.0, \"fp\": 37.0, \"fn\": 36.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9944937289691037, \"tn_rate\": 0.999997037858253, \"fp_rate\": 2.9621417469687283e-06, \"fn_rate\": 0.005506271030896299, \"precision\": 0.9943416424529744, \"recall\": 0.9944937289691037, \"specificity\": 0.999997037858253, \"npv\": 0.9999971179159074, \"accuracy\": 0.9999941588317663, \"f1\": 0.9944176798960006, \"f2\": 0.9944633079440824, \"f0_5\": 0.9943720560347464, \"p4\": 0.9971995746768392, \"phi\": 0.9944147606936516}, {\"truth_threshold\": -5.200000077486038, \"match_probability\": 0.02648420859582165, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6500.0, \"tn\": 12490925.0, \"fp\": 37.0, \"fn\": 38.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9941878250229428, \"tn_rate\": 0.999997037858253, \"fp_rate\": 2.9621417469687283e-06, \"fn_rate\": 0.005812174977057204, \"precision\": 0.9943399112742849, \"recall\": 0.9941878250229428, \"specificity\": 0.999997037858253, \"npv\": 0.9999969578006115, \"accuracy\": 0.9999939987997599, \"f1\": 0.994263862332696, \"f2\": 0.9942182385511946, \"f0_5\": 0.9943094903016582, \"p4\": 0.997122189222688, \"phi\": 0.994260863073139}, {\"truth_threshold\": -5.100000075995922, \"match_probability\": 0.02833121820332325, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6500.0, \"tn\": 12490938.0, \"fp\": 24.0, \"fn\": 38.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9941878250229428, \"tn_rate\": 0.9999980786107587, \"fp_rate\": 1.921389241277013e-06, \"fn_rate\": 0.005812174977057204, \"precision\": 0.9963212752912324, \"recall\": 0.9941878250229428, \"specificity\": 0.9999980786107587, \"npv\": 0.9999969578037777, \"accuracy\": 0.9999950390078015, \"f1\": 0.9952534068289696, \"f2\": 0.9946137838168686, \"f0_5\": 0.9958938530367102, \"p4\": 0.9976198224772822, \"phi\": 0.995251497299198}, {\"truth_threshold\": -5.000000074505806, \"match_probability\": 0.030303028785498974, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6496.0, \"tn\": 12490939.0, \"fp\": 23.0, \"fn\": 42.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9935760171306209, \"tn_rate\": 0.9999981586686437, \"fp_rate\": 1.841331356223804e-06, \"fn_rate\": 0.006423982869379015, \"precision\": 0.996471851510968, \"recall\": 0.9935760171306209, \"specificity\": 0.9999981586686437, \"npv\": 0.9999966375739423, \"accuracy\": 0.9999947989597919, \"f1\": 0.9950218273722907, \"f2\": 0.9941538367359432, \"f0_5\": 0.9958913350095051, \"p4\": 0.9975034082187577, \"phi\": 0.9950202800709534}, {\"truth_threshold\": -4.90000007301569, \"match_probability\": 0.032407497325934585, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6496.0, \"tn\": 12490940.0, \"fp\": 22.0, \"fn\": 42.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9935760171306209, \"tn_rate\": 0.9999982387265288, \"fp_rate\": 1.7612734711705952e-06, \"fn_rate\": 0.006423982869379015, \"precision\": 0.996624731512734, \"recall\": 0.9935760171306209, \"specificity\": 0.9999982387265288, \"npv\": 0.9999966375742115, \"accuracy\": 0.9999948789757952, \"f1\": 0.9950980392156863, \"f2\": 0.9941842669115396, \"f0_5\": 0.9960134927936216, \"p4\": 0.9975417229029651, \"phi\": 0.9950966461414167}, {\"truth_threshold\": -4.800000071525574, \"match_probability\": 0.03465289308554322, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6496.0, \"tn\": 12490943.0, \"fp\": 19.0, \"fn\": 42.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9935760171306209, \"tn_rate\": 0.999998478900184, \"fp_rate\": 1.5210998160109686e-06, \"fn_rate\": 0.006423982869379015, \"precision\": 0.9970836531082118, \"recall\": 0.9935760171306209, \"specificity\": 0.999998478900184, \"npv\": 0.9999966375750191, \"accuracy\": 0.9999951190238048, \"f1\": 0.9953267448096224, \"f2\": 0.9942755686166468, \"f0_5\": 0.9963801460212283, \"p4\": 0.997656684617874, \"phi\": 0.9953258498189623}, {\"truth_threshold\": -4.700000070035458, \"match_probability\": 0.037047907242669466, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6495.0, \"tn\": 12490945.0, \"fp\": 17.0, \"fn\": 43.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9934230651575405, \"tn_rate\": 0.9999986390159541, \"fp_rate\": 1.3609840459045507e-06, \"fn_rate\": 0.006576934842459468, \"precision\": 0.9973894348894349, \"recall\": 0.9934230651575405, \"specificity\": 0.9999986390159541, \"npv\": 0.9999965575181082, \"accuracy\": 0.9999951990398079, \"f1\": 0.9954022988505747, \"f2\": 0.9942138133725202, \"f0_5\": 0.9965936291658994, \"p4\": 0.9976946571936713, \"phi\": 0.995401874770323}, {\"truth_threshold\": -4.6000000685453415, \"match_probability\": 0.039601660807737325, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6493.0, \"tn\": 12490947.0, \"fp\": 15.0, \"fn\": 45.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9931171612113796, \"tn_rate\": 0.9999987991317242, \"fp_rate\": 1.2008682757981331e-06, \"fn_rate\": 0.0068828387886203735, \"precision\": 0.9976951444376152, \"recall\": 0.9931171612113796, \"specificity\": 0.9999987991317242, \"npv\": 0.9999963974038251, \"accuracy\": 0.9999951990398079, \"f1\": 0.9954008891614288, \"f2\": 0.9940293937538273, \"f0_5\": 0.9967761743936138, \"p4\": 0.9976939490986125, \"phi\": 0.9954011220116512}, {\"truth_threshold\": -4.500000067055225, \"match_probability\": 0.04232371044088178, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6491.0, \"tn\": 12490947.0, \"fp\": 15.0, \"fn\": 47.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9928112572652187, \"tn_rate\": 0.9999987991317242, \"fp_rate\": 1.2008682757981331e-06, \"fn_rate\": 0.007188742734781279, \"precision\": 0.9976944359053181, \"recall\": 0.9928112572652187, \"specificity\": 0.9999987991317242, \"npv\": 0.999996237289042, \"accuracy\": 0.9999950390078015, \"f1\": 0.995246856792395, \"f2\": 0.9937840651601445, \"f0_5\": 0.996713961058903, \"p4\": 0.9976165318565344, \"phi\": 0.9952473730288349}, {\"truth_threshold\": -4.300000064074993, \"match_probability\": 0.048313119674570026, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6490.0, \"tn\": 12490948.0, \"fp\": 14.0, \"fn\": 48.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9926583052921383, \"tn_rate\": 0.9999988791896093, \"fp_rate\": 1.120810390744924e-06, \"fn_rate\": 0.007341694707861731, \"precision\": 0.9978474784747847, \"recall\": 0.9926583052921383, \"specificity\": 0.9999988791896093, \"npv\": 0.9999961572319773, \"accuracy\": 0.9999950390078015, \"f1\": 0.9952461278944947, \"f2\": 0.9936918177364037, \"f0_5\": 0.9968053081034589, \"p4\": 0.997616165669983, \"phi\": 0.9952470316327022}, {\"truth_threshold\": -4.200000062584877, \"match_probability\": 0.05160178526561565, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6488.0, \"tn\": 12490948.0, \"fp\": 14.0, \"fn\": 50.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9923524013459774, \"tn_rate\": 0.9999988791896093, \"fp_rate\": 1.120810390744924e-06, \"fn_rate\": 0.007647598654022637, \"precision\": 0.9978468163641956, \"recall\": 0.9923524013459774, \"specificity\": 0.9999988791896093, \"npv\": 0.9999959971172839, \"accuracy\": 0.9999948789757952, \"f1\": 0.9950920245398773, \"f2\": 0.9934464384148955, \"f0_5\": 0.996743071345173, \"p4\": 0.9975387007682611, \"phi\": 0.9950932588112428}, {\"truth_threshold\": -4.100000061094761, \"match_probability\": 0.0551013486283602, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6488.0, \"tn\": 12490949.0, \"fp\": 13.0, \"fn\": 50.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9923524013459774, \"tn_rate\": 0.9999989592474943, \"fp_rate\": 1.0407525056917153e-06, \"fn_rate\": 0.007647598654022637, \"precision\": 0.9980003076449777, \"recall\": 0.9923524013459774, \"specificity\": 0.9999989592474943, \"npv\": 0.9999959971176045, \"accuracy\": 0.9999949589917984, \"f1\": 0.9951683411304548, \"f2\": 0.9934768627691177, \"f0_5\": 0.9968655890848749, \"p4\": 0.9975770653881216, \"phi\": 0.9951698301789526}, {\"truth_threshold\": -3.8000000566244125, \"match_probability\": 0.06698457743861425, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6488.0, \"tn\": 12490953.0, \"fp\": 9.0, \"fn\": 50.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9923524013459774, \"tn_rate\": 0.9999992794790346, \"fp_rate\": 7.205209654788799e-07, \"fn_rate\": 0.007647598654022637, \"precision\": 0.9986147452670463, \"recall\": 0.9923524013459774, \"specificity\": 0.9999992794790346, \"npv\": 0.9999959971188863, \"accuracy\": 0.9999952790558112, \"f1\": 0.9954737245876486, \"f2\": 0.9935985788232411, \"f0_5\": 0.9973559613847384, \"p4\": 0.9977305533815848, \"phi\": 0.9954762923829944}, {\"truth_threshold\": -3.7000000551342964, \"match_probability\": 0.07144878715678568, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6488.0, \"tn\": 12490954.0, \"fp\": 8.0, \"fn\": 50.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9923524013459774, \"tn_rate\": 0.9999993595369195, \"fp_rate\": 6.40463080425671e-07, \"fn_rate\": 0.007647598654022637, \"precision\": 0.9987684729064039, \"recall\": 0.9923524013459774, \"specificity\": 0.9999993595369195, \"npv\": 0.9999959971192067, \"accuracy\": 0.9999953590718144, \"f1\": 0.9955500997391438, \"f2\": 0.993629012496937, \"f0_5\": 0.9974786298505627, \"p4\": 0.9977689327601589, \"phi\": 0.9955529521513098}, {\"truth_threshold\": -3.6000000536441803, \"match_probability\": 0.0761862214703254, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6487.0, \"tn\": 12490954.0, \"fp\": 8.0, \"fn\": 51.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.992199449372897, \"tn_rate\": 0.9999993595369195, \"fp_rate\": 6.40463080425671e-07, \"fn_rate\": 0.00780055062710309, \"precision\": 0.9987682832948422, \"recall\": 0.992199449372897, \"specificity\": 0.9999993595369195, \"npv\": 0.9999959170619177, \"accuracy\": 0.9999952790558112, \"f1\": 0.9954730300007673, \"f2\": 0.9935062946059362, \"f0_5\": 0.9974475675010763, \"p4\": 0.9977302045116406, \"phi\": 0.9954760921166026}, {\"truth_threshold\": -3.400000050663948, \"match_probability\": 0.08653465658300358, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6487.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 51.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.992199449372897, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.00780055062710309, \"precision\": 0.9989220819217739, \"recall\": 0.992199449372897, \"specificity\": 0.9999994395948046, \"npv\": 0.9999959170622447, \"accuracy\": 0.9999953590718144, \"f1\": 0.9955494168201351, \"f2\": 0.9935367273172824, \"f0_5\": 0.997570277418958, \"p4\": 0.9977685897768772, \"phi\": 0.9955527754779164}, {\"truth_threshold\": -3.200000047683716, \"match_probability\": 0.09813940308831819, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6486.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 52.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9920464973998164, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.007953502600183543, \"precision\": 0.9989219159094409, \"recall\": 0.9920464973998164, \"specificity\": 0.9999994395948046, \"npv\": 0.9999958370049749, \"accuracy\": 0.9999952790558112, \"f1\": 0.9954723352006754, \"f2\": 0.9934139990810231, \"f0_5\": 0.9975392187019378, \"p4\": 0.9977298555343642, \"phi\": 0.9954759154146037}, {\"truth_threshold\": -3.1000000461935997, \"match_probability\": 0.10444750015659417, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6485.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 53.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.991893545426736, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.008106454573263994, \"precision\": 0.9989217498459643, \"recall\": 0.991893545426736, \"specificity\": 0.9999994395948046, \"npv\": 0.9999957569477179, \"accuracy\": 0.9999951990398079, \"f1\": 0.9953952417498081, \"f2\": 0.9932912633255728, \"f0_5\": 0.9975081523411062, \"p4\": 0.9976911123608679, \"phi\": 0.9953990494288513}, {\"truth_threshold\": -3.0000000447034836, \"match_probability\": 0.11111110805075623, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6484.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 54.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9917405934536555, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.008259406546344448, \"precision\": 0.9989215837313203, \"recall\": 0.9917405934536555, \"specificity\": 0.9999994395948046, \"npv\": 0.9999956768904738, \"accuracy\": 0.9999951190238048, \"f1\": 0.9953181364648093, \"f2\": 0.9931685200502405, \"f0_5\": 0.997477078333641, \"p4\": 0.9976523602532964, \"phi\": 0.9953221775192872}, {\"truth_threshold\": -2.9000000432133675, \"match_probability\": 0.11814376082605058, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6483.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 55.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9915876414805751, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.0084123585194249, \"precision\": 0.9989214175654854, \"recall\": 0.9915876414805751, \"specificity\": 0.9999994395948046, \"npv\": 0.9999955968332425, \"accuracy\": 0.9999950390078015, \"f1\": 0.9952410193429536, \"f2\": 0.9930457692543349, \"f0_5\": 0.9974459966767185, \"p4\": 0.9976135992085561, \"phi\": 0.9952452996845389}, {\"truth_threshold\": -2.8000000417232513, \"match_probability\": 0.1255586621587546, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6479.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 59.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9909758335882533, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.009024166411746712, \"precision\": 0.9989207523897625, \"recall\": 0.9909758335882533, \"specificity\": 0.9999994395948046, \"npv\": 0.9999952766044454, \"accuracy\": 0.9999947189437888, \"f1\": 0.9949324324324325, \"f2\": 0.9925546908511551, \"f0_5\": 0.9973215934979374, \"p4\": 0.9974584655959884, \"phi\": 0.9949377290662319}, {\"truth_threshold\": -2.600000038743019, \"match_probability\": 0.1415855743659812, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6476.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 62.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9905169776690119, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.00948302233098807, \"precision\": 0.9989202529693043, \"recall\": 0.9905169776690119, \"specificity\": 0.9999994395948046, \"npv\": 0.9999950364329822, \"accuracy\": 0.9999944788957792, \"f1\": 0.9947008678288918, \"f2\": 0.9921863030488739, \"f0_5\": 0.9972282106559901, \"p4\": 0.9973420213944986, \"phi\": 0.9947069888207287}, {\"truth_threshold\": -2.500000037252903, \"match_probability\": 0.15022110152606716, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6475.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 63.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9903640256959315, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.009635974304068522, \"precision\": 0.9989200863930886, \"recall\": 0.9903640256959315, \"specificity\": 0.9999994395948046, \"npv\": 0.9999949563758534, \"accuracy\": 0.9999943988797759, \"f1\": 0.9946236559139785, \"f2\": 0.9920634920634921, \"f0_5\": 0.9971970677015956, \"p4\": 0.9973031887408722, \"phi\": 0.9946300635350278}, {\"truth_threshold\": -2.3000000342726707, \"match_probability\": 0.16878839957195682, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6474.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 64.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.990211073722851, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.009788926277148976, \"precision\": 0.9989199197654683, \"recall\": 0.990211073722851, \"specificity\": 0.9999994395948046, \"npv\": 0.9999948763187375, \"accuracy\": 0.9999943188637728, \"f1\": 0.9945464321376449, \"f2\": 0.9919406735513131, \"f0_5\": 0.9971659170722691, \"p4\": 0.9972643471221716, \"phi\": 0.9945531323117648}, {\"truth_threshold\": -1.9000000283122063, \"match_probability\": 0.2113212378007128, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6471.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 67.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9897522178036097, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.010247782196390333, \"precision\": 0.9989194195739426, \"recall\": 0.9897522178036097, \"specificity\": 0.9999994395948046, \"npv\": 0.9999946361474665, \"accuracy\": 0.9999940788157632, \"f1\": 0.9943146896127842, \"f2\": 0.9915721728470732, \"f0_5\": 0.9970724191063174, \"p4\": 0.9971477684445391, \"phi\": 0.9943223030028223}, {\"truth_threshold\": -1.700000025331974, \"match_probability\": 0.2353489599091234, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6466.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 72.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9889874579382074, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.011012542061792597, \"precision\": 0.9989185848910861, \"recall\": 0.9889874579382074, \"specificity\": 0.9999994395948046, \"npv\": 0.9999942358622713, \"accuracy\": 0.9999936787357472, \"f1\": 0.9939282145876566, \"f2\": 0.9909578544061303, \"f0_5\": 0.9969164353993216, \"p4\": 0.9969532910566576, \"phi\": 0.9939374686079666}, {\"truth_threshold\": -1.600000023841858, \"match_probability\": 0.24805074388621665, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6465.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 73.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9888345059651269, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.01116549403487305, \"precision\": 0.9989184177997528, \"recall\": 0.9888345059651269, \"specificity\": 0.9999994395948046, \"npv\": 0.9999941558052708, \"accuracy\": 0.9999935987197439, \"f1\": 0.9938508839354343, \"f2\": 0.9908349681216283, \"f0_5\": 0.9968852155677542, \"p4\": 0.996914368612266, \"phi\": 0.9938604838845746}, {\"truth_threshold\": -1.4000000208616257, \"match_probability\": 0.2747995717943022, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6464.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 74.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9886815539920465, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.011318446007953502, \"precision\": 0.9989182506567764, \"recall\": 0.9886815539920465, \"specificity\": 0.9999994395948046, \"npv\": 0.999994075748283, \"accuracy\": 0.9999935187037408, \"f1\": 0.9937735413944192, \"f2\": 0.9907120743034056, \"f0_5\": 0.9968539880328172, \"p4\": 0.9968754371716575, \"phi\": 0.9937834932098174}, {\"truth_threshold\": -1.2000000178813934, \"match_probability\": 0.3032695424040186, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6463.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 75.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9885286020189661, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.011471397981033955, \"precision\": 0.998918083462133, \"recall\": 0.9885286020189661, \"specificity\": 0.9999994395948046, \"npv\": 0.9999939956913081, \"accuracy\": 0.9999934386877376, \"f1\": 0.9936961869618696, \"f2\": 0.9905891729507694, \"f0_5\": 0.996822752791659, \"p4\": 0.99683649673171, \"phi\": 0.9937064965823112}, {\"truth_threshold\": -1.1000000163912773, \"match_probability\": 0.318111997717226, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6462.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 76.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9883756500458856, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.011624349954114408, \"precision\": 0.9989179162157984, \"recall\": 0.9883756500458856, \"specificity\": 0.9999994395948046, \"npv\": 0.9999939156343459, \"accuracy\": 0.9999933586717343, \"f1\": 0.9936188206350427, \"f2\": 0.9904662640630268, \"f0_5\": 0.9967915098414265, \"p4\": 0.9967975472893, \"phi\": 0.9936294940006725}, {\"truth_threshold\": -1.0000000149011612, \"match_probability\": 0.33333333103806717, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6458.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 80.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9877638421535638, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.012236157846436219, \"precision\": 0.9989172467130704, \"recall\": 0.9877638421535638, \"specificity\": 0.9999994395948046, \"npv\": 0.9999935954066256, \"accuracy\": 0.9999930386077216, \"f1\": 0.9933092363300777, \"f2\": 0.9899745531471319, \"f0_5\": 0.9966664608926477, \"p4\": 0.9966416594325102, \"phi\": 0.9933214241050966}, {\"truth_threshold\": -0.800000011920929, \"match_probability\": 0.36481689239780585, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6457.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 81.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9876108901804833, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.012389109819516672, \"precision\": 0.9989170792079208, \"recall\": 0.9876108901804833, \"specificity\": 0.9999994395948046, \"npv\": 0.9999935153497276, \"accuracy\": 0.9999929585917183, \"f1\": 0.9932318104906938, \"f2\": 0.9898516065734608, \"f0_5\": 0.9966351793542014, \"p4\": 0.9966026649308819, \"phi\": 0.9932443917320187}, {\"truth_threshold\": -0.7000000104308128, \"match_probability\": 0.38102425962470177, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6456.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 82.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9874579382074029, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.012542061792597125, \"precision\": 0.9989169116509361, \"recall\": 0.9874579382074029, \"specificity\": 0.9999994395948046, \"npv\": 0.9999934352928423, \"accuracy\": 0.9999928785757152, \"f1\": 0.9931543727405584, \"f2\": 0.9897286524605243, \"f0_5\": 0.9966038900895338, \"p4\": 0.9965636614080188, \"phi\": 0.9931673533964943}, {\"truth_threshold\": -0.5000000074505806, \"match_probability\": 0.41421356112001384, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6454.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 84.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.987152034261242, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.01284796573875803, \"precision\": 0.9992258863601177, \"recall\": 0.987152034261242, \"specificity\": 0.9999995997105747, \"npv\": 0.9999932751801871, \"accuracy\": 0.9999928785757152, \"f1\": 0.9931522659075172, \"f2\": 0.9895434055993376, \"f0_5\": 0.9967875455612528, \"p4\": 0.996562600745935, \"phi\": 0.9931670695358664}, {\"truth_threshold\": -0.0, \"match_probability\": 0.5, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6451.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 87.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9866931783420007, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.013306821657999388, \"precision\": 0.9992255266418835, \"recall\": 0.9866931783420007, \"specificity\": 0.9999995997105747, \"npv\": 0.9999930350097238, \"accuracy\": 0.9999926385277056, \"f1\": 0.9929198091426812, \"f2\": 0.9891744357212954, \"f0_5\": 0.9966936530498733, \"p4\": 0.9964454995039487, \"phi\": 0.9929359186159613}, {\"truth_threshold\": 0.10000000149011612, \"match_probability\": 0.5173217450900928, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6446.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 92.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9859284184765984, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.014071581523401652, \"precision\": 0.999224926368005, \"recall\": 0.9859284184765984, \"specificity\": 0.9999995997105747, \"npv\": 0.9999926347258745, \"accuracy\": 0.9999922384476896, \"f1\": 0.9925321425821849, \"f2\": 0.9885593350305186, \"f0_5\": 0.9965370106981634, \"p4\": 0.9962501499375424, \"phi\": 0.9925505477037979}, {\"truth_threshold\": 0.4000000059604645, \"match_probability\": 0.5688740732440556, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6445.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 93.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9857754665035179, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.014224533496482105, \"precision\": 0.9992248062015504, \"recall\": 0.9857754665035179, \"specificity\": 0.9999995997105747, \"npv\": 0.999992554669143, \"accuracy\": 0.9999921584316863, \"f1\": 0.9924545734524176, \"f2\": 0.9884362922520091, \"f0_5\": 0.9965056589770549, \"p4\": 0.9962110528714946, \"phi\": 0.992473455602002}, {\"truth_threshold\": 1.0000000149011612, \"match_probability\": 0.6666666689619328, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6443.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 95.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.985469562557357, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.01453043744264301, \"precision\": 0.9992245657568238, \"recall\": 0.985469562557357, \"specificity\": 0.9999995997105747, \"npv\": 0.9999923945557188, \"accuracy\": 0.9999919983996799, \"f1\": 0.9922993993531496, \"f2\": 0.9881901840490798, \"f0_5\": 0.9964429322610578, \"p4\": 0.9961328315614428, \"phi\": 0.9923192534679103}, {\"truth_threshold\": 1.2000000178813934, \"match_probability\": 0.6967304575959814, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6441.0, \"tn\": 12490959.0, \"fp\": 3.0, \"fn\": 97.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.985163658611196, \"tn_rate\": 0.9999997598263448, \"fp_rate\": 2.401736551596266e-07, \"fn_rate\": 0.014836341388803916, \"precision\": 0.999534450651769, \"recall\": 0.985163658611196, \"specificity\": 0.9999997598263448, \"npv\": 0.9999922344435891, \"accuracy\": 0.9999919983996799, \"f1\": 0.9922970266522878, \"f2\": 0.9880046631488526, \"f0_5\": 0.9966268490437581, \"p4\": 0.996131636026028, \"phi\": 0.9923190645694996}, {\"truth_threshold\": 1.4000000208616257, \"match_probability\": 0.7252004282056979, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6433.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 105.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9839400428265525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016059957173447537, \"precision\": 1.0, \"recall\": 0.9839400428265525, \"specificity\": 1.0, \"npv\": 0.999991593992731, \"accuracy\": 0.9999915983196639, \"f1\": 0.9919050188882893, \"f2\": 0.9871106337271751, \"f0_5\": 0.9967462039045553, \"p4\": 0.995933976219228, \"phi\": 0.991933350492562}, {\"truth_threshold\": 1.600000023841858, \"match_probability\": 0.7519492561137834, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6432.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 106.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.983787090853472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.01621290914652799, \"precision\": 1.0, \"recall\": 0.983787090853472, \"specificity\": 1.0, \"npv\": 0.9999915139361982, \"accuracy\": 0.9999915183036607, \"f1\": 0.9918272937548188, \"f2\": 0.9869874785170636, \"f0_5\": 0.9967148081571934, \"p4\": 0.995894775925105, \"phi\": 0.9918562105332868}, {\"truth_threshold\": 1.700000025331974, \"match_probability\": 0.7646510400908766, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6431.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 107.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9836341388803915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016365861119608444, \"precision\": 1.0, \"recall\": 0.9836341388803915, \"specificity\": 1.0, \"npv\": 0.9999914338796784, \"accuracy\": 0.9999914382876576, \"f1\": 0.9917495566350528, \"f2\": 0.9868643157474757, \"f0_5\": 0.9966834046246358, \"p4\": 0.995855566533305, \"phi\": 0.9917790645864659}, {\"truth_threshold\": 1.9000000283122063, \"match_probability\": 0.7886787621992872, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6430.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 108.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9834811869073111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016518813092688895, \"precision\": 1.0, \"recall\": 0.9834811869073111, \"specificity\": 1.0, \"npv\": 0.9999913538231713, \"accuracy\": 0.9999913582716543, \"f1\": 0.9916718075262184, \"f2\": 0.9867411454177153, \"f0_5\": 0.9966519933039866, \"p4\": 0.9958163480406573, \"phi\": 0.9917019126507023}, {\"truth_threshold\": 2.0000000298023224, \"match_probability\": 0.8000000033051833, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6429.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 109.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9833282349342306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.01667176506576935, \"precision\": 1.0, \"recall\": 0.9833282349342306, \"specificity\": 1.0, \"npv\": 0.999991273766677, \"accuracy\": 0.9999912782556512, \"f1\": 0.9915940464255417, \"f2\": 0.9866179675270863, \"f0_5\": 0.9966205741923483, \"p4\": 0.9957771204439904, \"phi\": 0.9916247547245981}, {\"truth_threshold\": 2.3000000342726707, \"match_probability\": 0.8312116004280432, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6428.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 110.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9831752829611502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0168247170388498, \"precision\": 1.0, \"recall\": 0.9831752829611502, \"specificity\": 1.0, \"npv\": 0.9999911937101956, \"accuracy\": 0.9999911982396479, \"f1\": 0.9915162733302484, \"f2\": 0.9864947820748926, \"f0_5\": 0.9965891472868217, \"p4\": 0.9957378837401307, \"phi\": 0.9915475908067548}, {\"truth_threshold\": 2.400000035762787, \"match_probability\": 0.8407144092272857, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6427.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 111.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9830223309880698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016977669011930253, \"precision\": 1.0, \"recall\": 0.9830223309880698, \"specificity\": 1.0, \"npv\": 0.999991113653727, \"accuracy\": 0.9999911182236447, \"f1\": 0.9914384882375626, \"f2\": 0.9863715890604378, \"f0_5\": 0.9965577125845066, \"p4\": 0.9956986379259036, \"phi\": 0.9914704208957736}, {\"truth_threshold\": 2.500000037252903, \"match_probability\": 0.8497788984739328, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6388.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 150.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9770572040379321, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02294279596206791, \"precision\": 1.0, \"recall\": 0.9770572040379321, \"specificity\": 1.0, \"npv\": 0.9999879914614488, \"accuracy\": 0.99998799759952, \"f1\": 0.9883954819743154, \"f2\": 0.9815611555009219, \"f0_5\": 0.9953256466188843, \"p4\": 0.9941609110753875, \"phi\": 0.988456104745593}, {\"truth_threshold\": 2.600000038743019, \"match_probability\": 0.8584144256340188, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6385.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 153.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9765983481186907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.023401651881309268, \"precision\": 1.0, \"recall\": 0.9765983481186907, \"specificity\": 1.0, \"npv\": 0.9999877512936195, \"accuracy\": 0.9999877575515103, \"f1\": 0.988160643813356, \"f2\": 0.9811906444970342, \"f0_5\": 0.9952303759586009, \"p4\": 0.9940420447988639, \"phi\": 0.9882238542214375}, {\"truth_threshold\": 3.0000000447034836, \"match_probability\": 0.8888888919492438, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6384.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 154.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9764453961456103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.023554603854389723, \"precision\": 1.0, \"recall\": 0.9764453961456103, \"specificity\": 1.0, \"npv\": 0.999987671237702, \"accuracy\": 0.9999876775355071, \"f1\": 0.9880823401950163, \"f2\": 0.9810671256454389, \"f0_5\": 0.9951986032300305, \"p4\": 0.9940024042144268, \"phi\": 0.9881464252743235}, {\"truth_threshold\": 3.1000000461935997, \"match_probability\": 0.8955524998434058, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6380.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 158.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9758335882532885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02416641174671153, \"precision\": 1.0, \"recall\": 0.9758335882532885, \"specificity\": 1.0, \"npv\": 0.9999873510141605, \"accuracy\": 0.9999873574714943, \"f1\": 0.9877690044898592, \"f2\": 0.9805729743022255, \"f0_5\": 0.9950714330276375, \"p4\": 0.9938437493289402, \"phi\": 0.9878366489192678}, {\"truth_threshold\": 3.200000047683716, \"match_probability\": 0.9018605969116819, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6378.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 160.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9755276843071276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.024472315692872438, \"precision\": 1.0, \"recall\": 0.9755276843071276, \"specificity\": 1.0, \"npv\": 0.9999871909024666, \"accuracy\": 0.9999871974394879, \"f1\": 0.9876122638587798, \"f2\": 0.980325853058715, \"f0_5\": 0.9950078003120125, \"p4\": 0.9937643663121284, \"phi\": 0.9876817243818339}, {\"truth_threshold\": 3.300000049173832, \"match_probability\": 0.9078269283845571, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6377.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 161.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9753747323340471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02462526766595289, \"precision\": 1.0, \"recall\": 0.9753747323340471, \"specificity\": 1.0, \"npv\": 0.9999871108466388, \"accuracy\": 0.9999871174234847, \"f1\": 0.9875338753387534, \"f2\": 0.9802022810415322, \"f0_5\": 0.9949759720401922, \"p4\": 0.9937246608988384, \"phi\": 0.9876042530181497}, {\"truth_threshold\": 3.400000050663948, \"match_probability\": 0.9134653434169965, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6375.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 163.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9750688283878862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.024931171612113796, \"precision\": 1.0, \"recall\": 0.9750688283878862, \"specificity\": 1.0, \"npv\": 0.9999869507350219, \"accuracy\": 0.9999869573914782, \"f1\": 0.9873770618756292, \"f2\": 0.9799551142128078, \"f0_5\": 0.9949122916536612, \"p4\": 0.9936452222462342, \"phi\": 0.9874492920937119}, {\"truth_threshold\": 3.500000052154064, \"match_probability\": 0.9187896995557598, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6374.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 164.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9749158764148057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02508412358519425, \"precision\": 1.0, \"recall\": 0.9749158764148057, \"specificity\": 1.0, \"npv\": 0.9999868706792326, \"accuracy\": 0.9999868773754751, \"f1\": 0.9872986369268897, \"f2\": 0.9798315193998647, \"f0_5\": 0.9948804395329962, \"p4\": 0.9936054890004131, \"phi\": 0.9873718025301021}, {\"truth_threshold\": 3.7000000551342964, \"match_probability\": 0.9285512128432143, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6370.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 168.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.974304068522484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02569593147751606, \"precision\": 1.0, \"recall\": 0.974304068522484, \"specificity\": 1.0, \"npv\": 0.9999865504562038, \"accuracy\": 0.9999865573114622, \"f1\": 0.9869848156182213, \"f2\": 0.9793370641411967, \"f0_5\": 0.994752951464801, \"p4\": 0.9934464631443519, \"phi\": 0.9870617835663803}, {\"truth_threshold\": 3.9000000581145287, \"match_probability\": 0.9372195616099515, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6366.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 172.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9736922606301621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026307739369837872, \"precision\": 1.0, \"recall\": 0.9736922606301621, \"specificity\": 1.0, \"npv\": 0.99998623023338, \"accuracy\": 0.9999862372474495, \"f1\": 0.9866707997520149, \"f2\": 0.9788424872378375, \"f0_5\": 0.9946253359165053, \"p4\": 0.9932872885353352, \"phi\": 0.9867516673991352}, {\"truth_threshold\": 4.000000059604645, \"match_probability\": 0.9411764728755594, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6365.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 173.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9735393086570817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026460691342918324, \"precision\": 1.0, \"recall\": 0.9735393086570817, \"specificity\": 1.0, \"npv\": 0.999986150177706, \"accuracy\": 0.9999861572314462, \"f1\": 0.9865922653646438, \"f2\": 0.978718823999754, \"f0_5\": 0.9945934120882555, \"p4\": 0.9932474716159481, \"phi\": 0.9866741231585332}, {\"truth_threshold\": 4.100000061094761, \"match_probability\": 0.9448986513716398, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6363.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 175.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9732334047109208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02676659528907923, \"precision\": 1.0, \"recall\": 0.9732334047109208, \"specificity\": 1.0, \"npv\": 0.9999859900663967, \"accuracy\": 0.9999859971994399, \"f1\": 0.9864351600651112, \"f2\": 0.9784714747039828, \"f0_5\": 0.9945295404814004, \"p4\": 0.9931678098337335, \"phi\": 0.986519016428746}, {\"truth_threshold\": 4.200000062584877, \"match_probability\": 0.9483982147343843, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6361.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 177.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9729275007647599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.027072499235240136, \"precision\": 1.0, \"recall\": 0.9729275007647599, \"specificity\": 1.0, \"npv\": 0.9999858299551386, \"accuracy\": 0.9999858371674335, \"f1\": 0.9862780060469803, \"f2\": 0.9782240949773937, \"f0_5\": 0.994465636920768, \"p4\": 0.9930881107717843, \"phi\": 0.9863638853579481}, {\"truth_threshold\": 4.300000064074993, \"match_probability\": 0.9516868803254299, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6357.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 181.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.972315692872438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.027684307127561945, \"precision\": 1.0, \"recall\": 0.972315692872438, \"specificity\": 1.0, \"npv\": 0.9999855097327762, \"accuracy\": 0.9999855171034207, \"f1\": 0.9859635517642497, \"f2\": 0.9777292442092959, \"f0_5\": 0.9943377338422074, \"p4\": 0.9929286007038632, \"phi\": 0.9860535501473652}, {\"truth_threshold\": 4.400000065565109, \"match_probability\": 0.9547759482410569, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6354.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 184.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9718568369531967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.028143163046803303, \"precision\": 1.0, \"recall\": 0.9718568369531967, \"specificity\": 1.0, \"npv\": 0.9999852695661391, \"accuracy\": 0.9999852770554111, \"f1\": 0.9857275829972075, \"f2\": 0.9773580262105458, \"f0_5\": 0.9942417224760594, \"p4\": 0.9928088700985888, \"phi\": 0.9858207347587784}, {\"truth_threshold\": 4.700000070035458, \"match_probability\": 0.9629520927573305, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6351.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 187.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9713979810339554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02860201896604466, \"precision\": 1.0, \"recall\": 0.9713979810339554, \"specificity\": 1.0, \"npv\": 0.9999850293996173, \"accuracy\": 0.9999850370074015, \"f1\": 0.9854915043835829, \"f2\": 0.9769867396855675, \"f0_5\": 0.9941456389706342, \"p4\": 0.99268905534821, \"phi\": 0.985587864486454}, {\"truth_threshold\": 4.800000071525574, \"match_probability\": 0.9653471069144568, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6345.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 193.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9704802691954726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02951973080452738, \"precision\": 1.0, \"recall\": 0.9704802691954726, \"specificity\": 1.0, \"npv\": 0.9999845490669198, \"accuracy\": 0.9999845569113823, \"f1\": 0.9850190173096328, \"f2\": 0.9762439609810136, \"f0_5\": 0.9939532552164922, \"p4\": 0.9924491730567562, \"phi\": 0.9851219591348971}, {\"truth_threshold\": 4.90000007301569, \"match_probability\": 0.9675925026740654, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6344.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 194.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9703273172223922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02967268277760783, \"precision\": 1.0, \"recall\": 0.9703273172223922, \"specificity\": 1.0, \"npv\": 0.999984469011515, \"accuracy\": 0.9999844768953791, \"f1\": 0.9849402266728768, \"f2\": 0.9761201378631216, \"f0_5\": 0.9939211631259008, \"p4\": 0.9924091598672342, \"phi\": 0.985044286862272}, {\"truth_threshold\": 5.000000074505806, \"match_probability\": 0.969696971214501, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6343.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 195.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9701743652493117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.029825634750688283, \"precision\": 1.0, \"recall\": 0.9701743652493117, \"specificity\": 1.0, \"npv\": 0.9999843889561231, \"accuracy\": 0.9999843968793759, \"f1\": 0.9848614238024999, \"f2\": 0.975996307124173, \"f0_5\": 0.9938890629896584, \"p4\": 0.992369137295309, \"phi\": 0.9849666084770223}, {\"truth_threshold\": 5.100000075995922, \"match_probability\": 0.9716687817966767, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6341.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 197.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9698684613031509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03013153869684919, \"precision\": 1.0, \"recall\": 0.9698684613031509, \"specificity\": 1.0, \"npv\": 0.9999842288453777, \"accuracy\": 0.9999842368473695, \"f1\": 0.9847037813494837, \"f2\": 0.9757486227802912, \"f0_5\": 0.9938248385681149, \"p4\": 0.9922890639910333, \"phi\": 0.9848112333628636}, {\"truth_threshold\": 5.200000077486038, \"match_probability\": 0.9735157914041783, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6339.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 199.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9695625573569899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030437442643010095, \"precision\": 1.0, \"recall\": 0.9695625573569899, \"specificity\": 1.0, \"npv\": 0.9999840687346837, \"accuracy\": 0.999984076815363, \"f1\": 0.9845460899277783, \"f2\": 0.9755009079437382, \"f0_5\": 0.9937605819276353, \"p4\": 0.9922089531174841, \"phi\": 0.9846558337808434}, {\"truth_threshold\": 5.4000000804662704, \"match_probability\": 0.9768648415470134, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6336.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 202.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9691037014377486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030896298562251453, \"precision\": 1.0, \"recall\": 0.9691037014377486, \"specificity\": 1.0, \"npv\": 0.9999838285687387, \"accuracy\": 0.9999838367673535, \"f1\": 0.9843094609290042, \"f2\": 0.9751292785028318, \"f0_5\": 0.9936641365033562, \"p4\": 0.9920887163068618, \"phi\": 0.9844226885052252}, {\"truth_threshold\": 5.600000083446503, \"match_probability\": 0.9797991767207457, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6334.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 204.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9687977974915877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03120220250841236, \"precision\": 1.0, \"recall\": 0.9687977974915877, \"specificity\": 1.0, \"npv\": 0.9999836684581728, \"accuracy\": 0.999983676735347, \"f1\": 0.9841516469857055, \"f2\": 0.9748814874099612, \"f0_5\": 0.993599799209387, \"p4\": 0.9920085113942668, \"phi\": 0.9842672277028406}, {\"truth_threshold\": 5.700000084936619, \"match_probability\": 0.9811264334957893, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6332.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 206.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9684918935454268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03150810645457326, \"precision\": 1.0, \"recall\": 0.9684918935454268, \"specificity\": 1.0, \"npv\": 0.9999835083476581, \"accuracy\": 0.9999835167033406, \"f1\": 0.983993783993784, \"f2\": 0.9746336658047039, \"f0_5\": 0.9935354296114981, \"p4\": 0.9919282688196436, \"phi\": 0.9841117423920022}, {\"truth_threshold\": 5.800000086426735, \"match_probability\": 0.9823680546749124, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6329.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 209.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9680330376261854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03196696237381462, \"precision\": 1.0, \"recall\": 0.9680330376261854, \"specificity\": 1.0, \"npv\": 0.9999832681819822, \"accuracy\": 0.999983276655331, \"f1\": 0.9837568974897023, \"f2\": 0.9742618761737631, \"f0_5\": 0.993438814591574, \"p4\": 0.9918078342833048, \"phi\": 0.9838784684469748}, {\"truth_threshold\": 5.900000087916851, \"match_probability\": 0.9835293654795508, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6321.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 217.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9668094218415417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.033190578158458245, \"precision\": 1.0, \"recall\": 0.9668094218415417, \"specificity\": 1.0, \"npv\": 0.9999826277407441, \"accuracy\": 0.9999826365273055, \"f1\": 0.9831246597713663, \"f2\": 0.9732701013149385, \"f0_5\": 0.9931808183018038, \"p4\": 0.9914862602624209, \"phi\": 0.9832561345741071}, {\"truth_threshold\": 6.000000089406967, \"match_probability\": 0.9846153855541349, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6317.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 221.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.96619761394922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03380238605078006, \"precision\": 1.0, \"recall\": 0.96619761394922, \"specificity\": 1.0, \"npv\": 0.9999823075204326, \"accuracy\": 0.9999823164632926, \"f1\": 0.9828082458187476, \"f2\": 0.9727740306138163, \"f0_5\": 0.9930516254794692, \"p4\": 0.9913252463480805, \"phi\": 0.9829448201794835}, {\"truth_threshold\": 6.100000090897083, \"match_probability\": 0.985630843183972, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6313.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 225.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9655858060568981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03441419394310186, \"precision\": 1.0, \"recall\": 0.9655858060568981, \"specificity\": 1.0, \"npv\": 0.9999819873003262, \"accuracy\": 0.9999819963992799, \"f1\": 0.9824916348922262, \"f2\": 0.9722778376713384, \"f0_5\": 0.9929223026108839, \"p4\": 0.9911640808794583, \"phi\": 0.9826334073548306}, {\"truth_threshold\": 6.200000092387199, \"match_probability\": 0.9865801893041345, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6303.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 235.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9640562863260936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03594371367390639, \"precision\": 1.0, \"recall\": 0.9640562863260936, \"specificity\": 1.0, \"npv\": 0.9999811867509575, \"accuracy\": 0.9999811962392479, \"f1\": 0.9816992446071178, \"f2\": 0.9710368202126021, \"f0_5\": 0.9925984251968504, \"p4\": 0.9907605027508045, \"phi\": 0.9818544440471244}, {\"truth_threshold\": 6.3000000938773155, \"match_probability\": 0.987467611228855, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6302.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 236.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9639033343530131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.036096665646986846, \"precision\": 1.0, \"recall\": 0.9639033343530131, \"specificity\": 1.0, \"npv\": 0.9999811066960911, \"accuracy\": 0.9999811162232447, \"f1\": 0.981619937694704, \"f2\": 0.970912676403525, \"f0_5\": 0.9925659925659925, \"p4\": 0.9907200926382568, \"phi\": 0.98177651379241}, {\"truth_threshold\": 6.400000095367432, \"match_probability\": 0.9882970460445225, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6298.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 240.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9632915264606914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03670847353930866, \"precision\": 1.0, \"recall\": 0.9632915264606914, \"specificity\": 1.0, \"npv\": 0.9999807864767538, \"accuracy\": 0.9999807961592319, \"f1\": 0.9813025864755376, \"f2\": 0.9704160246533128, \"f0_5\": 0.9924361802710369, \"p4\": 0.9905583569294693, \"phi\": 0.9814647310202006}, {\"truth_threshold\": 6.500000096857548, \"match_probability\": 0.9890721936212699, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6293.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 245.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9625267665952891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03747323340471092, \"precision\": 1.0, \"recall\": 0.9625267665952891, \"specificity\": 1.0, \"npv\": 0.9999803862028706, \"accuracy\": 0.9999803960792158, \"f1\": 0.9809056192034915, \"f2\": 0.9697950377562028, \"f0_5\": 0.9922737306843267, \"p4\": 0.9903559727086484, \"phi\": 0.9810748634994975}, {\"truth_threshold\": 6.600000098347664, \"match_probability\": 0.9897965292084853, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6290.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 248.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9620679106760477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03793208932395228, \"precision\": 1.0, \"recall\": 0.9620679106760477, \"specificity\": 1.0, \"npv\": 0.9999801460386945, \"accuracy\": 0.9999801560312063, \"f1\": 0.9806672903024634, \"f2\": 0.9694223537389803, \"f0_5\": 0.9921761625339138, \"p4\": 0.9902344275687452, \"phi\": 0.9808408687534262}, {\"truth_threshold\": 6.70000009983778, \"match_probability\": 0.9904733155885336, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6289.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 249.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9619149587029673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03808504129703273, \"precision\": 1.0, \"recall\": 0.9619149587029673, \"specificity\": 1.0, \"npv\": 0.9999800659839947, \"accuracy\": 0.999980076015203, \"f1\": 0.9805878225617838, \"f2\": 0.9692981104158318, \"f0_5\": 0.9921436233987505, \"p4\": 0.9901938934005742, \"phi\": 0.9807628581236061}, {\"truth_threshold\": 6.800000101327896, \"match_probability\": 0.9911056147706719, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6288.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 250.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9617620067298868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03823799327011319, \"precision\": 1.0, \"recall\": 0.9617620067298868, \"specificity\": 1.0, \"npv\": 0.9999799859293077, \"accuracy\": 0.9999799959991998, \"f1\": 0.9805083424294402, \"f2\": 0.969173859432799, \"f0_5\": 0.9921110760492269, \"p4\": 0.9901533496659886, \"phi\": 0.9806848413007591}, {\"truth_threshold\": 6.900000102818012, \"match_probability\": 0.9916962992137202, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6286.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 252.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.961456102783726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03854389721627409, \"precision\": 1.0, \"recall\": 0.961456102783726, \"specificity\": 1.0, \"npv\": 0.9999798258199724, \"accuracy\": 0.9999798359671934, \"f1\": 0.980349344978166, \"f2\": 0.9689253344842469, \"f0_5\": 0.9920459566946531, \"p4\": 0.9900722334840125, \"phi\": 0.980528789070071}, {\"truth_threshold\": 7.1000001057982445, \"match_probability\": 0.9927634299608046, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6283.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 255.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9609972468644845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03900275313551545, \"precision\": 1.0, \"recall\": 0.9609972468644845, \"specificity\": 1.0, \"npv\": 0.9999795856560654, \"accuracy\": 0.9999795959191838, \"f1\": 0.9801107557912799, \"f2\": 0.9685524895945737, \"f0_5\": 0.9919482159772656, \"p4\": 0.9899504873781381, \"phi\": 0.9802946642393637}, {\"truth_threshold\": 7.200000107288361, \"match_probability\": 0.9932447677519157, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6276.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 262.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9599265830529213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04007341694707862, \"precision\": 1.0, \"recall\": 0.9599265830529213, \"specificity\": 1.0, \"npv\": 0.9999790252740645, \"accuracy\": 0.9999790358071614, \"f1\": 0.9795536132355237, \"f2\": 0.9676822499074873, \"f0_5\": 0.9917198660008849, \"p4\": 0.9896660774350681, \"phi\": 0.9797481558318564}, {\"truth_threshold\": 7.300000108778477, \"match_probability\": 0.9936942928922654, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6274.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 264.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9596206791067605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04037932089323952, \"precision\": 1.0, \"recall\": 0.9596206791067605, \"specificity\": 1.0, \"npv\": 0.9999788651650366, \"accuracy\": 0.999978875775155, \"f1\": 0.9793943178270371, \"f2\": 0.9674335409856288, \"f0_5\": 0.9916545489030789, \"p4\": 0.9895847310069513, \"phi\": 0.9795919546842348}, {\"truth_threshold\": 7.400000110268593, \"match_probability\": 0.9941140817673122, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6271.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 267.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9591618231875191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04083817681248088, \"precision\": 1.0, \"recall\": 0.9591618231875191, \"specificity\": 1.0, \"npv\": 0.9999786250015911, \"accuracy\": 0.9999786357271454, \"f1\": 0.9791552814427356, \"f2\": 0.967060420072171, \"f0_5\": 0.9915565112896085, \"p4\": 0.9894626392254878, \"phi\": 0.9793576063446255}, {\"truth_threshold\": 7.500000111758709, \"match_probability\": 0.9945060786121668, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6266.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 272.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9583970633221168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.041602936677883146, \"precision\": 1.0, \"recall\": 0.9583970633221168, \"specificity\": 1.0, \"npv\": 0.9999782247294383, \"accuracy\": 0.9999782356471294, \"f1\": 0.978756638550453, \"f2\": 0.9664383984206305, \"f0_5\": 0.991392949813303, \"p4\": 0.9892589603238144, \"phi\": 0.9789669013642684}, {\"truth_threshold\": 7.600000113248825, \"match_probability\": 0.9948721034855129, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6263.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 275.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9579382074028755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0420617925971245, \"precision\": 1.0, \"recall\": 0.9579382074028755, \"specificity\": 1.0, \"npv\": 0.9999779845663004, \"accuracy\": 0.9999779955991198, \"f1\": 0.9785173033356769, \"f2\": 0.9660650933209933, \"f0_5\": 0.9912947135169358, \"p4\": 0.9891366372726919, \"phi\": 0.9787324036618906}, {\"truth_threshold\": 7.700000114738941, \"match_probability\": 0.9952138598197071, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6262.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 276.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9577852554297951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04221474457020496, \"precision\": 1.0, \"recall\": 0.9577852554297951, \"specificity\": 1.0, \"npv\": 0.9999779045119467, \"accuracy\": 0.9999779155831167, \"f1\": 0.9784375, \"f2\": 0.9659406429320664, \"f0_5\": 0.9912619514974988, \"p4\": 0.9890958436167352, \"phi\": 0.9786542252997869}, {\"truth_threshold\": 7.800000116229057, \"match_probability\": 0.9955329415617687, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6260.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 278.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9574793514836342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04252064851636586, \"precision\": 1.0, \"recall\": 0.9574793514836342, \"specificity\": 1.0, \"npv\": 0.9999777444032778, \"accuracy\": 0.9999777555511102, \"f1\": 0.9782778559149867, \"f2\": 0.9656917191163766, \"f0_5\": 0.9911964025587434, \"p4\": 0.9890142273258592, \"phi\": 0.9784978498746523}, {\"truth_threshold\": 7.900000117719173, \"match_probability\": 0.99583083992065, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6258.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 280.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9571734475374732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.042826552462526764, \"precision\": 1.0, \"recall\": 0.9571734475374732, \"specificity\": 1.0, \"npv\": 0.9999775842946602, \"accuracy\": 0.9999775955191038, \"f1\": 0.9781181619256017, \"f2\": 0.9654427645788337, \"f0_5\": 0.991130820399113, \"p4\": 0.988932572373467, \"phi\": 0.9783414495049846}, {\"truth_threshold\": 8.00000011920929, \"match_probability\": 0.9961089497366072, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6253.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 285.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.956408687672071, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04359131232792903, \"precision\": 1.0, \"recall\": 0.956408687672071, \"specificity\": 1.0, \"npv\": 0.9999771840233405, \"accuracy\": 0.9999771954390878, \"f1\": 0.9777187084668908, \"f2\": 0.9648202437895387, \"f0_5\": 0.9909667194928684, \"p4\": 0.9887282656678122, \"phi\": 0.9779503393699376}, {\"truth_threshold\": 8.100000120699406, \"match_probability\": 0.9963685754887298, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6246.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 292.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9553380238605078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0446619761394922, \"precision\": 1.0, \"recall\": 0.9553380238605078, \"specificity\": 1.0, \"npv\": 0.9999766236440313, \"accuracy\": 0.9999766353270654, \"f1\": 0.9771589486858573, \"f2\": 0.9639483918760418, \"f0_5\": 0.9907366283865237, \"p4\": 0.9884418292253739, \"phi\": 0.9774025227810655}, {\"truth_threshold\": 8.200000122189522, \"match_probability\": 0.9966109369567457, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6245.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 293.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9551850718874273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04481492811257265, \"precision\": 1.0, \"recall\": 0.9551850718874273, \"specificity\": 1.0, \"npv\": 0.9999765435898955, \"accuracy\": 0.9999765553110622, \"f1\": 0.9770789329578347, \"f2\": 0.9638238108466833, \"f0_5\": 0.9907037248556381, \"p4\": 0.9884008709066727, \"phi\": 0.9773242382518993}, {\"truth_threshold\": 8.300000123679638, \"match_probability\": 0.9968371745531442, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6241.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 297.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9545732639951056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04542673600489446, \"precision\": 1.0, \"recall\": 0.9545732639951056, \"specificity\": 1.0, \"npv\": 0.9999762233734806, \"accuracy\": 0.9999762352470494, \"f1\": 0.9767587448157132, \"f2\": 0.9633254098107615, \"f0_5\": 0.990572027172878, \"p4\": 0.9882369404262159, \"phi\": 0.9770110375339279}, {\"truth_threshold\": 8.400000125169754, \"match_probability\": 0.9970483543414643, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6240.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 298.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.954420312022025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04557968797797492, \"precision\": 1.0, \"recall\": 0.954420312022025, \"specificity\": 1.0, \"npv\": 0.999976143319409, \"accuracy\": 0.9999761552310462, \"f1\": 0.9766786664579746, \"f2\": 0.9632007903185972, \"f0_5\": 0.9905390818464664, \"p4\": 0.9881959334873694, \"phi\": 0.9769327216965821}, {\"truth_threshold\": 8.50000012665987, \"match_probability\": 0.997245472756309, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6238.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 300.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9541144080758642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04588559192413582, \"precision\": 1.0, \"recall\": 0.9541144080758642, \"specificity\": 1.0, \"npv\": 0.999975983211304, \"accuracy\": 0.9999759951990398, \"f1\": 0.9765184721352536, \"f2\": 0.9629515282494597, \"f0_5\": 0.9904731660844712, \"p4\": 0.9881138904029276, \"phi\": 0.9767760712219222}, {\"truth_threshold\": 8.600000128149986, \"match_probability\": 0.9974294610402847, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6224.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 314.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9519730804527379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04802691954726216, \"precision\": 1.0, \"recall\": 0.9519730804527379, \"specificity\": 1.0, \"npv\": 0.9999748624560053, \"accuracy\": 0.999974874974995, \"f1\": 0.975395706002194, \"f2\": 0.9612058314801087, \"f0_5\": 0.9900108163135458, \"p4\": 0.9875384962205523, \"phi\": 0.9756788150757125}, {\"truth_threshold\": 8.700000129640102, \"match_probability\": 0.997601189412643, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6220.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 318.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.951361272560416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04863872743958397, \"precision\": 1.0, \"recall\": 0.951361272560416, \"specificity\": 1.0, \"npv\": 0.9999745422406671, \"accuracy\": 0.9999745549109822, \"f1\": 0.9750744630819878, \"f2\": 0.9607067836401829, \"f0_5\": 0.9898784136482272, \"p4\": 0.987373745856392, \"phi\": 0.9753650870489985}, {\"truth_threshold\": 8.800000131130219, \"match_probability\": 0.997761470983937, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6219.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 319.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9512083205873356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04879167941266442, \"precision\": 1.0, \"recall\": 0.9512083205873356, \"specificity\": 1.0, \"npv\": 0.9999744621868646, \"accuracy\": 0.999974474894979, \"f1\": 0.9749941208748139, \"f2\": 0.9605820024095642, \"f0_5\": 0.9898452919080665, \"p4\": 0.987332533763769, \"phi\": 0.9752866393050771}, {\"truth_threshold\": 8.900000132620335, \"match_probability\": 0.9979110654305032, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6218.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 320.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9510553686142551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.048944631385744876, \"precision\": 1.0, \"recall\": 0.9510553686142551, \"specificity\": 1.0, \"npv\": 0.9999743821330749, \"accuracy\": 0.9999743948789758, \"f1\": 0.9749137660708687, \"f2\": 0.9604572134692617, \"f0_5\": 0.9898121617319325, \"p4\": 0.9872913118635096, \"phi\": 0.9752081852632205}, {\"truth_threshold\": 9.00000013411045, \"match_probability\": 0.9980506824420605, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6214.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 324.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9504435607219334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04955643927806669, \"precision\": 1.0, \"recall\": 0.9504435607219334, \"specificity\": 1.0, \"npv\": 0.9999740619180443, \"accuracy\": 0.999974074814963, \"f1\": 0.9745922208281054, \"f2\": 0.9599579805969227, \"f0_5\": 0.9896795566031725, \"p4\": 0.9871263261159948, \"phi\": 0.9748943060860294}, {\"truth_threshold\": 9.100000135600567, \"match_probability\": 0.9981809849551747, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6208.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 330.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9495258488834506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.050474151116549404, \"precision\": 1.0, \"recall\": 0.9495258488834506, \"specificity\": 1.0, \"npv\": 0.999973581595883, \"accuracy\": 0.9999735947189438, \"f1\": 0.9741095245567237, \"f2\": 0.9592088998763906, \"f0_5\": 0.9894803952821166, \"p4\": 0.9868785526691093, \"phi\": 0.9744232981234876}, {\"truth_threshold\": 9.200000137090683, \"match_probability\": 0.9983025921847976, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6195.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 343.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9475374732334048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05246252676659529, \"precision\": 1.0, \"recall\": 0.9475374732334048, \"specificity\": 1.0, \"npv\": 0.9999725408994496, \"accuracy\": 0.9999725545109022, \"f1\": 0.9730621220450797, \"f2\": 0.9575849383250379, \"f0_5\": 0.989047831917747, \"p4\": 0.9863404931684719, \"phi\": 0.9734020005663908}, {\"truth_threshold\": 9.300000138580799, \"match_probability\": 0.9984160824655384, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6186.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 352.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9461609054756807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05383909452431936, \"precision\": 1.0, \"recall\": 0.9461609054756807, \"specificity\": 1.0, \"npv\": 0.9999718204185725, \"accuracy\": 0.9999718343668734, \"f1\": 0.9723357434768941, \"f2\": 0.9564598923866658, \"f0_5\": 0.9887475225369222, \"p4\": 0.985967011574786, \"phi\": 0.972694321489234}, {\"truth_threshold\": 9.400000140070915, \"match_probability\": 0.9985219959137808, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6185.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 353.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9460079535026001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05399204649739982, \"precision\": 1.0, \"recall\": 0.9460079535026001, \"specificity\": 1.0, \"npv\": 0.9999717403652058, \"accuracy\": 0.9999717543508702, \"f1\": 0.9722549713117975, \"f2\": 0.9563348486254136, \"f0_5\": 0.9887141121555086, \"p4\": 0.9859254640464832, \"phi\": 0.9726156587590608}, {\"truth_threshold\": 9.500000141561031, \"match_probability\": 0.9986208369212233, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6175.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 363.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9444784337717956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.055521566228204346, \"precision\": 1.0, \"recall\": 0.9444784337717956, \"specificity\": 1.0, \"npv\": 0.9999709398322436, \"accuracy\": 0.9999709541908381, \"f1\": 0.9714465507747975, \"f2\": 0.9550839855229375, \"f0_5\": 0.9883795377424931, \"p4\": 0.9855094421499894, \"phi\": 0.971828681954833}, {\"truth_threshold\": 9.600000143051147, \"match_probability\": 0.9987130764898899, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6170.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 368.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9437136739063934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.056286326093606606, \"precision\": 1.0, \"recall\": 0.9437136739063934, \"specificity\": 1.0, \"npv\": 0.9999705395662432, \"accuracy\": 0.9999705541108221, \"f1\": 0.9710418633931381, \"f2\": 0.9544582637213044, \"f0_5\": 0.9882119290153116, \"p4\": 0.9853010577965041, \"phi\": 0.9714349549466592}, {\"truth_threshold\": 9.700000144541264, \"match_probability\": 0.9987991544181472, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6160.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 378.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9421841541755889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.057815845824411134, \"precision\": 1.0, \"recall\": 0.9421841541755889, \"specificity\": 1.0, \"npv\": 0.9999697390352036, \"accuracy\": 0.9999697539507901, \"f1\": 0.9702315325248071, \"f2\": 0.9532062391681109, \"f0_5\": 0.9878760664571172, \"p4\": 0.9848835400401009, \"phi\": 0.9706470227503238}, {\"truth_threshold\": 9.80000014603138, \"match_probability\": 0.9988794813467569, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6149.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 389.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9405016824717038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05949831752829612, \"precision\": 1.0, \"recall\": 0.9405016824717038, \"specificity\": 1.0, \"npv\": 0.9999688584525405, \"accuracy\": 0.999968873774755, \"f1\": 0.9693386931504689, \"f2\": 0.9518281167765704, \"f0_5\": 0.9875056208646495, \"p4\": 0.984423113370518, \"phi\": 0.9697795593813696}, {\"truth_threshold\": 9.900000147521496, \"match_probability\": 0.9989544406735176, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6140.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 398.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9391251147139799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06087488528602019, \"precision\": 1.0, \"recall\": 0.9391251147139799, \"specificity\": 1.0, \"npv\": 0.9999681379769697, \"accuracy\": 0.9999681536307261, \"f1\": 0.9686070358100647, \"f2\": 0.950699863743342, \"f0_5\": 0.9872017493086372, \"p4\": 0.9840454957235867, \"phi\": 0.9690692401928495}, {\"truth_threshold\": 10.000000149011612, \"match_probability\": 0.9990243903445719, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6139.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 399.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9389721627408993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.061027837259100645, \"precision\": 1.0, \"recall\": 0.9389721627408993, \"specificity\": 1.0, \"npv\": 0.9999680579241925, \"accuracy\": 0.999968073614723, \"f1\": 0.9685256764218664, \"f2\": 0.9505744634727943, \"f0_5\": 0.9871679423683025, \"p4\": 0.9840034878071545, \"phi\": 0.9689902837597992}, {\"truth_threshold\": 10.200000151991844, \"match_probability\": 0.9991505751910027, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6136.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 402.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.938513306821658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.061486693178342, \"precision\": 1.0, \"recall\": 0.938513306821658, \"specificity\": 1.0, \"npv\": 0.9999678177659381, \"accuracy\": 0.9999678335667134, \"f1\": 0.9682815212245542, \"f2\": 0.9501982160555005, \"f0_5\": 0.9870664693391674, \"p4\": 0.9838774034831713, \"phi\": 0.9687533759253424}, {\"truth_threshold\": 10.30000015348196, \"match_probability\": 0.9992074135451509, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6127.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 411.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9371367390639339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06286326093606608, \"precision\": 1.0, \"recall\": 0.9371367390639339, \"specificity\": 1.0, \"npv\": 0.999967097291867, \"accuracy\": 0.9999671134226845, \"f1\": 0.9675483616265298, \"f2\": 0.9490690541838347, \"f0_5\": 0.9867615795915738, \"p4\": 0.9834986044857558, \"phi\": 0.9680423052363609}, {\"truth_threshold\": 10.400000154972076, \"match_probability\": 0.9992604514366183, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6120.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 418.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9360660752523707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06393392474762924, \"precision\": 1.0, \"recall\": 0.9360660752523707, \"specificity\": 1.0, \"npv\": 0.9999665369238627, \"accuracy\": 0.9999665533106621, \"f1\": 0.9669774055933007, \"f2\": 0.9481903817550819, \"f0_5\": 0.9865239538332581, \"p4\": 0.9832034154982748, \"phi\": 0.9674888896530156}, {\"truth_threshold\": 10.500000156462193, \"match_probability\": 0.9993099426168967, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6108.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 430.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9342306515754053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06576934842459468, \"precision\": 1.0, \"recall\": 0.9342306515754053, \"specificity\": 1.0, \"npv\": 0.9999655762944594, \"accuracy\": 0.9999655931186238, \"f1\": 0.9659971532500395, \"f2\": 0.9466831990080595, \"f0_5\": 0.9861155957378108, \"p4\": 0.9826962179706671, \"phi\": 0.9665394414583134}, {\"truth_threshold\": 10.600000157952309, \"match_probability\": 0.9993561239419685, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6098.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 440.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9327011318446008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0672988681553992, \"precision\": 1.0, \"recall\": 0.9327011318446008, \"specificity\": 1.0, \"npv\": 0.9999647757713666, \"accuracy\": 0.9999647929585918, \"f1\": 0.965178854067743, \"f2\": 0.9454263565891473, \"f0_5\": 0.9857743291302942, \"p4\": 0.9822724308576191, \"phi\": 0.965747522992778}, {\"truth_threshold\": 10.700000159442425, \"match_probability\": 0.9993992164911604, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6093.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 445.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9319363719791985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06806362802080147, \"precision\": 1.0, \"recall\": 0.9319363719791985, \"specificity\": 1.0, \"npv\": 0.9999643755103008, \"accuracy\": 0.9999643928785757, \"f1\": 0.9647692185891853, \"f2\": 0.9447976430454335, \"f0_5\": 0.9856033646069233, \"p4\": 0.9820601533792744, \"phi\": 0.9653513206193456}, {\"truth_threshold\": 10.800000160932541, \"match_probability\": 0.9994394266126935, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6089.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 449.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9313245640868767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06867543591312328, \"precision\": 1.0, \"recall\": 0.9313245640868767, \"specificity\": 1.0, \"npv\": 0.9999640553016789, \"accuracy\": 0.9999640728145629, \"f1\": 0.9644412766294448, \"f2\": 0.944294531807326, \"f0_5\": 0.9854664336117045, \"p4\": 0.9818901466906317, \"phi\": 0.9650342418310252}, {\"truth_threshold\": 10.900000162422657, \"match_probability\": 0.9994769469006325, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6084.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 454.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9305598042214744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06944019577852555, \"precision\": 1.0, \"recall\": 0.9305598042214744, \"specificity\": 1.0, \"npv\": 0.9999636550411899, \"accuracy\": 0.9999636727345469, \"f1\": 0.9640310568848043, \"f2\": 0.9436654671795508, \"f0_5\": 0.9852950702856773, \"p4\": 0.9816774070561771, \"phi\": 0.9646377470655602}, {\"truth_threshold\": 11.000000163912773, \"match_probability\": 0.9995119571076428, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6079.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 459.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9297950443560722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07020495564392781, \"precision\": 1.0, \"recall\": 0.9297950443560722, \"specificity\": 1.0, \"npv\": 0.9999632547810213, \"accuracy\": 0.9999632726545309, \"f1\": 0.9636205120076088, \"f2\": 0.9430362073779901, \"f0_5\": 0.9851234847993777, \"p4\": 0.9814644100153407, \"phi\": 0.9642410895795521}, {\"truth_threshold\": 11.10000016540289, \"match_probability\": 0.9995446249976983, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6077.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 461.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9294891404099113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07051085959008871, \"precision\": 1.0, \"recall\": 0.9294891404099113, \"specificity\": 1.0, \"npv\": 0.9999630946770436, \"accuracy\": 0.9999631126225245, \"f1\": 0.9634562029330163, \"f2\": 0.9427844487883583, \"f0_5\": 0.9850547883031836, \"p4\": 0.9813791390204586, \"phi\": 0.96408238097841}, {\"truth_threshold\": 11.200000166893005, \"match_probability\": 0.9995751071426191, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6070.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 468.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9284184765983481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07158152340165189, \"precision\": 1.0, \"recall\": 0.9284184765983481, \"specificity\": 1.0, \"npv\": 0.9999625343135253, \"accuracy\": 0.9999625525105021, \"f1\": 0.9628807106598984, \"f2\": 0.9419030476072249, \"f0_5\": 0.9848140696995262, \"p4\": 0.981080365183647, \"phi\": 0.9635266954074426}, {\"truth_threshold\": 11.300000168383121, \"match_probability\": 0.9996035496660847, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6062.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 476.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9271948608137045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0728051391862955, \"precision\": 1.0, \"recall\": 0.9271948608137045, \"specificity\": 1.0, \"npv\": 0.9999618938988449, \"accuracy\": 0.9999619123824764, \"f1\": 0.9622222222222222, \"f2\": 0.9408952629291613, \"f0_5\": 0.9845384265575261, \"p4\": 0.9807382883684369, \"phi\": 0.9628912342692438}, {\"truth_threshold\": 11.400000169873238, \"match_probability\": 0.99963008893853, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6057.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 481.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9264301009483022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07356989905169777, \"precision\": 1.0, \"recall\": 0.9264301009483022, \"specificity\": 1.0, \"npv\": 0.9999614936400862, \"accuracy\": 0.9999615123024604, \"f1\": 0.9618102421595871, \"f2\": 0.9402651432829333, \"f0_5\": 0.9843658584151336, \"p4\": 0.9805241531661433, \"phi\": 0.9624938584206135}, {\"truth_threshold\": 11.500000171363354, \"match_probability\": 0.999654852226126, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6052.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 486.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9256653410829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07433465891710003, \"precision\": 1.0, \"recall\": 0.9256653410829, \"specificity\": 1.0, \"npv\": 0.999961093381648, \"accuracy\": 0.9999611122224444, \"f1\": 0.9613979348689436, \"f2\": 0.9396348279716805, \"f0_5\": 0.9841930657646523, \"p4\": 0.980309758017546, \"phi\": 0.9620963187616678}, {\"truth_threshold\": 11.60000017285347, \"match_probability\": 0.9996779582968373, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6050.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 488.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9253594371367391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07464056286326094, \"precision\": 1.0, \"recall\": 0.9253594371367391, \"specificity\": 1.0, \"npv\": 0.9999609332783624, \"accuracy\": 0.9999609521904381, \"f1\": 0.9612329202414999, \"f2\": 0.9393826470405565, \"f0_5\": 0.9841238857440302, \"p4\": 0.9802239270670008, \"phi\": 0.9619372569857109}, {\"truth_threshold\": 11.700000174343586, \"match_probability\": 0.9996995179863626, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6040.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 498.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9238299174059346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07617008259406546, \"precision\": 1.0, \"recall\": 0.9238299174059346, \"specificity\": 1.0, \"npv\": 0.9999601327627035, \"accuracy\": 0.9999601520304061, \"f1\": 0.9604070599459373, \"f2\": 0.9381212723658051, \"f0_5\": 0.9837774447846765, \"p4\": 0.979794146241051, \"phi\": 0.9611415540176148}, {\"truth_threshold\": 11.800000175833702, \"match_probability\": 0.9997196347265854, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6038.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 500.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9235240134597736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07647598654022637, \"precision\": 1.0, \"recall\": 0.9235240134597736, \"specificity\": 1.0, \"npv\": 0.9999599726597255, \"accuracy\": 0.9999599919983997, \"f1\": 0.9602417302798982, \"f2\": 0.9378689033861448, \"f0_5\": 0.9837080482241772, \"p4\": 0.9797080646478731, \"phi\": 0.9609823345149665}, {\"truth_threshold\": 11.900000177323818, \"match_probability\": 0.9997384050389891, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6034.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 504.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9229122055674518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07708779443254818, \"precision\": 1.0, \"recall\": 0.9229122055674518, \"specificity\": 1.0, \"npv\": 0.9999596524539234, \"accuracy\": 0.9999596719343868, \"f1\": 0.9599109131403119, \"f2\": 0.9373640713353631, \"f0_5\": 0.9835691465084436, \"p4\": 0.9795357757891738, \"phi\": 0.9606638164960274}, {\"truth_threshold\": 12.000000178813934, \"match_probability\": 0.9997559189953416, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6029.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 509.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9221474457020495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07785255429795045, \"precision\": 1.0, \"recall\": 0.9221474457020495, \"specificity\": 1.0, \"npv\": 0.999959252196959, \"accuracy\": 0.9999592718543708, \"f1\": 0.9594970955677569, \"f2\": 0.9367328547900935, \"f0_5\": 0.9833953154563841, \"p4\": 0.9793201787643608, \"phi\": 0.9602655206866262}, {\"truth_threshold\": 12.10000018030405, \"match_probability\": 0.9997722606477963, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5996.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 542.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9171000305903946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08289996940960538, \"precision\": 1.0, \"recall\": 0.9171000305903946, \"specificity\": 1.0, \"npv\": 0.9999566105090307, \"accuracy\": 0.9999566313262652, \"f1\": 0.9567576192755705, \"f2\": 0.932561901206918, \"f0_5\": 0.9822423170172335, \"p4\": 0.9778906294390296, \"phi\": 0.9576326216701786}, {\"truth_threshold\": 12.200000181794167, \"match_probability\": 0.9997875084304283, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5993.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 545.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9166411746711532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08335882532884674, \"precision\": 1.0, \"recall\": 0.9166411746711532, \"specificity\": 1.0, \"npv\": 0.9999563703562748, \"accuracy\": 0.9999563912782556, \"f1\": 0.9565078605059453, \"f2\": 0.9321822989578472, \"f0_5\": 0.9821370042608981, \"p4\": 0.9777600983608152, \"phi\": 0.9573929088641081}, {\"truth_threshold\": 12.300000183284283, \"match_probability\": 0.9998017355340825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5991.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 547.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9163352707249923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08366472927500765, \"precision\": 1.0, \"recall\": 0.9163352707249923, \"specificity\": 1.0, \"npv\": 0.9999562102545017, \"accuracy\": 0.9999562312462492, \"f1\": 0.9563412882113497, \"f2\": 0.9319291914258159, \"f0_5\": 0.9820667497213298, \"p4\": 0.9776730244281735, \"phi\": 0.9572330670409879}, {\"truth_threshold\": 12.400000184774399, \"match_probability\": 0.9998150102562988, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5979.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 559.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9144998470480269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08550015295197308, \"precision\": 1.0, \"recall\": 0.9144998470480269, \"specificity\": 1.0, \"npv\": 0.9999552496449392, \"accuracy\": 0.9999552710542109, \"f1\": 0.9553407365982264, \"f2\": 0.9304098845351841, \"f0_5\": 0.9816444473632363, \"p4\": 0.9771496849769628, \"phi\": 0.9562734561071788}, {\"truth_threshold\": 12.500000186264515, \"match_probability\": 0.9998273963279586, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5976.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 562.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9140409911287856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08595900887121444, \"precision\": 1.0, \"recall\": 0.9140409911287856, \"specificity\": 1.0, \"npv\": 0.9999550094928369, \"accuracy\": 0.9999550310062012, \"f1\": 0.9550902988652709, \"f2\": 0.9300298804780877, \"f0_5\": 0.9815386636883253, \"p4\": 0.9770186096526663, \"phi\": 0.9560334031617446}, {\"truth_threshold\": 12.600000187754631, \"match_probability\": 0.9998389532181915, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5967.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 571.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9126644233710615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08733557662893851, \"precision\": 1.0, \"recall\": 0.9126644233710615, \"specificity\": 1.0, \"npv\": 0.9999542890372223, \"accuracy\": 0.9999543108621725, \"f1\": 0.9543382646941223, \"f2\": 0.9288894423861266, \"f0_5\": 0.9812208116819049, \"p4\": 0.9766248048718625, \"phi\": 0.955312883092014}, {\"truth_threshold\": 12.700000189244747, \"match_probability\": 0.9998497364189812, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5959.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 579.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9114408075864179, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08855919241358214, \"precision\": 1.0, \"recall\": 0.9114408075864179, \"specificity\": 1.0, \"npv\": 0.999953648633103, \"accuracy\": 0.9999536707341469, \"f1\": 0.9536688805313275, \"f2\": 0.9278751829591105, \"f0_5\": 0.9809376440376638, \"p4\": 0.9762740255172775, \"phi\": 0.9546719651582635}, {\"truth_threshold\": 12.800000190734863, \"match_probability\": 0.9998597977108138, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5952.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 586.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9103701437748547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0896298562251453, \"precision\": 1.0, \"recall\": 0.9103701437748547, \"specificity\": 1.0, \"npv\": 0.9999530882801715, \"accuracy\": 0.9999531106221244, \"f1\": 0.9530824659727782, \"f2\": 0.9269872913032644, \"f0_5\": 0.9806893824556778, \"p4\": 0.9759665278039918, \"phi\": 0.954110809469073}, {\"truth_threshold\": 12.90000019222498, \"match_probability\": 0.9998691854106266, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5948.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 590.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9097583358825329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09024166411746712, \"precision\": 1.0, \"recall\": 0.9097583358825329, \"specificity\": 1.0, \"npv\": 0.9999527680787783, \"accuracy\": 0.9999527905581116, \"f1\": 0.9527470767259331, \"f2\": 0.9264797507788162, \"f0_5\": 0.9805473128915265, \"p4\": 0.9757905771827411, \"phi\": 0.9537900011262866}, {\"truth_threshold\": 13.000000193715096, \"match_probability\": 0.9998779446032292, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5943.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 595.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9089935760171306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09100642398286937, \"precision\": 1.0, \"recall\": 0.9089935760171306, \"specificity\": 1.0, \"npv\": 0.9999523678273253, \"accuracy\": 0.9999523904780956, \"f1\": 0.9523275378575434, \"f2\": 0.925845147219193, \"f0_5\": 0.9803695150115473, \"p4\": 0.9755703953841924, \"phi\": 0.9533888391827111}, {\"truth_threshold\": 13.100000195205212, \"match_probability\": 0.9998861173572945, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5925.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 613.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9062404405016825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09375955949831753, \"precision\": 1.0, \"recall\": 0.9062404405016825, \"specificity\": 1.0, \"npv\": 0.9999509269247473, \"accuracy\": 0.999950950190038, \"f1\": 0.9508144106555404, \"f2\": 0.9235589363095053, \"f0_5\": 0.9797274952047093, \"p4\": 0.9747754930426697, \"phi\": 0.9519432590739579}, {\"truth_threshold\": 13.200000196695328, \"match_probability\": 0.9998937429269453, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5920.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 618.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9054756806362803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09452431936371979, \"precision\": 1.0, \"recall\": 0.9054756806362803, \"specificity\": 1.0, \"npv\": 0.9999505266747681, \"accuracy\": 0.999950550110022, \"f1\": 0.9503933215604431, \"f2\": 0.9229234222998254, \"f0_5\": 0.9795486134092263, \"p4\": 0.9745540602705028, \"phi\": 0.9515413200399878}, {\"truth_threshold\": 13.300000198185444, \"match_probability\": 0.9999008579398913, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5914.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 624.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9045579687977975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09544203120220252, \"precision\": 1.0, \"recall\": 0.9045579687977975, \"specificity\": 1.0, \"npv\": 0.9999500463752161, \"accuracy\": 0.9999500700140028, \"f1\": 0.9498875682621266, \"f2\": 0.9221605438782511, \"f0_5\": 0.979333642445519, \"p4\": 0.9742879800608159, \"phi\": 0.9510587693977848}, {\"truth_threshold\": 13.40000019967556, \"match_probability\": 0.999907496573012, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5901.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 637.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9025695931477516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0974304068522484, \"precision\": 1.0, \"recall\": 0.9025695931477516, \"specificity\": 1.0, \"npv\": 0.9999490057277696, \"accuracy\": 0.9999490298059612, \"f1\": 0.9487900956668542, \"f2\": 0.9205066608429788, \"f0_5\": 0.9788666976312123, \"p4\": 0.9737101183505118, \"phi\": 0.9500124037443994}, {\"truth_threshold\": 13.500000201165676, \"match_probability\": 0.9999136907162209, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5888.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 650.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9005812174977057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09941878250229427, \"precision\": 1.0, \"recall\": 0.9005812174977057, \"specificity\": 1.0, \"npv\": 0.999947965082489, \"accuracy\": 0.9999479895979195, \"f1\": 0.9476903267342669, \"f2\": 0.9188514357053683, \"f0_5\": 0.9783981389165836, \"p4\": 0.9731303956384985, \"phi\": 0.948964886509686}, {\"truth_threshold\": 13.600000202655792, \"match_probability\": 0.9999194701253888, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5884.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 654.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.899969409605384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10003059039461609, \"precision\": 1.0, \"recall\": 0.899969409605384, \"specificity\": 1.0, \"npv\": 0.9999476448843768, \"accuracy\": 0.9999476695339068, \"f1\": 0.9473514731927226, \"f2\": 0.9183418654014234, \"f0_5\": 0.9782536410188203, \"p4\": 0.9729516436236364, \"phi\": 0.9486423412450483}, {\"truth_threshold\": 13.700000204145908, \"match_probability\": 0.9999248625650565, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5880.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 658.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8993576017130621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1006423982869379, \"precision\": 1.0, \"recall\": 0.8993576017130621, \"specificity\": 1.0, \"npv\": 0.9999473246864699, \"accuracy\": 0.9999473494698939, \"f1\": 0.9470124013528749, \"f2\": 0.9178321678321678, \"f0_5\": 0.9781089892873778, \"p4\": 0.9727727143028713, \"phi\": 0.9483196864820513}, {\"truth_threshold\": 13.800000205636024, \"match_probability\": 0.999929893941616, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5877.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 661.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8988987457938208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10110125420617926, \"precision\": 1.0, \"recall\": 0.8988987457938208, \"specificity\": 1.0, \"npv\": 0.9999470845381742, \"accuracy\": 0.9999471094218844, \"f1\": 0.9467579540877971, \"f2\": 0.9174498111086827, \"f0_5\": 0.9780003993876056, \"p4\": 0.9726384007964163, \"phi\": 0.9480776234842547}, {\"truth_threshold\": 13.90000020712614, \"match_probability\": 0.9999345884275949, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5873.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 665.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8982869379014989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10171306209850108, \"precision\": 1.0, \"recall\": 0.8982869379014989, \"specificity\": 1.0, \"npv\": 0.9999467643406259, \"accuracy\": 0.9999467893578716, \"f1\": 0.9464184997179921, \"f2\": 0.9169398907103825, \"f0_5\": 0.9778554778554779, \"p4\": 0.9724591605543973, \"phi\": 0.9477547768299838}, {\"truth_threshold\": 14.000000208616257, \"match_probability\": 0.9999389685776376, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5860.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 678.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.896298562251453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10370143774854695, \"precision\": 1.0, \"recall\": 0.896298562251453, \"specificity\": 1.0, \"npv\": 0.9999457237000106, \"accuracy\": 0.9999457491498299, \"f1\": 0.9453137602839168, \"f2\": 0.9152817693364989, \"f0_5\": 0.9773834145039696, \"p4\": 0.9718753988468958, \"phi\": 0.9467047662718342}, {\"truth_threshold\": 14.100000210106373, \"match_probability\": 0.9999430554367367, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5856.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 682.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8956867543591313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10431324564086877, \"precision\": 1.0, \"recall\": 0.8956867543591313, \"specificity\": 1.0, \"npv\": 0.9999454035033339, \"accuracy\": 0.9999454290858172, \"f1\": 0.944973374213329, \"f2\": 0.9147713071732066, \"f0_5\": 0.9772378345904813, \"p4\": 0.9716954001251714, \"phi\": 0.9463814521641012}, {\"truth_threshold\": 14.200000211596489, \"match_probability\": 0.9999468686412301, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5831.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 707.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8918629550321199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10813704496788008, \"precision\": 1.0, \"recall\": 0.8918629550321199, \"specificity\": 1.0, \"npv\": 0.9999434022787508, \"accuracy\": 0.9999434286857372, \"f1\": 0.9428409734012451, \"f2\": 0.9115780258262202, \"f0_5\": 0.9763244256915143, \"p4\": 0.9705663382419949, \"phi\": 0.9443582358518394}, {\"truth_threshold\": 14.300000213086605, \"match_probability\": 0.9999504265130488, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5822.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 716.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8904863872743959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10951361272560416, \"precision\": 1.0, \"recall\": 0.8904863872743959, \"specificity\": 1.0, \"npv\": 0.9999426818398617, \"accuracy\": 0.9999427085417083, \"f1\": 0.9420711974110032, \"f2\": 0.9104272221179709, \"f0_5\": 0.9759940991081607, \"p4\": 0.9701581500386668, \"phi\": 0.9436288180386656}, {\"truth_threshold\": 14.400000214576721, \"match_probability\": 0.9999537461476637, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5811.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 727.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8888039155705109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11119608442948914, \"precision\": 1.0, \"recall\": 0.8888039155705109, \"specificity\": 1.0, \"npv\": 0.9999418013048516, \"accuracy\": 0.9999418283656731, \"f1\": 0.9411288363430237, \"f2\": 0.9090198041485468, \"f0_5\": 0.9755892821167148, \"p4\": 0.9696580054955887, \"phi\": 0.9427365423820071}, {\"truth_threshold\": 14.500000216066837, \"match_probability\": 0.9999568434961527, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5805.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 733.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8878862037320281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11211379626797185, \"precision\": 1.0, \"recall\": 0.8878862037320281, \"specificity\": 1.0, \"npv\": 0.9999413210136815, \"accuracy\": 0.999941348269654, \"f1\": 0.9406141132625779, \"f2\": 0.9082517132396658, \"f0_5\": 0.975367968277438, \"p4\": 0.9693846189483971, \"phi\": 0.9422494910954461}, {\"truth_threshold\": 14.600000217556953, \"match_probability\": 0.9999597334417798, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5797.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 741.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8866625879473845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11333741205261548, \"precision\": 1.0, \"recall\": 0.8866625879473845, \"specificity\": 1.0, \"npv\": 0.9999406806261725, \"accuracy\": 0.9999407081416283, \"f1\": 0.9399270368869072, \"f2\": 0.90722714325957, \"f0_5\": 0.9750723272556011, \"p4\": 0.9690194642164635, \"phi\": 0.941599698214624}, {\"truth_threshold\": 14.70000021904707, \"match_probability\": 0.9999624298714548, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5793.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 745.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8860507800550627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11394921994493729, \"precision\": 1.0, \"recall\": 0.8860507800550627, \"specificity\": 1.0, \"npv\": 0.9999403604327255, \"accuracy\": 0.9999403880776155, \"f1\": 0.9395831643824507, \"f2\": 0.9067146658318985, \"f0_5\": 0.9749242679232581, \"p4\": 0.9688366122308105, \"phi\": 0.9412746338715163}, {\"truth_threshold\": 14.800000220537186, \"match_probability\": 0.9999649457424121, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5779.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 759.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8839094524319364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11609054756806363, \"precision\": 1.0, \"recall\": 0.8839094524319364, \"specificity\": 1.0, \"npv\": 0.999939239757276, \"accuracy\": 0.9999392678535707, \"f1\": 0.9383778517496143, \"f2\": 0.9049199837148852, \"f0_5\": 0.9744048020503137, \"p4\": 0.9681951838171412, \"phi\": 0.9401360252001093}, {\"truth_threshold\": 14.900000222027302, \"match_probability\": 0.9999672931444318, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5775.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 763.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8832976445396146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11670235546038545, \"precision\": 1.0, \"recall\": 0.8832976445396146, \"specificity\": 1.0, \"npv\": 0.9999389195647519, \"accuracy\": 0.9999389477895579, \"f1\": 0.9380329732802729, \"f2\": 0.9044069283051962, \"f0_5\": 0.9742560226735947, \"p4\": 0.9680115041375922, \"phi\": 0.9398104555361323}, {\"truth_threshold\": 15.000000223517418, \"match_probability\": 0.9999694833578969, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5772.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 766.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8828387886203732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1171612113796268, \"precision\": 1.0, \"recall\": 0.8828387886203732, \"specificity\": 1.0, \"npv\": 0.9999386794204933, \"accuracy\": 0.9999387077415484, \"f1\": 0.9377741673436231, \"f2\": 0.9040220523743892, \"f0_5\": 0.9741443326807534, \"p4\": 0.9678736231866163, \"phi\": 0.939566204391284}, {\"truth_threshold\": 15.100000225007534, \"match_probability\": 0.9999715269079685, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5768.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 770.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8822269807280514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11777301927194861, \"precision\": 1.0, \"recall\": 0.8822269807280514, \"specificity\": 1.0, \"npv\": 0.999938359228328, \"accuracy\": 0.9999383876775355, \"f1\": 0.9374288964732651, \"f2\": 0.9035087719298246, \"f0_5\": 0.9739952718676123, \"p4\": 0.9676896201065586, \"phi\": 0.939240437575049}, {\"truth_threshold\": 15.20000022649765, \"match_probability\": 0.9999734336151354, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5761.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 777.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8811563169164882, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11884368308351177, \"precision\": 1.0, \"recall\": 0.8811563169164882, \"specificity\": 1.0, \"npv\": 0.9999377988925321, \"accuracy\": 0.9999378275655131, \"f1\": 0.9368241320432555, \"f2\": 0.9026102215398114, \"f0_5\": 0.9737340274491245, \"p4\": 0.9673671689485884, \"phi\": 0.938670074103635}, {\"truth_threshold\": 15.300000227987766, \"match_probability\": 0.9999752126423825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5755.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 783.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8802386050780056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11976139492199449, \"precision\": 1.0, \"recall\": 0.8802386050780056, \"specificity\": 1.0, \"npv\": 0.9999373186052068, \"accuracy\": 0.9999373474694939, \"f1\": 0.9363052143496299, \"f2\": 0.901839721691165, \"f0_5\": 0.973509709723256, \"p4\": 0.9670903297171322, \"phi\": 0.9381809156524601}, {\"truth_threshold\": 15.400000229477882, \"match_probability\": 0.9999768725392036, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5746.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 792.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8788620373202815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12113796267971857, \"precision\": 1.0, \"recall\": 0.8788620373202815, \"specificity\": 1.0, \"npv\": 0.9999365981750842, \"accuracy\": 0.9999366273254651, \"f1\": 0.9355258873331163, \"f2\": 0.9006834284281147, \"f0_5\": 0.9731725492852787, \"p4\": 0.9666742854799766, \"phi\": 0.9374467002786164}, {\"truth_threshold\": 15.500000230967999, \"match_probability\": 0.9999784212826682, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5742.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 796.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8782502294279596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12174977057204038, \"precision\": 1.0, \"recall\": 0.8782502294279596, \"specificity\": 1.0, \"npv\": 0.9999362779842517, \"accuracy\": 0.9999363072614523, \"f1\": 0.9351791530944625, \"f2\": 0.9001693108421647, \"f0_5\": 0.9730224361146885, \"p4\": 0.96648907368388, \"phi\": 0.9371201980285181}, {\"truth_threshold\": 15.600000232458115, \"match_probability\": 0.9999798663157408, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5741.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 797.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8780972774548792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12190272254512083, \"precision\": 1.0, \"recall\": 0.8780972774548792, \"specificity\": 1.0, \"npv\": 0.9999361979365756, \"accuracy\": 0.9999362272454491, \"f1\": 0.9350924342373157, \"f2\": 0.9000407612955821, \"f0_5\": 0.9729848823808556, \"p4\": 0.9664427415250191, \"phi\": 0.9370385547226381}, {\"truth_threshold\": 15.70000023394823, \"match_probability\": 0.9999812145830361, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5736.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 802.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.877332517589477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1226674824105231, \"precision\": 1.0, \"recall\": 0.877332517589477, \"specificity\": 1.0, \"npv\": 0.9999357976983875, \"accuracy\": 0.999935827165433, \"f1\": 0.9346586279941339, \"f2\": 0.8993978926241847, \"f0_5\": 0.9727969608574724, \"p4\": 0.9662109052502622, \"phi\": 0.9366302316403032}, {\"truth_threshold\": 15.800000235438347, \"match_probability\": 0.9999824725641815, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5733.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 805.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8768736616702355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12312633832976445, \"precision\": 1.0, \"recall\": 0.8768736616702355, \"specificity\": 1.0, \"npv\": 0.9999355575556285, \"accuracy\": 0.9999355871174235, \"f1\": 0.9343981745579008, \"f2\": 0.8990120746432492, \"f0_5\": 0.9726840855106889, \"p4\": 0.9660716629413537, \"phi\": 0.9363851524816444}, {\"truth_threshold\": 15.900000236928463, \"match_probability\": 0.9999836463049459, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5732.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 806.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8767207096971551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1232792903028449, \"precision\": 1.0, \"recall\": 0.8767207096971551, \"specificity\": 1.0, \"npv\": 0.9999354775080677, \"accuracy\": 0.9999355071014203, \"f1\": 0.9343113284433577, \"f2\": 0.8988834525153682, \"f0_5\": 0.9726464399647051, \"p4\": 0.9660252253877262, \"phi\": 0.9363034451993846}, {\"truth_threshold\": 16.00000023841858, \"match_probability\": 0.9999847414462861, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5725.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 813.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8756500458855919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12434995411440808, \"precision\": 1.0, \"recall\": 0.8756500458855919, \"specificity\": 1.0, \"npv\": 0.9999349171755014, \"accuracy\": 0.9999349469893979, \"f1\": 0.9337030090516187, \"f2\": 0.8979828716629544, \"f0_5\": 0.9723826346898566, \"p4\": 0.9656998337462014, \"phi\": 0.9357312948209724}, {\"truth_threshold\": 16.100000239908695, \"match_probability\": 0.9999857632514492, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5722.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 816.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8751911899663506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12480881003364944, \"precision\": 1.0, \"recall\": 0.8751911899663506, \"specificity\": 1.0, \"npv\": 0.9999346770331653, \"accuracy\": 0.9999347069413883, \"f1\": 0.933442088091354, \"f2\": 0.8975967873501913, \"f0_5\": 0.9722694215999457, \"p4\": 0.9655602038156232, \"phi\": 0.9354859805904492}, {\"truth_threshold\": 16.20000024139881, \"match_probability\": 0.9999867166312594, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5719.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 819.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8747323340471093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1252676659528908, \"precision\": 1.0, \"recall\": 0.8747323340471093, \"specificity\": 1.0, \"npv\": 0.9999344368909445, \"accuracy\": 0.9999344668933787, \"f1\": 0.9331810394060537, \"f2\": 0.897210630353613, \"f0_5\": 0.9721561161351737, \"p4\": 0.9654204678889048, \"phi\": 0.9352406021317177}, {\"truth_threshold\": 16.300000242888927, \"match_probability\": 0.9999876061677141, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5709.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 829.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8732028143163046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12679718568369533, \"precision\": 1.0, \"recall\": 0.8732028143163046, \"specificity\": 1.0, \"npv\": 0.9999336364177083, \"accuracy\": 0.9999336667333467, \"f1\": 0.9323099534579897, \"f2\": 0.8959229151627381, \"f0_5\": 0.971777762647239, \"p4\": 0.9649539143860022, \"phi\": 0.9344222094157861}, {\"truth_threshold\": 16.400000244379044, \"match_probability\": 0.9999884361359999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5701.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 837.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8719791985316611, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12802080146833894, \"precision\": 1.0, \"recall\": 0.8719791985316611, \"specificity\": 1.0, \"npv\": 0.9999329960400419, \"accuracy\": 0.999933026605321, \"f1\": 0.9316120598088079, \"f2\": 0.8948921608639688, \"f0_5\": 0.9714743371276668, \"p4\": 0.9645798196300518, \"phi\": 0.9337669797504933}, {\"truth_threshold\": 16.50000024586916, \"match_probability\": 0.9999892105250341, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5697.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 841.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8713673906393392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12863260936066076, \"precision\": 1.0, \"recall\": 0.8713673906393392, \"specificity\": 1.0, \"npv\": 0.9999326758515164, \"accuracy\": 0.9999327065413083, \"f1\": 0.9312627707396812, \"f2\": 0.8943765895318534, \"f0_5\": 0.9713223760485576, \"p4\": 0.9643924874742633, \"phi\": 0.9334391927553439}, {\"truth_threshold\": 16.600000247359276, \"match_probability\": 0.9999899330566321, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5687.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 851.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8698378709085347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13016212909146527, \"precision\": 1.0, \"recall\": 0.8698378709085347, \"specificity\": 1.0, \"npv\": 0.9999318753810996, \"accuracy\": 0.9999319063812763, \"f1\": 0.9303885480572597, \"f2\": 0.893087094443921, \"f0_5\": 0.9709417469097863, \"p4\": 0.9639233241597182, \"phi\": 0.9326192221561134}, {\"truth_threshold\": 16.700000248849392, \"match_probability\": 0.9999906072033913, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5684.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 854.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8693790149892934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13062098501070663, \"precision\": 1.0, \"recall\": 0.8693790149892934, \"specificity\": 1.0, \"npv\": 0.9999316352402244, \"accuracy\": 0.9999316663332667, \"f1\": 0.9301260022909508, \"f2\": 0.8927000879507476, \"f0_5\": 0.9708273553323769, \"p4\": 0.9637823426345631, \"phi\": 0.9323730906143632}, {\"truth_threshold\": 16.800000250339508, \"match_probability\": 0.9999912362053778, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5682.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 856.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8690731110431325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13092688895686755, \"precision\": 1.0, \"recall\": 0.8690731110431325, \"specificity\": 1.0, \"npv\": 0.9999314751463718, \"accuracy\": 0.9999315063012603, \"f1\": 0.9299509001636661, \"f2\": 0.8924420430985739, \"f0_5\": 0.9707510421649695, \"p4\": 0.9636882952140735, \"phi\": 0.9322089668821074}, {\"truth_threshold\": 16.900000251829624, \"match_probability\": 0.999991823085696, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5675.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 863.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8680024472315693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13199755276843073, \"precision\": 1.0, \"recall\": 0.8680024472315693, \"specificity\": 1.0, \"npv\": 0.9999309148182912, \"accuracy\": 0.9999309461892378, \"f1\": 0.92933759109146, \"f2\": 0.8915386307223426, \"f0_5\": 0.9704836172104795, \"p4\": 0.9633587523239053, \"phi\": 0.931634306541348}, {\"truth_threshold\": 17.00000025331974, \"match_probability\": 0.9999923706650156, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5664.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 874.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8663199755276844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1336800244723157, \"precision\": 1.0, \"recall\": 0.8663199755276844, \"specificity\": 1.0, \"npv\": 0.9999300343040046, \"accuracy\": 0.9999300660132027, \"f1\": 0.9283723979675463, \"f2\": 0.8901181795323108, \"f0_5\": 0.9700623415770364, \"p4\": 0.9628397115890741, \"phi\": 0.9307305533008152}, {\"truth_threshold\": 17.100000254809856, \"match_probability\": 0.9999928815751264, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5659.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 879.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.865555215662282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13444478433771795, \"precision\": 1.0, \"recall\": 0.865555215662282, \"specificity\": 1.0, \"npv\": 0.9999296340707506, \"accuracy\": 0.9999296659331867, \"f1\": 0.9279330983028614, \"f2\": 0.8894721951526202, \"f0_5\": 0.969870432576952, \"p4\": 0.9626033027270717, \"phi\": 0.9303194666700334}, {\"truth_threshold\": 17.200000256299973, \"match_probability\": 0.999993358271586, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5644.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 894.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8632609360660752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13673906393392474, \"precision\": 1.0, \"recall\": 0.8632609360660752, \"specificity\": 1.0, \"npv\": 0.9999284333729112, \"accuracy\": 0.9999284656931386, \"f1\": 0.9266130356263339, \"f2\": 0.8875330230217637, \"f0_5\": 0.9692931235831559, \"p4\": 0.9618922642822093, \"phi\": 0.9290851174099084}, {\"truth_threshold\": 17.30000025779009, \"match_probability\": 0.999993803045519, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5636.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 902.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8620373202814317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13796267971856838, \"precision\": 1.0, \"recall\": 0.8620373202814317, \"specificity\": 1.0, \"npv\": 0.999927793001909, \"accuracy\": 0.9999278255651131, \"f1\": 0.9259076720880565, \"f2\": 0.8864980495784572, \"f0_5\": 0.9689842514269995, \"p4\": 0.9615119285232326, \"phi\": 0.9284261280006568}, {\"truth_threshold\": 17.400000259280205, \"match_probability\": 0.9999942180346287, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5617.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 921.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.859131232792903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14086876720709698, \"precision\": 1.0, \"recall\": 0.859131232792903, \"specificity\": 1.0, \"npv\": 0.9999262721240665, \"accuracy\": 0.9999263052610522, \"f1\": 0.9242287124640066, \"f2\": 0.8840378985803771, \"f0_5\": 0.9682479487002689, \"p4\": 0.9606055049643152, \"phi\": 0.9268591537401791}, {\"truth_threshold\": 17.50000026077032, \"match_probability\": 0.9999946052334694, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5612.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 926.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8583664729275008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14163352707249924, \"precision\": 1.0, \"recall\": 0.8583664729275008, \"specificity\": 1.0, \"npv\": 0.9999258718938242, \"accuracy\": 0.9999259051810362, \"f1\": 0.9237860082304526, \"f2\": 0.8833900012592872, \"f0_5\": 0.9680535430897674, \"p4\": 0.9603662381864468, \"phi\": 0.9264463523844528}, {\"truth_threshold\": 17.600000262260437, \"match_probability\": 0.999994966503032, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5610.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 928.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8580605689813399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14193943101866013, \"precision\": 1.0, \"recall\": 0.8580605689813399, \"specificity\": 1.0, \"npv\": 0.999925711801817, \"accuracy\": 0.9999257451490298, \"f1\": 0.9236088244978597, \"f2\": 0.8831307852150369, \"f0_5\": 0.9679757057077784, \"p4\": 0.9602704455254009, \"phi\": 0.9262811804240322}, {\"truth_threshold\": 17.700000263750553, \"match_probability\": 0.9999953035796879, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5605.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 933.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8572958091159376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14270419088406242, \"precision\": 1.0, \"recall\": 0.8572958091159376, \"specificity\": 1.0, \"npv\": 0.9999253115720232, \"accuracy\": 0.9999253450690138, \"f1\": 0.9231656098163551, \"f2\": 0.8824826022609189, \"f0_5\": 0.967780924096968, \"p4\": 0.9600307486667761, \"phi\": 0.925868121840062}, {\"truth_threshold\": 17.80000026524067, \"match_probability\": 0.9999956180835331, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5599.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 939.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8563780972774548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14362190272254513, \"precision\": 1.0, \"recall\": 0.8563780972774548, \"specificity\": 1.0, \"npv\": 0.9999248312966937, \"accuracy\": 0.9999248649729946, \"f1\": 0.9226332701656093, \"f2\": 0.8817045132436774, \"f0_5\": 0.9675468307181863, \"p4\": 0.9597427059410888, \"phi\": 0.9253722085984335}, {\"truth_threshold\": 17.900000266730785, \"match_probability\": 0.9999959115261747, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5586.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 952.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.854389721627409, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.145610278372591, \"precision\": 1.0, \"recall\": 0.854389721627409, \"specificity\": 1.0, \"npv\": 0.9999237907017291, \"accuracy\": 0.999923824764953, \"f1\": 0.9214780600461894, \"f2\": 0.8800176444640494, \"f0_5\": 0.9670382937469705, \"p4\": 0.9591170873887016, \"phi\": 0.9242968187688811}, {\"truth_threshold\": 18.0000002682209, \"match_probability\": 0.9999961853179954, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5579.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 959.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8533190578158458, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14668094218415417, \"precision\": 1.0, \"recall\": 0.8533190578158458, \"specificity\": 1.0, \"npv\": 0.9999232303822606, \"accuracy\": 0.9999232646529306, \"f1\": 0.9208549971114962, \"f2\": 0.8791087579969116, \"f0_5\": 0.9667637069383794, \"p4\": 0.9587793480337542, \"phi\": 0.9237172450690567}, {\"truth_threshold\": 18.100000269711018, \"match_probability\": 0.999996440774932, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5577.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 961.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8530131538696849, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14698684613031507, \"precision\": 1.0, \"recall\": 0.8530131538696849, \"specificity\": 1.0, \"npv\": 0.9999230702910993, \"accuracy\": 0.9999231046209242, \"f1\": 0.9206768468840281, \"f2\": 0.8788490024898358, \"f0_5\": 0.9666851556541635, \"p4\": 0.9586827391809754, \"phi\": 0.9235515858987354}, {\"truth_threshold\": 18.200000271201134, \"match_probability\": 0.9999966791247992, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5565.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 973.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8511777301927195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14882226980728053, \"precision\": 1.0, \"recall\": 0.8511777301927195, \"specificity\": 1.0, \"npv\": 0.9999221097452076, \"accuracy\": 0.9999221444288858, \"f1\": 0.9196067090803933, \"f2\": 0.8772897815051864, \"f0_5\": 0.9662129314535731, \"p4\": 0.9581020388861288, \"phi\": 0.9225570073130663}, {\"truth_threshold\": 18.30000027269125, \"match_probability\": 0.999996901513191, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5553.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 985.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.849342306515754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15065769348424596, \"precision\": 1.0, \"recall\": 0.849342306515754, \"specificity\": 1.0, \"npv\": 0.9999211492011614, \"accuracy\": 0.9999211842368474, \"f1\": 0.9185344471094202, \"f2\": 0.8757293802239394, \"f0_5\": 0.9657391304347827, \"p4\": 0.9575195373920614, \"phi\": 0.9215613572608162}, {\"truth_threshold\": 18.400000274181366, \"match_probability\": 0.9999971090089864, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5544.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 994.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8479657387580299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15203426124197003, \"precision\": 1.0, \"recall\": 0.8479657387580299, \"specificity\": 1.0, \"npv\": 0.9999204287943377, \"accuracy\": 0.9999204640928185, \"f1\": 0.9177288528389339, \"f2\": 0.8745583038869258, \"f0_5\": 0.9653827401267674, \"p4\": 0.9570814741836221, \"phi\": 0.9208139144810078}, {\"truth_threshold\": 18.500000275671482, \"match_probability\": 0.9999973026094866, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5533.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1005.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.846283267054145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.153716732945855, \"precision\": 1.0, \"recall\": 0.846283267054145, \"specificity\": 1.0, \"npv\": 0.9999195482985186, \"accuracy\": 0.9999195839167834, \"f1\": 0.9167426062463756, \"f2\": 0.8731260848982169, \"f0_5\": 0.9649459365190094, \"p4\": 0.9565446760663825, \"phi\": 0.9198995500191177}, {\"truth_threshold\": 18.600000277161598, \"match_probability\": 0.999997483245208, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5516.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1022.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8436830835117773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15631691648822268, \"precision\": 1.0, \"recall\": 0.8436830835117773, \"specificity\": 1.0, \"npv\": 0.9999181875353026, \"accuracy\": 0.9999182236447289, \"f1\": 0.9152148664343787, \"f2\": 0.8709106984969054, \"f0_5\": 0.9642682329907, \"p4\": 0.9557120624321677, \"phi\": 0.918484654046703}, {\"truth_threshold\": 18.700000278651714, \"match_probability\": 0.9999976517843541, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5503.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1035.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8416947078617314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15830529213826858, \"precision\": 1.0, \"recall\": 0.8416947078617314, \"specificity\": 1.0, \"npv\": 0.9999171469541659, \"accuracy\": 0.9999171834366873, \"f1\": 0.9140436840793954, \"f2\": 0.8692149739377666, \"f0_5\": 0.9637478108581436, \"p4\": 0.955072873158984, \"phi\": 0.9174012049760577}, {\"truth_threshold\": 18.80000028014183, \"match_probability\": 0.9999978090369889, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5490.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1048.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8397063322116856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16029366778831447, \"precision\": 1.0, \"recall\": 0.8397063322116856, \"specificity\": 1.0, \"npv\": 0.999916106375195, \"accuracy\": 0.9999161432286457, \"f1\": 0.9128699700698371, \"f2\": 0.8675178560141584, \"f0_5\": 0.9632254895080357, \"p4\": 0.9544315183791322, \"phi\": 0.9163164770993178}, {\"truth_threshold\": 18.900000281631947, \"match_probability\": 0.9999979557589296, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5473.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1065.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8371061486693179, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16289385133068215, \"precision\": 1.0, \"recall\": 0.8371061486693179, \"specificity\": 1.0, \"npv\": 0.9999147456213471, \"accuracy\": 0.9999147829565913, \"f1\": 0.9113312796603114, \"f2\": 0.8652964426877471, \"f0_5\": 0.9625395708758354, \"p4\": 0.9535895378246938, \"phi\": 0.9148960496716262}, {\"truth_threshold\": 19.000000283122063, \"match_probability\": 0.9999980926553794, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5465.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1073.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8358825328846742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1641174671153258, \"precision\": 1.0, \"recall\": 0.8358825328846742, \"specificity\": 1.0, \"npv\": 0.9999141052678767, \"accuracy\": 0.9999141428285657, \"f1\": 0.9106056819128551, \"f2\": 0.8642502451212956, \"f0_5\": 0.9622156489893654, \"p4\": 0.9531920167099226, \"phi\": 0.91422685093932}, {\"truth_threshold\": 19.10000028461218, \"match_probability\": 0.9999982203843173, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5458.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1080.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.834811869073111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16518813092688894, \"precision\": 1.0, \"recall\": 0.834811869073111, \"specificity\": 1.0, \"npv\": 0.9999135449592629, \"accuracy\": 0.9999135827165433, \"f1\": 0.9099699899966656, \"f2\": 0.8633343878519456, \"f0_5\": 0.9619316179062389, \"p4\": 0.9528435030256921, \"phi\": 0.9136409006710253}, {\"truth_threshold\": 19.200000286102295, \"match_probability\": 0.9999983395596597, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5447.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1091.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8331293973692261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16687060263077394, \"precision\": 1.0, \"recall\": 0.8331293973692261, \"specificity\": 1.0, \"npv\": 0.999912664475567, \"accuracy\": 0.9999127025405081, \"f1\": 0.9089695452649145, \"f2\": 0.8618943637456882, \"f0_5\": 0.961484148838523, \"p4\": 0.952294546881684, \"phi\": 0.9127193629897342}, {\"truth_threshold\": 19.30000028759241, \"match_probability\": 0.9999984507542113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5430.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1108.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8305292138268584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16947078617314162, \"precision\": 1.0, \"recall\": 0.8305292138268584, \"specificity\": 1.0, \"npv\": 0.999911303731087, \"accuracy\": 0.9999113422684537, \"f1\": 0.9074197860962567, \"f2\": 0.8596668988664429, \"f0_5\": 0.960789864817043, \"p4\": 0.9514430403299171, \"phi\": 0.9112933386041887}, {\"truth_threshold\": 19.400000289082527, \"match_probability\": 0.9999985545024187, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5423.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1115.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8294585500152952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1705414499847048, \"precision\": 1.0, \"recall\": 0.8294585500152952, \"specificity\": 1.0, \"npv\": 0.9999107434256129, \"accuracy\": 0.9999107821564313, \"f1\": 0.9067803695343198, \"f2\": 0.8587490102929533, \"f0_5\": 0.9605030109812256, \"p4\": 0.9510913138152849, \"phi\": 0.9107055042034856}, {\"truth_threshold\": 19.500000290572643, \"match_probability\": 0.9999986513029383, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5410.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1128.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8274701743652493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1725298256347507, \"precision\": 1.0, \"recall\": 0.8274701743652493, \"specificity\": 1.0, \"npv\": 0.9999097028599698, \"accuracy\": 0.9999097419483897, \"f1\": 0.9055908938734516, \"f2\": 0.8570432798935429, \"f0_5\": 0.959968769962382, \"p4\": 0.9504363871548699, \"phi\": 0.9096128056349272}, {\"truth_threshold\": 19.60000029206276, \"match_probability\": 0.9999987416210334, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5407.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1131.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.827011318446008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17298868155399205, \"precision\": 1.0, \"recall\": 0.827011318446008, \"specificity\": 1.0, \"npv\": 0.9999094627297443, \"accuracy\": 0.9999095019003801, \"f1\": 0.9053160318124739, \"f2\": 0.8566494502360658, \"f0_5\": 0.9598452034367677, \"p4\": 0.9502849316808804, \"phi\": 0.909360458288552}, {\"truth_threshold\": 19.700000293552876, \"match_probability\": 0.9999988258908107, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5406.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1132.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8268583664729275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17314163352707249, \"precision\": 1.0, \"recall\": 0.8268583664729275, \"specificity\": 1.0, \"npv\": 0.9999093826863614, \"accuracy\": 0.9999094218843769, \"f1\": 0.905224380442063, \"f2\": 0.8565181570441727, \"f0_5\": 0.9598039911938072, \"p4\": 0.9502344199173562, \"phi\": 0.909276326970519}, {\"truth_threshold\": 19.80000029504299, \"match_probability\": 0.9999989045173057, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5397.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1141.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8254817987152034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1745182012847966, \"precision\": 1.0, \"recall\": 0.8254817987152034, \"specificity\": 1.0, \"npv\": 0.9999086622964924, \"accuracy\": 0.9999087017403481, \"f1\": 0.9043988269794722, \"f2\": 0.8553361437763479, \"f0_5\": 0.9594325535092085, \"p4\": 0.9497792143940353, \"phi\": 0.9085187951294247}, {\"truth_threshold\": 19.900000296533108, \"match_probability\": 0.9999989778784306, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5385.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1153.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.823646375038238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17635362496176202, \"precision\": 1.0, \"recall\": 0.823646375038238, \"specificity\": 1.0, \"npv\": 0.9999077017782817, \"accuracy\": 0.9999077415483096, \"f1\": 0.9032961502977439, \"f2\": 0.853759076640137, \"f0_5\": 0.9589358216397179, \"p4\": 0.9491705897882066, \"phi\": 0.9075077707339466}, {\"truth_threshold\": 20.000000298023224, \"match_probability\": 0.99999904632679, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5352.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1186.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.818598959926583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18140104007341695, \"precision\": 1.0, \"recall\": 0.818598959926583, \"specificity\": 1.0, \"npv\": 0.9999050603627174, \"accuracy\": 0.999905101020204, \"f1\": 0.9002523128679563, \"f2\": 0.8494159471813103, \"f0_5\": 0.9575610105202891, \"p4\": 0.947486877939124, \"phi\": 0.9047216380955238}, {\"truth_threshold\": 20.10000029951334, \"match_probability\": 0.9999991101913761, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5336.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1202.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8161517283572958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1838482716427042, \"precision\": 1.0, \"recall\": 0.8161517283572958, \"specificity\": 1.0, \"npv\": 0.9999037796814066, \"accuracy\": 0.9999038207641529, \"f1\": 0.898770422772444, \"f2\": 0.8473069105691057, \"f0_5\": 0.9568897496592784, \"p4\": 0.9466652135799521, \"phi\": 0.9033676981041401}, {\"truth_threshold\": 20.200000301003456, \"match_probability\": 0.9999991697791492, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5317.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1221.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8132456408687672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18675435913123278, \"precision\": 1.0, \"recall\": 0.8132456408687672, \"specificity\": 1.0, \"npv\": 0.9999022588766111, \"accuracy\": 0.999902300460092, \"f1\": 0.8970054829185997, \"f2\": 0.844799644094188, \"f0_5\": 0.9560886139682083, \"p4\": 0.9456849343847354, \"phi\": 0.9017572585381487}, {\"truth_threshold\": 20.300000302493572, \"match_probability\": 0.9999992253765136, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5300.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1238.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8106454573263995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1893545426736005, \"precision\": 1.0, \"recall\": 0.8106454573263995, \"specificity\": 1.0, \"npv\": 0.9999008981604521, \"accuracy\": 0.9999009401880377, \"f1\": 0.8954215239060652, \"f2\": 0.8425537326720082, \"f0_5\": 0.9553680871007283, \"p4\": 0.9448036234244319, \"phi\": 0.9003139012979624}, {\"truth_threshold\": 20.40000030398369, \"match_probability\": 0.9999992772506945, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5287.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1251.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8086570816763536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1913429183236464, \"precision\": 1.0, \"recall\": 0.8086570816763536, \"specificity\": 1.0, \"npv\": 0.9998998576153, \"accuracy\": 0.999899899979996, \"f1\": 0.8942071881606766, \"f2\": 0.8408346321447884, \"f0_5\": 0.9548147077945532, \"p4\": 0.9441269734933921, \"phi\": 0.8992085969494452}, {\"truth_threshold\": 20.500000305473804, \"match_probability\": 0.9999993256510213, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5259.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1279.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8043744264301009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19562557356989904, \"precision\": 1.0, \"recall\": 0.8043744264301009, \"specificity\": 1.0, \"npv\": 0.9998976164484819, \"accuracy\": 0.9998976595319063, \"f1\": 0.8915826057472239, \"f2\": 0.8371271210722359, \"f0_5\": 0.953615724958294, \"p4\": 0.9426615454164293, \"phi\": 0.8968233224663443}, {\"truth_threshold\": 20.60000030696392, \"match_probability\": 0.9999993708101274, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5238.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1300.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8011624349954114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19883756500458855, \"precision\": 1.0, \"recall\": 0.8011624349954114, \"specificity\": 1.0, \"npv\": 0.9998959355799614, \"accuracy\": 0.9998959791958392, \"f1\": 0.8896059782608695, \"f2\": 0.8343421471806308, \"f0_5\": 0.952710076391415, \"p4\": 0.9415552181730203, \"phi\": 0.8950302019994951}, {\"truth_threshold\": 20.700000308454037, \"match_probability\": 0.9999994129450668, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5218.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1320.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7981033955338024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20189660446619762, \"precision\": 1.0, \"recall\": 0.7981033955338024, \"specificity\": 1.0, \"npv\": 0.999894334758053, \"accuracy\": 0.9998943788757751, \"f1\": 0.8877169105137802, \"f2\": 0.8316863245138667, \"f0_5\": 0.9518423932871215, \"p4\": 0.9404957368561905, \"phi\": 0.8933191276052553}, {\"truth_threshold\": 20.800000309944153, \"match_probability\": 0.9999994522583585, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5202.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1336.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7956561639645151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20434383603548487, \"precision\": 1.0, \"recall\": 0.7956561639645151, \"specificity\": 1.0, \"npv\": 0.9998930541042168, \"accuracy\": 0.999893098619724, \"f1\": 0.8862010221465076, \"f2\": 0.8295592268929004, \"f0_5\": 0.951144591530754, \"p4\": 0.9396440204811094, \"phi\": 0.8919479086826341}, {\"truth_threshold\": 20.90000031143427, \"match_probability\": 0.9999994889389594, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5178.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1360.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7919853166105842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20801468338941573, \"precision\": 1.0, \"recall\": 0.7919853166105842, \"specificity\": 1.0, \"npv\": 0.9998911331296135, \"accuracy\": 0.9998911782356471, \"f1\": 0.8839194264254011, \"f2\": 0.8263645068624321, \"f0_5\": 0.950091743119266, \"p4\": 0.9383595042261512, \"phi\": 0.8898871252286846}, {\"truth_threshold\": 21.000000312924385, \"match_probability\": 0.9999995231631726, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5151.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1387.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.787855613337412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21214438666258795, \"precision\": 1.0, \"recall\": 0.787855613337412, \"specificity\": 1.0, \"npv\": 0.9998889720420074, \"accuracy\": 0.9998890178035608, \"f1\": 0.8813414321156643, \"f2\": 0.8227645912532345, \"f0_5\": 0.9488983862648294, \"p4\": 0.9369043754351617, \"phi\": 0.887563034007991}, {\"truth_threshold\": 21.1000003144145, \"match_probability\": 0.9999995550954947, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5139.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1399.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7860201896604466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21397981033955338, \"precision\": 1.0, \"recall\": 0.7860201896604466, \"specificity\": 1.0, \"npv\": 0.9998880115616255, \"accuracy\": 0.9998880576115223, \"f1\": 0.8801918300933459, \"f2\": 0.8211626346233741, \"f0_5\": 0.9483649516498117, \"p4\": 0.9362542071199095, \"phi\": 0.8865281521118636}, {\"truth_threshold\": 21.200000315904617, \"match_probability\": 0.9999995848894065, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5125.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1413.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7838788620373203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21612113796267973, \"precision\": 1.0, \"recall\": 0.7838788620373203, \"specificity\": 1.0, \"npv\": 0.9998868910035121, \"accuracy\": 0.9998869373874775, \"f1\": 0.878847637829032, \"f2\": 0.8192921315982991, \"f0_5\": 0.9477402174717064, \"p4\": 0.9354929789946973, \"phi\": 0.8853192634783608}, {\"truth_threshold\": 21.300000317394733, \"match_probability\": 0.9999996126881108, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5110.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1428.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7815845824411135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21841541755888652, \"precision\": 1.0, \"recall\": 0.7815845824411135, \"specificity\": 1.0, \"npv\": 0.9998856904083205, \"accuracy\": 0.9998857371474295, \"f1\": 0.8774038461538461, \"f2\": 0.8172861621137483, \"f0_5\": 0.9470679813181111, \"p4\": 0.9346741345274632, \"phi\": 0.8840221941934668}, {\"truth_threshold\": 21.40000031888485, \"match_probability\": 0.9999996386252203, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5083.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1455.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7774548791679413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22254512083205874, \"precision\": 1.0, \"recall\": 0.7774548791679413, \"specificity\": 1.0, \"npv\": 0.9998835293442414, \"accuracy\": 0.9998835767153431, \"f1\": 0.8747956286033904, \"f2\": 0.8136705618696974, \"f0_5\": 0.9458503907703759, \"p4\": 0.9331916953769841, \"phi\": 0.8816826688147738}, {\"truth_threshold\": 21.500000320374966, \"match_probability\": 0.9999996628254004, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5058.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1480.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7736310798409299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22636892015907006, \"precision\": 1.0, \"recall\": 0.7736310798409299, \"specificity\": 1.0, \"npv\": 0.999881528367312, \"accuracy\": 0.9998815763152631, \"f1\": 0.872369782683684, \"f2\": 0.8103172060237104, \"f0_5\": 0.9447142323496451, \"p4\": 0.9318092099418559, \"phi\": 0.8795109018675112}, {\"truth_threshold\": 21.600000321865082, \"match_probability\": 0.999999685404968, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5028.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1510.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7690425206485164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23095747935148364, \"precision\": 1.0, \"recall\": 0.7690425206485164, \"specificity\": 1.0, \"npv\": 0.9998791272055683, \"accuracy\": 0.9998791758351671, \"f1\": 0.8694449247795262, \"f2\": 0.8062860808210391, \"f0_5\": 0.9433395872420263, \"p4\": 0.9301375747863783, \"phi\": 0.8768976931945988}, {\"truth_threshold\": 21.700000323355198, \"match_probability\": 0.9999997064724503, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5012.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1526.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7665952890792291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2334047109207709, \"precision\": 1.0, \"recall\": 0.7665952890792291, \"specificity\": 1.0, \"npv\": 0.9998778465906871, \"accuracy\": 0.9998778955791158, \"f1\": 0.8678787878787879, \"f2\": 0.8041329739442947, \"f0_5\": 0.9426013691416535, \"p4\": 0.9292403364699487, \"phi\": 0.8755007977444138}, {\"truth_threshold\": 21.800000324845314, \"match_probability\": 0.999999726129107, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4987.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1551.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7627714897522178, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2372285102477822, \"precision\": 1.0, \"recall\": 0.7627714897522178, \"specificity\": 1.0, \"npv\": 0.9998758456365024, \"accuracy\": 0.9998758951790359, \"f1\": 0.8654229934924078, \"f2\": 0.8007643148463341, \"f0_5\": 0.9414407611568376, \"p4\": 0.9278303853778125, \"phi\": 0.8733136826727346}, {\"truth_threshold\": 21.90000032633543, \"match_probability\": 0.9999997444694171, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4965.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1573.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7594065463444478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24059345365555215, \"precision\": 1.0, \"recall\": 0.7594065463444478, \"specificity\": 1.0, \"npv\": 0.9998740848034446, \"accuracy\": 0.9998741348269654, \"f1\": 0.8632530644179779, \"f2\": 0.7977954172960118, \"f0_5\": 0.9404121524357906, \"p4\": 0.9265814704934491, \"phi\": 0.8713844877663931}, {\"truth_threshold\": 22.000000327825546, \"match_probability\": 0.9999997615815319, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4943.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1595.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7560416029366779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24395839706332212, \"precision\": 1.0, \"recall\": 0.7560416029366779, \"specificity\": 1.0, \"npv\": 0.9998723239765887, \"accuracy\": 0.999872374474895, \"f1\": 0.8610748192666144, \"f2\": 0.7948223187007557, \"f0_5\": 0.9393766628658304, \"p4\": 0.9253248444110449, \"phi\": 0.8694510190639155}, {\"truth_threshold\": 22.100000329315662, \"match_probability\": 0.9999997775477002, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4919.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1619.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.752370755582747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24762924441725298, \"precision\": 1.0, \"recall\": 0.752370755582747, \"specificity\": 1.0, \"npv\": 0.999870403081637, \"accuracy\": 0.9998704540908182, \"f1\": 0.8586890110849262, \"f2\": 0.7915741366547585, \"f0_5\": 0.9382391088731212, \"p4\": 0.9239451007487015, \"phi\": 0.8673368726460077}, {\"truth_threshold\": 22.20000033080578, \"match_probability\": 0.9999997924446623, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4888.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1650.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.747629244417253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.252370755582747, \"precision\": 1.0, \"recall\": 0.747629244417253, \"specificity\": 1.0, \"npv\": 0.9998679219365814, \"accuracy\": 0.9998679735947189, \"f1\": 0.8555925083143707, \"f2\": 0.7873711340206185, \"f0_5\": 0.9367573783058644, \"p4\": 0.922149070095091, \"phi\": 0.8645984611335457}, {\"truth_threshold\": 22.300000332295895, \"match_probability\": 0.9999998063440199, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4862.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1676.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7436524931171612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2563475068828388, \"precision\": 1.0, \"recall\": 0.7436524931171612, \"specificity\": 1.0, \"npv\": 0.999865840985707, \"accuracy\": 0.9998658931786357, \"f1\": 0.8529824561403508, \"f2\": 0.7838395563293996, \"f0_5\": 0.9355037327791887, \"p4\": 0.920630534439612, \"phi\": 0.86229503386701}, {\"truth_threshold\": 22.40000033378601, \"match_probability\": 0.9999998193125794, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4837.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1701.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7398286937901499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26017130620985013, \"precision\": 1.0, \"recall\": 0.7398286937901499, \"specificity\": 1.0, \"npv\": 0.9998638400795731, \"accuracy\": 0.9998638927785557, \"f1\": 0.8504615384615385, \"f2\": 0.7804382200135532, \"f0_5\": 0.9342888047593294, \"p4\": 0.9191597963719398, \"phi\": 0.8600743914185992}, {\"truth_threshold\": 22.500000335276127, \"match_probability\": 0.9999998314126736, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4815.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1723.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7364637503823799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26353624961762007, \"precision\": 1.0, \"recall\": 0.7364637503823799, \"specificity\": 1.0, \"npv\": 0.9998620792887998, \"accuracy\": 0.9998621324264853, \"f1\": 0.848233946974368, \"f2\": 0.777440501178674, \"f0_5\": 0.9332118768896813, \"p4\": 0.9178568545008681, \"phi\": 0.8581154798616292}, {\"truth_threshold\": 22.600000336766243, \"match_probability\": 0.9999998427024609, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4799.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1739.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7340165188130927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2659834811869073, \"precision\": 1.0, \"recall\": 0.7340165188130927, \"specificity\": 1.0, \"npv\": 0.9998607987175872, \"accuracy\": 0.9998608521704341, \"f1\": 0.8466084502072859, \"f2\": 0.7752576653419921, \"f0_5\": 0.932424030465532, \"p4\": 0.9169041030842923, \"phi\": 0.85668800783737}, {\"truth_threshold\": 22.70000033825636, \"match_probability\": 0.9999998532362051, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4776.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1762.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7304986234322423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26950137656775774, \"precision\": 1.0, \"recall\": 0.7304986234322423, \"specificity\": 1.0, \"npv\": 0.9998589579022157, \"accuracy\": 0.9998590118023605, \"f1\": 0.8442637440339402, \"f2\": 0.772115882048629, \"f0_5\": 0.931284611184775, \"p4\": 0.9155268474313526, \"phi\": 0.8546318461033177}, {\"truth_threshold\": 22.800000339746475, \"match_probability\": 0.9999998630645361, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4757.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1781.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7275925359437136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27240746405628635, \"precision\": 1.0, \"recall\": 0.7275925359437136, \"specificity\": 1.0, \"npv\": 0.9998574372337604, \"accuracy\": 0.9998574914982996, \"f1\": 0.8423196104471005, \"f2\": 0.7695169691675564, \"f0_5\": 0.9303371665493233, \"p4\": 0.9143822290355259, \"phi\": 0.8529295447685548}, {\"truth_threshold\": 22.90000034123659, \"match_probability\": 0.9999998722346936, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4744.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1794.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7256041602936678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2743958397063322, \"precision\": 1.0, \"recall\": 0.7256041602936678, \"specificity\": 1.0, \"npv\": 0.9998563967790614, \"accuracy\": 0.999856451290258, \"f1\": 0.840985640843822, \"f2\": 0.7677369238736406, \"f0_5\": 0.9296856627733793, \"p4\": 0.9135954511481305, \"phi\": 0.8517628550242862}, {\"truth_threshold\": 23.000000342726707, \"match_probability\": 0.999999880790753, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4727.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1811.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7230039767513001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27699602324869993, \"precision\": 1.0, \"recall\": 0.7230039767513001, \"specificity\": 1.0, \"npv\": 0.9998550361877223, \"accuracy\": 0.9998550910182037, \"f1\": 0.839236573457612, \"f2\": 0.7654069108455585, \"f0_5\": 0.9288296785349367, \"p4\": 0.9125621208394814, \"phi\": 0.8502347718945269}, {\"truth_threshold\": 23.100000344216824, \"match_probability\": 0.9999998887738388, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4718.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1820.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.721627408993576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.278372591006424, \"precision\": 1.0, \"recall\": 0.721627408993576, \"specificity\": 1.0, \"npv\": 0.9998543158761596, \"accuracy\": 0.9998543708741748, \"f1\": 0.8383084577114428, \"f2\": 0.764172335600907, \"f0_5\": 0.928374655647383, \"p4\": 0.9120130025008165, \"phi\": 0.8494246754932173}, {\"truth_threshold\": 23.20000034570694, \"match_probability\": 0.9999998962223214, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4705.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1833.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7196390333435301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28036096665646987, \"precision\": 1.0, \"recall\": 0.7196390333435301, \"specificity\": 1.0, \"npv\": 0.9998532754279567, \"accuracy\": 0.9998533306661332, \"f1\": 0.8369652228053011, \"f2\": 0.7623877888323557, \"f0_5\": 0.9277151194889187, \"p4\": 0.9112172981527895, \"phi\": 0.8482531724752564}, {\"truth_threshold\": 23.300000347197056, \"match_probability\": 0.9999999031720016, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4693.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1845.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7178036096665646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2821963903334353, \"precision\": 1.0, \"recall\": 0.7178036096665646, \"specificity\": 1.0, \"npv\": 0.9998523150161529, \"accuracy\": 0.9998523704740948, \"f1\": 0.835722553646158, \"f2\": 0.7607391797698169, \"f0_5\": 0.9271039114974319, \"p4\": 0.9104801312555832, \"phi\": 0.847170349370223}, {\"truth_threshold\": 23.400000348687172, \"match_probability\": 0.9999999096562825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4673.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1865.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7147445702049556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28525542979504437, \"precision\": 1.0, \"recall\": 0.7147445702049556, \"specificity\": 1.0, \"npv\": 0.9998507143339134, \"accuracy\": 0.9998507701540308, \"f1\": 0.8336455267148336, \"f2\": 0.7579886455798864, \"f0_5\": 0.9260800634165676, \"p4\": 0.9092457851144679, \"phi\": 0.8453625666456439}, {\"truth_threshold\": 23.500000350177288, \"match_probability\": 0.9999999157063305, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4666.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1872.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7136739063933925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28632609360660755, \"precision\": 1.0, \"recall\": 0.7136739063933925, \"specificity\": 1.0, \"npv\": 0.9998501540963404, \"accuracy\": 0.9998502100420084, \"f1\": 0.8329168154230632, \"f2\": 0.75702511519242, \"f0_5\": 0.9257201809380208, \"p4\": 0.908812060803313, \"phi\": 0.8447289300609816}, {\"truth_threshold\": 23.600000351667404, \"match_probability\": 0.9999999213512251, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4639.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1899.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7095442031202203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29045579687977974, \"precision\": 1.0, \"recall\": 0.7095442031202203, \"specificity\": 1.0, \"npv\": 0.9998479931858684, \"accuracy\": 0.999848049609922, \"f1\": 0.8300975216963407, \"f2\": 0.7533045370400442, \"f0_5\": 0.9243245397306129, \"p4\": 0.9071307861529526, \"phi\": 0.8422804447251631}, {\"truth_threshold\": 23.70000035315752, \"match_probability\": 0.9999999266180979, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4618.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1920.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7063322116855307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29366778831446927, \"precision\": 1.0, \"recall\": 0.7063322116855307, \"specificity\": 1.0, \"npv\": 0.999846312484181, \"accuracy\": 0.9998463692738547, \"f1\": 0.827895302975977, \"f2\": 0.7504062398440039, \"f0_5\": 0.9232307077169132, \"p4\": 0.9058138985306241, \"phi\": 0.8403711425570097}, {\"truth_threshold\": 23.800000354647636, \"match_probability\": 0.9999999315322641, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4596.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1942.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7029672682777608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2970327317222392, \"precision\": 1.0, \"recall\": 0.7029672682777608, \"specificity\": 1.0, \"npv\": 0.9998445517551403, \"accuracy\": 0.9998446089217844, \"f1\": 0.8255793066283456, \"f2\": 0.7473656823208014, \"f0_5\": 0.9220768798651794, \"p4\": 0.9044255506065761, \"phi\": 0.8383662643795451}, {\"truth_threshold\": 23.900000356137753, \"match_probability\": 0.9999999361173434, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4579.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1959.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7003670847353931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2996329152646069, \"precision\": 1.0, \"recall\": 0.7003670847353931, \"specificity\": 1.0, \"npv\": 0.9998431911960382, \"accuracy\": 0.99984324864973, \"f1\": 0.8237833948007556, \"f2\": 0.7450131788747518, \"f0_5\": 0.9211796893860144, \"p4\": 0.9033465484881688, \"phi\": 0.8368137552708497}, {\"truth_threshold\": 24.00000035762787, \"match_probability\": 0.9999999403953735, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4563.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1975.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6979198531661058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30208014683389417, \"precision\": 1.0, \"recall\": 0.6979198531661058, \"specificity\": 1.0, \"npv\": 0.9998419106732068, \"accuracy\": 0.9998419683936788, \"f1\": 0.8220881001711557, \"f2\": 0.7427966791469965, \"f0_5\": 0.9203307785397338, \"p4\": 0.9023260490296173, \"phi\": 0.8353499383410303}, {\"truth_threshold\": 24.100000359117985, \"match_probability\": 0.9999999443869169, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4551.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1987.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6960844294891404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3039155705108596, \"precision\": 1.0, \"recall\": 0.6960844294891404, \"specificity\": 1.0, \"npv\": 0.9998409502832357, \"accuracy\": 0.9998410082016403, \"f1\": 0.8208134187032194, \"f2\": 0.7411327883268736, \"f0_5\": 0.9196912133214776, \"p4\": 0.901557491807666, \"phi\": 0.8342503925427822}, {\"truth_threshold\": 24.2000003606081, \"match_probability\": 0.9999999481111586, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4521.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2017.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6914958702967269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3085041297032732, \"precision\": 1.0, \"recall\": 0.6914958702967269, \"specificity\": 1.0, \"npv\": 0.99983854931638, \"accuracy\": 0.9998386077215443, \"f1\": 0.8176146125327788, \"f2\": 0.7369673654353992, \"f0_5\": 0.9180813906262691, \"p4\": 0.8996240605783042, \"phi\": 0.8314951760628242}, {\"truth_threshold\": 24.300000362098217, \"match_probability\": 0.999999951585999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4506.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2032.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.68920159070052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31079840929947994, \"precision\": 1.0, \"recall\": 0.68920159070052, \"specificity\": 1.0, \"npv\": 0.9998373488372763, \"accuracy\": 0.9998374074814963, \"f1\": 0.8160086925027165, \"f2\": 0.7348815969730575, \"f0_5\": 0.9172705805716147, \"p4\": 0.8986508409522244, \"phi\": 0.8301141435130723}, {\"truth_threshold\": 24.400000363588333, \"match_probability\": 0.9999999548281396, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4489.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2049.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6866014071581523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3133985928418477, \"precision\": 1.0, \"recall\": 0.6866014071581523, \"specificity\": 1.0, \"npv\": 0.9998359882977771, \"accuracy\": 0.9998360472094419, \"f1\": 0.8141833680964904, \"f2\": 0.7325152573349434, \"f0_5\": 0.9163468604556217, \"p4\": 0.8975425682181113, \"phi\": 0.8285461945435606}, {\"truth_threshold\": 24.50000036507845, \"match_probability\": 0.999999957853164, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4466.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2072.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.683083511777302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3169164882226981, \"precision\": 1.0, \"recall\": 0.683083511777302, \"specificity\": 1.0, \"npv\": 0.9998341475737599, \"accuracy\": 0.9998342068413683, \"f1\": 0.811704834605598, \"f2\": 0.7293095564700502, \"f0_5\": 0.9150889271371199, \"p4\": 0.8960341191904556, \"phi\": 0.8264201236172489}, {\"truth_threshold\": 24.600000366568565, \"match_probability\": 0.9999999606756114, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4456.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2082.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6815539920464974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3184460079535026, \"precision\": 1.0, \"recall\": 0.6815539920464974, \"specificity\": 1.0, \"npv\": 0.9998333472610839, \"accuracy\": 0.9998334066813362, \"f1\": 0.8106239767145715, \"f2\": 0.7279142707788814, \"f0_5\": 0.9145390362039242, \"p4\": 0.8953750115325081, \"phi\": 0.8254940394739404}, {\"truth_threshold\": 24.70000036805868, \"match_probability\": 0.999999963309048, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4437.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2101.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6786479045579688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3213520954420312, \"precision\": 1.0, \"recall\": 0.6786479045579688, \"specificity\": 1.0, \"npv\": 0.9998318266705291, \"accuracy\": 0.9998318863772755, \"f1\": 0.8085649202733485, \"f2\": 0.7252607146359803, \"f0_5\": 0.913489253067611, \"p4\": 0.8941172205584833, \"phi\": 0.823731615321593}, {\"truth_threshold\": 24.800000369548798, \"match_probability\": 0.9999999657661313, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4429.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2109.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6774242887733252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32257571122667483, \"precision\": 1.0, \"recall\": 0.6774242887733252, \"specificity\": 1.0, \"npv\": 0.9998311864232582, \"accuracy\": 0.9998312462492499, \"f1\": 0.8076958147168779, \"f2\": 0.7241424413851738, \"f0_5\": 0.9130452708831533, \"p4\": 0.893585461558059, \"phi\": 0.8229884144726252}, {\"truth_threshold\": 24.900000371038914, \"match_probability\": 0.999999968058671, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4415.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2123.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6752829611501988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3247170388498012, \"precision\": 1.0, \"recall\": 0.6752829611501988, \"specificity\": 1.0, \"npv\": 0.999830065992507, \"accuracy\": 0.999830126025205, \"f1\": 0.8061718250707569, \"f2\": 0.7221840546995125, \"f0_5\": 0.9122654764856599, \"p4\": 0.892651780137451, \"phi\": 0.8216861977728596}, {\"truth_threshold\": 25.00000037252903, \"match_probability\": 0.9999999701976862, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4409.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2129.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6743652493117162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3256347506882839, \"precision\": 1.0, \"recall\": 0.6743652493117162, \"specificity\": 1.0, \"npv\": 0.9998295858086682, \"accuracy\": 0.9998296459291859, \"f1\": 0.8055174933771809, \"f2\": 0.7213441968521972, \"f0_5\": 0.9119301729130471, \"p4\": 0.8922504167912851, \"phi\": 0.8211274736014453}, {\"truth_threshold\": 25.100000374019146, \"match_probability\": 0.9999999721934579, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4393.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2145.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6719180177424289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3280819822575711, \"precision\": 1.0, \"recall\": 0.6719180177424289, \"specificity\": 1.0, \"npv\": 0.999828305320686, \"accuracy\": 0.9998283656731346, \"f1\": 0.8037690970633977, \"f2\": 0.7191029628417089, \"f0_5\": 0.9110327664869349, \"p4\": 0.8911765334715824, \"phi\": 0.8196356830896563}, {\"truth_threshold\": 25.200000375509262, \"match_probability\": 0.9999999740555788, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4374.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2164.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6690119302539003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33098806974609973, \"precision\": 1.0, \"recall\": 0.6690119302539003, \"specificity\": 1.0, \"npv\": 0.9998267847454673, \"accuracy\": 0.9998268453690738, \"f1\": 0.8016862170087976, \"f2\": 0.7164384459149578, \"f0_5\": 0.9099608887409503, \"p4\": 0.8898944893386471, \"phi\": 0.8178606526677487}, {\"truth_threshold\": 25.300000376999378, \"match_probability\": 0.9999999757929992, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4360.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2178.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6668706026307739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3331293973692261, \"precision\": 1.0, \"recall\": 0.6668706026307739, \"specificity\": 1.0, \"npv\": 0.9998256643245813, \"accuracy\": 0.999825725145029, \"f1\": 0.8001468159295283, \"f2\": 0.7144729942317777, \"f0_5\": 0.9091667361748269, \"p4\": 0.8889450602452386, \"phi\": 0.8165502699122985}, {\"truth_threshold\": 25.400000378489494, \"match_probability\": 0.9999999774140695, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4339.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2199.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6636586111960844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33634138880391556, \"precision\": 1.0, \"recall\": 0.6636586111960844, \"specificity\": 1.0, \"npv\": 0.9998239836979609, \"accuracy\": 0.9998240448089618, \"f1\": 0.7978302840856853, \"f2\": 0.7115214325538683, \"f0_5\": 0.9079685276638486, \"p4\": 0.8875132731248652, \"phi\": 0.81458074888959}, {\"truth_threshold\": 25.50000037997961, \"match_probability\": 0.9999999789265818, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4328.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2210.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6619761394921995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33802386050780053, \"precision\": 1.0, \"recall\": 0.6619761394921995, \"specificity\": 1.0, \"npv\": 0.9998231033719859, \"accuracy\": 0.9998231646329265, \"f1\": 0.7966132891588441, \"f2\": 0.7099737532808399, \"f0_5\": 0.9073375262054507, \"p4\": 0.8867596029657924, \"phi\": 0.8135471947866931}, {\"truth_threshold\": 25.600000381469727, \"match_probability\": 0.9999999803378055, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4317.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2221.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6602936677883144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33970633221168556, \"precision\": 1.0, \"recall\": 0.6602936677883144, \"specificity\": 1.0, \"npv\": 0.9998222230475612, \"accuracy\": 0.9998222844568914, \"f1\": 0.7953938277291571, \"f2\": 0.7084249565131773, \"f0_5\": 0.9067041922204486, \"p4\": 0.8860033816096013, \"phi\": 0.812512327778687}, {\"truth_threshold\": 25.700000382959843, \"match_probability\": 0.9999999816545239, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4297.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2241.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6572346283267054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34276537167329457, \"precision\": 1.0, \"recall\": 0.6572346283267054, \"specificity\": 1.0, \"npv\": 0.9998206224616698, \"accuracy\": 0.9998206841368273, \"f1\": 0.7931702814951546, \"f2\": 0.7056060954382738, \"f0_5\": 0.9055466576751243, \"p4\": 0.8846218551733269, \"phi\": 0.8106273713593508}, {\"truth_threshold\": 25.80000038444996, \"match_probability\": 0.9999999828830655, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4288.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2250.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6558580605689813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3441419394310187, \"precision\": 1.0, \"recall\": 0.6558580605689813, \"specificity\": 1.0, \"npv\": 0.9998199021996905, \"accuracy\": 0.9998199639927986, \"f1\": 0.7921670053574728, \"f2\": 0.7043363994743759, \"f0_5\": 0.9050232165470663, \"p4\": 0.8839973818044735, \"phi\": 0.8097777114584951}, {\"truth_threshold\": 25.900000385940075, \"match_probability\": 0.9999999840293354, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4279.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2259.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6544814928112572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3455185071887427, \"precision\": 1.0, \"recall\": 0.6544814928112572, \"specificity\": 1.0, \"npv\": 0.999819181938749, \"accuracy\": 0.9998192438487697, \"f1\": 0.7911620597208099, \"f2\": 0.7030659524826657, \"f0_5\": 0.9044981821256447, \"p4\": 0.8833711687237881, \"phi\": 0.8089271603405356}, {\"truth_threshold\": 26.00000038743019, \"match_probability\": 0.999999985098843, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4270.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2268.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6531049250535332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3468950749464668, \"precision\": 1.0, \"recall\": 0.6531049250535332, \"specificity\": 1.0, \"npv\": 0.9998184616788452, \"accuracy\": 0.999818523704741, \"f1\": 0.7901554404145078, \"f2\": 0.7017947537965946, \"f0_5\": 0.9039715471250741, \"p4\": 0.8827432086474299, \"phi\": 0.8080757151912815}, {\"truth_threshold\": 26.100000388920307, \"match_probability\": 0.9999999860967289, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4257.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2281.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6511165494034873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3488834505965127, \"precision\": 1.0, \"recall\": 0.6511165494034873, \"specificity\": 1.0, \"npv\": 0.9998174213052607, \"accuracy\": 0.9998174834966993, \"f1\": 0.78869847151459, \"f2\": 0.6999572494985037, \"f0_5\": 0.9032080115420521, \"p4\": 0.8818330561456207, \"phi\": 0.8068442658864065}, {\"truth_threshold\": 26.200000390410423, \"match_probability\": 0.9999999870277894, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4246.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2292.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6494340776996024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3505659223003977, \"precision\": 1.0, \"recall\": 0.6494340776996024, \"specificity\": 1.0, \"npv\": 0.9998165409908419, \"accuracy\": 0.9998166033206641, \"f1\": 0.7874629080118695, \"f2\": 0.6984012106059609, \"f0_5\": 0.9025593061814472, \"p4\": 0.8810600517432094, \"phi\": 0.8058008024116097}, {\"truth_threshold\": 26.30000039190054, \"match_probability\": 0.9999999878964996, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4229.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2309.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6468338941572346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35316610584276537, \"precision\": 1.0, \"recall\": 0.6468338941572346, \"specificity\": 1.0, \"npv\": 0.999815180507971, \"accuracy\": 0.9998152430486097, \"f1\": 0.7855484350329711, \"f2\": 0.6959942069056319, \"f0_5\": 0.9015519740769166, \"p4\": 0.879860191038494, \"phi\": 0.804185517555178}, {\"truth_threshold\": 26.400000393390656, \"match_probability\": 0.9999999887070348, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4217.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2321.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6449984704802691, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3550015295197308, \"precision\": 1.0, \"recall\": 0.6449984704802691, \"specificity\": 1.0, \"npv\": 0.9998142201693502, \"accuracy\": 0.9998142828565714, \"f1\": 0.7841933984193399, \"f2\": 0.694293523000428, \"f0_5\": 0.9008373921216782, \"p4\": 0.8790093921827526, \"phi\": 0.8030433629472657}, {\"truth_threshold\": 26.50000039488077, \"match_probability\": 0.9999999894632908, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4203.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2335.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6428571428571429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35714285714285715, \"precision\": 1.0, \"recall\": 0.6428571428571429, \"specificity\": 1.0, \"npv\": 0.9998130997766242, \"accuracy\": 0.9998131626325265, \"f1\": 0.782608695652174, \"f2\": 0.6923076923076923, \"f0_5\": 0.9, \"p4\": 0.8780127516316948, \"phi\": 0.8017087954572684}, {\"truth_threshold\": 26.600000396370888, \"match_probability\": 0.9999999901689027, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4193.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2345.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6413276231263383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35867237687366166, \"precision\": 1.0, \"recall\": 0.6413276231263383, \"specificity\": 1.0, \"npv\": 0.999812299497643, \"accuracy\": 0.9998123624724945, \"f1\": 0.781474233529028, \"f2\": 0.6908881199538639, \"f0_5\": 0.8993993993993994, \"p4\": 0.8772981854872046, \"phi\": 0.8007541730202234}, {\"truth_threshold\": 26.700000397861004, \"match_probability\": 0.999999990827262, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4166.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2372.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6371979198531661, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3628020801468339, \"precision\": 1.0, \"recall\": 0.6371979198531661, \"specificity\": 1.0, \"npv\": 0.999810138750793, \"accuracy\": 0.999810202040408, \"f1\": 0.7784005979073244, \"f2\": 0.6870505970050795, \"f0_5\": 0.8977674338419102, \"p4\": 0.8753576115751266, \"phi\": 0.7981709971303835}, {\"truth_threshold\": 26.80000039935112, \"match_probability\": 0.9999999914415327, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4159.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2379.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6361272560416029, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3638727439583971, \"precision\": 1.0, \"recall\": 0.6361272560416029, \"specificity\": 1.0, \"npv\": 0.9998095785586898, \"accuracy\": 0.9998096419283857, \"f1\": 0.7776011965971767, \"f2\": 0.6860545676487084, \"f0_5\": 0.8973418486234573, \"p4\": 0.8748518021551898, \"phi\": 0.7974999208605921}, {\"truth_threshold\": 26.900000400841236, \"match_probability\": 0.9999999920146677, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4146.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2392.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6341388803915571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.365861119608443, \"precision\": 1.0, \"recall\": 0.6341388803915571, \"specificity\": 1.0, \"npv\": 0.9998085382035921, \"accuracy\": 0.999808601720344, \"f1\": 0.7761138150505429, \"f2\": 0.6842035777939138, \"f0_5\": 0.8965487414583514, \"p4\": 0.8739094728754639, \"phi\": 0.7962521378447566}, {\"truth_threshold\": 27.000000402331352, \"match_probability\": 0.9999999925494215, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4122.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2416.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6304680330376262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36953196696237384, \"precision\": 1.0, \"recall\": 0.6304680330376262, \"specificity\": 1.0, \"npv\": 0.9998066175537152, \"accuracy\": 0.9998066813362673, \"f1\": 0.7733583489681051, \"f2\": 0.6807821893373852, \"f0_5\": 0.8950751324589594, \"p4\": 0.8721595772089327, \"phi\": 0.7939433931881372}, {\"truth_threshold\": 27.10000040382147, \"match_probability\": 0.9999999930483645, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4102.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2436.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6274089935760171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37259100642398285, \"precision\": 1.0, \"recall\": 0.6274089935760171, \"specificity\": 1.0, \"npv\": 0.9998050170177881, \"accuracy\": 0.9998050810162032, \"f1\": 0.7710526315789473, \"f2\": 0.6779268857010643, \"f0_5\": 0.8938377059182429, \"p4\": 0.8706911201362929, \"phi\": 0.79201430511032}, {\"truth_threshold\": 27.200000405311584, \"match_probability\": 0.9999999935138947, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4083.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2455.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6245029060874885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37549709391251146, \"precision\": 1.0, \"recall\": 0.6245029060874885, \"specificity\": 1.0, \"npv\": 0.9998034965134038, \"accuracy\": 0.9998035607121424, \"f1\": 0.7688541568590528, \"f2\": 0.675210848354556, \"f0_5\": 0.8926541320507214, \"p4\": 0.8692874015545988, \"phi\": 0.7901773149673766}, {\"truth_threshold\": 27.3000004068017, \"match_probability\": 0.9999999939482498, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4071.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2467.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.622667482410523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3773325175894769, \"precision\": 1.0, \"recall\": 0.622667482410523, \"specificity\": 1.0, \"npv\": 0.9998025361972281, \"accuracy\": 0.9998026005201041, \"f1\": 0.7674615892167028, \"f2\": 0.6734936968533898, \"f0_5\": 0.8919025501708877, \"p4\": 0.8683964471127058, \"phi\": 0.789014909948845}, {\"truth_threshold\": 27.400000408291817, \"match_probability\": 0.9999999943535174, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4062.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2476.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6212909146527991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.378709085347201, \"precision\": 1.0, \"recall\": 0.6212909146527991, \"specificity\": 1.0, \"npv\": 0.999801815961307, \"accuracy\": 0.9998018803760752, \"f1\": 0.7664150943396226, \"f2\": 0.6722049381081617, \"f0_5\": 0.8913367857456332, \"p4\": 0.8677259838532362, \"phi\": 0.78814198258317}, {\"truth_threshold\": 27.500000409781933, \"match_probability\": 0.9999999947316455, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4053.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2485.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.619914346895075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38008565310492504, \"precision\": 1.0, \"recall\": 0.619914346895075, \"specificity\": 1.0, \"npv\": 0.9998010957264236, \"accuracy\": 0.9998011602320465, \"f1\": 0.7653668208856577, \"f2\": 0.6709154113557358, \"f0_5\": 0.8907692307692308, \"p4\": 0.8670535849533395, \"phi\": 0.7872680885709938}, {\"truth_threshold\": 27.60000041127205, \"match_probability\": 0.9999999950844514, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4046.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2492.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6188436830835118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3811563169164882, \"precision\": 1.0, \"recall\": 0.6188436830835118, \"specificity\": 1.0, \"npv\": 0.9998005355444539, \"accuracy\": 0.999800600120024, \"f1\": 0.7645502645502645, \"f2\": 0.6699119146963375, \"f0_5\": 0.8903265557609366, \"p4\": 0.8665292644361258, \"phi\": 0.7865877228670668}, {\"truth_threshold\": 27.700000412762165, \"match_probability\": 0.999999995413631, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4032.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2506.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6167023554603854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38329764453961457, \"precision\": 1.0, \"recall\": 0.6167023554603854, \"specificity\": 1.0, \"npv\": 0.9997994151823977, \"accuracy\": 0.9997994798959792, \"f1\": 0.7629139072847683, \"f2\": 0.6679035250463822, \"f0_5\": 0.8894379246448425, \"p4\": 0.8654770794285569, \"phi\": 0.785225225225795}, {\"truth_threshold\": 27.80000041425228, \"match_probability\": 0.9999999957207664, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4022.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2516.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6151728357295809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3848271642704191, \"precision\": 1.0, \"recall\": 0.6151728357295809, \"specificity\": 1.0, \"npv\": 0.9997986149253234, \"accuracy\": 0.9997986797359472, \"f1\": 0.7617424242424242, \"f2\": 0.6664678199774641, \"f0_5\": 0.8888004950057456, \"p4\": 0.8647226112062963, \"phi\": 0.7842505652545738}, {\"truth_threshold\": 27.900000415742397, \"match_probability\": 0.9999999960073339, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4012.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2526.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6136433159987764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38635668400122364, \"precision\": 1.0, \"recall\": 0.6136433159987764, \"specificity\": 1.0, \"npv\": 0.9997978146695302, \"accuracy\": 0.9997978795759151, \"f1\": 0.7605687203791469, \"f2\": 0.6650311629757326, \"f0_5\": 0.8881608075799168, \"p4\": 0.863965706758565, \"phi\": 0.7832746940391605}, {\"truth_threshold\": 28.000000417232513, \"match_probability\": 0.9999999962747108, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3980.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2558.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6087488528602019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3912511471397981, \"precision\": 1.0, \"recall\": 0.6087488528602019, \"specificity\": 1.0, \"npv\": 0.9997952538596008, \"accuracy\": 0.9997953190638128, \"f1\": 0.7567978703175509, \"f2\": 0.6604274525421479, \"f0_5\": 0.8860984949683854, \"p4\": 0.8615271028638909, \"phi\": 0.7801437136080162}, {\"truth_threshold\": 28.10000041872263, \"match_probability\": 0.9999999965241823, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3963.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2575.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6061486693178342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3938513306821658, \"precision\": 1.0, \"recall\": 0.6061486693178342, \"specificity\": 1.0, \"npv\": 0.9997938934346614, \"accuracy\": 0.9997939587917584, \"f1\": 0.7547852585468051, \"f2\": 0.6579777519508551, \"f0_5\": 0.8849933005806163, \"p4\": 0.8602212636973778, \"phi\": 0.7784752649233736}, {\"truth_threshold\": 28.200000420212746, \"match_probability\": 0.9999999967569474, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3940.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2598.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6026307739369838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3973692260630162, \"precision\": 1.0, \"recall\": 0.6026307739369838, \"specificity\": 1.0, \"npv\": 0.9997920528656363, \"accuracy\": 0.9997921184236848, \"f1\": 0.75205191830502, \"f2\": 0.6546590455935132, \"f0_5\": 0.8834873082787694, \"p4\": 0.8584429960406973, \"phi\": 0.7762122509948322}, {\"truth_threshold\": 28.300000421702862, \"match_probability\": 0.9999999969741249, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3910.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2628.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5980422147445702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4019577852554298, \"precision\": 1.0, \"recall\": 0.5980422147445702, \"specificity\": 1.0, \"npv\": 0.9997896521336141, \"accuracy\": 0.9997897179435887, \"f1\": 0.748468606431853, \"f2\": 0.6503226664892555, \"f0_5\": 0.881504193344756, \"p4\": 0.8561033359413205, \"phi\": 0.7732505530813993}, {\"truth_threshold\": 28.400000423192978, \"match_probability\": 0.9999999971767587, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3892.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2646.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5952890792291221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40471092077087795, \"precision\": 1.0, \"recall\": 0.5952890792291221, \"specificity\": 1.0, \"npv\": 0.9997882116999349, \"accuracy\": 0.9997882776555311, \"f1\": 0.7463087248322148, \"f2\": 0.6477166821994408, \"f0_5\": 0.8803039898670044, \"p4\": 0.8546884455976975, \"phi\": 0.771468083569881}, {\"truth_threshold\": 28.500000424683094, \"match_probability\": 0.9999999973658228, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3883.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2655.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.593912511471398, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.406087488528602, \"precision\": 1.0, \"recall\": 0.593912511471398, \"specificity\": 1.0, \"npv\": 0.9997874914846517, \"accuracy\": 0.9997875575115023, \"f1\": 0.7452259859898283, \"f2\": 0.6464125187281505, \"f0_5\": 0.8797009515178976, \"p4\": 0.8539778508183035, \"phi\": 0.7705753045649324}, {\"truth_threshold\": 28.60000042617321, \"match_probability\": 0.9999999975422257, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3854.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2684.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5894769042520649, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41052309574793516, \"precision\": 1.0, \"recall\": 0.5894769042520649, \"specificity\": 1.0, \"npv\": 0.9997851707980201, \"accuracy\": 0.9997852370474095, \"f1\": 0.7417244033872209, \"f2\": 0.6422048923548623, \"f0_5\": 0.8777443746014394, \"p4\": 0.8516737405371603, \"phi\": 0.7676915183842653}, {\"truth_threshold\": 28.700000427663326, \"match_probability\": 0.9999999977068155, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3824.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2714.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5848883450596513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41511165494034874, \"precision\": 1.0, \"recall\": 0.5848883450596513, \"specificity\": 1.0, \"npv\": 0.9997827700990485, \"accuracy\": 0.9997828365673135, \"f1\": 0.7380814514572477, \"f2\": 0.6378436082199093, \"f0_5\": 0.8756984519556654, \"p4\": 0.849266761340273, \"phi\": 0.7646968613917454}, {\"truth_threshold\": 28.800000429153442, \"match_probability\": 0.9999999978603832, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3810.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2728.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5827470174365249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4172529825634751, \"precision\": 1.0, \"recall\": 0.5827470174365249, \"specificity\": 1.0, \"npv\": 0.9997816497768073, \"accuracy\": 0.9997817163432686, \"f1\": 0.7363741785852339, \"f2\": 0.6358053534477004, \"f0_5\": 0.8747359720819176, \"p4\": 0.8481352554548997, \"phi\": 0.7632953389712287}, {\"truth_threshold\": 28.90000043064356, \"match_probability\": 0.999999998003667, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3786.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2752.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.579076170082594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42092382991740596, \"precision\": 1.0, \"recall\": 0.579076170082594, \"specificity\": 1.0, \"npv\": 0.9997797292302353, \"accuracy\": 0.9997797959591919, \"f1\": 0.7334366524602867, \"f2\": 0.6323067673191262, \"f0_5\": 0.8730744396273407, \"p4\": 0.8461831791563587, \"phi\": 0.7608867304197502}, {\"truth_threshold\": 29.000000432133675, \"match_probability\": 0.9999999981373554, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3765.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2773.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5758641786479045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42413582135209543, \"precision\": 1.0, \"recall\": 0.5758641786479045, \"specificity\": 1.0, \"npv\": 0.9997780487580376, \"accuracy\": 0.9997781156231246, \"f1\": 0.7308550907502669, \"f2\": 0.6292408998228431, \"f0_5\": 0.8716084822668766, \"p4\": 0.8444621864819424, \"phi\": 0.7587729336753203}, {\"truth_threshold\": 29.10000043362379, \"match_probability\": 0.9999999982620912, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3746.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2792.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5729580911593759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42704190884062404, \"precision\": 1.0, \"recall\": 0.5729580911593759, \"specificity\": 1.0, \"npv\": 0.9997765283356788, \"accuracy\": 0.9997765953190638, \"f1\": 0.7285103072734345, \"f2\": 0.6264633085825139, \"f0_5\": 0.870272279527925, \"p4\": 0.8428945901367119, \"phi\": 0.7568553701078947}, {\"truth_threshold\": 29.200000435113907, \"match_probability\": 0.9999999983784738, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3728.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2810.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5702049556439278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4297950443560722, \"precision\": 1.0, \"recall\": 0.5702049556439278, \"specificity\": 1.0, \"npv\": 0.9997750879398152, \"accuracy\": 0.9997751550310062, \"f1\": 0.7262809273329437, \"f2\": 0.6238286479250335, \"f0_5\": 0.868997668997669, \"p4\": 0.8414002003525125, \"phi\": 0.7550342440397165}, {\"truth_threshold\": 29.300000436604023, \"match_probability\": 0.9999999984870624, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3705.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2833.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5666870602630774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4333129397369226, \"precision\": 1.0, \"recall\": 0.5666870602630774, \"specificity\": 1.0, \"npv\": 0.9997732474400293, \"accuracy\": 0.9997733146629326, \"f1\": 0.7234208727911745, \"f2\": 0.6204575141507854, \"f0_5\": 0.8673564940537504, \"p4\": 0.8394774021283078, \"phi\": 0.7527008453040692}, {\"truth_threshold\": 29.40000043809414, \"match_probability\": 0.9999999985883794, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3675.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2863.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5620985010706638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43790149892933616, \"precision\": 1.0, \"recall\": 0.5620985010706638, \"specificity\": 1.0, \"npv\": 0.9997708467983184, \"accuracy\": 0.9997709141828366, \"f1\": 0.7196710075394106, \"f2\": 0.6160525698192912, \"f0_5\": 0.8651944627554383, \"p4\": 0.8369467069299513, \"phi\": 0.7496463795680488}, {\"truth_threshold\": 29.500000439584255, \"match_probability\": 0.9999999986829113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3645.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2893.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5575099418782502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4424900581217498, \"precision\": 1.0, \"recall\": 0.5575099418782502, \"specificity\": 1.0, \"npv\": 0.9997684461681362, \"accuracy\": 0.9997685137027406, \"f1\": 0.7158990474319945, \"f2\": 0.6116387555794207, \"f0_5\": 0.8630078605928592, \"p4\": 0.8343899502277868, \"phi\": 0.7465794320197324}, {\"truth_threshold\": 29.60000044107437, \"match_probability\": 0.9999999987711129, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3627.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2911.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5547568063628021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44524319363719794, \"precision\": 1.0, \"recall\": 0.5547568063628021, \"specificity\": 1.0, \"npv\": 0.9997670057955608, \"accuracy\": 0.999767073414683, \"f1\": 0.7136251844564683, \"f2\": 0.6089861983276805, \"f0_5\": 0.861683930438088, \"p4\": 0.8328432186219793, \"phi\": 0.7447332080967293}, {\"truth_threshold\": 29.700000442564487, \"match_probability\": 0.9999999988534077, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3592.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2946.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5494034873049862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4505965126950138, \"precision\": 1.0, \"recall\": 0.5494034873049862, \"specificity\": 1.0, \"npv\": 0.9997642050829892, \"accuracy\": 0.9997642728545709, \"f1\": 0.7091806515301086, \"f2\": 0.6038192576654116, \"f0_5\": 0.8590835166937721, \"p4\": 0.8298080748099809, \"phi\": 0.7411301780087569}, {\"truth_threshold\": 29.800000444054604, \"match_probability\": 0.9999999989301916, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3562.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2976.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5448149281125727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45518507188742735, \"precision\": 1.0, \"recall\": 0.5448149281125727, \"specificity\": 1.0, \"npv\": 0.9997618044847029, \"accuracy\": 0.9997618723744749, \"f1\": 0.7053465346534653, \"f2\": 0.59938076327657, \"f0_5\": 0.8568267102857693, \"p4\": 0.827177079214499, \"phi\": 0.7380278826982279}, {\"truth_threshold\": 29.90000044554472, \"match_probability\": 0.9999999990018335, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3531.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3007.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5400734169470787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4599265830529214, \"precision\": 1.0, \"recall\": 0.5400734169470787, \"specificity\": 1.0, \"npv\": 0.9997593238785849, \"accuracy\": 0.9997593918783757, \"f1\": 0.7013606117787268, \"f2\": 0.5947848937102045, \"f0_5\": 0.8544671377407802, \"p4\": 0.8244293508083116, \"phi\": 0.7348084336558804}, {\"truth_threshold\": 30.000000447034836, \"match_probability\": 0.9999999990686778, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3507.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3031.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5364025695931478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46359743040685225, \"precision\": 1.0, \"recall\": 0.5364025695931478, \"specificity\": 1.0, \"npv\": 0.9997574034177864, \"accuracy\": 0.9997574714942988, \"f1\": 0.6982578397212543, \"f2\": 0.5912202029738022, \"f0_5\": 0.8526208304969367, \"p4\": 0.8222815079706218, \"phi\": 0.7323062475242675}, {\"truth_threshold\": 30.100000448524952, \"match_probability\": 0.9999999991310455, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3472.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3066.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5310492505353319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4689507494646681, \"precision\": 1.0, \"recall\": 0.5310492505353319, \"specificity\": 1.0, \"npv\": 0.9997546027590142, \"accuracy\": 0.9997546709341868, \"f1\": 0.6937062937062937, \"f2\": 0.5860113421550095, \"f0_5\": 0.8498971898560658, \"p4\": 0.8191165462812937, \"phi\": 0.72864184104018}, {\"truth_threshold\": 30.200000450015068, \"match_probability\": 0.9999999991892369, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3434.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3104.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5252370755582747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4747629244417253, \"precision\": 1.0, \"recall\": 0.5252370755582747, \"specificity\": 1.0, \"npv\": 0.9997515620615418, \"accuracy\": 0.9997516303260652, \"f1\": 0.6887284396309667, \"f2\": 0.580342053674035, \"f0_5\": 0.8468975041925619, \"p4\": 0.8156356282103336, \"phi\": 0.724642385416435}, {\"truth_threshold\": 30.300000451505184, \"match_probability\": 0.9999999992435312, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3392.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3146.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5188130926888956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4811869073111043, \"precision\": 1.0, \"recall\": 0.5188130926888956, \"specificity\": 1.0, \"npv\": 0.9997482013121705, \"accuracy\": 0.9997482696539308, \"f1\": 0.6831822759315207, \"f2\": 0.5740590305984294, \"f0_5\": 0.8435292947378892, \"p4\": 0.8117330694768484, \"phi\": 0.7201961234503612}, {\"truth_threshold\": 30.4000004529953, \"match_probability\": 0.9999999992941897, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3359.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3179.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5137656775772408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48623432242275927, \"precision\": 1.0, \"recall\": 0.5137656775772408, \"specificity\": 1.0, \"npv\": 0.9997455607392297, \"accuracy\": 0.9997456291258252, \"f1\": 0.6787915529958574, \"f2\": 0.5691098234556606, \"f0_5\": 0.8408430960248323, \"p4\": 0.808625261706386, \"phi\": 0.7166833020365612}, {\"truth_threshold\": 30.500000454485416, \"match_probability\": 0.9999999993414557, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3332.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3206.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5096359743040685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49036402569593146, \"precision\": 1.0, \"recall\": 0.5096359743040685, \"specificity\": 1.0, \"npv\": 0.9997434002808351, \"accuracy\": 0.9997434686937388, \"f1\": 0.675177304964539, \"f2\": 0.5650522317188984, \"f0_5\": 0.8386187455954898, \"p4\": 0.8060548357370882, \"phi\": 0.7137963307948464}, {\"truth_threshold\": 30.600000455975533, \"match_probability\": 0.9999999993855564, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3296.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3242.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5041297032731722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49587029672682775, \"precision\": 1.0, \"recall\": 0.5041297032731722, \"specificity\": 1.0, \"npv\": 0.9997405196841671, \"accuracy\": 0.9997405881176236, \"f1\": 0.6703274354281066, \"f2\": 0.5596305351806574, \"f0_5\": 0.8356150491836528, \"p4\": 0.8025881779261574, \"phi\": 0.7099287932874297}, {\"truth_threshold\": 30.70000045746565, \"match_probability\": 0.9999999994267039, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3262.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3276.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4989293361884368, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5010706638115632, \"precision\": 1.0, \"recall\": 0.4989293361884368, \"specificity\": 1.0, \"npv\": 0.9997377991358897, \"accuracy\": 0.9997378675735147, \"f1\": 0.6657142857142857, \"f2\": 0.5544978581627796, \"f0_5\": 0.8327376697641172, \"p4\": 0.799272004654923, \"phi\": 0.7062566930552646}, {\"truth_threshold\": 30.800000458955765, \"match_probability\": 0.9999999994650958, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3230.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3308.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4940348730498623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5059651269501376, \"precision\": 1.0, \"recall\": 0.4940348730498623, \"specificity\": 1.0, \"npv\": 0.9997352386333895, \"accuracy\": 0.9997353070614123, \"f1\": 0.6613431613431613, \"f2\": 0.5496562521271526, \"f0_5\": 0.8299928050159318, \"p4\": 0.7961128297112132, \"phi\": 0.7027830900795212}, {\"truth_threshold\": 30.90000046044588, \"match_probability\": 0.9999999995009168, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3194.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3344.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.48852860201896603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5114713979810339, \"precision\": 1.0, \"recall\": 0.48852860201896603, \"specificity\": 1.0, \"npv\": 0.9997323580837543, \"accuracy\": 0.999732426485297, \"f1\": 0.6563912864775997, \"f2\": 0.5441968240986846, \"f0_5\": 0.8268613441027234, \"p4\": 0.7925137927777076, \"phi\": 0.6988546710781726}, {\"truth_threshold\": 31.000000461935997, \"match_probability\": 0.9999999995343388, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3169.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3369.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4847048026919547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5152951973080453, \"precision\": 1.0, \"recall\": 0.4847048026919547, \"specificity\": 1.0, \"npv\": 0.9997303577118295, \"accuracy\": 0.999730426085217, \"f1\": 0.6529308746265582, \"f2\": 0.5403976672009823, \"f0_5\": 0.8246591027375871, \"p4\": 0.7899859630888851, \"phi\": 0.6961135724720999}, {\"truth_threshold\": 31.100000463426113, \"match_probability\": 0.9999999995655228, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3141.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3397.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.48042214744570205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.519577852554298, \"precision\": 1.0, \"recall\": 0.48042214744570205, \"specificity\": 1.0, \"npv\": 0.9997281173047773, \"accuracy\": 0.9997281856371274, \"f1\": 0.6490339911147845, \"f2\": 0.5361349127777968, \"f0_5\": 0.8221652183017485, \"p4\": 0.7871265975834781, \"phi\": 0.6930306840085869}, {\"truth_threshold\": 31.20000046491623, \"match_probability\": 0.9999999995946184, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3116.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3422.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.47659834811869073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5234016518813093, \"precision\": 1.0, \"recall\": 0.47659834811869073, \"specificity\": 1.0, \"npv\": 0.9997261169498232, \"accuracy\": 0.9997261852370474, \"f1\": 0.6455355293142738, \"f2\": 0.5323219898865655, \"f0_5\": 0.8199136932954426, \"p4\": 0.7845480465758479, \"phi\": 0.6902664818093074}, {\"truth_threshold\": 31.300000466406345, \"match_probability\": 0.9999999996217657, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3082.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3456.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.47139798103395536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5286020189660446, \"precision\": 1.0, \"recall\": 0.47139798103395536, \"specificity\": 1.0, \"npv\": 0.999723396479932, \"accuracy\": 0.9997234646929386, \"f1\": 0.6407484407484407, \"f2\": 0.5271259492371896, \"f0_5\": 0.8168133149581257, \"p4\": 0.7810019017914082, \"phi\": 0.6864893230728709}, {\"truth_threshold\": 31.40000046789646, \"match_probability\": 0.9999999996470949, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3041.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3497.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.46512695013765676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5348730498623432, \"precision\": 1.0, \"recall\": 0.46512695013765676, \"specificity\": 1.0, \"npv\": 0.9997201159329908, \"accuracy\": 0.9997201840368074, \"f1\": 0.6349305773045203, \"f2\": 0.5208440379543041, \"f0_5\": 0.8130146508394824, \"p4\": 0.7766642471537647, \"phi\": 0.6819067154055433}, {\"truth_threshold\": 31.500000469386578, \"match_probability\": 0.9999999996707278, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3019.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3519.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4617620067298868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5382379932701132, \"precision\": 1.0, \"recall\": 0.4617620067298868, \"specificity\": 1.0, \"npv\": 0.9997183556483858, \"accuracy\": 0.999718423684737, \"f1\": 0.6317882180600607, \"f2\": 0.5174659764834939, \"f0_5\": 0.8109487482540023, \"p4\": 0.7743085240229989, \"phi\": 0.6794350256418206}, {\"truth_threshold\": 31.600000470876694, \"match_probability\": 0.9999999996927782, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2989.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3549.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.45717344753747324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5428265524625268, \"precision\": 1.0, \"recall\": 0.45717344753747324, \"specificity\": 1.0, \"npv\": 0.9997159552702782, \"accuracy\": 0.9997160232046409, \"f1\": 0.6274797942689199, \"f2\": 0.5128513091520538, \"f0_5\": 0.808099924299773, \"p4\": 0.7710638615481691, \"phi\": 0.6760499906287489}, {\"truth_threshold\": 31.70000047236681, \"match_probability\": 0.999999999713352, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2949.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3589.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4510553686142551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5489446313857449, \"precision\": 1.0, \"recall\": 0.4510553686142551, \"specificity\": 1.0, \"npv\": 0.9997127547840655, \"accuracy\": 0.9997128225645129, \"f1\": 0.6216928428375672, \"f2\": 0.5066836191196179, \"f0_5\": 0.804243482055198, \"p4\": 0.766678607122116, \"phi\": 0.6715100930868418}, {\"truth_threshold\": 31.800000473856926, \"match_probability\": 0.9999999997325479, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2928.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3610.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4478433771795656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5521566228204344, \"precision\": 1.0, \"recall\": 0.4478433771795656, \"specificity\": 1.0, \"npv\": 0.9997110745370069, \"accuracy\": 0.9997111422284457, \"f1\": 0.6186351151489542, \"f2\": 0.5034387895460798, \"f0_5\": 0.8021917808219178, \"p4\": 0.7643488574629762, \"phi\": 0.6691143279174835}, {\"truth_threshold\": 31.900000475347042, \"match_probability\": 0.9999999997504584, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2890.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3648.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4420312022025084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5579687977974915, \"precision\": 1.0, \"recall\": 0.4420312022025084, \"specificity\": 1.0, \"npv\": 0.9997080341043058, \"accuracy\": 0.9997081016203241, \"f1\": 0.6130674586338566, \"f2\": 0.49755526478892637, \"f0_5\": 0.7984307658304785, \"p4\": 0.7600840654831864, \"phi\": 0.664757206930946}, {\"truth_threshold\": 32.00000047683716, \"match_probability\": 0.9999999997671695, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2866.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3672.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.43836035484857755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5616396451514225, \"precision\": 1.0, \"recall\": 0.43836035484857755, \"specificity\": 1.0, \"npv\": 0.9997061138405495, \"accuracy\": 0.9997061812362472, \"f1\": 0.6095278604849, \"f2\": 0.4938314149838032, \"f0_5\": 0.7960226641484279, \"p4\": 0.757357419872006, \"phi\": 0.6619905790926603}, {\"truth_threshold\": 32.100000478327274, \"match_probability\": 0.9999999997827614, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2829.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3709.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4327011318446008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5672988681553992, \"precision\": 1.0, \"recall\": 0.4327011318446008, \"specificity\": 1.0, \"npv\": 0.9997031534483781, \"accuracy\": 0.9997032206441289, \"f1\": 0.6040354435785203, \"f2\": 0.48807839619060767, \"f0_5\": 0.7922594376610284, \"p4\": 0.7531026537432727, \"phi\": 0.6577025817234793}, {\"truth_threshold\": 32.20000047981739, \"match_probability\": 0.9999999997973092, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2793.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3745.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4271948608137045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5728051391862955, \"precision\": 1.0, \"recall\": 0.4271948608137045, \"specificity\": 1.0, \"npv\": 0.9997002730836345, \"accuracy\": 0.9997003400680136, \"f1\": 0.5986496624156039, \"f2\": 0.48246674727932287, \"f0_5\": 0.7885375494071146, \"p4\": 0.7489021169240127, \"phi\": 0.6535034957943114}, {\"truth_threshold\": 32.30000048130751, \"match_probability\": 0.9999999998108828, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2769.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3769.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.42352401345977364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5764759865402264, \"precision\": 1.0, \"recall\": 0.42352401345977364, \"specificity\": 1.0, \"npv\": 0.9996983528496932, \"accuracy\": 0.9996984196839368, \"f1\": 0.5950359944128075, \"f2\": 0.47871788665675463, \"f0_5\": 0.7860224821164983, \"p4\": 0.7460678107546789, \"phi\": 0.6506890644908879}, {\"truth_threshold\": 32.40000048279762, \"match_probability\": 0.9999999998235475, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2721.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3817.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4161823187519119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5838176812480881, \"precision\": 1.0, \"recall\": 0.4161823187519119, \"specificity\": 1.0, \"npv\": 0.9996945124039409, \"accuracy\": 0.9996945789157832, \"f1\": 0.587752457068798, \"f2\": 0.4712014684999827, \"f0_5\": 0.7809091952703479, \"p4\": 0.7403159266615168, \"phi\": 0.6450233950918633}, {\"truth_threshold\": 32.50000048428774, \"match_probability\": 0.9999999998353639, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2691.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3847.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.41159375955949834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5884062404405017, \"precision\": 1.0, \"recall\": 0.41159375955949834, \"specificity\": 1.0, \"npv\": 0.9996921121403296, \"accuracy\": 0.9996921784356871, \"f1\": 0.5831617726730957, \"f2\": 0.4664910030163298, \"f0_5\": 0.7776557623396139, \"p4\": 0.736663436249704, \"phi\": 0.6414569625764567}, {\"truth_threshold\": 32.600000485777855, \"match_probability\": 0.9999999998463891, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2670.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3868.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4083817681248088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5916182318751911, \"precision\": 1.0, \"recall\": 0.4083817681248088, \"specificity\": 1.0, \"npv\": 0.9996904319626597, \"accuracy\": 0.99969049809962, \"f1\": 0.5799304952215465, \"f2\": 0.46318784262022067, \"f0_5\": 0.7753513764664886, \"p4\": 0.7340798089700987, \"phi\": 0.6389486256205306}, {\"truth_threshold\": 32.70000048726797, \"match_probability\": 0.999999999856676, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2650.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3888.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.40532272866319974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5946772713368003, \"precision\": 1.0, \"recall\": 0.40532272866319974, \"specificity\": 1.0, \"npv\": 0.999688831798701, \"accuracy\": 0.9996888977795559, \"f1\": 0.5768393556813235, \"f2\": 0.4600374973960142, \"f0_5\": 0.7731357217878398, \"p4\": 0.7315983254669013, \"phi\": 0.6365505518957438}, {\"truth_threshold\": 32.80000048875809, \"match_probability\": 0.999999999866274, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2625.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3913.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4014989293361884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5985010706638115, \"precision\": 1.0, \"recall\": 0.4014989293361884, \"specificity\": 1.0, \"npv\": 0.9996868316009564, \"accuracy\": 0.9996868973794759, \"f1\": 0.5729564553093965, \"f2\": 0.4560934079299441, \"f0_5\": 0.7703368940016434, \"p4\": 0.7284674226973759, \"phi\": 0.6335402059532375}, {\"truth_threshold\": 32.9000004902482, \"match_probability\": 0.9999999998752291, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2599.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3939.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3975221780360967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6024778219639033, \"precision\": 1.0, \"recall\": 0.3975221780360967, \"specificity\": 1.0, \"npv\": 0.9996847514037926, \"accuracy\": 0.9996848169633927, \"f1\": 0.5688956988070483, \"f2\": 0.45198427880769365, \"f0_5\": 0.7673910475965513, \"p4\": 0.7251765366545053, \"phi\": 0.6303942097826641}, {\"truth_threshold\": 33.00000049173832, \"match_probability\": 0.9999999998835847, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2566.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3972.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3924747629244417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6075252370755583, \"precision\": 1.0, \"recall\": 0.3924747629244417, \"specificity\": 1.0, \"npv\": 0.9996821111660134, \"accuracy\": 0.999682176435287, \"f1\": 0.5637082601054482, \"f2\": 0.4467581307890522, \"f0_5\": 0.7635995714795858, \"p4\": 0.7209477194409156, \"phi\": 0.6263784794991655}, {\"truth_threshold\": 33.100000493228436, \"match_probability\": 0.9999999998913807, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2543.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3995.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3889568675435913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6110431324564087, \"precision\": 1.0, \"recall\": 0.3889568675435913, \"specificity\": 1.0, \"npv\": 0.9996802710085357, \"accuracy\": 0.9996803360672134, \"f1\": 0.5600704768197335, \"f2\": 0.4431085554974734, \"f0_5\": 0.7609216038300419, \"p4\": 0.7179654165710856, \"phi\": 0.6235643565475888}, {\"truth_threshold\": 33.20000049471855, \"match_probability\": 0.9999999998986546, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2518.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4020.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.38513306821658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.61486693178342, \"precision\": 1.0, \"recall\": 0.38513306821658, \"specificity\": 1.0, \"npv\": 0.999678270845048, \"accuracy\": 0.9996783356671334, \"f1\": 0.556095406360424, \"f2\": 0.43913498430415066, \"f0_5\": 0.7579771222155328, \"p4\": 0.714690663691739, \"phi\": 0.6204910633361279}, {\"truth_threshold\": 33.30000049620867, \"match_probability\": 0.9999999999054414, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2491.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4047.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.38100336494340775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6189966350565922, \"precision\": 1.0, \"recall\": 0.38100336494340775, \"specificity\": 1.0, \"npv\": 0.9996761106774713, \"accuracy\": 0.999676175235047, \"f1\": 0.5517776054934102, \"f2\": 0.4348357364801173, \"f0_5\": 0.754756999151618, \"p4\": 0.7111145586313528, \"phi\": 0.6171547310210423}, {\"truth_threshold\": 33.400000497698784, \"match_probability\": 0.9999999999117737, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2469.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4069.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3776384215356378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6223615784643622, \"precision\": 1.0, \"recall\": 0.3776384215356378, \"specificity\": 1.0, \"npv\": 0.9996743505478298, \"accuracy\": 0.9996744148829766, \"f1\": 0.5482402575774398, \"f2\": 0.4313266482652598, \"f0_5\": 0.7521018642622151, \"p4\": 0.7081699839132561, \"phi\": 0.614422854222193}, {\"truth_threshold\": 33.5000004991889, \"match_probability\": 0.999999999917682, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2456.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4082.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3756500458855919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6243499541144081, \"precision\": 1.0, \"recall\": 0.3756500458855919, \"specificity\": 1.0, \"npv\": 0.9996733104741368, \"accuracy\": 0.999673374674935, \"f1\": 0.5461418723593506, \"f2\": 0.4292505592841163, \"f0_5\": 0.7505194963940839, \"p4\": 0.7064168719665873, \"phi\": 0.6128028434580007}, {\"truth_threshold\": 33.600000500679016, \"match_probability\": 0.9999999999231945, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2437.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4101.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3727439583970633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6272560416029367, \"precision\": 1.0, \"recall\": 0.3727439583970633, \"specificity\": 1.0, \"npv\": 0.9996717903703246, \"accuracy\": 0.9996718543708741, \"f1\": 0.5430640668523676, \"f2\": 0.42621287907936617, \"f0_5\": 0.7481886282696795, \"p4\": 0.7038368729476359, \"phi\": 0.6104274078385685}, {\"truth_threshold\": 33.70000050216913, \"match_probability\": 0.999999999928338, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2406.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4132.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3680024472315693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6319975527684307, \"precision\": 1.0, \"recall\": 0.3680024472315693, \"specificity\": 1.0, \"npv\": 0.9996693102108716, \"accuracy\": 0.999669373874775, \"f1\": 0.5380143112701252, \"f2\": 0.42124798655368023, \"f0_5\": 0.744338571958916, \"p4\": 0.6995815063317525, \"phi\": 0.6065317407851757}, {\"truth_threshold\": 33.80000050365925, \"match_probability\": 0.9999999999331369, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2386.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4152.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.36494340776996026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6350565922300397, \"precision\": 1.0, \"recall\": 0.36494340776996026, \"specificity\": 1.0, \"npv\": 0.9996677101145296, \"accuracy\": 0.9996677735547109, \"f1\": 0.5347377857463022, \"f2\": 0.4180391057537319, \"f0_5\": 0.7418231563238403, \"p4\": 0.6968054438215368, \"phi\": 0.6040050833948247}, {\"truth_threshold\": 33.900000505149364, \"match_probability\": 0.9999999999376146, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2367.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4171.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.36203732028143165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6379626797185683, \"precision\": 1.0, \"recall\": 0.36203732028143165, \"specificity\": 1.0, \"npv\": 0.9996661900277493, \"accuracy\": 0.9996662532506502, \"f1\": 0.5316114542391914, \"f2\": 0.4149865002279182, \"f0_5\": 0.7394102211670623, \"p4\": 0.6941455644011864, \"phi\": 0.6015949373237733}, {\"truth_threshold\": 34.00000050663948, \"match_probability\": 0.9999999999417923, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2352.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4186.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.35974304068522484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6402569593147751, \"precision\": 1.0, \"recall\": 0.35974304068522484, \"specificity\": 1.0, \"npv\": 0.9996649899625039, \"accuracy\": 0.9996650530106022, \"f1\": 0.5291338582677165, \"f2\": 0.412573673870334, \"f0_5\": 0.7374890254609306, \"p4\": 0.692029905599789, \"phi\": 0.5996853534610261}, {\"truth_threshold\": 34.1000005081296, \"match_probability\": 0.9999999999456903, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2319.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4219.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3546956255735699, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6453043744264301, \"precision\": 1.0, \"recall\": 0.3546956255735699, \"specificity\": 1.0, \"npv\": 0.9996623498291061, \"accuracy\": 0.9996624124824965, \"f1\": 0.523653607316247, \"f2\": 0.407256506620772, \"f0_5\": 0.7332110787909447, \"p4\": 0.6873257973127358, \"phi\": 0.5954627297614684}, {\"truth_threshold\": 34.20000050961971, \"match_probability\": 0.9999999999493273, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2306.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4232.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.35270724992352404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.647292750076476, \"precision\": 1.0, \"recall\": 0.35270724992352404, \"specificity\": 1.0, \"npv\": 0.9996613097803844, \"accuracy\": 0.9996613722744548, \"f1\": 0.5214834916327453, \"f2\": 0.4051584791622742, \"f0_5\": 0.7315061540413653, \"p4\": 0.685453661254731, \"phi\": 0.5937910334684984}, {\"truth_threshold\": 34.30000051110983, \"match_probability\": 0.9999999999527207, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2281.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4257.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3488834505965127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6511165494034873, \"precision\": 1.0, \"recall\": 0.3488834505965127, \"specificity\": 1.0, \"npv\": 0.9996593096927713, \"accuracy\": 0.9996593718743749, \"f1\": 0.5172922100011339, \"f2\": 0.40111841873878945, \"f0_5\": 0.7281956327416678, \"p4\": 0.681822731113485, \"phi\": 0.5905629427813278}, {\"truth_threshold\": 34.400000512599945, \"match_probability\": 0.9999999999558868, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2266.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4272.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3465891710003059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.653410828999694, \"precision\": 1.0, \"recall\": 0.3465891710003059, \"specificity\": 1.0, \"npv\": 0.9996581096440451, \"accuracy\": 0.9996581716343269, \"f1\": 0.5147660154475239, \"f2\": 0.39869097051164754, \"f0_5\": 0.7261889501345982, \"p4\": 0.6796245724930094, \"phi\": 0.5886175970061228}, {\"truth_threshold\": 34.50000051409006, \"match_probability\": 0.999999999958841, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2254.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4284.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.34475374732334046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6552462526766595, \"precision\": 1.0, \"recall\": 0.34475374732334046, \"specificity\": 1.0, \"npv\": 0.9996571496071386, \"accuracy\": 0.9996572114422885, \"f1\": 0.5127388535031847, \"f2\": 0.39674716609167077, \"f0_5\": 0.7245724572457246, \"p4\": 0.6778553371465866, \"phi\": 0.5870566824128912}, {\"truth_threshold\": 34.60000051558018, \"match_probability\": 0.9999999999615973, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2237.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4301.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3421535637809728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6578464362190273, \"precision\": 1.0, \"recall\": 0.3421535637809728, \"specificity\": 1.0, \"npv\": 0.9996557895580109, \"accuracy\": 0.999655851170234, \"f1\": 0.5098575498575498, \"f2\": 0.3939906301736588, \"f0_5\": 0.7222652718584528, \"p4\": 0.6753324640190307, \"phi\": 0.5848382605058903}, {\"truth_threshold\": 34.70000051707029, \"match_probability\": 0.999999999964169, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2217.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4321.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3390945243193637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6609054756806363, \"precision\": 1.0, \"recall\": 0.3390945243193637, \"specificity\": 1.0, \"npv\": 0.9996541895049516, \"accuracy\": 0.99965425085017, \"f1\": 0.5064534551684752, \"f2\": 0.390743417110226, \"f0_5\": 0.7195248604439829, \"p4\": 0.6723394013728743, \"phi\": 0.5822175382741751}, {\"truth_threshold\": 34.80000051856041, \"match_probability\": 0.9999999999665685, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2200.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4338.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.336494340776996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.663505659223004, \"precision\": 1.0, \"recall\": 0.336494340776996, \"specificity\": 1.0, \"npv\": 0.9996528294638785, \"accuracy\": 0.9996528905781156, \"f1\": 0.5035477225909819, \"f2\": 0.38797968397291194, \"f0_5\": 0.7171730342939105, \"p4\": 0.6697738061905856, \"phi\": 0.5799806202420099}, {\"truth_threshold\": 34.900000520050526, \"match_probability\": 0.9999999999688073, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2183.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4355.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.33389415723462834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6661058427653717, \"precision\": 1.0, \"recall\": 0.33389415723462834, \"specificity\": 1.0, \"npv\": 0.999651469426506, \"accuracy\": 0.9996515303060612, \"f1\": 0.5006306616213737, \"f2\": 0.38521263455090876, \"f0_5\": 0.714800261951539, \"p4\": 0.667188217164862, \"phi\": 0.5777350473292416}, {\"truth_threshold\": 35.00000052154064, \"match_probability\": 0.9999999999708962, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2166.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4372.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.33129397369226066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6687060263077393, \"precision\": 1.0, \"recall\": 0.33129397369226066, \"specificity\": 1.0, \"npv\": 0.9996501093928342, \"accuracy\": 0.9996501700340068, \"f1\": 0.4977022058823529, \"f2\": 0.3824422628716717, \"f0_5\": 0.7124062623339035, \"p4\": 0.6645823996059999, \"phi\": 0.5754807182196942}, {\"truth_threshold\": 35.10000052303076, \"match_probability\": 0.9999999999728452, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2158.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4380.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.330070357907617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.669929642092383, \"precision\": 1.0, \"recall\": 0.330070357907617, \"specificity\": 1.0, \"npv\": 0.9996494693782692, \"accuracy\": 0.9996495299059812, \"f1\": 0.4963201471941122, \"f2\": 0.3811374072765807, \"f0_5\": 0.7112722478576137, \"p4\": 0.6633490652404486, \"phi\": 0.5744167982744278}, {\"truth_threshold\": 35.200000524520874, \"match_probability\": 0.9999999999746636, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2141.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4397.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32747017436524933, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6725298256347507, \"precision\": 1.0, \"recall\": 0.32747017436524933, \"specificity\": 1.0, \"npv\": 0.9996481093500394, \"accuracy\": 0.9996481696339268, \"f1\": 0.49337481276644773, \"f2\": 0.37836213904499344, \"f0_5\": 0.708846510395974, \"p4\": 0.6607130657318285, \"phi\": 0.5721494041531016}, {\"truth_threshold\": 35.30000052601099, \"match_probability\": 0.9999999999763604, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2123.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4415.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3247170388498012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6752829611501988, \"precision\": 1.0, \"recall\": 0.3247170388498012, \"specificity\": 1.0, \"npv\": 0.9996466693241829, \"accuracy\": 0.9996467293458692, \"f1\": 0.4902436208290036, \"f2\": 0.37541998231653406, \"f0_5\": 0.7062541583499667, \"p4\": 0.657899304367231, \"phi\": 0.5697388053827955}, {\"truth_threshold\": 35.400000527501106, \"match_probability\": 0.9999999999779434, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2115.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4423.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32349342306515755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6765065769348425, \"precision\": 1.0, \"recall\": 0.32349342306515755, \"specificity\": 1.0, \"npv\": 0.9996460293140227, \"accuracy\": 0.9996460892178436, \"f1\": 0.48884779845140414, \"f2\": 0.3741111543495949, \"f0_5\": 0.7050940125350047, \"p4\": 0.6566411730829261, \"phi\": 0.5686641503350515}, {\"truth_threshold\": 35.50000052899122, \"match_probability\": 0.9999999999794205, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2106.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4432.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32211685530743345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6778831446925665, \"precision\": 1.0, \"recall\": 0.32211685530743345, \"specificity\": 1.0, \"npv\": 0.9996453093035722, \"accuracy\": 0.9996453690738147, \"f1\": 0.4872744099953725, \"f2\": 0.3726378370726874, \"f0_5\": 0.7037829167223634, \"p4\": 0.6552201610841019, \"phi\": 0.5674527323537119}, {\"truth_threshold\": 35.60000053048134, \"match_probability\": 0.9999999999807987, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2096.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4442.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32058733557662894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6794126644233711, \"precision\": 1.0, \"recall\": 0.32058733557662894, \"specificity\": 1.0, \"npv\": 0.9996445092931769, \"accuracy\": 0.9996445689137827, \"f1\": 0.4855223534862173, \"f2\": 0.3709997167941093, \"f0_5\": 0.7023187240316312, \"p4\": 0.6536342428161607, \"phi\": 0.5661036740369262}, {\"truth_threshold\": 35.700000531971455, \"match_probability\": 0.9999999999820844, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2092.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4446.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31997552768430715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6800244723156929, \"precision\": 1.0, \"recall\": 0.31997552768430715, \"specificity\": 1.0, \"npv\": 0.9996441892893774, \"accuracy\": 0.99964424884977, \"f1\": 0.48482039397450755, \"f2\": 0.3703441438889676, \"f0_5\": 0.7017308466389374, \"p4\": 0.6529977964850909, \"phi\": 0.565563150288648}, {\"truth_threshold\": 35.80000053346157, \"match_probability\": 0.9999999999832843, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2067.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4471.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3161517283572958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6838482716427042, \"precision\": 1.0, \"recall\": 0.3161517283572958, \"specificity\": 1.0, \"npv\": 0.9996421892702718, \"accuracy\": 0.99964224844969, \"f1\": 0.4804183614177804, \"f2\": 0.36624260250186047, \"f0_5\": 0.6980278265568013, \"p4\": 0.6489928437454996, \"phi\": 0.5621731102397797}, {\"truth_threshold\": 35.90000053495169, \"match_probability\": 0.9999999999844037, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2057.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4481.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31462220862649126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6853777913735087, \"precision\": 1.0, \"recall\": 0.31462220862649126, \"specificity\": 1.0, \"npv\": 0.9996413892648705, \"accuracy\": 0.999641448289658, \"f1\": 0.47865037812681793, \"f2\": 0.3645999503704491, \"f0_5\": 0.6965325748340783, \"p4\": 0.6473776286589381, \"phi\": 0.5608113601960713}, {\"truth_threshold\": 36.0000005364418, \"match_probability\": 0.9999999999854481, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2047.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4491.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31309268889568675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6869073111043132, \"precision\": 1.0, \"recall\": 0.31309268889568675, \"specificity\": 1.0, \"npv\": 0.9996405892607495, \"accuracy\": 0.9996406481296259, \"f1\": 0.4768782760629004, \"f2\": 0.3629561331962126, \"f0_5\": 0.6950292000543257, \"p4\": 0.6457547707627153, \"phi\": 0.559446297709545}, {\"truth_threshold\": 36.10000053793192, \"match_probability\": 0.9999999999864226, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2037.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4501.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31156316916488225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6884368308351178, \"precision\": 1.0, \"recall\": 0.31156316916488225, \"specificity\": 1.0, \"npv\": 0.9996397892579091, \"accuracy\": 0.9996398479695939, \"f1\": 0.4751020408163265, \"f2\": 0.36131114973926, \"f0_5\": 0.6935176358436607, \"p4\": 0.6441242156702721, \"phi\": 0.5580778984734203}, {\"truth_threshold\": 36.200000539422035, \"match_probability\": 0.9999999999873318, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2030.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4508.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31049250535331907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6895074946466809, \"precision\": 1.0, \"recall\": 0.31049250535331907, \"specificity\": 1.0, \"npv\": 0.9996392292566826, \"accuracy\": 0.9996392878575715, \"f1\": 0.4738562091503268, \"f2\": 0.3601589667163438, \"f0_5\": 0.6924546322827125, \"p4\": 0.6429782178937783, \"phi\": 0.5571180204780386}, {\"truth_threshold\": 36.30000054091215, \"match_probability\": 0.9999999999881801, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2016.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4522.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3083511777301927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6916488222698073, \"precision\": 1.0, \"recall\": 0.3083511777301927, \"specificity\": 1.0, \"npv\": 0.9996381092561121, \"accuracy\": 0.9996381676335268, \"f1\": 0.4713584288052373, \"f2\": 0.35785288270377735, \"f0_5\": 0.6903163950143816, \"p4\": 0.6406747507223893, \"phi\": 0.5551932891283046}, {\"truth_threshold\": 36.40000054240227, \"match_probability\": 0.9999999999889717, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2008.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4530.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3071275619455491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6928724380544509, \"precision\": 1.0, \"recall\": 0.3071275619455491, \"specificity\": 1.0, \"npv\": 0.9996374692569128, \"accuracy\": 0.9996375275055011, \"f1\": 0.46992745143926984, \"f2\": 0.3565340909090909, \"f0_5\": 0.6890871654083733, \"p4\": 0.6393515688372079, \"phi\": 0.5540904427638997}, {\"truth_threshold\": 36.500000543892384, \"match_probability\": 0.9999999999897102, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1990.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4548.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.30437442643010093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6956255735698991, \"precision\": 1.0, \"recall\": 0.30437442643010093, \"specificity\": 1.0, \"npv\": 0.9996360292617108, \"accuracy\": 0.9996360872174435, \"f1\": 0.46669793621013134, \"f2\": 0.3535640679411556, \"f0_5\": 0.6863015588357014, \"p4\": 0.6363558457399204, \"phi\": 0.5516009817299067}, {\"truth_threshold\": 36.6000005453825, \"match_probability\": 0.9999999999903993, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1979.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4559.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.30269195472621596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.697308045273784, \"precision\": 1.0, \"recall\": 0.30269195472621596, \"specificity\": 1.0, \"npv\": 0.9996351492666853, \"accuracy\": 0.9996352070414083, \"f1\": 0.46471762357637664, \"f2\": 0.35174718282321993, \"f0_5\": 0.6845855818458558, \"p4\": 0.6345123598985047, \"phi\": 0.5500741016850054}, {\"truth_threshold\": 36.700000546872616, \"match_probability\": 0.9999999999910423, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1975.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4563.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.30208014683389417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6979198531661058, \"precision\": 1.0, \"recall\": 0.30208014683389417, \"specificity\": 1.0, \"npv\": 0.9996348292688783, \"accuracy\": 0.9996348869773954, \"f1\": 0.46399624104311055, \"f2\": 0.3510861449852455, \"f0_5\": 0.6839589970910098, \"p4\": 0.6338395811740775, \"phi\": 0.5495178213723532}, {\"truth_threshold\": 36.80000054836273, \"match_probability\": 0.9999999999916421, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1961.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4577.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2999388192107678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7000611807892322, \"precision\": 1.0, \"recall\": 0.2999388192107678, \"specificity\": 1.0, \"npv\": 0.9996337092781672, \"accuracy\": 0.9996337667533507, \"f1\": 0.46146605482998, \"f2\": 0.3487710311955323, \"f0_5\": 0.6817549714921429, \"p4\": 0.6314746194376453, \"phi\": 0.547566392690579}, {\"truth_threshold\": 36.90000054985285, \"match_probability\": 0.9999999999922018, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1945.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4593.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2974915876414806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7025084123585195, \"precision\": 1.0, \"recall\": 0.2974915876414806, \"specificity\": 1.0, \"npv\": 0.9996324292918561, \"accuracy\": 0.9996324864972994, \"f1\": 0.45856418719792524, \"f2\": 0.34612236181798767, \"f0_5\": 0.679214974158402, \"p4\": 0.6287521477463737, \"phi\": 0.5453276432090568}, {\"truth_threshold\": 37.000000551342964, \"match_probability\": 0.999999999992724, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1923.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4615.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2941266442337106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7058733557662894, \"precision\": 1.0, \"recall\": 0.2941266442337106, \"specificity\": 1.0, \"npv\": 0.9996306693160307, \"accuracy\": 0.9996307261452291, \"f1\": 0.45455619903084743, \"f2\": 0.34247551202137133, \"f0_5\": 0.6756851721714687, \"p4\": 0.6249740769561738, \"phi\": 0.5422342798449967}, {\"truth_threshold\": 37.10000055283308, \"match_probability\": 0.9999999999932113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1909.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4629.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2919853166105843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7080146833894158, \"precision\": 1.0, \"recall\": 0.2919853166105843, \"specificity\": 1.0, \"npv\": 0.9996295493346413, \"accuracy\": 0.9996296059211842, \"f1\": 0.45199479105007695, \"f2\": 0.3401518121235879, \"f0_5\": 0.6734161140115705, \"p4\": 0.622548681324381, \"phi\": 0.5402565598452007}, {\"truth_threshold\": 37.200000554323196, \"match_probability\": 0.999999999993666, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1897.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4641.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.29014989293361887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7098501070663812, \"precision\": 1.0, \"recall\": 0.29014989293361887, \"specificity\": 1.0, \"npv\": 0.9996285893525907, \"accuracy\": 0.9996286457291458, \"f1\": 0.44979253112033196, \"f2\": 0.3381582231095583, \"f0_5\": 0.6714568880079287, \"p4\": 0.6204565119809383, \"phi\": 0.5385555943206222}, {\"truth_threshold\": 37.30000055581331, \"match_probability\": 0.9999999999940901, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1885.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4653.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.28831446925665344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7116855307433466, \"precision\": 1.0, \"recall\": 0.28831446925665344, \"specificity\": 1.0, \"npv\": 0.9996276293723838, \"accuracy\": 0.9996276855371075, \"f1\": 0.4475839962008785, \"f2\": 0.33616292756001, \"f0_5\": 0.6694843017474073, \"p4\": 0.6183519893000621, \"phi\": 0.5368492427272162}, {\"truth_threshold\": 37.40000055730343, \"match_probability\": 0.9999999999944859, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1865.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4673.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.28525542979504437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7147445702049556, \"precision\": 1.0, \"recall\": 0.28525542979504437, \"specificity\": 1.0, \"npv\": 0.9996260294094698, \"accuracy\": 0.9996260852170434, \"f1\": 0.44388908723075093, \"f2\": 0.33283363672056254, \"f0_5\": 0.6661665952278897, \"p4\": 0.6148167009398807, \"phi\": 0.5339932140519316}, {\"truth_threshold\": 37.500000558793545, \"match_probability\": 0.9999999999948551, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1848.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4690.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2826552462526767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7173447537473233, \"precision\": 1.0, \"recall\": 0.2826552462526767, \"specificity\": 1.0, \"npv\": 0.9996246694450197, \"accuracy\": 0.999624724944989, \"f1\": 0.44073455759599334, \"f2\": 0.33, \"f0_5\": 0.6633165829145728, \"p4\": 0.6117841003619418, \"phi\": 0.5315535317371455}, {\"truth_threshold\": 37.60000056028366, \"match_probability\": 0.9999999999951996, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1841.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4697.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2815845824411135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7184154175588865, \"precision\": 1.0, \"recall\": 0.2815845824411135, \"specificity\": 1.0, \"npv\": 0.9996241094607335, \"accuracy\": 0.9996241648329666, \"f1\": 0.4394319131161236, \"f2\": 0.328832208052013, \"f0_5\": 0.662134944612286, \"p4\": 0.610527928609566, \"phi\": 0.5305456978061084}, {\"truth_threshold\": 37.70000056177378, \"match_probability\": 0.9999999999955211, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1827.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4711.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.27944325481798715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7205567451820128, \"precision\": 1.0, \"recall\": 0.27944325481798715, \"specificity\": 1.0, \"npv\": 0.9996229894940433, \"accuracy\": 0.9996230446089218, \"f1\": 0.43682008368200836, \"f2\": 0.326494871153365, \"f0_5\": 0.659757330637007, \"p4\": 0.608002417096662, \"phi\": 0.5285242679150145}, {\"truth_threshold\": 37.80000056326389, \"match_probability\": 0.999999999995821, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1813.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4725.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2773019271948608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7226980728051392, \"precision\": 1.0, \"recall\": 0.2773019271948608, \"specificity\": 1.0, \"npv\": 0.9996218695298625, \"accuracy\": 0.999621924384877, \"f1\": 0.43419949706621963, \"f2\": 0.3241551939924906, \"f0_5\": 0.6573604060913706, \"p4\": 0.6054591942982298, \"phi\": 0.5264950815409015}, {\"truth_threshold\": 37.90000056475401, \"match_probability\": 0.9999999999961009, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1795.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4743.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.27454879167941265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7254512083205873, \"precision\": 1.0, \"recall\": 0.27454879167941265, \"specificity\": 1.0, \"npv\": 0.9996204295796035, \"accuracy\": 0.9996204840968194, \"f1\": 0.43081723268930755, \"f2\": 0.3211435932300426, \"f0_5\": 0.6542498906546144, \"p4\": 0.6021630104126332, \"phi\": 0.5238745852578989}, {\"truth_threshold\": 38.000000566244125, \"match_probability\": 0.999999999996362, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1781.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4757.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.27240746405628635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7275925359437136, \"precision\": 1.0, \"recall\": 0.27240746405628635, \"specificity\": 1.0, \"npv\": 0.9996193096211591, \"accuracy\": 0.9996193638727745, \"f1\": 0.4281764635172497, \"f2\": 0.31879855368202487, \"f0_5\": 0.6518079344166301, \"p4\": 0.5995785981953056, \"phi\": 0.5218273288699966}, {\"truth_threshold\": 38.10000056773424, \"match_probability\": 0.9999999999966056, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1766.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4772.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.27011318446007954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7298868155399205, \"precision\": 1.0, \"recall\": 0.27011318446007954, \"specificity\": 1.0, \"npv\": 0.9996181096684676, \"accuracy\": 0.9996181636327266, \"f1\": 0.4253371868978805, \"f2\": 0.3162834013897844, \"f0_5\": 0.6491692398176738, \"p4\": 0.5967892329030753, \"phi\": 0.5196248943675763}, {\"truth_threshold\": 38.20000056922436, \"match_probability\": 0.999999999996833, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1742.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4796.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2664423371061487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7335576628938514, \"precision\": 1.0, \"recall\": 0.2664423371061487, \"specificity\": 1.0, \"npv\": 0.9996161897501536, \"accuracy\": 0.9996162432486497, \"f1\": 0.4207729468599034, \"f2\": 0.3122535312253531, \"f0_5\": 0.6448985636013623, \"p4\": 0.5922818641453882, \"phi\": 0.5160814604364066}, {\"truth_threshold\": 38.300000570714474, \"match_probability\": 0.999999999997045, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1729.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4809.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2644539614561028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7355460385438972, \"precision\": 1.0, \"recall\": 0.2644539614561028, \"specificity\": 1.0, \"npv\": 0.9996151497974795, \"accuracy\": 0.9996152030406081, \"f1\": 0.4182895850973751, \"f2\": 0.31006778809942254, \"f0_5\": 0.6425598335067638, \"p4\": 0.5898172606359282, \"phi\": 0.5141519097460197}, {\"truth_threshold\": 38.40000057220459, \"match_probability\": 0.999999999997243, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1698.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4840.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.25971245029060874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7402875497093913, \"precision\": 1.0, \"recall\": 0.25971245029060874, \"specificity\": 1.0, \"npv\": 0.9996126699190656, \"accuracy\": 0.999612722544509, \"f1\": 0.41233608547838757, \"f2\": 0.30484739676840217, \"f0_5\": 0.6369092273068268, \"p4\": 0.5838734392658088, \"phi\": 0.5095212025482531}, {\"truth_threshold\": 38.500000573694706, \"match_probability\": 0.9999999999974276, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1677.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4861.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.25650045885591927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7434995411440808, \"precision\": 1.0, \"recall\": 0.25650045885591927, \"specificity\": 1.0, \"npv\": 0.9996109900084212, \"accuracy\": 0.9996110422084417, \"f1\": 0.40827754108338404, \"f2\": 0.30130439469618026, \"f0_5\": 0.6330212894458704, \"p4\": 0.5797926885287605, \"phi\": 0.5063602251506133}, {\"truth_threshold\": 38.60000057518482, \"match_probability\": 0.9999999999975998, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1653.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4885.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.25282961150198835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7471703884980117, \"precision\": 1.0, \"recall\": 0.25282961150198835, \"specificity\": 1.0, \"npv\": 0.9996090701174558, \"accuracy\": 0.9996091218243649, \"f1\": 0.40361372237822, \"f2\": 0.2972486962776479, \"f0_5\": 0.6285171102661598, \"p4\": 0.575074213936618, \"phi\": 0.5027233561827621}, {\"truth_threshold\": 38.70000057667494, \"match_probability\": 0.9999999999977606, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1621.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4917.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.24793514836341388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7520648516365861, \"precision\": 1.0, \"recall\": 0.24793514836341388, \"specificity\": 1.0, \"npv\": 0.9996065102743072, \"accuracy\": 0.9996065613122624, \"f1\": 0.3973526167422478, \"f2\": 0.29183019479350447, \"f0_5\": 0.6224082322223928, \"p4\": 0.5686902131349882, \"phi\": 0.4978328920731281}, {\"truth_threshold\": 38.800000578165054, \"match_probability\": 0.9999999999979106, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1601.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4937.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.24487610890180483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7551238910981952, \"precision\": 1.0, \"recall\": 0.24487610890180483, \"specificity\": 1.0, \"npv\": 0.9996049103789971, \"accuracy\": 0.9996049609921984, \"f1\": 0.393414424376459, \"f2\": 0.2884372860591648, \"f0_5\": 0.6185288208932159, \"p4\": 0.5646453310054512, \"phi\": 0.4947518174729085}, {\"truth_threshold\": 38.90000057965517, \"match_probability\": 0.9999999999980504, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1586.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4952.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.24258182930559805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.757418170694402, \"precision\": 1.0, \"recall\": 0.24258182930559805, \"specificity\": 1.0, \"npv\": 0.9996037104608755, \"accuracy\": 0.9996037607521504, \"f1\": 0.39044805514524866, \"f2\": 0.2858893936116519, \"f0_5\": 0.615587641670548, \"p4\": 0.5615834716993262, \"phi\": 0.49242836703855986}, {\"truth_threshold\": 39.00000058114529, \"match_probability\": 0.999999999998181, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1567.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4971.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.23967574181706944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7603242581829306, \"precision\": 1.0, \"recall\": 0.23967574181706944, \"specificity\": 1.0, \"npv\": 0.9996021905687235, \"accuracy\": 0.9996022404480897, \"f1\": 0.38667489204194944, \"f2\": 0.2826581045492262, \"f0_5\": 0.6118225831641418, \"p4\": 0.5576699197808568, \"phi\": 0.48946950522634847}, {\"truth_threshold\": 39.1000005826354, \"match_probability\": 0.9999999999983028, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1534.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5004.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2346283267054145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7653716732945856, \"precision\": 1.0, \"recall\": 0.2346283267054145, \"specificity\": 1.0, \"npv\": 0.9995995507670236, \"accuracy\": 0.999599599919984, \"f1\": 0.3800792864222002, \"f2\": 0.27703532471285125, \"f0_5\": 0.6051759507653464, \"p4\": 0.550777515962443, \"phi\": 0.484287486904164}, {\"truth_threshold\": 39.20000058412552, \"match_probability\": 0.9999999999984165, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1521.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5017.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2326399510553686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7673600489446314, \"precision\": 1.0, \"recall\": 0.2326399510553686, \"specificity\": 1.0, \"npv\": 0.9995985108489699, \"accuracy\": 0.9995985597119423, \"f1\": 0.3774661868718203, \"f2\": 0.27481660824630505, \"f0_5\": 0.6025194105530027, \"p4\": 0.5480285743369318, \"phi\": 0.48223080432395}, {\"truth_threshold\": 39.300000585615635, \"match_probability\": 0.9999999999985225, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1498.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5040.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2291220556745182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7708779443254818, \"precision\": 1.0, \"recall\": 0.2291220556745182, \"specificity\": 1.0, \"npv\": 0.9995966709992524, \"accuracy\": 0.9995967193438687, \"f1\": 0.37282229965156793, \"f2\": 0.2708860759493671, \"f0_5\": 0.5977653631284916, \"p4\": 0.5431174513395639, \"phi\": 0.4785704170806568}, {\"truth_threshold\": 39.40000058710575, \"match_probability\": 0.9999999999986214, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1485.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5053.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.22713368002447232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7728663199755277, \"precision\": 1.0, \"recall\": 0.22713368002447232, \"specificity\": 1.0, \"npv\": 0.9995956310871906, \"accuracy\": 0.9995956791358271, \"f1\": 0.37018571606630934, \"f2\": 0.2686615768715852, \"f0_5\": 0.5950472832184645, \"p4\": 0.540314328806217, \"phi\": 0.47648907041528077}, {\"truth_threshold\": 39.50000058859587, \"match_probability\": 0.9999999999987138, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1462.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5076.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2236157846436219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7763842153563781, \"precision\": 1.0, \"recall\": 0.2236157846436219, \"specificity\": 1.0, \"npv\": 0.999593791248074, \"accuracy\": 0.9995938387677535, \"f1\": 0.3655, \"f2\": 0.26472079380024627, \"f0_5\": 0.5901824640723398, \"p4\": 0.5353059286733589, \"phi\": 0.47278425307409605}, {\"truth_threshold\": 39.60000059008598, \"match_probability\": 0.9999999999988, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1428.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5110.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.21841541755888652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7815845824411135, \"precision\": 1.0, \"recall\": 0.21841541755888652, \"specificity\": 1.0, \"npv\": 0.9995910714983076, \"accuracy\": 0.9995911182236448, \"f1\": 0.3585237258347979, \"f2\": 0.25888324873096447, \"f0_5\": 0.5828571428571429, \"p4\": 0.5277852221205623, \"phi\": 0.46725378678983187}, {\"truth_threshold\": 39.7000005915761, \"match_probability\": 0.9999999999988802, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1396.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5142.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.21352095442031202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.786479045579688, \"precision\": 1.0, \"recall\": 0.21352095442031202, \"specificity\": 1.0, \"npv\": 0.9995885117473414, \"accuracy\": 0.9995885577115423, \"f1\": 0.3519032014116461, \"f2\": 0.253375925657035, \"f0_5\": 0.5758125721828081, \"p4\": 0.5205762482125187, \"phi\": 0.46198819579711303}, {\"truth_threshold\": 39.800000593066216, \"match_probability\": 0.9999999999989553, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1363.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5175.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.20847353930865709, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7915264606913429, \"precision\": 1.0, \"recall\": 0.20847353930865709, \"specificity\": 1.0, \"npv\": 0.9995858720178884, \"accuracy\": 0.9995859171834367, \"f1\": 0.34501961776990253, \"f2\": 0.24768308195529712, \"f0_5\": 0.5683903252710593, \"p4\": 0.513005581135573, \"phi\": 0.45649447376994556}, {\"truth_threshold\": 39.90000059455633, \"match_probability\": 0.9999999999990252, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1342.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5196.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.20526154787396758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7947384521260324, \"precision\": 1.0, \"recall\": 0.20526154787396758, \"specificity\": 1.0, \"npv\": 0.9995841921973138, \"accuracy\": 0.9995842368473695, \"f1\": 0.34060913705583756, \"f2\": 0.24405324798137776, \"f0_5\": 0.5635813875356963, \"p4\": 0.5081140048552163, \"phi\": 0.4529637938298934}, {\"truth_threshold\": 40.00000059604645, \"match_probability\": 0.9999999999990905, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1312.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5226.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.200672988681554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.799327011318446, \"precision\": 1.0, \"recall\": 0.200672988681554, \"specificity\": 1.0, \"npv\": 0.9995817924634296, \"accuracy\": 0.9995818363672735, \"f1\": 0.3342675159235669, \"f2\": 0.23885814156714244, \"f0_5\": 0.5565925674529102, \"p4\": 0.501023962097016, \"phi\": 0.44787170677025495}, {\"truth_threshold\": 40.100000597536564, \"match_probability\": 0.9999999999991515, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1291.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5247.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.19746099724686447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8025390027531355, \"precision\": 1.0, \"recall\": 0.19746099724686447, \"specificity\": 1.0, \"npv\": 0.9995801126565664, \"accuracy\": 0.9995801560312062, \"f1\": 0.32979946353301826, \"f2\": 0.23521480887658056, \"f0_5\": 0.5516151085284566, \"p4\": 0.495987995829972, \"phi\": 0.44427253558294455}, {\"truth_threshold\": 40.20000059902668, \"match_probability\": 0.9999999999992082, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1253.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5285.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.19164882226980728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8083511777301927, \"precision\": 1.0, \"recall\": 0.19164882226980728, \"specificity\": 1.0, \"npv\": 0.9995770730204037, \"accuracy\": 0.9995771154230846, \"f1\": 0.3216531895777179, \"f2\": 0.22860791826309068, \"f0_5\": 0.5424242424242425, \"p4\": 0.48671865254625213, \"phi\": 0.4376845540023791}, {\"truth_threshold\": 40.300000600516796, \"match_probability\": 0.9999999999992613, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1219.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5319.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1864484551850719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8135515448149281, \"precision\": 1.0, \"recall\": 0.1864484551850719, \"specificity\": 1.0, \"npv\": 0.9995743533616122, \"accuracy\": 0.9995743948789758, \"f1\": 0.3142967642129689, \"f2\": 0.22268093968068395, \"f0_5\": 0.5339933415104258, \"p4\": 0.47824931322594355, \"phi\": 0.4317048691257602}, {\"truth_threshold\": 40.40000060200691, \"match_probability\": 0.9999999999993108, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1194.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5344.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.18262465585806056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8173753441419395, \"precision\": 1.0, \"recall\": 0.18262465585806056, \"specificity\": 1.0, \"npv\": 0.9995723536219424, \"accuracy\": 0.9995723944788958, \"f1\": 0.3088463528194516, \"f2\": 0.21831346449206465, \"f0_5\": 0.5276648400212126, \"p4\": 0.4719129380977742, \"phi\": 0.42725467473795864}, {\"truth_threshold\": 40.50000060349703, \"match_probability\": 0.9999999999993568, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1162.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5376.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1777301927194861, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8222698072805139, \"precision\": 1.0, \"recall\": 0.1777301927194861, \"specificity\": 1.0, \"npv\": 0.9995697939668405, \"accuracy\": 0.9995698339667933, \"f1\": 0.3018181818181818, \"f2\": 0.21271143003587903, \"f0_5\": 0.5193992490613266, \"p4\": 0.4636640178444148, \"phi\": 0.42148989563013667}, {\"truth_threshold\": 40.600000604987144, \"match_probability\": 0.9999999999993999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1135.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5403.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.17360048944631384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8263995105536861, \"precision\": 1.0, \"recall\": 0.17360048944631384, \"specificity\": 1.0, \"npv\": 0.9995676342680452, \"accuracy\": 0.999567673534707, \"f1\": 0.29584256483774274, \"f2\": 0.20797449334848095, \"f0_5\": 0.5122765842209785, \"p4\": 0.4565800908380884, \"phi\": 0.4165638372970302}, {\"truth_threshold\": 40.70000060647726, \"match_probability\": 0.9999999999994401, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1121.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5417.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.17145916182318752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8285408381768125, \"precision\": 1.0, \"recall\": 0.17145916182318752, \"specificity\": 1.0, \"npv\": 0.9995665144278995, \"accuracy\": 0.9995665533106621, \"f1\": 0.2927275101188145, \"f2\": 0.20551461152055145, \"f0_5\": 0.5085283977499546, \"p4\": 0.45286131121604556, \"phi\": 0.41398651759487615}, {\"truth_threshold\": 40.80000060796738, \"match_probability\": 0.9999999999994776, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1092.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5446.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1670235546038544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8329764453961456, \"precision\": 1.0, \"recall\": 0.1670235546038544, \"specificity\": 1.0, \"npv\": 0.9995641947670082, \"accuracy\": 0.9995642328465694, \"f1\": 0.28623853211009176, \"f2\": 0.20041109969167523, \"f0_5\": 0.5006418485237484, \"p4\": 0.44505686828986374, \"phi\": 0.40859609012412873}, {\"truth_threshold\": 40.90000060945749, \"match_probability\": 0.9999999999995126, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1057.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5481.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.16167023554603854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8383297644539615, \"precision\": 1.0, \"recall\": 0.16167023554603854, \"specificity\": 1.0, \"npv\": 0.9995613951906155, \"accuracy\": 0.9995614322864573, \"f1\": 0.2783410138248848, \"f2\": 0.19423720092616414, \"f0_5\": 0.4908972691807542, \"p4\": 0.43545144029541955, \"phi\": 0.40199418677786086}, {\"truth_threshold\": 41.00000061094761, \"match_probability\": 0.9999999999995453, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1023.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5515.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.15646986846130315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8435301315386968, \"precision\": 1.0, \"recall\": 0.15646986846130315, \"specificity\": 1.0, \"npv\": 0.999558675617136, \"accuracy\": 0.9995587117423484, \"f1\": 0.27059912709959, \"f2\": 0.18822447102115916, \"f0_5\": 0.48118532455315144, \"p4\": 0.4259193945255929, \"phi\": 0.3954754284316127}, {\"truth_threshold\": 41.100000612437725, \"match_probability\": 0.9999999999995757, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 990.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5548.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1514224533496482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8485775466503518, \"precision\": 1.0, \"recall\": 0.1514224533496482, \"specificity\": 1.0, \"npv\": 0.9995560360452639, \"accuracy\": 0.9995560712142428, \"f1\": 0.2630180658873539, \"f2\": 0.18237418023727064, \"f0_5\": 0.47151838445418176, \"p4\": 0.41647211496375114, \"phi\": 0.38904399139226303}, {\"truth_threshold\": 41.20000061392784, \"match_probability\": 0.9999999999996041, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 961.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5577.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.14698684613031507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8530131538696849, \"precision\": 1.0, \"recall\": 0.14698684613031507, \"specificity\": 1.0, \"npv\": 0.999553716433006, \"accuracy\": 0.9995537507501501, \"f1\": 0.2563008401120149, \"f2\": 0.17722125917456572, \"f0_5\": 0.4628202658447313, \"p4\": 0.40800604360991427, \"phi\": 0.383303076319931}, {\"truth_threshold\": 41.30000061541796, \"match_probability\": 0.9999999999996306, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 933.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5605.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.14270419088406242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8572958091159376, \"precision\": 1.0, \"recall\": 0.14270419088406242, \"specificity\": 1.0, \"npv\": 0.9995514768175932, \"accuracy\": 0.9995515103020605, \"f1\": 0.24976576094231026, \"f2\": 0.17223555473509322, \"f0_5\": 0.4542356377799416, \"p4\": 0.3996821965394049, \"phi\": 0.3776773553527194}, {\"truth_threshold\": 41.40000061690807, \"match_probability\": 0.9999999999996554, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 904.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5634.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.13826858366472927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8617314163352707, \"precision\": 1.0, \"recall\": 0.13826858366472927, \"specificity\": 1.0, \"npv\": 0.999549157226496, \"accuracy\": 0.9995491898379676, \"f1\": 0.2429454447729105, \"f2\": 0.1670609107037256, \"f0_5\": 0.44514477053377977, \"p4\": 0.39090168773179385, \"phi\": 0.3717610069291579}, {\"truth_threshold\": 41.50000061839819, \"match_probability\": 0.9999999999996785, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 870.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5668.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.13306821657999388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8669317834200061, \"precision\": 1.0, \"recall\": 0.13306821657999388, \"specificity\": 1.0, \"npv\": 0.9995464377196092, \"accuracy\": 0.9995464692938588, \"f1\": 0.23488120950323974, \"f2\": 0.16097994226926207, \"f0_5\": 0.43421840686763824, \"p4\": 0.3803946030266656, \"phi\": 0.36470242918883106}, {\"truth_threshold\": 41.600000619888306, \"match_probability\": 0.9999999999997, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 840.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5698.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1284796573875803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8715203426124197, \"precision\": 1.0, \"recall\": 0.1284796573875803, \"specificity\": 1.0, \"npv\": 0.9995440381669982, \"accuracy\": 0.9995440688137628, \"f1\": 0.22770398481973433, \"f2\": 0.15560165975103735, \"f0_5\": 0.4243281471004243, \"p4\": 0.3709271215677005, \"phi\": 0.3583588642234128}, {\"truth_threshold\": 41.70000062137842, \"match_probability\": 0.9999999999997201, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 812.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5726.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.12419700214132762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8758029978586723, \"precision\": 1.0, \"recall\": 0.12419700214132762, \"specificity\": 1.0, \"npv\": 0.9995417985949557, \"accuracy\": 0.9995418283656732, \"f1\": 0.22095238095238096, \"f2\": 0.1505711318795431, \"f0_5\": 0.41487839771101576, \"p4\": 0.3619194654203466, \"phi\": 0.3523352024712322}, {\"truth_threshold\": 41.80000062286854, \"match_probability\": 0.9999999999997388, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 785.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5753.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1200672988681554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8799327011318446, \"precision\": 1.0, \"recall\": 0.1200672988681554, \"specificity\": 1.0, \"npv\": 0.9995396390171337, \"accuracy\": 0.9995396679335867, \"f1\": 0.21439300832991942, \"f2\": 0.14571036121320116, \"f0_5\": 0.40555899979334575, \"p4\": 0.3530723430518043, \"phi\": 0.34642751704857155}, {\"truth_threshold\": 41.900000624358654, \"match_probability\": 0.9999999999997563, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 762.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5776.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.11654940348730498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.883450596512695, \"precision\": 1.0, \"recall\": 0.11654940348730498, \"specificity\": 1.0, \"npv\": 0.9995377993841272, \"accuracy\": 0.9995378275655131, \"f1\": 0.20876712328767122, \"f2\": 0.14156201233558743, \"f0_5\": 0.3974546213227624, \"p4\": 0.3454077847015164, \"phi\": 0.34131442143752666}, {\"truth_threshold\": 42.00000062584877, \"match_probability\": 0.9999999999997726, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 741.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5797.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.11333741205261548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8866625879473845, \"precision\": 1.0, \"recall\": 0.11333741205261548, \"specificity\": 1.0, \"npv\": 0.9995361197251224, \"accuracy\": 0.9995361472294458, \"f1\": 0.20359939552136283, \"f2\": 0.1377681924664411, \"f0_5\": 0.38991791201852244, \"p4\": 0.3383042642300457, \"phi\": 0.336578129210379}, {\"truth_threshold\": 42.100000627338886, \"match_probability\": 0.9999999999997878, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 715.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5823.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.10936066075252371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8906393392474763, \"precision\": 1.0, \"recall\": 0.10936066075252371, \"specificity\": 1.0, \"npv\": 0.9995340401551279, \"accuracy\": 0.9995340668133627, \"f1\": 0.1971597959465049, \"f2\": 0.13306286522499722, \"f0_5\": 0.3804000851244946, \"p4\": 0.32936660332180356, \"phi\": 0.33062017947488376}, {\"truth_threshold\": 42.200000628829, \"match_probability\": 0.999999999999802, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 686.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5852.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.10492505353319058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8950749464668094, \"precision\": 1.0, \"recall\": 0.10492505353319058, \"specificity\": 1.0, \"npv\": 0.999531720644958, \"accuracy\": 0.9995317463492699, \"f1\": 0.18992248062015504, \"f2\": 0.1278038601982264, \"f0_5\": 0.3695324283559578, \"p4\": 0.31920630644964443, \"phi\": 0.3238455176419682}, {\"truth_threshold\": 42.30000063031912, \"match_probability\": 0.9999999999998154, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 666.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5872.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.10186601407158152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8981339859284184, \"precision\": 1.0, \"recall\": 0.10186601407158152, \"specificity\": 1.0, \"npv\": 0.9995301209890441, \"accuracy\": 0.9995301460292059, \"f1\": 0.18489727928928373, \"f2\": 0.12417033335819226, \"f0_5\": 0.3618778526407303, \"p4\": 0.3120785253533428, \"phi\": 0.3190895632414817}, {\"truth_threshold\": 42.400000631809235, \"match_probability\": 0.9999999999998277, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 632.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5906.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.09666564698684613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9033343530131539, \"precision\": 1.0, \"recall\": 0.09666564698684613, \"specificity\": 1.0, \"npv\": 0.9995274015857413, \"accuracy\": 0.999527425485097, \"f1\": 0.17629009762900977, \"f2\": 0.11798088410991636, \"f0_5\": 0.3485550408118244, \"p4\": 0.299728531431679, \"phi\": 0.3108375185774183}, {\"truth_threshold\": 42.50000063329935, \"match_probability\": 0.9999999999998392, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 620.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5918.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0948302233098807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9051697766901193, \"precision\": 1.0, \"recall\": 0.0948302233098807, \"specificity\": 1.0, \"npv\": 0.9995264417998733, \"accuracy\": 0.9995264652930587, \"f1\": 0.1732327465772562, \"f2\": 0.11579261915434036, \"f0_5\": 0.3437569305832779, \"p4\": 0.2952980778292644, \"phi\": 0.307872239216225}, {\"truth_threshold\": 42.60000063478947, \"match_probability\": 0.99999999999985, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 595.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5943.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.09100642398286937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9089935760171306, \"precision\": 1.0, \"recall\": 0.09100642398286937, \"specificity\": 1.0, \"npv\": 0.9995244422519016, \"accuracy\": 0.9995244648929786, \"f1\": 0.16683022571148184, \"f2\": 0.11122742737503272, \"f0_5\": 0.33359497645211933, \"p4\": 0.2859448577970874, \"phi\": 0.3016009701125273}, {\"truth_threshold\": 42.70000063627958, \"match_probability\": 0.99999999999986, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 563.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5975.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.08611196084429489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9138880391557052, \"precision\": 1.0, \"recall\": 0.08611196084429489, \"specificity\": 1.0, \"npv\": 0.9995218828421717, \"accuracy\": 0.9995219043808762, \"f1\": 0.15856921560343615, \"f2\": 0.10537151413063822, \"f0_5\": 0.32025028441410697, \"p4\": 0.2737238706423358, \"phi\": 0.29337823579522904}, {\"truth_threshold\": 42.8000006377697, \"match_probability\": 0.9999999999998694, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 538.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6000.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.08228816151728358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9177118384827164, \"precision\": 1.0, \"recall\": 0.08228816151728358, \"specificity\": 1.0, \"npv\": 0.9995198833124402, \"accuracy\": 0.9995199039807962, \"f1\": 0.1520633126059921, \"f2\": 0.10078681153990258, \"f0_5\": 0.3095512082853855, \"p4\": 0.2639759300209948, \"phi\": 0.2867902606396363}, {\"truth_threshold\": 42.900000639259815, \"match_probability\": 0.9999999999998782, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 524.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6014.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.08014683389415724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9198531661058428, \"precision\": 1.0, \"recall\": 0.08014683389415724, \"specificity\": 1.0, \"npv\": 0.9995187635792852, \"accuracy\": 0.9995187837567514, \"f1\": 0.14839988671764373, \"f2\": 0.09821562453141401, \"f0_5\": 0.3034514709288858, \"p4\": 0.2584383229072315, \"phi\": 0.2830340338522602}, {\"truth_threshold\": 43.00000064074993, \"match_probability\": 0.9999999999998863, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 510.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6028.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0780055062710309, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9219944937289691, \"precision\": 1.0, \"recall\": 0.0780055062710309, \"specificity\": 1.0, \"npv\": 0.9995176438486387, \"accuracy\": 0.9995176635327065, \"f1\": 0.14472190692395007, \"f2\": 0.09564173730402821, \"f0_5\": 0.29727209139659594, \"p4\": 0.2528430553021201, \"phi\": 0.279227290634782}, {\"truth_threshold\": 43.10000064224005, \"match_probability\": 0.999999999999894, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 496.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6042.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.07586417864790455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9241358213520955, \"precision\": 1.0, \"recall\": 0.07586417864790455, \"specificity\": 1.0, \"npv\": 0.9995165241205012, \"accuracy\": 0.9995165433086617, \"f1\": 0.14102928632357123, \"f2\": 0.09306514560192135, \"f0_5\": 0.29101149964796996, \"p4\": 0.24718922182332975, \"phi\": 0.27536793594645387}, {\"truth_threshold\": 43.200000643730164, \"match_probability\": 0.9999999999999011, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 464.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6074.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.07096971550933007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9290302844906699, \"precision\": 1.0, \"recall\": 0.07096971550933007, \"specificity\": 1.0, \"npv\": 0.9995139647513218, \"accuracy\": 0.9995139827965593, \"f1\": 0.13253356183947443, \"f2\": 0.08716561466786896, \"f0_5\": 0.2763878961162735, \"p4\": 0.2340412601848542, \"phi\": 0.26633666988607463}, {\"truth_threshold\": 43.30000064522028, \"match_probability\": 0.9999999999999076, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 446.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6092.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.06821657999388192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.931783420006118, \"precision\": 1.0, \"recall\": 0.06821657999388192, \"specificity\": 1.0, \"npv\": 0.9995125251119183, \"accuracy\": 0.9995125425085017, \"f1\": 0.1277205040091638, \"f2\": 0.08384089029250319, \"f0_5\": 0.2679644316270127, \"p4\": 0.22650466362910335, \"phi\": 0.2611193714073778}, {\"truth_threshold\": 43.400000646710396, \"match_probability\": 0.9999999999999138, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 432.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6106.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.06607525237075558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9339247476292444, \"precision\": 1.0, \"recall\": 0.06607525237075558, \"specificity\": 1.0, \"npv\": 0.9995114053952495, \"accuracy\": 0.9995114222844569, \"f1\": 0.12395982783357246, \"f2\": 0.08125188083057479, \"f0_5\": 0.26131139608032905, \"p4\": 0.22057102638271434, \"phi\": 0.25698826502184824}, {\"truth_threshold\": 43.50000064820051, \"match_probability\": 0.9999999999999196, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 407.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6131.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.06225145304374426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9377485469562558, \"precision\": 1.0, \"recall\": 0.06225145304374426, \"specificity\": 1.0, \"npv\": 0.9995094059074379, \"accuracy\": 0.9995094218843769, \"f1\": 0.1172066234701224, \"f2\": 0.07662186076282992, \"f0_5\": 0.24920401665442077, \"p4\": 0.20981545111599006, \"phi\": 0.24944120118502394}, {\"truth_threshold\": 43.60000064969063, \"match_probability\": 0.999999999999925, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 387.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6151.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.05919241358213521, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9408075864178648, \"precision\": 1.0, \"recall\": 0.05919241358213521, \"specificity\": 1.0, \"npv\": 0.9995078063229483, \"accuracy\": 0.9995078215643128, \"f1\": 0.11176895306859205, \"f2\": 0.07291156411319191, \"f0_5\": 0.23930249814494187, \"p4\": 0.2010600965611296, \"phi\": 0.2432350292421728}, {\"truth_threshold\": 43.700000651180744, \"match_probability\": 0.9999999999999301, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 376.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6162.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.05750994187825023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9424900581217498, \"precision\": 1.0, \"recall\": 0.05750994187825023, \"specificity\": 1.0, \"npv\": 0.9995069265536615, \"accuracy\": 0.9995069413882777, \"f1\": 0.1087648249927683, \"f2\": 0.07086851628468034, \"f0_5\": 0.23377269335986073, \"p4\": 0.1961862261923861, \"phi\": 0.23975317568910237}, {\"truth_threshold\": 43.80000065267086, \"match_probability\": 0.9999999999999347, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 357.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6181.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.05460385438972163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9453961456102784, \"precision\": 1.0, \"recall\": 0.05460385438972163, \"specificity\": 1.0, \"npv\": 0.9995054069558138, \"accuracy\": 0.9995054210842168, \"f1\": 0.10355329949238579, \"f2\": 0.06733562186427251, \"f0_5\": 0.22407732864674867, \"p4\": 0.18766813603537594, \"phi\": 0.23361688231622885}, {\"truth_threshold\": 43.900000654160976, \"match_probability\": 0.999999999999939, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 335.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6203.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.051238910981951664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9487610890180483, \"precision\": 1.0, \"recall\": 0.051238910981951664, \"specificity\": 1.0, \"npv\": 0.9995036474272365, \"accuracy\": 0.9995036607321465, \"f1\": 0.09748290411756147, \"f2\": 0.06323856986446182, \"f0_5\": 0.2126174155877126, \"p4\": 0.1776442326638859, \"phi\": 0.22630395139427015}, {\"truth_threshold\": 44.00000065565109, \"match_probability\": 0.9999999999999432, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 315.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6223.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.048179871520342615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9518201284796574, \"precision\": 1.0, \"recall\": 0.048179871520342615, \"specificity\": 1.0, \"npv\": 0.9995020478611784, \"accuracy\": 0.9995020604120824, \"f1\": 0.09193054136874361, \"f2\": 0.059508066649034644, \"f0_5\": 0.20197486535008977, \"p4\": 0.16837813389051387, \"phi\": 0.21944448102030478}, {\"truth_threshold\": 44.10000065714121, \"match_probability\": 0.9999999999999469, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 293.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6245.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.04481492811257265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9551850718874273, \"precision\": 1.0, \"recall\": 0.04481492811257265, \"specificity\": 1.0, \"npv\": 0.9995002883444277, \"accuracy\": 0.999500300060012, \"f1\": 0.08578539013321622, \"f2\": 0.05539799584042352, \"f0_5\": 0.19001297016861218, \"p4\": 0.15801224929058907, \"phi\": 0.2116424663687587}, {\"truth_threshold\": 44.200000658631325, \"match_probability\": 0.9999999999999505, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 288.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6250.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.04405016824717039, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9559498317528297, \"precision\": 1.0, \"recall\": 0.04405016824717039, \"specificity\": 1.0, \"npv\": 0.999499888455121, \"accuracy\": 0.999499899979996, \"f1\": 0.08438324055083504, \"f2\": 0.05446293494704992, \"f0_5\": 0.18725617685305593, \"p4\": 0.15563058267771712, \"phi\": 0.2098288308347452}, {\"truth_threshold\": 44.30000066012144, \"match_probability\": 0.9999999999999538, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 257.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6281.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.03930865708167636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9606913429183237, \"precision\": 1.0, \"recall\": 0.03930865708167636, \"specificity\": 1.0, \"npv\": 0.9994974091485618, \"accuracy\": 0.9994974194838968, \"f1\": 0.07564385577630611, \"f2\": 0.04865765458745125, \"f0_5\": 0.16983875231297912, \"p4\": 0.14064602875924506, \"phi\": 0.1982142802883909}, {\"truth_threshold\": 44.40000066161156, \"match_probability\": 0.9999999999999569, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 243.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6295.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.037167329458550016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9628326705414499, \"precision\": 1.0, \"recall\": 0.037167329458550016, \"specificity\": 1.0, \"npv\": 0.9994962894657604, \"accuracy\": 0.999496299259852, \"f1\": 0.0716708450081109, \"f2\": 0.04603144534949801, \"f0_5\": 0.1617842876165113, \"p4\": 0.13375307831987132, \"phi\": 0.19273974131759178}, {\"truth_threshold\": 44.50000066310167, \"match_probability\": 0.9999999999999598, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 238.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6300.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.03640256959314775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9635974304068522, \"precision\": 1.0, \"recall\": 0.03640256959314775, \"specificity\": 1.0, \"npv\": 0.9994958895796535, \"accuracy\": 0.999495899179836, \"f1\": 0.07024793388429752, \"f2\": 0.04509283819628647, \"f0_5\": 0.1588785046728972, \"p4\": 0.1312719583939023, \"phi\": 0.19074647749955556}, {\"truth_threshold\": 44.60000066459179, \"match_probability\": 0.9999999999999625, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 222.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6316.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.033955338023860505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9660446619761395, \"precision\": 1.0, \"recall\": 0.033955338023860505, \"specificity\": 1.0, \"npv\": 0.9994946099462619, \"accuracy\": 0.9994946189237848, \"f1\": 0.06568047337278106, \"f2\": 0.042086903768863274, \"f0_5\": 0.14947481820630218, \"p4\": 0.12326293216632181, \"phi\": 0.18422317262969914}, {\"truth_threshold\": 44.700000666081905, \"match_probability\": 0.999999999999965, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 220.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6318.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0336494340776996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9663505659223004, \"precision\": 1.0, \"recall\": 0.0336494340776996, \"specificity\": 1.0, \"npv\": 0.9994944499923183, \"accuracy\": 0.9994944588917783, \"f1\": 0.06510802012429713, \"f2\": 0.04171090550583953, \"f0_5\": 0.14828794823402536, \"p4\": 0.12225429228641106, \"phi\": 0.1833914463818941}, {\"truth_threshold\": 44.80000066757202, \"match_probability\": 0.9999999999999674, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 203.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6335.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.031049250535331904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9689507494646681, \"precision\": 1.0, \"recall\": 0.031049250535331904, \"specificity\": 1.0, \"npv\": 0.9994930903858651, \"accuracy\": 0.9994930986197239, \"f1\": 0.060228452751817235, \"f2\": 0.03851261620185923, \"f0_5\": 0.1380952380952381, \"p4\": 0.11361246719554564, \"phi\": 0.17616330881237402}, {\"truth_threshold\": 44.90000066906214, \"match_probability\": 0.9999999999999696, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 184.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6354.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.028143163046803303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9718568369531967, \"precision\": 1.0, \"recall\": 0.028143163046803303, \"specificity\": 1.0, \"npv\": 0.9994915708300887, \"accuracy\": 0.9994915783156632, \"f1\": 0.05474561142517108, \"f2\": 0.03493317132442284, \"f0_5\": 0.12647786637338465, \"p4\": 0.10380681013152619, \"phi\": 0.1677165890476453}, {\"truth_threshold\": 45.000000670552254, \"match_probability\": 0.9999999999999716, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 175.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6363.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02676659528907923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9732334047109208, \"precision\": 1.0, \"recall\": 0.02676659528907923, \"specificity\": 1.0, \"npv\": 0.999490851042123, \"accuracy\": 0.9994908581716343, \"f1\": 0.05213764337851929, \"f2\": 0.033235841531507576, \"f0_5\": 0.12088974854932302, \"p4\": 0.09910677686281072, \"phi\": 0.16356334279104803}, {\"truth_threshold\": 45.10000067204237, \"match_probability\": 0.9999999999999735, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 165.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6373.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.025237075558274702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9747629244417253, \"precision\": 1.0, \"recall\": 0.025237075558274702, \"specificity\": 1.0, \"npv\": 0.9994900512789326, \"accuracy\": 0.9994900580116023, \"f1\": 0.049231687304192154, \"f2\": 0.03134855796633355, \"f0_5\": 0.11461517088080023, \"p4\": 0.09384218682572967, \"phi\": 0.15882130192096486}, {\"truth_threshold\": 45.200000673532486, \"match_probability\": 0.9999999999999752, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 162.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6376.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.024778219639033344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9752217803609666, \"precision\": 1.0, \"recall\": 0.024778219639033344, \"specificity\": 1.0, \"npv\": 0.9994898113502252, \"accuracy\": 0.9994898179635927, \"f1\": 0.04835820895522388, \"f2\": 0.0307820931823364, \"f0_5\": 0.11271917617589758, \"p4\": 0.09225403918846606, \"phi\": 0.1573708298021329}, {\"truth_threshold\": 45.3000006750226, \"match_probability\": 0.9999999999999769, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 142.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6396.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.021719180177424288, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9782808198225758, \"precision\": 1.0, \"recall\": 0.021719180177424288, \"specificity\": 1.0, \"npv\": 0.999488211828452, \"accuracy\": 0.9994882176435287, \"f1\": 0.04251497005988024, \"f2\": 0.027002357952384575, \"f0_5\": 0.09991556431184914, \"p4\": 0.08156146892205354, \"phi\": 0.14733656897699826}, {\"truth_threshold\": 45.40000067651272, \"match_probability\": 0.9999999999999785, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 141.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6397.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.021566228204343837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9784337717956562, \"precision\": 1.0, \"recall\": 0.021566228204343837, \"specificity\": 1.0, \"npv\": 0.9994881318524977, \"accuracy\": 0.9994881376275255, \"f1\": 0.042221889504416826, \"f2\": 0.026813220248735406, \"f0_5\": 0.09926781188397635, \"p4\": 0.08102200105893484, \"phi\": 0.14681685577298087}, {\"truth_threshold\": 45.500000678002834, \"match_probability\": 0.9999999999999799, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 131.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6407.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02003670847353931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9799632915264607, \"precision\": 1.0, \"recall\": 0.02003670847353931, \"specificity\": 1.0, \"npv\": 0.999487332093659, \"accuracy\": 0.9994873374674935, \"f1\": 0.0392862498125656, \"f2\": 0.024921051630331394, \"f0_5\": 0.09274992919852733, \"p4\": 0.07560163324601013, \"phi\": 0.14151479179278828}, {\"truth_threshold\": 45.60000067949295, \"match_probability\": 0.9999999999999812, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 124.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6414.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.01896604466197614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9810339553380238, \"precision\": 1.0, \"recall\": 0.01896604466197614, \"specificity\": 1.0, \"npv\": 0.9994867722632335, \"accuracy\": 0.9994867773554711, \"f1\": 0.037226058240768536, \"f2\": 0.02359567666311463, \"f0_5\": 0.08814330395223202, \"p4\": 0.07177936752506696, \"phi\": 0.13768191879037298}, {\"truth_threshold\": 45.70000068098307, \"match_probability\": 0.9999999999999825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 112.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6426.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.017130620985010708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9828693790149893, \"precision\": 1.0, \"recall\": 0.017130620985010708, \"specificity\": 1.0, \"npv\": 0.9994858125553916, \"accuracy\": 0.9994858171634327, \"f1\": 0.03368421052631579, \"f2\": 0.021321961620469083, \"f0_5\": 0.08016032064128256, \"p4\": 0.06517256980599781, \"phi\": 0.13085034441980603}, {\"truth_threshold\": 45.80000068247318, \"match_probability\": 0.9999999999999837, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 106.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6432.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.01621290914652799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983787090853472, \"precision\": 1.0, \"recall\": 0.01621290914652799, \"specificity\": 1.0, \"npv\": 0.9994853327021618, \"accuracy\": 0.9994853370674135, \"f1\": 0.03190848886213125, \"f2\": 0.020184324777210754, \"f0_5\": 0.07612754955472566, \"p4\": 0.061843148253533604, \"phi\": 0.1272971519413826}, {\"truth_threshold\": 45.9000006839633, \"match_probability\": 0.9999999999999848, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 100.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6438.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.015295197308045273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9847048026919547, \"precision\": 1.0, \"recall\": 0.015295197308045273, \"specificity\": 1.0, \"npv\": 0.9994848528493927, \"accuracy\": 0.9994848569713943, \"f1\": 0.030129557095510694, \"f2\": 0.019046167911016303, \"f0_5\": 0.07206687806284232, \"p4\": 0.058496195529687475, \"phi\": 0.12364189431877069}, {\"truth_threshold\": 46.000000685453415, \"match_probability\": 0.9999999999999858, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 89.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6449.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.013612725604160294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9863872743958397, \"precision\": 1.0, \"recall\": 0.013612725604160294, \"specificity\": 1.0, \"npv\": 0.9994839731205127, \"accuracy\": 0.999483976795359, \"f1\": 0.026859815904632565, \"f2\": 0.01695819519073206, \"f0_5\": 0.0645488830867421, \"p4\": 0.05231412140495124, \"phi\": 0.11664347847970524}, {\"truth_threshold\": 46.10000068694353, \"match_probability\": 0.9999999999999868, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 83.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6455.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.012695013765677577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9873049862343224, \"precision\": 1.0, \"recall\": 0.012695013765677577, \"specificity\": 1.0, \"npv\": 0.9994834932690491, \"accuracy\": 0.9994834966993399, \"f1\": 0.02507174142878719, \"f2\": 0.01581856298837431, \"f0_5\": 0.06040756914119359, \"p4\": 0.04891673815424463, \"phi\": 0.11264304996589043}, {\"truth_threshold\": 46.30000068992376, \"match_probability\": 0.9999999999999885, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 78.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6460.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.011930253900275314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9880697460997246, \"precision\": 1.0, \"recall\": 0.011930253900275314, \"specificity\": 1.0, \"npv\": 0.9994830933931814, \"accuracy\": 0.9994830966193239, \"f1\": 0.02357920193470375, \"f2\": 0.014868471216164697, \"f0_5\": 0.05693430656934306, \"p4\": 0.04607178698819498, \"phi\": 0.1091974682545948}, {\"truth_threshold\": 46.40000069141388, \"match_probability\": 0.9999999999999892, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 75.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6463.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.011471397981033955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9885286020189661, \"precision\": 1.0, \"recall\": 0.011471397981033955, \"specificity\": 1.0, \"npv\": 0.9994828534678144, \"accuracy\": 0.9994828565713143, \"f1\": 0.022682594888855285, \"f2\": 0.014298242269417012, \"f0_5\": 0.05484059666569172, \"p4\": 0.04435875774234208, \"phi\": 0.10707691435294885}, {\"truth_threshold\": 46.500000692903996, \"match_probability\": 0.9999999999999899, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 62.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6476.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.00948302233098807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905169776690119, \"precision\": 1.0, \"recall\": 0.00948302233098807, \"specificity\": 1.0, \"npv\": 0.999481813792555, \"accuracy\": 0.9994818163632726, \"f1\": 0.018787878787878787, \"f2\": 0.011825741969939726, \"f0_5\": 0.04568228706159741, \"p4\": 0.036882631534392994, \"phi\": 0.09735557693122288}, {\"truth_threshold\": 46.60000069439411, \"match_probability\": 0.9999999999999907, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 60.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6478.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.009177118384827165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9908228816151728, \"precision\": 1.0, \"recall\": 0.009177118384827165, \"specificity\": 1.0, \"npv\": 0.999481653842707, \"accuracy\": 0.9994816563312663, \"f1\": 0.018187329493785997, \"f2\": 0.011445139630703495, \"f0_5\": 0.04426084390675716, \"p4\": 0.035724752658006585, \"phi\": 0.09577244625035619}, {\"truth_threshold\": 46.70000069588423, \"match_probability\": 0.9999999999999912, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 57.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6481.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.008718262465585805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9912817375344142, \"precision\": 1.0, \"recall\": 0.008718262465585805, \"specificity\": 1.0, \"npv\": 0.999481413918031, \"accuracy\": 0.9994814162832566, \"f1\": 0.01728582259287339, \"f2\": 0.01087412720821092, \"f0_5\": 0.042122376588826484, \"p4\": 0.03398405051876811, \"phi\": 0.09334742254616461}, {\"truth_threshold\": 46.90000069886446, \"match_probability\": 0.9999999999999923, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 49.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6489.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.007494646680942184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9925053533190579, \"precision\": 1.0, \"recall\": 0.007494646680942184, \"specificity\": 1.0, \"npv\": 0.9994807741194585, \"accuracy\": 0.999480776155231, \"f1\": 0.01487778958554729, \"f2\": 0.009350788137857334, \"f0_5\": 0.036382536382536385, \"p4\": 0.02931926008524652, \"phi\": 0.08654914942632264}, {\"truth_threshold\": 47.000000700354576, \"match_probability\": 0.9999999999999929, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 47.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6491.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.007188742734781279, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9928112572652187, \"precision\": 1.0, \"recall\": 0.007188742734781279, \"specificity\": 1.0, \"npv\": 0.9994806141699433, \"accuracy\": 0.9994806161232247, \"f1\": 0.014274867122247532, \"f2\": 0.008969808007939234, \"f0_5\": 0.034939042521558134, \"p4\": 0.028147823405097274, \"phi\": 0.08476443242108632}, {\"truth_threshold\": 47.10000070184469, \"match_probability\": 0.9999999999999933, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 42.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6496.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.006423982869379015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935760171306209, \"precision\": 1.0, \"recall\": 0.006423982869379015, \"specificity\": 1.0, \"npv\": 0.9994802142963793, \"accuracy\": 0.9994802160432087, \"f1\": 0.01276595744680851, \"f2\": 0.008017103153393906, \"f0_5\": 0.031315240083507306, \"p4\": 0.02521000140369941, \"phi\": 0.08012891971643701}, {\"truth_threshold\": 47.20000070333481, \"match_probability\": 0.9999999999999938, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 40.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6498.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0061180789232181095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938819210767819, \"precision\": 1.0, \"recall\": 0.0061180789232181095, \"specificity\": 1.0, \"npv\": 0.9994800543470433, \"accuracy\": 0.9994800560112023, \"f1\": 0.012161751292186074, \"f2\": 0.0076359193646915085, \"f0_5\": 0.029859659599880562, \"p4\": 0.02403116550675825, \"phi\": 0.07819781233946085}, {\"truth_threshold\": 47.40000070631504, \"match_probability\": 0.9999999999999946, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 39.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6499.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.005965126950137657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940348730498624, \"precision\": 1.0, \"recall\": 0.005965126950137657, \"specificity\": 1.0, \"npv\": 0.9994799743723946, \"accuracy\": 0.999479975995199, \"f1\": 0.011859510415082864, \"f2\": 0.0074453056393417585, \"f0_5\": 0.029130564684792352, \"p4\": 0.02344095031506342, \"phi\": 0.07721414981239945}, {\"truth_threshold\": 47.50000070780516, \"match_probability\": 0.999999999999995, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 34.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6504.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.005200367084735393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9947996329152646, \"precision\": 1.0, \"recall\": 0.005200367084735393, \"specificity\": 1.0, \"npv\": 0.9994795744993425, \"accuracy\": 0.999479575915183, \"f1\": 0.010346926354230066, \"f2\": 0.00649201863591232, \"f0_5\": 0.025471980821096793, \"p4\": 0.020481873101726385, \"phi\": 0.07209480342640319}, {\"truth_threshold\": 47.60000070929527, \"match_probability\": 0.9999999999999953, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 29.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6509.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.004435607219333129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955643927806669, \"precision\": 1.0, \"recall\": 0.004435607219333129, \"specificity\": 1.0, \"npv\": 0.9994791746266104, \"accuracy\": 0.999479175835167, \"f1\": 0.008832038982792752, \"f2\": 0.0055383675184293955, \"f0_5\": 0.02179140366696724, \"p4\": 0.01750939402285685, \"phi\": 0.06658300866247267}, {\"truth_threshold\": 47.70000071078539, \"match_probability\": 0.9999999999999957, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 26.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6512.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0039767513000917715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960232486999082, \"precision\": 1.0, \"recall\": 0.0039767513000917715, \"specificity\": 1.0, \"npv\": 0.9994789347031248, \"accuracy\": 0.9994789357871574, \"f1\": 0.007921998781230956, \"f2\": 0.004966001986400795, \"f0_5\": 0.019572417946401688, \"p4\": 0.015719435750727193, \"phi\": 0.06304505653098416}, {\"truth_threshold\": 47.800000712275505, \"match_probability\": 0.9999999999999959, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 25.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6513.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0038237993270113183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961762006729887, \"precision\": 1.0, \"recall\": 0.0038237993270113183, \"specificity\": 1.0, \"npv\": 0.9994788547286552, \"accuracy\": 0.9994788557711543, \"f1\": 0.007618467164406522, \"f2\": 0.004775184322114834, \"f0_5\": 0.018830973184694184, \"p4\": 0.015121700118283716, \"phi\": 0.061820761658794486}, {\"truth_threshold\": 48.00000071525574, \"match_probability\": 0.9999999999999964, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 24.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6514.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0036708473539308656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963291526460691, \"precision\": 1.0, \"recall\": 0.0036708473539308656, \"specificity\": 1.0, \"npv\": 0.9994787747541983, \"accuracy\": 0.999478775755151, \"f1\": 0.00731484303565986, \"f2\": 0.004584352078239609, \"f0_5\": 0.01808863430810974, \"p4\": 0.014523421819345864, \"phi\": 0.06057172620634575}, {\"truth_threshold\": 48.10000071674585, \"match_probability\": 0.9999999999999967, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 22.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6516.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.00336494340776996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966350565922301, \"precision\": 1.0, \"recall\": 0.00336494340776996, \"specificity\": 1.0, \"npv\": 0.9994786148053231, \"accuracy\": 0.9994786157231447, \"f1\": 0.006707317073170732, \"f2\": 0.004202643845037059, \"f0_5\": 0.016601267733172352, \"p4\": 0.013325234263099556, \"phi\": 0.05799300799317297}, {\"truth_threshold\": 48.50000072270632, \"match_probability\": 0.9999999999999974, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 20.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6518.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0030590394616090547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996940960538391, \"precision\": 1.0, \"recall\": 0.0030590394616090547, \"specificity\": 1.0, \"npv\": 0.9994784548564991, \"accuracy\": 0.9994784556911382, \"f1\": 0.006099420555047271, \"f2\": 0.0038208772734219776, \"f0_5\": 0.015110305228165609, \"p4\": 0.012124867150756665, \"phi\": 0.0552941591348858}, {\"truth_threshold\": 48.600000724196434, \"match_probability\": 0.9999999999999977, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 19.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6519.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.002906087488528602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970939125114714, \"precision\": 1.0, \"recall\": 0.002906087488528602, \"specificity\": 1.0, \"npv\": 0.9994783748821062, \"accuracy\": 0.999478375675135, \"f1\": 0.0057953332316608205, \"f2\": 0.003629972106530129, \"f0_5\": 0.014363471424251588, \"p4\": 0.011523864401635763, \"phi\": 0.053894077599489436}, {\"truth_threshold\": 48.800000727176666, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 18.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6520.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0027531355154481493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972468644845518, \"precision\": 1.0, \"recall\": 0.0027531355154481493, \"specificity\": 1.0, \"npv\": 0.9994782949077262, \"accuracy\": 0.9994782956591318, \"f1\": 0.005491153142159854, \"f2\": 0.003439052350019106, \"f0_5\": 0.01361573373676248, \"p4\": 0.010922314529486318, \"phi\": 0.0524566410536361}, {\"truth_threshold\": 48.90000072866678, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 16.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6522.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.002447231569287244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9975527684307127, \"precision\": 1.0, \"recall\": 0.002447231569287244, \"specificity\": 1.0, \"npv\": 0.9994781349590045, \"accuracy\": 0.9994781356271254, \"f1\": 0.004882514494964907, \"f2\": 0.003057169061449098, \"f0_5\": 0.012117540139351712, \"p4\": 0.009717570424759955, \"phi\": 0.04945659151906864}, {\"truth_threshold\": 49.0000007301569, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 15.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6523.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.002294279596206791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977057204037932, \"precision\": 1.0, \"recall\": 0.002294279596206791, \"specificity\": 1.0, \"npv\": 0.9994780549846629, \"accuracy\": 0.9994780556111222, \"f1\": 0.0045780558522813975, \"f2\": 0.0028662055260442543, \"f0_5\": 0.011367080933616247, \"p4\": 0.009114374693103295, \"phi\": 0.0478861369125529}, {\"truth_threshold\": 49.30000073462725, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 14.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6524.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0021413276231263384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978586723768736, \"precision\": 1.0, \"recall\": 0.0021413276231263384, \"specificity\": 1.0, \"npv\": 0.9994779750103341, \"accuracy\": 0.999477975595119, \"f1\": 0.004273504273504274, \"f2\": 0.002675227394328518, \"f0_5\": 0.010615711252653927, \"p4\": 0.008510628840252391, \"phi\": 0.0462624015437591}, {\"truth_threshold\": 49.40000073611736, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 12.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6526.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0018354236769654328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981645763230346, \"precision\": 1.0, \"recall\": 0.0018354236769654328, \"specificity\": 1.0, \"npv\": 0.9994778150617148, \"accuracy\": 0.9994778155631127, \"f1\": 0.00366412213740458, \"f2\": 0.0022932273352698363, \"f0_5\": 0.009110233829334954, \"p4\": 0.007301483757742319, \"phi\": 0.04283065778581914}, {\"truth_threshold\": 49.600000739097595, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 10.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6528.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0015295197308045274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984704802691955, \"precision\": 1.0, \"recall\": 0.0015295197308045274, \"specificity\": 1.0, \"npv\": 0.9994776551131467, \"accuracy\": 0.9994776555311062, \"f1\": 0.0030543677458766036, \"f2\": 0.0019111688708814312, \"f0_5\": 0.007601094557616297, \"p4\": 0.006090129137012272, \"phi\": 0.0390988592415917}, {\"truth_threshold\": 49.80000074207783, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 9.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6529.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0013765677577240747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986234322422759, \"precision\": 1.0, \"recall\": 0.0013765677577240747, \"specificity\": 1.0, \"npv\": 0.9994775751388819, \"accuracy\": 0.999477575515103, \"f1\": 0.0027493508477165114, \"f2\": 0.0017201177325025802, \"f0_5\": 0.006845147550958321, \"p4\": 0.005483621356207485, \"phi\": 0.037092433251330735}, {\"truth_threshold\": 50.00000074505806, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 7.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6531.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0010706638115631692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989293361884368, \"precision\": 1.0, \"recall\": 0.0010706638115631692, \"specificity\": 1.0, \"npv\": 0.9994774151903906, \"accuracy\": 0.9994774154830967, \"f1\": 0.0021390374331550803, \"f2\": 0.001337971635001338, \"f0_5\": 0.005330490405117271, \"p4\": 0.004268941054375471, \"phi\": 0.03271244868424019}, {\"truth_threshold\": 50.400000751018524, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6533.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0007647598654022637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992352401345977, \"precision\": 1.0, \"recall\": 0.0007647598654022637, \"specificity\": 1.0, \"npv\": 0.9994772552419505, \"accuracy\": 0.9994772554510902, \"f1\": 0.0015283509093687911, \"f2\": 0.0009557670986733952, \"f0_5\": 0.003812137846904544, \"p4\": 0.003052036016885189, \"phi\": 0.027647062975865232}, {\"truth_threshold\": 50.600000753998756, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6534.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.000611807892321811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993881921076782, \"precision\": 1.0, \"recall\": 0.000611807892321811, \"specificity\": 1.0, \"npv\": 0.9994771752677496, \"accuracy\": 0.999477175435087, \"f1\": 0.0012228676245796392, \"f2\": 0.000764642911760208, \"f0_5\": 0.003051571559353067, \"p4\": 0.0024427473112691466, \"phi\": 0.024728283887571315}, {\"truth_threshold\": 50.80000075697899, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6535.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0004588559192413582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995411440807587, \"precision\": 1.0, \"recall\": 0.0004588559192413582, \"specificity\": 1.0, \"npv\": 0.9994770952935615, \"accuracy\": 0.9994770954190838, \"f1\": 0.0009172909341079345, \"f2\": 0.0005735041101127892, \"f0_5\": 0.0022900763358778627, \"p4\": 0.0018329001257368872, \"phi\": 0.021415321181845713}, {\"truth_threshold\": 51.30000076442957, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6536.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0003059039461609055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996940960538391, \"precision\": 1.0, \"recall\": 0.0003059039461609055, \"specificity\": 1.0, \"npv\": 0.9994770153193864, \"accuracy\": 0.9994770154030806, \"f1\": 0.0006116207951070336, \"f2\": 0.00038235069205475264, \"f0_5\": 0.0015276504735716467, \"p4\": 0.001222493692029335, \"phi\": 0.017485535824884636}, {\"truth_threshold\": 51.80000077188015, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6537.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.00015295197308045274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998470480269196, \"precision\": 1.0, \"recall\": 0.00015295197308045274, \"specificity\": 1.0, \"npv\": 0.9994769353452239, \"accuracy\": 0.9994769353870774, \"f1\": 0.0003058571647040832, \"f2\": 0.0001911826559094559, \"f0_5\": 0.0007642922653622745, \"p4\": 0.0006115272404776511, \"phi\": 0.012364140459791619}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.roc_chart_from_labels_column(\"cluster\", match_weight_round_to_nearest=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:51:11.820946Z",
     "iopub.status.busy": "2024-05-15T15:51:11.820644Z",
     "iopub.status.idle": "2024-05-15T15:51:12.084284Z",
     "shell.execute_reply": "2024-05-15T15:51:12.083443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clerical_match_score</th>\n",
       "      <th>found_by_blocking_rules</th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>rec_id_l</th>\n",
       "      <th>rec_id_r</th>\n",
       "      <th>given_name_l</th>\n",
       "      <th>given_name_r</th>\n",
       "      <th>gamma_given_name</th>\n",
       "      <th>tf_given_name_l</th>\n",
       "      <th>...</th>\n",
       "      <th>postcode_l</th>\n",
       "      <th>postcode_r</th>\n",
       "      <th>gamma_postcode</th>\n",
       "      <th>tf_postcode_l</th>\n",
       "      <th>tf_postcode_r</th>\n",
       "      <th>bf_postcode</th>\n",
       "      <th>bf_tf_adj_postcode</th>\n",
       "      <th>cluster_l</th>\n",
       "      <th>cluster_r</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-27.447151</td>\n",
       "      <td>5.464925e-09</td>\n",
       "      <td>rec-993-dup-1</td>\n",
       "      <td>rec-993-dup-3</td>\n",
       "      <td>westbrook</td>\n",
       "      <td>jake</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>...</td>\n",
       "      <td>2704</td>\n",
       "      <td>2074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.230072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-993</td>\n",
       "      <td>rec-993</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-27.447151</td>\n",
       "      <td>5.464925e-09</td>\n",
       "      <td>rec-829-dup-0</td>\n",
       "      <td>rec-829-dup-2</td>\n",
       "      <td>wilde</td>\n",
       "      <td>kyra</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>3859</td>\n",
       "      <td>3595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.230072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-19.359354</td>\n",
       "      <td>1.486802e-06</td>\n",
       "      <td>rec-829-dup-0</td>\n",
       "      <td>rec-829-dup-1</td>\n",
       "      <td>wilde</td>\n",
       "      <td>kyra</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>3859</td>\n",
       "      <td>3889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.230072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-15.232752</td>\n",
       "      <td>2.597009e-05</td>\n",
       "      <td>rec-721-dup-0</td>\n",
       "      <td>rec-721-dup-1</td>\n",
       "      <td>mikhaili</td>\n",
       "      <td>elly</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>...</td>\n",
       "      <td>4806</td>\n",
       "      <td>4860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.230072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-721</td>\n",
       "      <td>rec-721</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-12.570818</td>\n",
       "      <td>1.643370e-04</td>\n",
       "      <td>rec-401-dup-1</td>\n",
       "      <td>rec-401-dup-3</td>\n",
       "      <td>whitbe</td>\n",
       "      <td>alexa-ose</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>3040</td>\n",
       "      <td>3041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.230072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-401</td>\n",
       "      <td>rec-401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clerical_match_score  found_by_blocking_rules  match_weight  \\\n",
       "0                   1.0                    False    -27.447151   \n",
       "1                   1.0                    False    -27.447151   \n",
       "2                   1.0                    False    -19.359354   \n",
       "3                   1.0                     True    -15.232752   \n",
       "4                   1.0                     True    -12.570818   \n",
       "\n",
       "   match_probability       rec_id_l       rec_id_r given_name_l given_name_r  \\\n",
       "0       5.464925e-09  rec-993-dup-1  rec-993-dup-3    westbrook         jake   \n",
       "1       5.464925e-09  rec-829-dup-0  rec-829-dup-2        wilde         kyra   \n",
       "2       1.486802e-06  rec-829-dup-0  rec-829-dup-1        wilde         kyra   \n",
       "3       2.597009e-05  rec-721-dup-0  rec-721-dup-1     mikhaili         elly   \n",
       "4       1.643370e-04  rec-401-dup-1  rec-401-dup-3       whitbe    alexa-ose   \n",
       "\n",
       "   gamma_given_name  tf_given_name_l  ...  postcode_l  postcode_r  \\\n",
       "0                 0           0.0004  ...        2704        2074   \n",
       "1                 0           0.0002  ...        3859        3595   \n",
       "2                 0           0.0002  ...        3859        3889   \n",
       "3                 0           0.0008  ...        4806        4860   \n",
       "4                 0           0.0002  ...        3040        3041   \n",
       "\n",
       "   gamma_postcode tf_postcode_l tf_postcode_r  bf_postcode  \\\n",
       "0               0        0.0002        0.0014     0.230072   \n",
       "1               0        0.0004        0.0006     0.230072   \n",
       "2               0        0.0004        0.0002     0.230072   \n",
       "3               0        0.0008        0.0014     0.230072   \n",
       "4               0        0.0020        0.0004     0.230072   \n",
       "\n",
       "   bf_tf_adj_postcode  cluster_l  cluster_r  match_key  \n",
       "0                 1.0    rec-993    rec-993          5  \n",
       "1                 1.0    rec-829    rec-829          5  \n",
       "2                 1.0    rec-829    rec-829          5  \n",
       "3                 1.0    rec-721    rec-721          2  \n",
       "4                 1.0    rec-401    rec-401          0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_errors_df = linker.prediction_errors_from_labels_column(\n",
    "    \"cluster\"\n",
    ").as_pandas_dataframe()\n",
    "len(pred_errors_df)\n",
    "pred_errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:51:12.087291Z",
     "iopub.status.busy": "2024-05-15T15:51:12.087021Z",
     "iopub.status.idle": "2024-05-15T15:51:13.092062Z",
     "shell.execute_reply": "2024-05-15T15:51:13.091503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-8b10770aa5e945a58cd574ad70dc2b71.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-8b10770aa5e945a58cd574ad70dc2b71.vega-embed details,\n",
       "  #altair-viz-8b10770aa5e945a58cd574ad70dc2b71.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-8b10770aa5e945a58cd574ad70dc2b71\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8b10770aa5e945a58cd574ad70dc2b71\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8b10770aa5e945a58cd574ad70dc2b71\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-68ef494aa4e2e61d85639119b6daed34\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 9, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-68ef494aa4e2e61d85639119b6daed34\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" westbrook\", \"value_r\": \" jake\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" jake\", \"value_r\": \" westbrook\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.058382284691117774, \"u_probability\": 0.9984723526565924, \"bayes_factor\": 0.05847160868879598, \"log2_bayes_factor\": -4.096119906044184, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19001115\", \"value_r\": \"19501111\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"2330929\", \"value_r\": \"3733536\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 24\", \"value_r\": \" 15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"2704\", \"value_r\": \"2074\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.447151268247957, \"bayes_factor\": 5.464924579856201e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" wilde\", \"value_r\": \" kyra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" kyra\", \"value_r\": \" wilde\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.058382284691117774, \"u_probability\": 0.9984723526565924, \"bayes_factor\": 0.05847160868879598, \"log2_bayes_factor\": -4.096119906044184, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19090815\", \"value_r\": \"19220601\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"5230360\", \"value_r\": \"6073461\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 26\", \"value_r\": \" 62\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"3859\", \"value_r\": \"3595\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.447151268247957, \"bayes_factor\": 5.464924579856201e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" wilde\", \"value_r\": \" kyra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" kyra\", \"value_r\": \" everett\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.058382284691117774, \"u_probability\": 0.9984723526565924, \"bayes_factor\": 0.05847160868879598, \"log2_bayes_factor\": -4.096119906044184, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19090815\", \"value_r\": \"19220601\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"5230360\", \"value_r\": \"6073461\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"label_for_charts\": \"Exact match on street_number\", \"m_probability\": 0.768128872117923, \"u_probability\": 0.014484318478188797, \"bayes_factor\": 53.031757985341834, \"log2_bayes_factor\": 5.728784669025015, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on street_number` then comparison is 53.03 times more likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 26\", \"value_r\": \" 26\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"label_for_charts\": \"Term freq adjustment on street_number with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.2070265398490663, \"log2_bayes_factor\": 0.2714573981208437, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on street_number makes comparison 1.21 times more likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \" 26\", \"value_r\": \" 26\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"3859\", \"value_r\": \"3889\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -19.359353563228375, \"bayes_factor\": 1.4868045476946566e-06, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" mikhaili\", \"value_r\": \" elly\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.5618944210496456, \"u_probability\": 0.0029364371860301367, \"bayes_factor\": 191.3524402029824, \"log2_bayes_factor\": 7.580088488723616, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 191.35 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" reid\", \"value_r\": \" reid\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.29364371860301364, \"log2_bayes_factor\": -1.7678613177269973, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.41 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \" reid\", \"value_r\": \" reid\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d') IS NULL OR try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d') IS NULL\", \"label_for_charts\": \"transformed date_of_birth is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `transformed date_of_birth is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19850523\", \"value_r\": \"\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"2111602\", \"value_r\": \"6391700\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 46\", \"value_r\": \" 58\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"4806\", \"value_r\": \"4860\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.2327521801044, \"bayes_factor\": 2.597076110048726e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" whitbe\", \"value_r\": \" alexa-ose\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" alexa-rose\", \"value_r\": \" white\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.058382284691117774, \"u_probability\": 0.9984723526565924, \"bayes_factor\": 0.05847160868879598, \"log2_bayes_factor\": -4.096119906044184, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19300526\", \"value_r\": \"19160822\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"label_for_charts\": \"Exact match on soc_sec_id\", \"m_probability\": 0.8589356345410205, \"u_probability\": 0.0004441492804676408, \"bayes_factor\": 1933.8895103841098, \"log2_bayes_factor\": 10.917289655808569, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match on soc_sec_id` then comparison is 1,933.89 times more likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"2502613\", \"value_r\": \"2502613\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 22\", \"value_r\": \" 43\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"3040\", \"value_r\": \"3041\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.570817560726056, \"bayes_factor\": 0.00016436405389050606, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" zarran\", \"value_r\": \" bradshaw\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" bradshaw\", \"value_r\": \" zarrna\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.058382284691117774, \"u_probability\": 0.9984723526565924, \"bayes_factor\": 0.05847160868879598, \"log2_bayes_factor\": -4.096119906044184, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19350707\", \"value_r\": \"19550120\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"label_for_charts\": \"Exact match on soc_sec_id\", \"m_probability\": 0.8589356345410205, \"u_probability\": 0.0004441492804676408, \"bayes_factor\": 1933.8895103841098, \"log2_bayes_factor\": 10.917289655808569, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match on soc_sec_id` then comparison is 1,933.89 times more likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"7831798\", \"value_r\": \"7831798\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 89\", \"value_r\": \" 63\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"6174\", \"value_r\": \"6147\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.570817560726056, \"bayes_factor\": 0.00016436405389050606, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" amy\", \"value_r\": \" chandelr\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" chandler\", \"value_r\": \" ay\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9294024247696142, \"u_probability\": 0.00048151626398019293, \"bayes_factor\": 1930.157908036612, \"log2_bayes_factor\": 10.91450316522398, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,930.16 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19510715\", \"value_r\": \"19510715\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"8026179\", \"value_r\": \"1609739\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" \", \"value_r\": \" 65\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"2068\", \"value_r\": \"2086\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.436528196979793, \"bayes_factor\": 0.00018039810484390308, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" spicer\", \"value_r\": \" anika\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" anika\", \"value_r\": \" spicer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9294024247696142, \"u_probability\": 0.00048151626398019293, \"bayes_factor\": 1930.157908036612, \"log2_bayes_factor\": 10.91450316522398, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,930.16 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19861012\", \"value_r\": \"19861012\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"5087622\", \"value_r\": \"1434508\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 39\", \"value_r\": \" 3\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"2076\", \"value_r\": \"2067\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.436528196979793, \"bayes_factor\": 0.00018039810484390308, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" morrison\", \"value_r\": \" robin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" rob inq\", \"value_r\": \" morrisn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9294024247696142, \"u_probability\": 0.00048151626398019293, \"bayes_factor\": 1930.157908036612, \"log2_bayes_factor\": 10.91450316522398, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,930.16 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19250124\", \"value_r\": \"19250124\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"8539119\", \"value_r\": \"1191533\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 87\", \"value_r\": \" 14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"6196\", \"value_r\": \"6169\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.436528196979793, \"bayes_factor\": 0.00018039810484390308, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 0.2513178399235832, \"log2_bayes_factor\": -1.9924150095988993, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" joel\", \"value_r\": \" ryan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2457171343971432, \"u_probability\": 0.9777146519795691, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 0.2022130469058518, \"log2_bayes_factor\": -2.3060520111027545, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" ryan\", \"value_r\": \" joel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19942480704470256, \"u_probability\": 0.9862113750630176, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9294024247696142, \"u_probability\": 0.00048151626398019293, \"bayes_factor\": 1930.157908036612, \"log2_bayes_factor\": 10.91450316522398, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,930.16 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19720615\", \"value_r\": \"19720615\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06425098017588118, \"u_probability\": 0.9992422097584438, \"bayes_factor\": 0.06429970586552101, \"log2_bayes_factor\": -3.9590440517133336, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.55 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"9499826\", \"value_r\": \"7563426\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 0.23527898361193694, \"log2_bayes_factor\": -2.087555637873725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 62\", \"value_r\": \" 26\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2318711278820771, \"u_probability\": 0.9855156815218112, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.25 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 0.2300722889173896, \"log2_bayes_factor\": -2.119840866427398, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"370\", \"value_r\": \"3070\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22977614195518548, \"u_probability\": 0.9987128090758012, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.436528196979793, \"bayes_factor\": 0.00018039810484390308, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 9}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.prediction_errors_from_labels_column(\"cluster\").as_record_dict(\n",
    "    limit=10\n",
    ")\n",
    "linker.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "94aaeff2f888492ea321d4e4492526ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bdf3a462cd3d48bda4269ac1cc8ed9ef",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e05a7090510949ac956ea05719a3b8c2",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "b179423ef9d24cb1ac973b4b55daa86c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "bdf3a462cd3d48bda4269ac1cc8ed9ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "db3fd6bdb9884f5a88fd4cf5d39330d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "e05a7090510949ac956ea05719a3b8c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "e181cb7618b74e4bbf9f2e144b68b87e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b179423ef9d24cb1ac973b4b55daa86c",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_db3fd6bdb9884f5a88fd4cf5d39330d4",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
