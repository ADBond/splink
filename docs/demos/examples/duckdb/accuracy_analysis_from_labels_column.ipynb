{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation when you have fully labelled data\n",
    "\n",
    "In this example, our data contains a fully-populated ground-truth column called `cluster` that enables us to perform accuracy analysis of the final model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/moj-analytical-services/splink/blob/splink4_dev/docs/demos/examples/duckdb/accuracy_analysis_from_labels_column.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:16.264709Z",
     "iopub.status.busy": "2024-06-07T09:09:16.264397Z",
     "iopub.status.idle": "2024-06-07T09:09:16.269613Z",
     "shell.execute_reply": "2024-06-07T09:09:16.268968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're running in Google Colab.\n",
    "# !pip install git+https://github.com/moj-analytical-services/splink.git@splink4_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:16.273849Z",
     "iopub.status.busy": "2024-06-07T09:09:16.273306Z",
     "iopub.status.idle": "2024-06-07T09:09:17.467426Z",
     "shell.execute_reply": "2024-06-07T09:09:17.466787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>city</th>\n",
       "      <th>email</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Alan</td>\n",
       "      <td>1971-06-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robert255@smith.net</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Allen</td>\n",
       "      <td>1971-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta25@smith.net</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id first_name surname         dob city                email  cluster\n",
       "0          0     Robert    Alan  1971-06-24  NaN  robert255@smith.net        0\n",
       "1          1     Robert   Allen  1971-05-24  NaN  roberta25@smith.net        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import splink_datasets\n",
    "\n",
    "df = splink_datasets.fake_1000\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:17.501913Z",
     "iopub.status.busy": "2024-06-07T09:09:17.501641Z",
     "iopub.status.idle": "2024-06-07T09:09:17.581434Z",
     "shell.execute_reply": "2024-06-07T09:09:17.580667Z"
    }
   },
   "outputs": [],
   "source": [
    "from splink import SettingsCreator, Linker, block_on, DuckDBAPI\n",
    "import splink.comparison_template_library as ctl\n",
    "import splink.comparison_library as cl\n",
    "\n",
    "settings = SettingsCreator(\n",
    "    link_type=\"dedupe_only\",\n",
    "    blocking_rules_to_generate_predictions=[\n",
    "        block_on(\"first_name\"),\n",
    "        block_on(\"surname\"),\n",
    "    ],\n",
    "    comparisons=[\n",
    "        ctl.NameComparison(\"first_name\"),\n",
    "        ctl.NameComparison(\"surname\"),\n",
    "        ctl.DateComparison(\n",
    "            \"dob\",\n",
    "            input_is_string=True,\n",
    "            datetime_metrics=[\"month\", \"year\", \"year\"],\n",
    "            datetime_thresholds=[1, 1, 10],\n",
    "        ),\n",
    "        cl.ExactMatch(\"city\").configure(term_frequency_adjustments=True),\n",
    "        ctl.EmailComparison(\"email\", include_username_fuzzy_level=False),\n",
    "    ],\n",
    "    retain_intermediate_calculation_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:17.585114Z",
     "iopub.status.busy": "2024-06-07T09:09:17.584837Z",
     "iopub.status.idle": "2024-06-07T09:09:17.847471Z",
     "shell.execute_reply": "2024-06-07T09:09:17.846845Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.00333.\n",
      "This means that amongst all possible pairwise record comparisons, one in 300.13 are expected to match.  With 499,500 total possible comparisons, we expect a total of around 1,664.29 matching pairs\n"
     ]
    }
   ],
   "source": [
    "db_api = DuckDBAPI()\n",
    "linker = Linker(df, settings, database_api=db_api)\n",
    "deterministic_rules = [\n",
    "    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.surname = r.surname and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) <= 2\",\n",
    "    \"l.email = r.email\",\n",
    "]\n",
    "\n",
    "linker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:17.850459Z",
     "iopub.status.busy": "2024-06-07T09:09:17.850216Z",
     "iopub.status.idle": "2024-06-07T09:09:18.931010Z",
     "shell.execute_reply": "2024-06-07T09:09:18.930397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated u probabilities using random sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - dob (no m values are trained).\n",
      "    - city (no m values are trained).\n",
      "    - email (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.training.estimate_u_using_random_sampling(max_pairs=1e6, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:18.934824Z",
     "iopub.status.busy": "2024-06-07T09:09:18.934551Z",
     "iopub.status.idle": "2024-06-07T09:09:20.495494Z",
     "shell.execute_reply": "2024-06-07T09:09:20.494833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"dob\" = r.\"dob\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - city\n",
      "    - email\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - dob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.417 in the m_probability of surname, level `Exact match on surname`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was 0.121 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 0.0354 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was 0.0127 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 5: Largest change in params was 0.00539 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 6: Largest change in params was 0.0025 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 7: Largest change in params was 0.0012 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 8: Largest change in params was 0.000599 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 9: Largest change in params was 0.000313 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 10: Largest change in params was 0.000186 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 11: Largest change in params was 0.000147 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 12: Largest change in params was 0.000158 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 13: Largest change in params was 0.000184 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 14: Largest change in params was 0.000195 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 15: Largest change in params was 0.000179 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 16: Largest change in params was 0.000144 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 17: Largest change in params was 0.000105 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 18: Largest change in params was 7.27e-05 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 18 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - dob (no m values are trained).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"email\" = r.\"email\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - dob\n",
      "    - city\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - email\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.466 in the m_probability of dob, level `Exact match on dob`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was 0.0884 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 0.0193 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was 0.00688 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 5: Largest change in params was 0.00294 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 6: Largest change in params was 0.00138 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 7: Largest change in params was 0.000681 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 8: Largest change in params was 0.000346 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 9: Largest change in params was 0.000178 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 10: Largest change in params was 9.26e-05 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 10 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n"
     ]
    }
   ],
   "source": [
    "session_dob = linker.training.estimate_parameters_using_expectation_maximisation(block_on(\"dob\"))\n",
    "session_email = linker.training.estimate_parameters_using_expectation_maximisation(\n",
    "    block_on(\"email\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:20.498372Z",
     "iopub.status.busy": "2024-06-07T09:09:20.498155Z",
     "iopub.status.idle": "2024-06-07T09:09:20.768827Z",
     "shell.execute_reply": "2024-06-07T09:09:20.768326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth_threshold</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>total_clerical_labels</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>P_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>npv</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f0_5</th>\n",
       "      <th>p4</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-19.3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>499500.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>497469.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>495147.0</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306659</td>\n",
       "      <td>0.505662</td>\n",
       "      <td>0.995332</td>\n",
       "      <td>0.997976</td>\n",
       "      <td>0.993341</td>\n",
       "      <td>0.381784</td>\n",
       "      <td>0.447573</td>\n",
       "      <td>0.332858</td>\n",
       "      <td>0.552084</td>\n",
       "      <td>0.390667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-19.2</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>499500.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>497469.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>495383.0</td>\n",
       "      <td>2086.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329907</td>\n",
       "      <td>0.505662</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.997977</td>\n",
       "      <td>0.993814</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.456973</td>\n",
       "      <td>0.354554</td>\n",
       "      <td>0.570207</td>\n",
       "      <td>0.405492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-18.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>499500.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>497469.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>495584.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352679</td>\n",
       "      <td>0.505662</td>\n",
       "      <td>0.996211</td>\n",
       "      <td>0.997978</td>\n",
       "      <td>0.994216</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.465295</td>\n",
       "      <td>0.375393</td>\n",
       "      <td>0.586607</td>\n",
       "      <td>0.419506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.1</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>499500.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>497469.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>495836.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386090</td>\n",
       "      <td>0.505662</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.997979</td>\n",
       "      <td>0.994721</td>\n",
       "      <td>0.437860</td>\n",
       "      <td>0.476168</td>\n",
       "      <td>0.405256</td>\n",
       "      <td>0.608551</td>\n",
       "      <td>0.439259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>499500.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>497469.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>495957.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404490</td>\n",
       "      <td>0.505662</td>\n",
       "      <td>0.996961</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>0.994963</td>\n",
       "      <td>0.449453</td>\n",
       "      <td>0.481572</td>\n",
       "      <td>0.421351</td>\n",
       "      <td>0.619682</td>\n",
       "      <td>0.449767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   truth_threshold  match_probability  total_clerical_labels       p  \\\n",
       "0            -19.3           0.000002               499500.0  2031.0   \n",
       "1            -19.2           0.000002               499500.0  2031.0   \n",
       "2            -18.0           0.000004               499500.0  2031.0   \n",
       "3            -17.1           0.000007               499500.0  2031.0   \n",
       "4            -17.0           0.000008               499500.0  2031.0   \n",
       "\n",
       "          n      tp        tn      fp      fn    P_rate  ...  precision  \\\n",
       "0  497469.0  1027.0  495147.0  2322.0  1004.0  0.004066  ...   0.306659   \n",
       "1  497469.0  1027.0  495383.0  2086.0  1004.0  0.004066  ...   0.329907   \n",
       "2  497469.0  1027.0  495584.0  1885.0  1004.0  0.004066  ...   0.352679   \n",
       "3  497469.0  1027.0  495836.0  1633.0  1004.0  0.004066  ...   0.386090   \n",
       "4  497469.0  1027.0  495957.0  1512.0  1004.0  0.004066  ...   0.404490   \n",
       "\n",
       "     recall  specificity       npv  accuracy        f1        f2      f0_5  \\\n",
       "0  0.505662     0.995332  0.997976  0.993341  0.381784  0.447573  0.332858   \n",
       "1  0.505662     0.995807  0.997977  0.993814  0.399300  0.456973  0.354554   \n",
       "2  0.505662     0.996211  0.997978  0.994216  0.415537  0.465295  0.375393   \n",
       "3  0.505662     0.996717  0.997979  0.994721  0.437860  0.476168  0.405256   \n",
       "4  0.505662     0.996961  0.997980  0.994963  0.449453  0.481572  0.421351   \n",
       "\n",
       "         p4       phi  \n",
       "0  0.552084  0.390667  \n",
       "1  0.570207  0.405492  \n",
       "2  0.586607  0.419506  \n",
       "3  0.608551  0.439259  \n",
       "4  0.619682  0.449767  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.evaluation.accuracy_analysis_from_labels_column(\n",
    "    \"cluster\", output_type=\"table\"\n",
    ").as_pandas_dataframe(limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:20.771736Z",
     "iopub.status.busy": "2024-06-07T09:09:20.771453Z",
     "iopub.status.idle": "2024-06-07T09:09:21.322647Z",
     "shell.execute_reply": "2024-06-07T09:09:21.322088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ec1b2ff94e6649cc8fea1c786c85fca9.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ec1b2ff94e6649cc8fea1c786c85fca9.vega-embed details,\n",
       "  #altair-viz-ec1b2ff94e6649cc8fea1c786c85fca9.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ec1b2ff94e6649cc8fea1c786c85fca9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ec1b2ff94e6649cc8fea1c786c85fca9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ec1b2ff94e6649cc8fea1c786c85fca9\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-61ba03f1bd78f59f5627d2d5820e38c6\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-61ba03f1bd78f59f5627d2d5820e38c6\": [{\"truth_threshold\": -19.30000028759241, \"match_probability\": 1.549245788689352e-06, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 495147.0, \"fp\": 2322.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9953323724694403, \"fp_rate\": 0.004667627530559693, \"fn_rate\": 0.49433776464795665, \"precision\": 0.30665870409077334, \"recall\": 0.5056622353520434, \"specificity\": 0.9953323724694403, \"npv\": 0.9979764225004082, \"accuracy\": 0.9933413413413413, \"f1\": 0.38178438661710035, \"f2\": 0.4475725616665214, \"f0_5\": 0.3328579762753614, \"p4\": 0.5520838600447853, \"phi\": 0.3906668091548052}, {\"truth_threshold\": -19.200000286102295, \"match_probability\": 1.66044034034615e-06, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 495383.0, \"fp\": 2086.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9958067738894283, \"fp_rate\": 0.004193226110571714, \"fn_rate\": 0.49433776464795665, \"precision\": 0.3299068422743334, \"recall\": 0.5056622353520434, \"specificity\": 0.9958067738894283, \"npv\": 0.9979773845809822, \"accuracy\": 0.9938138138138138, \"f1\": 0.39930015552099535, \"f2\": 0.4569725015573552, \"f0_5\": 0.3545536145826141, \"p4\": 0.5702066197429636, \"phi\": 0.4054920201274509}, {\"truth_threshold\": -18.0000002682209, \"match_probability\": 3.8146820045553597e-06, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 495584.0, \"fp\": 1885.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9962108191666215, \"fp_rate\": 0.0037891808333785624, \"fn_rate\": 0.49433776464795665, \"precision\": 0.35267857142857145, \"recall\": 0.5056622353520434, \"specificity\": 0.9962108191666215, \"npv\": 0.9979782032590397, \"accuracy\": 0.9942162162162163, \"f1\": 0.4155371232045317, \"f2\": 0.4652953968829286, \"f0_5\": 0.375392938080269, \"p4\": 0.5866068392152763, \"phi\": 0.4195058838683131}, {\"truth_threshold\": -17.100000254809856, \"match_probability\": 7.118424873502875e-06, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 495836.0, \"fp\": 1633.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9967173833947442, \"fp_rate\": 0.003282616605255805, \"fn_rate\": 0.49433776464795665, \"precision\": 0.38609022556390976, \"recall\": 0.5056622353520434, \"specificity\": 0.9967173833947442, \"npv\": 0.9979792287255455, \"accuracy\": 0.9947207207207207, \"f1\": 0.43785973140055423, \"f2\": 0.47616839762611274, \"f0_5\": 0.40525609659853207, \"p4\": 0.6085509510670755, \"phi\": 0.4392592241697643}, {\"truth_threshold\": -17.00000025331974, \"match_probability\": 7.629334984424643e-06, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 495957.0, \"fp\": 1512.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9969606146312635, \"fp_rate\": 0.0030393853687365443, \"fn_rate\": 0.49433776464795665, \"precision\": 0.40448995667585663, \"recall\": 0.5056622353520434, \"specificity\": 0.9969606146312635, \"npv\": 0.9979797207426739, \"accuracy\": 0.9949629629629629, \"f1\": 0.44945295404814006, \"f2\": 0.48157179030291664, \"f0_5\": 0.4213506195125954, \"p4\": 0.6196816822759246, \"phi\": 0.4497671133997727}, {\"truth_threshold\": -16.600000247359276, \"match_probability\": 1.0066943367963594e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 496056.0, \"fp\": 1413.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9971596220065974, \"fp_rate\": 0.002840377993402604, \"fn_rate\": 0.49433776464795665, \"precision\": 0.4209016393442623, \"recall\": 0.5056622353520434, \"specificity\": 0.9971596220065974, \"npv\": 0.9979801231239689, \"accuracy\": 0.9951611611611612, \"f1\": 0.4594050547975844, \"f2\": 0.4860848163574404, \"f0_5\": 0.4355016538037486, \"p4\": 0.6290960934518653, \"phi\": 0.4589367122141537}, {\"truth_threshold\": -16.50000024586916, \"match_probability\": 1.0789474965962542e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 496067.0, \"fp\": 1402.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.99718173393719, \"fp_rate\": 0.002818266062809944, \"fn_rate\": 0.49433776464795665, \"precision\": 0.42280773981062164, \"recall\": 0.5056622353520434, \"specificity\": 0.99718173393719, \"npv\": 0.9979801678231077, \"accuracy\": 0.9951831831831832, \"f1\": 0.4605381165919282, \"f2\": 0.4865914905714015, \"f0_5\": 0.43713288499191283, \"p4\": 0.630159826144145, \"phi\": 0.4599898495656788}, {\"truth_threshold\": -15.900000236928463, \"match_probability\": 1.6353695054159956e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 496086.0, \"fp\": 1383.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9972199272718502, \"fp_rate\": 0.0027800727281498947, \"fn_rate\": 0.49433776464795665, \"precision\": 0.42614107883817426, \"recall\": 0.5056622353520434, \"specificity\": 0.9972199272718502, \"npv\": 0.9979802450260516, \"accuracy\": 0.9952212212212213, \"f1\": 0.4625084440441342, \"f2\": 0.4874691475223087, \"f0_5\": 0.43997943620940794, \"p4\": 0.6320056802051437, \"phi\": 0.46182577727943097}, {\"truth_threshold\": -15.800000235438347, \"match_probability\": 1.7527435818536736e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 496149.0, \"fp\": 1320.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9973465683288808, \"fp_rate\": 0.0026534316711192053, \"fn_rate\": 0.49433776464795665, \"precision\": 0.43757988922028124, \"recall\": 0.5056622353520434, \"specificity\": 0.9973465683288808, \"npv\": 0.9979805009725377, \"accuracy\": 0.9953473473473473, \"f1\": 0.46916400182731843, \"f2\": 0.49040206284022536, \"f0_5\": 0.4496891146335056, \"p4\": 0.6382042737022956, \"phi\": 0.4680712667977883}, {\"truth_threshold\": -15.500000230967999, \"match_probability\": 2.1578717331772276e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1027.0, \"tn\": 496172.0, \"fp\": 1297.0, \"fn\": 1004.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 0.9973928023655746, \"fp_rate\": 0.0026071976344254617, \"fn_rate\": 0.49433776464795665, \"precision\": 0.4419104991394148, \"recall\": 0.5056622353520434, \"specificity\": 0.9973928023655746, \"npv\": 0.9979805943971551, \"accuracy\": 0.9953933933933934, \"f1\": 0.4716417910447761, \"f2\": 0.49148162327718226, \"f0_5\": 0.4533415732321003, \"p4\": 0.6404976580873983, \"phi\": 0.4704141054971495}, {\"truth_threshold\": -14.400000214576721, \"match_probability\": 4.625385233621647e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496330.0, \"fp\": 1139.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9977104100959054, \"fp_rate\": 0.0022895899040945265, \"fn_rate\": 0.4948301329394387, \"precision\": 0.4739030023094688, \"recall\": 0.5051698670605613, \"specificity\": 0.9977104100959054, \"npv\": 0.997979229292127, \"accuracy\": 0.9957077077077077, \"f1\": 0.4890371782650143, \"f2\": 0.49859072796190107, \"f0_5\": 0.4798428584790946, \"p4\": 0.6563845856325707, \"phi\": 0.48713475282823193}, {\"truth_threshold\": -14.300000213086605, \"match_probability\": 4.957348695121048e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496331.0, \"fp\": 1138.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9977124202714139, \"fp_rate\": 0.002287579728586103, \"fn_rate\": 0.4948301329394387, \"precision\": 0.47412199630314233, \"recall\": 0.5051698670605613, \"specificity\": 0.9977124202714139, \"npv\": 0.9979792333553171, \"accuracy\": 0.9957097097097097, \"f1\": 0.4891537544696067, \"f2\": 0.49863919129082424, \"f0_5\": 0.4800224571909797, \"p4\": 0.6564898011289704, \"phi\": 0.4872487518946398}, {\"truth_threshold\": -13.40000019967556, \"match_probability\": 9.25034269879762e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496436.0, \"fp\": 1033.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9979234886997984, \"fp_rate\": 0.0020765113002016206, \"fn_rate\": 0.4948301329394387, \"precision\": 0.498300145701797, \"recall\": 0.5051698670605613, \"specificity\": 0.9979234886997984, \"npv\": 0.997979659899365, \"accuracy\": 0.9959199199199199, \"f1\": 0.5017114914425428, \"f2\": 0.5037808111558479, \"f0_5\": 0.49965910197720853, \"p4\": 0.6677283504996344, \"phi\": 0.4996749671496337}, {\"truth_threshold\": -13.300000198185444, \"match_probability\": 9.914206010875549e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496488.0, \"fp\": 981.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9980280178262364, \"fp_rate\": 0.0019719821737635914, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5112107623318386, \"recall\": 0.5051698670605613, \"specificity\": 0.9980280178262364, \"npv\": 0.9979798710735629, \"accuracy\": 0.996024024024024, \"f1\": 0.5081723625557206, \"f2\": 0.5063665975718094, \"f0_5\": 0.5099910527885476, \"p4\": 0.6734377905595093, \"phi\": 0.5061853906759526}, {\"truth_threshold\": -13.200000196695328, \"match_probability\": 0.00010625707305470121, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496533.0, \"fp\": 936.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9981184757241155, \"fp_rate\": 0.0018815242758845275, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5229357798165137, \"recall\": 0.5051698670605613, \"specificity\": 0.9981184757241155, \"npv\": 0.9979800537848366, \"accuracy\": 0.9961141141141141, \"f1\": 0.5138993238166792, \"f2\": 0.5086258179654968, \"f0_5\": 0.5192833282720923, \"p4\": 0.6784580445813054, \"phi\": 0.5120262362648247}, {\"truth_threshold\": -13.100000195205212, \"match_probability\": 0.00011388264270550263, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496537.0, \"fp\": 932.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9981265164261491, \"fp_rate\": 0.001873483573850833, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5240040858018387, \"recall\": 0.5051698670605613, \"specificity\": 0.9981265164261491, \"npv\": 0.9979800700242392, \"accuracy\": 0.9961221221221221, \"f1\": 0.5144146402607169, \"f2\": 0.5088276135687364, \"f0_5\": 0.5201257223968366, \"p4\": 0.6789079139975555, \"phi\": 0.512555107149103}, {\"truth_threshold\": -12.800000190734863, \"match_probability\": 0.00014020228918616167, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496555.0, \"fp\": 914.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9981626995853008, \"fp_rate\": 0.0018373004146992073, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5288659793814433, \"recall\": 0.5051698670605613, \"specificity\": 0.9981626995853008, \"npv\": 0.9979801430983198, \"accuracy\": 0.9961581581581581, \"f1\": 0.5167464114832536, \"f2\": 0.509737678855326, \"f0_5\": 0.5239505668471045, \"p4\": 0.6809397311477347, \"phi\": 0.5149551544116822}, {\"truth_threshold\": -12.200000181794167, \"match_probability\": 0.00021249156957169895, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496575.0, \"fp\": 894.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9982029030954692, \"fp_rate\": 0.0017970969045307346, \"fn_rate\": 0.4948301329394387, \"precision\": 0.534375, \"recall\": 0.5051698670605613, \"specificity\": 0.9982029030954692, \"npv\": 0.997980224285542, \"accuracy\": 0.9961981981981982, \"f1\": 0.5193621867881549, \"f2\": 0.510752688172043, \"f0_5\": 0.5282669138090825, \"p4\": 0.683211616514616, \"phi\": 0.5176612057665209}, {\"truth_threshold\": -12.10000018030405, \"match_probability\": 0.0002277393522037113, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496603.0, \"fp\": 866.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9982591880097051, \"fp_rate\": 0.0017408119902948727, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5422832980972516, \"recall\": 0.5051698670605613, \"specificity\": 0.9982591880097051, \"npv\": 0.9979803379366892, \"accuracy\": 0.9962542542542543, \"f1\": 0.5230690797858781, \"f2\": 0.5121805111821086, \"f0_5\": 0.5344306698614439, \"p4\": 0.6864178434080551, \"phi\": 0.5215212476758672}, {\"truth_threshold\": -11.900000177323818, \"match_probability\": 0.0002615949610108224, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496624.0, \"fp\": 845.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983014016953821, \"fp_rate\": 0.0016985983046179762, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5483698556921432, \"recall\": 0.5051698670605613, \"specificity\": 0.9983014016953821, \"npv\": 0.9979804231666562, \"accuracy\": 0.9962962962962963, \"f1\": 0.5258841619682214, \"f2\": 0.5132566283141571, \"f0_5\": 0.5391487125591172, \"p4\": 0.6888423312645094, \"phi\": 0.5244727524688039}, {\"truth_threshold\": -11.800000175833702, \"match_probability\": 0.0002803652734145845, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496637.0, \"fp\": 832.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983275339769915, \"fp_rate\": 0.0016724660230084689, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5522066738428417, \"recall\": 0.5051698670605613, \"specificity\": 0.9983275339769915, \"npv\": 0.9979804759244597, \"accuracy\": 0.9963223223223223, \"f1\": 0.5276420673695037, \"f2\": 0.513925065117211, \"f0_5\": 0.5421113811687626, \"p4\": 0.6903518062146036, \"phi\": 0.5263248046521227}, {\"truth_threshold\": -11.000000163912773, \"match_probability\": 0.00048804289235713973, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496641.0, \"fp\": 828.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983355746790252, \"fp_rate\": 0.0016644253209747743, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5533980582524272, \"recall\": 0.5051698670605613, \"specificity\": 0.9983355746790252, \"npv\": 0.9979804921570755, \"accuracy\": 0.9963303303303304, \"f1\": 0.5281853281853282, \"f2\": 0.5141310883944679, \"f0_5\": 0.5430295331851381, \"p4\": 0.690817591837267, \"phi\": 0.5268985676481476}, {\"truth_threshold\": -10.900000162422657, \"match_probability\": 0.0005230530993675534, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496646.0, \"fp\": 823.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983456255565674, \"fp_rate\": 0.0016543744434326562, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5548945375878853, \"recall\": 0.5051698670605613, \"specificity\": 0.9983456255565674, \"npv\": 0.9979805124474782, \"accuracy\": 0.9963403403403404, \"f1\": 0.5288659793814433, \"f2\": 0.5143888498947158, \"f0_5\": 0.5441816060252467, \"p4\": 0.6914007084716597, \"phi\": 0.5276183783515087}, {\"truth_threshold\": -10.700000159442425, \"match_probability\": 0.0006007835088396779, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496649.0, \"fp\": 820.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983516560830926, \"fp_rate\": 0.0016483439169073851, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5557963163596966, \"recall\": 0.5051698670605613, \"specificity\": 0.9983516560830926, \"npv\": 0.9979805246215242, \"accuracy\": 0.9963463463463463, \"f1\": 0.529275212793397, \"f2\": 0.5145436308926781, \"f0_5\": 0.544875199150292, \"p4\": 0.6917510511984236, \"phi\": 0.5280516626737817}, {\"truth_threshold\": -10.600000157952309, \"match_probability\": 0.0006438760580315065, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496656.0, \"fp\": 813.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983657273116516, \"fp_rate\": 0.0016342726883484197, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5579119086460033, \"recall\": 0.5051698670605613, \"specificity\": 0.9983657273116516, \"npv\": 0.9979805530270606, \"accuracy\": 0.9963603603603604, \"f1\": 0.5302325581395348, \"f2\": 0.5149051490514905, \"f0_5\": 0.5465004793863855, \"p4\": 0.6925698999011948, \"phi\": 0.5290667643082287}, {\"truth_threshold\": -9.700000144541264, \"match_probability\": 0.001200845581852835, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496667.0, \"fp\": 802.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983878392422443, \"fp_rate\": 0.0016121607577557597, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5612691466083151, \"recall\": 0.5051698670605613, \"specificity\": 0.9983878392422443, \"npv\": 0.9979805976627176, \"accuracy\": 0.9963823823823824, \"f1\": 0.5317439751230889, \"f2\": 0.5154742765273312, \"f0_5\": 0.5490741731777802, \"p4\": 0.6938605861076456, \"phi\": 0.5306736459214381}, {\"truth_threshold\": -9.400000140070915, \"match_probability\": 0.001478004086219237, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496670.0, \"fp\": 799.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983938697687695, \"fp_rate\": 0.0016061302312304886, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5621917808219178, \"recall\": 0.5051698670605613, \"specificity\": 0.9983938697687695, \"npv\": 0.9979806098357362, \"accuracy\": 0.9963883883883884, \"f1\": 0.5321576763485477, \"f2\": 0.5156297115287969, \"f0_5\": 0.5497803022184118, \"p4\": 0.6942134267544686, \"phi\": 0.5311143966305074}, {\"truth_threshold\": -9.300000138580799, \"match_probability\": 0.0015839175344616876, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496672.0, \"fp\": 797.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983978901197864, \"fp_rate\": 0.0016021098802136416, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5628085573230938, \"recall\": 0.5051698670605613, \"specificity\": 0.9983978901197864, \"npv\": 0.9979806179510003, \"accuracy\": 0.9963923923923924, \"f1\": 0.5324338349766476, \"f2\": 0.5157333869508395, \"f0_5\": 0.5502520647860131, \"p4\": 0.6944488532771046, \"phi\": 0.531408832485679}, {\"truth_threshold\": -8.600000128149986, \"match_probability\": 0.0025705389597152823, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496910.0, \"fp\": 559.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9988763118907912, \"fp_rate\": 0.001123688109208815, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6473186119873817, \"recall\": 0.5051698670605613, \"specificity\": 0.9988763118907912, \"npv\": 0.9979815832019522, \"accuracy\": 0.9968688688688688, \"f1\": 0.5674778761061947, \"f2\": 0.5283757338551859, \"f0_5\": 0.6128300083622028, \"p4\": 0.7236526322200384, \"phi\": 0.5703166643731759}, {\"truth_threshold\": -8.400000125169754, \"match_probability\": 0.0029516456585356845, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496912.0, \"fp\": 557.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.998880332241808, \"fp_rate\": 0.0011196677581919677, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6481364497789008, \"recall\": 0.5051698670605613, \"specificity\": 0.998880332241808, \"npv\": 0.9979815913093949, \"accuracy\": 0.9968728728728729, \"f1\": 0.5677919203099059, \"f2\": 0.528484598743175, \"f0_5\": 0.6134162381920364, \"p4\": 0.7239084525411419, \"phi\": 0.5706802321645739}, {\"truth_threshold\": -8.100000120699406, \"match_probability\": 0.003631424511270156, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496914.0, \"fp\": 555.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9988843525928249, \"fp_rate\": 0.0011156474071751204, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6489563567362429, \"recall\": 0.5051698670605613, \"specificity\": 0.9988843525928249, \"npv\": 0.9979815994167726, \"accuracy\": 0.9968768768768769, \"f1\": 0.5681063122923588, \"f2\": 0.5285935085007728, \"f0_5\": 0.6140035906642729, \"p4\": 0.7241644537933594, \"phi\": 0.571044487455106}, {\"truth_threshold\": -7.200000107288361, \"match_probability\": 0.006755232248084272, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 497008.0, \"fp\": 461.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9990733090906168, \"fp_rate\": 0.0009266909093832982, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6899798251513114, \"recall\": 0.5051698670605613, \"specificity\": 0.9990733090906168, \"npv\": 0.9979819803900701, \"accuracy\": 0.9970650650650651, \"f1\": 0.5832859579306424, \"f2\": 0.5337633961086256, \"f0_5\": 0.6429377114926682, \"p4\": 0.7364041991592148, \"phi\": 0.5889822118679692}, {\"truth_threshold\": -7.1000001057982445, \"match_probability\": 0.007236570039195372, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1025.0, \"tn\": 497054.0, \"fp\": 415.0, \"fn\": 1006.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5046774987690793, \"tn_rate\": 0.9991657771640042, \"fp_rate\": 0.0008342228359958108, \"fn_rate\": 0.49532250123092075, \"precision\": 0.7118055555555556, \"recall\": 0.5046774987690793, \"specificity\": 0.9991657771640042, \"npv\": 0.9979801630325663, \"accuracy\": 0.9971551551551552, \"f1\": 0.5906078939786805, \"f2\": 0.5358636553743203, \"f0_5\": 0.6578102939288923, \"p4\": 0.7422251487416562, \"phi\": 0.5980140146049732}, {\"truth_threshold\": -6.600000098347664, \"match_probability\": 0.010203470791514735, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1025.0, \"tn\": 497107.0, \"fp\": 362.0, \"fn\": 1006.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5046774987690793, \"tn_rate\": 0.9992723164659506, \"fp_rate\": 0.0007276835340493578, \"fn_rate\": 0.49532250123092075, \"precision\": 0.7390050468637347, \"recall\": 0.5046774987690793, \"specificity\": 0.9992723164659506, \"npv\": 0.9979803779463696, \"accuracy\": 0.9972612612612612, \"f1\": 0.5997659449970744, \"f2\": 0.5388497529176742, \"f0_5\": 0.6762105818709593, \"p4\": 0.7494305167951033, \"phi\": 0.6094289693343778}, {\"truth_threshold\": -6.000000089406967, \"match_probability\": 0.015384614445865122, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1025.0, \"tn\": 497123.0, \"fp\": 346.0, \"fn\": 1006.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5046774987690793, \"tn_rate\": 0.9993044792740854, \"fp_rate\": 0.0006955207259145796, \"fn_rate\": 0.49532250123092075, \"precision\": 0.7476294675419402, \"recall\": 0.5046774987690793, \"specificity\": 0.9993044792740854, \"npv\": 0.9979804428170213, \"accuracy\": 0.9972932932932933, \"f1\": 0.6025867136978248, \"f2\": 0.539757767245919, \"f0_5\": 0.6819693945442449, \"p4\": 0.751633293636175, \"phi\": 0.6130040436010974}, {\"truth_threshold\": -5.900000087916851, \"match_probability\": 0.016470634520449206, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1023.0, \"tn\": 497167.0, \"fp\": 302.0, \"fn\": 1008.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5036927621861153, \"tn_rate\": 0.9993929269964561, \"fp_rate\": 0.0006070730035439394, \"fn_rate\": 0.4963072378138848, \"precision\": 0.7720754716981132, \"recall\": 0.5036927621861153, \"specificity\": 0.9993929269964561, \"npv\": 0.9979766146434486, \"accuracy\": 0.9973773773773774, \"f1\": 0.6096543504171633, \"f2\": 0.5413271245634459, \"f0_5\": 0.6977220024553267, \"p4\": 0.7571194297807958, \"phi\": 0.6224164076915241}, {\"truth_threshold\": -5.600000083446503, \"match_probability\": 0.02020082327925431, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1023.0, \"tn\": 497194.0, \"fp\": 275.0, \"fn\": 1008.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5036927621861153, \"tn_rate\": 0.9994472017351835, \"fp_rate\": 0.0005527982648165012, \"fn_rate\": 0.4963072378138848, \"precision\": 0.788135593220339, \"recall\": 0.5036927621861153, \"specificity\": 0.9994472017351835, \"npv\": 0.9979767243005849, \"accuracy\": 0.9974314314314314, \"f1\": 0.614598978672274, \"f2\": 0.542878369772872, \"f0_5\": 0.7081545064377682, \"p4\": 0.7609286094405532, \"phi\": 0.6289074042142978}, {\"truth_threshold\": -5.000000074505806, \"match_probability\": 0.030303028785498974, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1022.0, \"tn\": 497295.0, \"fp\": 174.0, \"fn\": 1009.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5032003938946332, \"tn_rate\": 0.9996502294615343, \"fp_rate\": 0.00034977053846571343, \"fn_rate\": 0.49679960610536683, \"precision\": 0.8545150501672241, \"recall\": 0.5032003938946332, \"specificity\": 0.9996502294615343, \"npv\": 0.997975131646545, \"accuracy\": 0.9976316316316316, \"f1\": 0.6334056399132321, \"f2\": 0.5482832618025751, \"f0_5\": 0.7498165810711666, \"p4\": 0.7752068513314447, \"phi\": 0.6547329374104119}, {\"truth_threshold\": -4.500000067055225, \"match_probability\": 0.04232371044088178, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1021.0, \"tn\": 497295.0, \"fp\": 174.0, \"fn\": 1010.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5027080256031512, \"tn_rate\": 0.9996502294615343, \"fp_rate\": 0.00034977053846571343, \"fn_rate\": 0.49729197439684886, \"precision\": 0.8543933054393306, \"recall\": 0.5027080256031512, \"specificity\": 0.9996502294615343, \"npv\": 0.9979731289069947, \"accuracy\": 0.9976296296296296, \"f1\": 0.6329820210787352, \"f2\": 0.5478055585363236, \"f0_5\": 0.7495228307150198, \"p4\": 0.7748892061614011, \"phi\": 0.6543648176926443}, {\"truth_threshold\": -4.400000065565109, \"match_probability\": 0.04522405175894309, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1021.0, \"tn\": 497297.0, \"fp\": 172.0, \"fn\": 1010.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5027080256031512, \"tn_rate\": 0.9996542498125511, \"fp_rate\": 0.00034575018744886614, \"fn_rate\": 0.49729197439684886, \"precision\": 0.8558256496227996, \"recall\": 0.5027080256031512, \"specificity\": 0.9996542498125511, \"npv\": 0.9979731370420243, \"accuracy\": 0.9976336336336337, \"f1\": 0.6333746898263027, \"f2\": 0.5479231512289363, \"f0_5\": 0.7504042334264295, \"p4\": 0.7751839749617189, \"phi\": 0.6549170185726637}, {\"truth_threshold\": -4.300000064074993, \"match_probability\": 0.048313119674570026, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1016.0, \"tn\": 497331.0, \"fp\": 138.0, \"fn\": 1015.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5002461841457411, \"tn_rate\": 0.9997225957798376, \"fp_rate\": 0.0002774042201624624, \"fn_rate\": 0.499753815854259, \"precision\": 0.8804159445407279, \"recall\": 0.5002461841457411, \"specificity\": 0.9997225957798376, \"npv\": 0.9979632624722582, \"accuracy\": 0.9976916916916917, \"f1\": 0.6379905808477238, \"f2\": 0.5475317956456133, \"f0_5\": 0.7642545509252294, \"p4\": 0.7786402025597812, \"phi\": 0.6626931269013433}, {\"truth_threshold\": -3.500000052154064, \"match_probability\": 0.08121030044424019, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1016.0, \"tn\": 497358.0, \"fp\": 111.0, \"fn\": 1015.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5002461841457411, \"tn_rate\": 0.999776870518565, \"fp_rate\": 0.0002231294814350241, \"fn_rate\": 0.499753815854259, \"precision\": 0.90150842945874, \"recall\": 0.5002461841457411, \"specificity\": 0.999776870518565, \"npv\": 0.9979633728151405, \"accuracy\": 0.9977457457457457, \"f1\": 0.643445218492717, \"f2\": 0.5491298238028322, \"f0_5\": 0.7768771983483713, \"p4\": 0.7826974277823744, \"phi\": 0.6706389775112944}, {\"truth_threshold\": -3.400000050663948, \"match_probability\": 0.08653465658300358, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1010.0, \"tn\": 497373.0, \"fp\": 96.0, \"fn\": 1021.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.49729197439684886, \"tn_rate\": 0.9998070231511913, \"fp_rate\": 0.0001929768488086695, \"fn_rate\": 0.5027080256031512, \"precision\": 0.9132007233273056, \"recall\": 0.49729197439684886, \"specificity\": 0.9998070231511913, \"npv\": 0.9979514199609144, \"accuracy\": 0.9977637637637637, \"f1\": 0.6439273190946765, \"f2\": 0.5471289274106176, \"f0_5\": 0.7823392718822618, \"p4\": 0.7830567821679341, \"phi\": 0.6730028358352753}, {\"truth_threshold\": -3.300000049173832, \"match_probability\": 0.09217307161544283, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1010.0, \"tn\": 497376.0, \"fp\": 93.0, \"fn\": 1021.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.49729197439684886, \"tn_rate\": 0.9998130536777166, \"fp_rate\": 0.00018694632228339857, \"fn_rate\": 0.5027080256031512, \"precision\": 0.915684496826836, \"recall\": 0.49729197439684886, \"specificity\": 0.9998130536777166, \"npv\": 0.997951432291928, \"accuracy\": 0.9977697697697697, \"f1\": 0.6445437141033823, \"f2\": 0.5473068169502547, \"f0_5\": 0.7837963681514822, \"p4\": 0.7835133050035521, \"phi\": 0.6739235967040439}, {\"truth_threshold\": -3.1000000461935997, \"match_probability\": 0.10444750015659417, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1006.0, \"tn\": 497397.0, \"fp\": 72.0, \"fn\": 1025.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.49532250123092075, \"tn_rate\": 0.9998552673633935, \"fp_rate\": 0.00014473263660650212, \"fn_rate\": 0.5046774987690793, \"precision\": 0.9332096474953617, \"recall\": 0.49532250123092075, \"specificity\": 0.9998552673633935, \"npv\": 0.9979435097166658, \"accuracy\": 0.9978038038038038, \"f1\": 0.6471534255387584, \"f2\": 0.5466202999347968, \"f0_5\": 0.7930001576541069, \"p4\": 0.7854437267162243, \"phi\": 0.6790333884337372}, {\"truth_threshold\": -2.9000000432133675, \"match_probability\": 0.11814376082605058, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1006.0, \"tn\": 497403.0, \"fp\": 66.0, \"fn\": 1025.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.49532250123092075, \"tn_rate\": 0.999867328416444, \"fp_rate\": 0.00013267158355596026, \"fn_rate\": 0.5046774987690793, \"precision\": 0.9384328358208955, \"recall\": 0.49532250123092075, \"specificity\": 0.999867328416444, \"npv\": 0.9979435344723812, \"accuracy\": 0.9978158158158158, \"f1\": 0.6484047695778279, \"f2\": 0.5469769464984776, \"f0_5\": 0.7960120272194967, \"p4\": 0.7863665377686024, \"phi\": 0.6809435037441399}, {\"truth_threshold\": -2.2000000327825546, \"match_probability\": 0.1787376058900962, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1005.0, \"tn\": 497409.0, \"fp\": 60.0, \"fn\": 1026.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4948301329394387, \"tn_rate\": 0.9998793894694946, \"fp_rate\": 0.00012061053050541843, \"fn_rate\": 0.5051698670605613, \"precision\": 0.9436619718309859, \"recall\": 0.4948301329394387, \"specificity\": 0.9998793894694946, \"npv\": 0.9979415570736405, \"accuracy\": 0.9978258258258258, \"f1\": 0.6492248062015504, \"f2\": 0.5468494939601698, \"f0_5\": 0.798760133524082, \"p4\": 0.7869708587029541, \"phi\": 0.6825102432073631}, {\"truth_threshold\": -2.1000000312924385, \"match_probability\": 0.18913982061899084, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 997.0, \"tn\": 497422.0, \"fp\": 47.0, \"fn\": 1034.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.49089118660758246, \"tn_rate\": 0.9999055217511041, \"fp_rate\": 9.44782488959111e-05, \"fn_rate\": 0.5091088133924175, \"precision\": 0.9549808429118773, \"recall\": 0.49089118660758246, \"specificity\": 0.9999055217511041, \"npv\": 0.9979255942349977, \"accuracy\": 0.9978358358358358, \"f1\": 0.6484552845528455, \"f2\": 0.543739092495637, \"f0_5\": 0.8031255034638312, \"p4\": 0.7864068068316283, \"phi\": 0.6838737768956271}, {\"truth_threshold\": -1.9000000283122063, \"match_probability\": 0.2113212378007128, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 985.0, \"tn\": 497438.0, \"fp\": 31.0, \"fn\": 1046.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.48498276710979815, \"tn_rate\": 0.9999376845592388, \"fp_rate\": 6.231544076113285e-05, \"fn_rate\": 0.5150172328902018, \"precision\": 0.969488188976378, \"recall\": 0.48498276710979815, \"specificity\": 0.9999376845592388, \"npv\": 0.9979016377657056, \"accuracy\": 0.9978438438438438, \"f1\": 0.6465375779455201, \"f2\": 0.5388402625820569, \"f0_5\": 0.8080393765381461, \"p4\": 0.7849961936126697, \"phi\": 0.6849139447578817}, {\"truth_threshold\": -1.8000000268220901, \"match_probability\": 0.22310460998179016, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 984.0, \"tn\": 497443.0, \"fp\": 26.0, \"fn\": 1047.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4844903988183161, \"tn_rate\": 0.999947735436781, \"fp_rate\": 5.226456321901465e-05, \"fn_rate\": 0.5155096011816839, \"precision\": 0.9742574257425742, \"recall\": 0.4844903988183161, \"specificity\": 0.999947735436781, \"npv\": 0.9978996569640314, \"accuracy\": 0.9978518518518519, \"f1\": 0.6471555409404801, \"f2\": 0.5386468141011606, \"f0_5\": 0.8104101465985835, \"p4\": 0.7854527574255196, \"phi\": 0.6862579422850174}, {\"truth_threshold\": -1.3000000193715096, \"match_probability\": 0.2888262766358852, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 984.0, \"tn\": 497444.0, \"fp\": 25.0, \"fn\": 1047.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4844903988183161, \"tn_rate\": 0.9999497456122894, \"fp_rate\": 5.025438771059101e-05, \"fn_rate\": 0.5155096011816839, \"precision\": 0.9752229930624381, \"recall\": 0.4844903988183161, \"specificity\": 0.9999497456122894, \"npv\": 0.9978996611774335, \"accuracy\": 0.9978538538538538, \"f1\": 0.6473684210526316, \"f2\": 0.5387057921821964, \"f0_5\": 0.8109444536014505, \"p4\": 0.785609841435128, \"phi\": 0.6866000867817142}, {\"truth_threshold\": -1.0000000149011612, \"match_probability\": 0.33333333103806717, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 983.0, \"tn\": 497444.0, \"fp\": 25.0, \"fn\": 1048.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.48399803052683404, \"tn_rate\": 0.9999497456122894, \"fp_rate\": 5.025438771059101e-05, \"fn_rate\": 0.5160019694731659, \"precision\": 0.9751984126984127, \"recall\": 0.48399803052683404, \"specificity\": 0.9999497456122894, \"npv\": 0.9978976593405712, \"accuracy\": 0.9978518518518519, \"f1\": 0.6469233300427772, \"f2\": 0.5382172579938678, \"f0_5\": 0.8106547913574138, \"p4\": 0.7852817027443472, \"phi\": 0.6862417067134454}, {\"truth_threshold\": -0.9000000134110451, \"match_probability\": 0.34891031813411577, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 979.0, \"tn\": 497445.0, \"fp\": 24.0, \"fn\": 1052.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.48202855736090594, \"tn_rate\": 0.9999517557877978, \"fp_rate\": 4.824421220216737e-05, \"fn_rate\": 0.517971442639094, \"precision\": 0.9760717846460618, \"recall\": 0.48202855736090594, \"specificity\": 0.9999517557877978, \"npv\": 0.9978896563068584, \"accuracy\": 0.9978458458458458, \"f1\": 0.6453526697429136, \"f2\": 0.5363208063985976, \"f0_5\": 0.8100281317226543, \"p4\": 0.7841224998774745, \"phi\": 0.6851497940634962}, {\"truth_threshold\": -0.800000011920929, \"match_probability\": 0.36481689239780585, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 979.0, \"tn\": 497449.0, \"fp\": 20.0, \"fn\": 1052.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.48202855736090594, \"tn_rate\": 0.9999597964898316, \"fp_rate\": 4.020351016847281e-05, \"fn_rate\": 0.517971442639094, \"precision\": 0.97997997997998, \"recall\": 0.48202855736090594, \"specificity\": 0.9999597964898316, \"npv\": 0.9978896732403747, \"accuracy\": 0.9978538538538538, \"f1\": 0.6462046204620462, \"f2\": 0.5365559574701304, \"f0_5\": 0.8121785299485648, \"p4\": 0.7847522808354152, \"phi\": 0.6865287935959207}, {\"truth_threshold\": -0.7000000104308128, \"match_probability\": 0.38102425962470177, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 975.0, \"tn\": 497456.0, \"fp\": 13.0, \"fn\": 1056.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.48005908419497784, \"tn_rate\": 0.9999738677183905, \"fp_rate\": 2.6132281609507326e-05, \"fn_rate\": 0.5199409158050221, \"precision\": 0.9868421052631579, \"recall\": 0.48005908419497784, \"specificity\": 0.9999738677183905, \"npv\": 0.997881695927079, \"accuracy\": 0.9978598598598598, \"f1\": 0.6459092414706856, \"f2\": 0.5350087796312555, \"f0_5\": 0.8148086244359017, \"p4\": 0.7845353659323945, \"phi\": 0.6875317251623392}, {\"truth_threshold\": -0.6000000089406967, \"match_probability\": 0.3975010577814427, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 974.0, \"tn\": 497458.0, \"fp\": 11.0, \"fn\": 1057.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4795667159034958, \"tn_rate\": 0.9999778880694074, \"fp_rate\": 2.2111930592660045e-05, \"fn_rate\": 0.5204332840965041, \"precision\": 0.9888324873096447, \"recall\": 0.4795667159034958, \"specificity\": 0.9999778880694074, \"npv\": 0.9978797027170697, \"accuracy\": 0.9978618618618619, \"f1\": 0.6458885941644562, \"f2\": 0.5346360742123175, \"f0_5\": 0.8156087757494557, \"p4\": 0.7845204458336407, \"phi\": 0.6878753567337593}, {\"truth_threshold\": -0.4000000059604645, \"match_probability\": 0.4311259267559445, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 973.0, \"tn\": 497462.0, \"fp\": 7.0, \"fn\": 1058.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4790743476120138, \"tn_rate\": 0.999985928771441, \"fp_rate\": 1.4071228558965483e-05, \"fn_rate\": 0.5209256523879862, \"precision\": 0.9928571428571429, \"recall\": 0.4790743476120138, \"specificity\": 0.999985928771441, \"npv\": 0.9978777180454145, \"accuracy\": 0.9978678678678679, \"f1\": 0.6462969113251411, \"f2\": 0.5343804920913884, \"f0_5\": 0.81750966224164, \"p4\": 0.7848225065119834, \"phi\": 0.688927947093673}, {\"truth_threshold\": 0.10000000149011612, \"match_probability\": 0.5173217450900928, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 971.0, \"tn\": 497462.0, \"fp\": 7.0, \"fn\": 1060.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.47808961102904973, \"tn_rate\": 0.999985928771441, \"fp_rate\": 1.4071228558965483e-05, \"fn_rate\": 0.5219103889709503, \"precision\": 0.9928425357873211, \"recall\": 0.47808961102904973, \"specificity\": 0.999985928771441, \"npv\": 0.9978737147006551, \"accuracy\": 0.9978638638638638, \"f1\": 0.6453971419076105, \"f2\": 0.5333992529114481, \"f0_5\": 0.8169274777048628, \"p4\": 0.7841581185800753, \"phi\": 0.6882130529430239}, {\"truth_threshold\": 0.20000000298023224, \"match_probability\": 0.5346019618947252, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 969.0, \"tn\": 497463.0, \"fp\": 6.0, \"fn\": 1062.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4771048744460857, \"tn_rate\": 0.9999879389469495, \"fp_rate\": 1.2061053050541843e-05, \"fn_rate\": 0.5228951255539144, \"precision\": 0.9938461538461538, \"recall\": 0.4771048744460857, \"specificity\": 0.9999879389469495, \"npv\": 0.9978697156612005, \"accuracy\": 0.9978618618618619, \"f1\": 0.6447105788423154, \"f2\": 0.5324760962743159, \"f0_5\": 0.8168942842690946, \"p4\": 0.7836508373981423, \"phi\": 0.6878521020319585}, {\"truth_threshold\": 0.30000000447034836, \"match_probability\": 0.5517995194264473, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 965.0, \"tn\": 497463.0, \"fp\": 6.0, \"fn\": 1066.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4751354012801576, \"tn_rate\": 0.9999879389469495, \"fp_rate\": 1.2061053050541843e-05, \"fn_rate\": 0.5248645987198425, \"precision\": 0.9938208032955715, \"recall\": 0.4751354012801576, \"specificity\": 0.9999879389469495, \"npv\": 0.9978617091483143, \"accuracy\": 0.9978538538538538, \"f1\": 0.64290473017988, \"f2\": 0.5305112699285321, \"f0_5\": 0.8157227387996618, \"p4\": 0.7823141056096692, \"phi\": 0.6864193381287772}, {\"truth_threshold\": 0.4000000059604645, \"match_probability\": 0.5688740732440556, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 964.0, \"tn\": 497464.0, \"fp\": 5.0, \"fn\": 1067.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.47464303298867555, \"tn_rate\": 0.9999899491224579, \"fp_rate\": 1.0050877542118202e-05, \"fn_rate\": 0.5253569670113245, \"precision\": 0.9948400412796697, \"recall\": 0.47464303298867555, \"specificity\": 0.9999899491224579, \"npv\": 0.9978597118333664, \"accuracy\": 0.9978538538538538, \"f1\": 0.6426666666666667, \"f2\": 0.5300780820411305, \"f0_5\": 0.8159810394447266, \"p4\": 0.7821378295772213, \"phi\": 0.6864168151793969}, {\"truth_threshold\": 0.5000000074505806, \"match_probability\": 0.5857864388799862, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 962.0, \"tn\": 497464.0, \"fp\": 5.0, \"fn\": 1069.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4736582964057115, \"tn_rate\": 0.9999899491224579, \"fp_rate\": 1.0050877542118202e-05, \"fn_rate\": 0.5263417035942886, \"precision\": 0.9948293691830403, \"recall\": 0.4736582964057115, \"specificity\": 0.9999899491224579, \"npv\": 0.9978557086491767, \"accuracy\": 0.9978498498498498, \"f1\": 0.6417611741160774, \"f2\": 0.5290947090529095, \"f0_5\": 0.8153924393965079, \"p4\": 0.7814662667263776, \"phi\": 0.6856993112707813}, {\"truth_threshold\": 0.6000000089406967, \"match_probability\": 0.6024989422185573, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 960.0, \"tn\": 497464.0, \"fp\": 5.0, \"fn\": 1071.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4726735598227474, \"tn_rate\": 0.9999899491224579, \"fp_rate\": 1.0050877542118202e-05, \"fn_rate\": 0.5273264401772526, \"precision\": 0.9948186528497409, \"recall\": 0.4726735598227474, \"specificity\": 0.9999899491224579, \"npv\": 0.9978517054971066, \"accuracy\": 0.9978458458458458, \"f1\": 0.6408544726301736, \"f2\": 0.5281109032896908, \"f0_5\": 0.8148022407061619, \"p4\": 0.7807930677090621, \"phi\": 0.6849810616375575}, {\"truth_threshold\": 0.7000000104308128, \"match_probability\": 0.6189757403752982, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 959.0, \"tn\": 497465.0, \"fp\": 4.0, \"fn\": 1072.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.47218119153126537, \"tn_rate\": 0.9999919592979664, \"fp_rate\": 8.040702033694562e-06, \"fn_rate\": 0.5278188084687346, \"precision\": 0.995846313603323, \"recall\": 0.47218119153126537, \"specificity\": 0.9999919592979664, \"npv\": 0.9978497082463288, \"accuracy\": 0.9978458458458458, \"f1\": 0.6406145624582499, \"f2\": 0.527676901067459, \"f0_5\": 0.8150603433622301, \"p4\": 0.7806149801201594, \"phi\": 0.684979256330601}, {\"truth_threshold\": 0.800000011920929, \"match_probability\": 0.6351831076021942, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 957.0, \"tn\": 497465.0, \"fp\": 4.0, \"fn\": 1074.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4711964549483013, \"tn_rate\": 0.9999919592979664, \"fp_rate\": 8.040702033694562e-06, \"fn_rate\": 0.5288035450516987, \"precision\": 0.9958376690946931, \"recall\": 0.4711964549483013, \"specificity\": 0.9999919592979664, \"npv\": 0.9978457051504496, \"accuracy\": 0.9978418418418419, \"f1\": 0.6397058823529411, \"f2\": 0.5266923500275179, \"f0_5\": 0.814468085106383, \"p4\": 0.7799393715649482, \"phi\": 0.6842602526622814}, {\"truth_threshold\": 1.4000000208616257, \"match_probability\": 0.7252004282056979, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 955.0, \"tn\": 497465.0, \"fp\": 4.0, \"fn\": 1076.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.47021171836533726, \"tn_rate\": 0.9999919592979664, \"fp_rate\": 8.040702033694562e-06, \"fn_rate\": 0.5297882816346627, \"precision\": 0.9958289885297185, \"recall\": 0.47021171836533726, \"specificity\": 0.9999919592979664, \"npv\": 0.997841702086689, \"accuracy\": 0.9978378378378379, \"f1\": 0.6387959866220736, \"f2\": 0.5257073654079049, \"f0_5\": 0.8138742116925175, \"p4\": 0.7792621115825045, \"phi\": 0.6835404985178782}, {\"truth_threshold\": 1.5000000223517418, \"match_probability\": 0.7387961280260511, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 954.0, \"tn\": 497466.0, \"fp\": 3.0, \"fn\": 1077.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.46971935007385524, \"tn_rate\": 0.9999939694734747, \"fp_rate\": 6.0305265252709215e-06, \"fn_rate\": 0.5302806499261448, \"precision\": 0.9968652037617555, \"recall\": 0.46971935007385524, \"specificity\": 0.9999939694734747, \"npv\": 0.9978397049000788, \"accuracy\": 0.9978378378378379, \"f1\": 0.6385542168674698, \"f2\": 0.5252725470763132, \"f0_5\": 0.8141321044546851, \"p4\": 0.7790821924875713, \"phi\": 0.683539424333062}, {\"truth_threshold\": 1.600000023841858, \"match_probability\": 0.7519492561137834, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 952.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1079.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4687346134908912, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5312653865091088, \"precision\": 0.9979035639412998, \"recall\": 0.4687346134908912, \"specificity\": 0.9999959796489831, \"npv\": 0.9978357062337276, \"accuracy\": 0.9978358358358358, \"f1\": 0.63785594639866, \"f2\": 0.5243445692883895, \"f0_5\": 0.8140926971096288, \"p4\": 0.7785619524917188, \"phi\": 0.6831789360934705}, {\"truth_threshold\": 1.8000000268220901, \"match_probability\": 0.7768953900182098, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 951.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1080.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.46824224519940916, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5317577548005908, \"precision\": 0.9979013641133263, \"recall\": 0.46824224519940916, \"specificity\": 0.9999959796489831, \"npv\": 0.9978337047459919, \"accuracy\": 0.9978338338338338, \"f1\": 0.6373994638069705, \"f2\": 0.5238514927839595, \"f0_5\": 0.8137942837583433, \"p4\": 0.778221509082384, \"phi\": 0.6828185857619715}, {\"truth_threshold\": 2.0000000298023224, \"match_probability\": 0.8000000033051833, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 948.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1083.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4667651403249631, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5332348596750369, \"precision\": 0.9978947368421053, \"recall\": 0.4667651403249631, \"specificity\": 0.9999959796489831, \"npv\": 0.9978277003309598, \"accuracy\": 0.9978278278278279, \"f1\": 0.6360281784636028, \"f2\": 0.5223716111968261, \"f0_5\": 0.8128965872063111, \"p4\": 0.7771976705303588, \"phi\": 0.68173640064037}, {\"truth_threshold\": 2.2000000327825546, \"match_probability\": 0.8212623941099038, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 943.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1088.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.46430329886755295, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.535696701132447, \"precision\": 0.9978835978835979, \"recall\": 0.46430329886755295, \"specificity\": 0.9999959796489831, \"npv\": 0.9978176931331548, \"accuracy\": 0.9978178178178179, \"f1\": 0.633736559139785, \"f2\": 0.5199029661484177, \"f0_5\": 0.8113921872311134, \"p4\": 0.7754828653969006, \"phi\": 0.6799289602870743}, {\"truth_threshold\": 2.3000000342726707, \"match_probability\": 0.8312116004280432, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 942.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1089.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4638109305760709, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5361890694239291, \"precision\": 0.9978813559322034, \"recall\": 0.4638109305760709, \"specificity\": 0.9999959796489831, \"npv\": 0.9978156917176807, \"accuracy\": 0.9978158158158158, \"f1\": 0.6332773109243698, \"f2\": 0.5194089104543449, \"f0_5\": 0.8110900637162046, \"p4\": 0.7751386362251282, \"phi\": 0.6795668997167984}, {\"truth_threshold\": 2.400000035762787, \"match_probability\": 0.8407144092272857, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 941.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1090.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4633185622845889, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5366814377154111, \"precision\": 0.9978791092258749, \"recall\": 0.4633185622845889, \"specificity\": 0.9999959796489831, \"npv\": 0.9978136903102354, \"accuracy\": 0.9978138138138138, \"f1\": 0.632817753866846, \"f2\": 0.5189147457814051, \"f0_5\": 0.8107875236946407, \"p4\": 0.7747939825088848, \"phi\": 0.6792046476016111}, {\"truth_threshold\": 2.600000038743019, \"match_probability\": 0.8584144256340188, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 935.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1096.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4603643525356967, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5396356474643033, \"precision\": 0.9978655282817502, \"recall\": 0.4603643525356967, \"specificity\": 0.9999959796489831, \"npv\": 0.9978016820341662, \"accuracy\": 0.9978018018018018, \"f1\": 0.6300539083557951, \"f2\": 0.5159474671669794, \"f0_5\": 0.8089634884928188, \"p4\": 0.7727171005166645, \"phi\": 0.6770270952380184}, {\"truth_threshold\": 2.7000000402331352, \"match_probability\": 0.8666314458464526, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 934.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1097.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.45987198424421466, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5401280157557853, \"precision\": 0.9978632478632479, \"recall\": 0.45987198424421466, \"specificity\": 0.9999959796489831, \"npv\": 0.9977996806829214, \"accuracy\": 0.9977997997997998, \"f1\": 0.6295921806538591, \"f2\": 0.5154525386313465, \"f0_5\": 0.8086580086580086, \"p4\": 0.7723694528174642, \"phi\": 0.6766634936764843}, {\"truth_threshold\": 2.8000000417232513, \"match_probability\": 0.8744413378412453, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 928.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1103.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4569177744953225, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5430822255046776, \"precision\": 0.9978494623655914, \"recall\": 0.4569177744953225, \"specificity\": 0.9999959796489831, \"npv\": 0.997787672744048, \"accuracy\": 0.9977877877877878, \"f1\": 0.6268152651131375, \"f2\": 0.5124806715263972, \"f0_5\": 0.8068162058772388, \"p4\": 0.7702744894623189, \"phi\": 0.6744777988699306}, {\"truth_threshold\": 2.9000000432133675, \"match_probability\": 0.8818562391739494, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 925.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1106.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4554406696208764, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5445593303791236, \"precision\": 0.9978425026968716, \"recall\": 0.4554406696208764, \"specificity\": 0.9999959796489831, \"npv\": 0.997781668882992, \"accuracy\": 0.9977817817817818, \"f1\": 0.625422582826234, \"f2\": 0.510993260413214, \"f0_5\": 0.8058895277922983, \"p4\": 0.7692211360295698, \"phi\": 0.6733823109025162}, {\"truth_threshold\": 3.0000000447034836, \"match_probability\": 0.8888888919492438, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 921.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1110.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4534711964549483, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5465288035450517, \"precision\": 0.9978331527627302, \"recall\": 0.4534711964549483, \"specificity\": 0.9999959796489831, \"npv\": 0.9977736638473095, \"accuracy\": 0.9977737737737737, \"f1\": 0.6235612728503723, \"f2\": 0.5090085111086547, \"f0_5\": 0.8046479119343002, \"p4\": 0.7678105260038732, \"phi\": 0.6719189025752881}, {\"truth_threshold\": 3.1000000461935997, \"match_probability\": 0.8955524998434058, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 917.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1114.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.45150172328902016, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5484982767109798, \"precision\": 0.9978237214363439, \"recall\": 0.45150172328902016, \"specificity\": 0.9999959796489831, \"npv\": 0.997765658940072, \"accuracy\": 0.9977657657657658, \"f1\": 0.6216949152542373, \"f2\": 0.5070220059714696, \"f0_5\": 0.8033993341510426, \"p4\": 0.7663928517952519, \"phi\": 0.6704523236662111}, {\"truth_threshold\": 3.400000050663948, \"match_probability\": 0.9134653434169965, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 906.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1125.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4460856720827179, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5539143279172821, \"precision\": 0.9977973568281938, \"recall\": 0.4460856720827179, \"specificity\": 0.9999959796489831, \"npv\": 0.9977436461074386, \"accuracy\": 0.9977437437437437, \"f1\": 0.6165362368152433, \"f2\": 0.5015500442869796, \"f0_5\": 0.799929366060392, \"p4\": 0.7624573856836947, \"phi\": 0.6664027122965219}, {\"truth_threshold\": 3.500000052154064, \"match_probability\": 0.9187896995557598, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 904.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1127.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4451009354997538, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5548990645002462, \"precision\": 0.9977924944812362, \"recall\": 0.4451009354997538, \"specificity\": 0.9999959796489831, \"npv\": 0.9977396438785866, \"accuracy\": 0.9977397397397397, \"f1\": 0.6155941436840313, \"f2\": 0.5005537098560354, \"f0_5\": 0.7992926613616269, \"p4\": 0.7617359753471191, \"phi\": 0.6656637918013737}, {\"truth_threshold\": 3.6000000536441803, \"match_probability\": 0.9238137785296746, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 901.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1130.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.44362383062530775, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5563761693746923, \"precision\": 0.9977851605758582, \"recall\": 0.44362383062530775, \"specificity\": 0.9999959796489831, \"npv\": 0.997733640595511, \"accuracy\": 0.9977337337337338, \"f1\": 0.6141785957736878, \"f2\": 0.4990583804143126, \"f0_5\": 0.798334219386851, \"p4\": 0.7606504383457937, \"phi\": 0.664553881713238}, {\"truth_threshold\": 3.9000000581145287, \"match_probability\": 0.9372195616099515, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 896.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1135.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.44116198916789756, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5588380108321024, \"precision\": 0.9977728285077951, \"recall\": 0.44116198916789756, \"specificity\": 0.9999959796489831, \"npv\": 0.9977236352842548, \"accuracy\": 0.9977237237237238, \"f1\": 0.6118129054284739, \"f2\": 0.49656395477721127, \"f0_5\": 0.7967277254134804, \"p4\": 0.7588320279950711, \"phi\": 0.6626999305348448}, {\"truth_threshold\": 4.000000059604645, \"match_probability\": 0.9411764728755594, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 892.0, \"tn\": 497467.0, \"fp\": 2.0, \"fn\": 1139.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.43919251600196946, \"tn_rate\": 0.9999959796489831, \"fp_rate\": 4.020351016847281e-06, \"fn_rate\": 0.5608074839980305, \"precision\": 0.9977628635346756, \"recall\": 0.43919251600196946, \"specificity\": 0.9999959796489831, \"npv\": 0.9977156311797291, \"accuracy\": 0.9977157157157157, \"f1\": 0.6099145299145299, \"f2\": 0.4945664227101353, \"f0_5\": 0.795434278580346, \"p4\": 0.7573689726748798, \"phi\": 0.661213053823421}, {\"truth_threshold\": 4.300000064074993, \"match_probability\": 0.9516868803254299, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 883.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1148.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4347612013786312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5652387986213688, \"precision\": 1.0, \"recall\": 0.4347612013786312, \"specificity\": 1.0, \"npv\": 0.9976976316491415, \"accuracy\": 0.9977017017017017, \"f1\": 0.6060398078242965, \"f2\": 0.4901743088708782, \"f0_5\": 0.793636527053748, \"p4\": 0.7543723992254191, \"phi\": 0.658604753208171}, {\"truth_threshold\": 4.500000067055225, \"match_probability\": 0.9576762895591182, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 880.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1151.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.43328409650418515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5667159034958149, \"precision\": 1.0, \"recall\": 0.43328409650418515, \"specificity\": 1.0, \"npv\": 0.9976916288957522, \"accuracy\": 0.9976956956956957, \"f1\": 0.6046032291308828, \"f2\": 0.48867170146601513, \"f0_5\": 0.7926499729778418, \"p4\": 0.7532576145050915, \"phi\": 0.657483015762297}, {\"truth_threshold\": 4.6000000685453415, \"match_probability\": 0.9603983391922627, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 873.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1158.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4298375184638109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5701624815361891, \"precision\": 1.0, \"recall\": 0.4298375184638109, \"specificity\": 1.0, \"npv\": 0.9976776227520772, \"accuracy\": 0.9976816816816817, \"f1\": 0.6012396694214877, \"f2\": 0.4851617205735245, \"f0_5\": 0.7903313416621401, \"p4\": 0.750639695476175, \"phi\": 0.6548582087678424}, {\"truth_threshold\": 4.90000007301569, \"match_probability\": 0.9675925026740654, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 869.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1162.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4278680452978828, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5721319547021172, \"precision\": 1.0, \"recall\": 0.4278680452978828, \"specificity\": 1.0, \"npv\": 0.9976696194179664, \"accuracy\": 0.9976736736736737, \"f1\": 0.5993103448275862, \"f2\": 0.4831535638830201, \"f0_5\": 0.788995823497367, \"p4\": 0.7491331147859155, \"phi\": 0.6533536178161471}, {\"truth_threshold\": 5.000000074505806, \"match_probability\": 0.969696971214501, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 858.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1173.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4224519940915805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5775480059084195, \"precision\": 1.0, \"recall\": 0.4224519940915805, \"specificity\": 1.0, \"npv\": 0.9976476109112349, \"accuracy\": 0.9976516516516517, \"f1\": 0.5939771547248183, \"f2\": 0.47762191048764197, \"f0_5\": 0.785282811641955, \"p4\": 0.744949595176136, \"phi\": 0.6491981381906086}, {\"truth_threshold\": 5.100000075995922, \"match_probability\": 0.9716687817966767, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 850.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1181.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.41851304775972425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5814869522402757, \"precision\": 1.0, \"recall\": 0.41851304775972425, \"specificity\": 1.0, \"npv\": 0.9976316053344029, \"accuracy\": 0.9976356356356356, \"f1\": 0.5900728913571677, \"f2\": 0.473590372186316, \"f0_5\": 0.7825446510771497, \"p4\": 0.741869236231064, \"phi\": 0.6461593020996659}, {\"truth_threshold\": 5.200000077486038, \"match_probability\": 0.9735157914041783, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 849.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1182.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.41802067946824223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5819793205317577, \"precision\": 1.0, \"recall\": 0.41802067946824223, \"specificity\": 1.0, \"npv\": 0.9976296046734089, \"accuracy\": 0.9976336336336337, \"f1\": 0.5895833333333333, \"f2\": 0.47308592443998665, \"f0_5\": 0.7822001105583195, \"p4\": 0.7414819238939885, \"phi\": 0.6457784490080265}, {\"truth_threshold\": 5.4000000804662704, \"match_probability\": 0.9768648415470134, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 845.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1186.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4160512063023141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5839487936976858, \"precision\": 1.0, \"recall\": 0.4160512063023141, \"specificity\": 1.0, \"npv\": 0.997621602109675, \"accuracy\": 0.9976256256256256, \"f1\": 0.5876216968011126, \"f2\": 0.47106700858512657, \"f0_5\": 0.7808168545555351, \"p4\": 0.7399275926524876, \"phi\": 0.6442528005301782}, {\"truth_threshold\": 5.500000081956387, \"match_probability\": 0.9783806392104205, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 842.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1189.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.41457410142786805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.585425898572132, \"precision\": 1.0, \"recall\": 0.41457410142786805, \"specificity\": 1.0, \"npv\": 0.9976156002711277, \"accuracy\": 0.9976196196196196, \"f1\": 0.5861468847894187, \"f2\": 0.4695516395271024, \"f0_5\": 0.7797740322281904, \"p4\": 0.7387564801081082, \"phi\": 0.643106205111431}, {\"truth_threshold\": 5.600000083446503, \"match_probability\": 0.9797991767207457, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 836.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1195.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4116198916789759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5883801083210242, \"precision\": 1.0, \"recall\": 0.4116198916789759, \"specificity\": 1.0, \"npv\": 0.9976035968106781, \"accuracy\": 0.9976076076076076, \"f1\": 0.5831880013951866, \"f2\": 0.46651785714285715, \"f0_5\": 0.7776744186046511, \"p4\": 0.7364003429729491, \"phi\": 0.6408069010690881}, {\"truth_threshold\": 5.700000084936619, \"match_probability\": 0.9811264334957893, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 835.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1196.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.41112752338749387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5888724766125062, \"precision\": 1.0, \"recall\": 0.41112752338749387, \"specificity\": 1.0, \"npv\": 0.9976015962620196, \"accuracy\": 0.9976056056056056, \"f1\": 0.5826936496859735, \"f2\": 0.4660118316776426, \"f0_5\": 0.7773226587227704, \"p4\": 0.7360058380999589, \"phi\": 0.6404228865356193}, {\"truth_threshold\": 5.800000086426735, \"match_probability\": 0.9823680546749124, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 829.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1202.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.40817331363860165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5918266863613983, \"precision\": 1.0, \"recall\": 0.40817331363860165, \"specificity\": 1.0, \"npv\": 0.9975895931385623, \"accuracy\": 0.9975935935935936, \"f1\": 0.5797202797202797, \"f2\": 0.4629733050374176, \"f0_5\": 0.7752010473162521, \"p4\": 0.7336278226603018, \"phi\": 0.6381139787551683}, {\"truth_threshold\": 5.900000087916851, \"match_probability\": 0.9835293654795508, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 817.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1214.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.40226489414081734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5977351058591827, \"precision\": 1.0, \"recall\": 0.40226489414081734, \"specificity\": 1.0, \"npv\": 0.997565587758155, \"accuracy\": 0.9975695695695695, \"f1\": 0.5737359550561798, \"f2\": 0.4568840174477128, \"f0_5\": 0.7709001698433666, \"p4\": 0.728814572176657, \"phi\": 0.6334710850212948}, {\"truth_threshold\": 6.100000090897083, \"match_probability\": 0.985630843183972, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 815.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1216.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.4012801575578533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5987198424421467, \"precision\": 1.0, \"recall\": 0.4012801575578533, \"specificity\": 1.0, \"npv\": 0.997561586973741, \"accuracy\": 0.9975655655655655, \"f1\": 0.5727336612789881, \"f2\": 0.45586754670544805, \"f0_5\": 0.7701757701757702, \"p4\": 0.7280048468962632, \"phi\": 0.6326939787879168}, {\"truth_threshold\": 6.200000092387199, \"match_probability\": 0.9865801893041345, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 802.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1229.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3948793697685869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.605120630231413, \"precision\": 1.0, \"recall\": 0.3948793697685869, \"specificity\": 1.0, \"npv\": 0.9975355826572394, \"accuracy\": 0.9975395395395396, \"f1\": 0.5661842569714084, \"f2\": 0.44924938382254087, \"f0_5\": 0.765413246802825, \"p4\": 0.7226883265009849, \"phi\": 0.6276194883856226}, {\"truth_threshold\": 6.3000000938773155, \"match_probability\": 0.987467611228855, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 791.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1240.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3894633185622846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6105366814377154, \"precision\": 1.0, \"recall\": 0.3894633185622846, \"specificity\": 1.0, \"npv\": 0.9975135800637246, \"accuracy\": 0.9975175175175175, \"f1\": 0.5605953224663359, \"f2\": 0.44363432417274257, \"f0_5\": 0.7613089509143407, \"p4\": 0.7181162848442236, \"phi\": 0.6232936300031979}, {\"truth_threshold\": 6.400000095367432, \"match_probability\": 0.9882970460445225, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 789.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1242.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.38847858197932056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6115214180206795, \"precision\": 1.0, \"recall\": 0.38847858197932056, \"specificity\": 1.0, \"npv\": 0.9975095796964575, \"accuracy\": 0.9975135135135135, \"f1\": 0.5595744680851064, \"f2\": 0.44261191518007403, \"f0_5\": 0.7605552342394447, \"p4\": 0.7172776426839207, \"phi\": 0.6225039012177096}, {\"truth_threshold\": 6.500000096857548, \"match_probability\": 0.9890721936212699, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 782.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1249.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3850320039389463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6149679960610537, \"precision\": 1.0, \"recall\": 0.3850320039389463, \"specificity\": 1.0, \"npv\": 0.9974955786636938, \"accuracy\": 0.9974994994994995, \"f1\": 0.5559900462140064, \"f2\": 0.4390298675050528, \"f0_5\": 0.7578988176003102, \"p4\": 0.7143243120374653, \"phi\": 0.6197319755935794}, {\"truth_threshold\": 6.70000009983778, \"match_probability\": 0.9904733155885336, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 781.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1250.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3845396356474643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6154603643525357, \"precision\": 1.0, \"recall\": 0.3845396356474643, \"specificity\": 1.0, \"npv\": 0.9974935785482406, \"accuracy\": 0.9974974974974975, \"f1\": 0.5554765291607396, \"f2\": 0.43851768669286917, \"f0_5\": 0.7575169738118331, \"p4\": 0.7139000956318889, \"phi\": 0.6193349798417862}, {\"truth_threshold\": 6.800000101327896, \"match_probability\": 0.9911056147706719, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 778.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1253.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3830625307730182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6169374692269818, \"precision\": 1.0, \"recall\": 0.3830625307730182, \"specificity\": 1.0, \"npv\": 0.997487578250007, \"accuracy\": 0.9974914914914915, \"f1\": 0.553933784264863, \"f2\": 0.43698045383059986, \"f0_5\": 0.756367878670037, \"p4\": 0.7126239521328657, \"phi\": 0.6181424723630441}, {\"truth_threshold\": 6.900000102818012, \"match_probability\": 0.9916962992137202, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 773.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1258.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3806006893156081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6193993106843919, \"precision\": 1.0, \"recall\": 0.3806006893156081, \"specificity\": 1.0, \"npv\": 0.9974775779133674, \"accuracy\": 0.9974814814814815, \"f1\": 0.551355206847361, \"f2\": 0.4344160953130269, \"f0_5\": 0.7544407573687293, \"p4\": 0.7104853263367068, \"phi\": 0.6161498630452585}, {\"truth_threshold\": 7.000000104308128, \"match_probability\": 0.9922480625716311, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 763.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1268.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.37567700640078777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6243229935992122, \"precision\": 1.0, \"recall\": 0.37567700640078777, \"specificity\": 1.0, \"npv\": 0.9974575778416279, \"accuracy\": 0.9974614614614614, \"f1\": 0.5461703650680029, \"f2\": 0.4292787217283673, \"f0_5\": 0.7505410190832186, \"p4\": 0.7061635750352407, \"phi\": 0.6121453069781092}, {\"truth_threshold\": 7.1000001057982445, \"match_probability\": 0.9927634299608046, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 759.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1272.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.37370753323485967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6262924667651403, \"precision\": 1.0, \"recall\": 0.37370753323485967, \"specificity\": 1.0, \"npv\": 0.9974495780374985, \"accuracy\": 0.9974534534534535, \"f1\": 0.5440860215053763, \"f2\": 0.4272205336035123, \"f0_5\": 0.7489638839550029, \"p4\": 0.7044180412888266, \"phi\": 0.6105361752873824}, {\"truth_threshold\": 7.200000107288361, \"match_probability\": 0.9932447677519157, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 757.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1274.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3727227966518956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6272772033481043, \"precision\": 1.0, \"recall\": 0.3727227966518956, \"specificity\": 1.0, \"npv\": 0.9974455781835535, \"accuracy\": 0.9974494494494495, \"f1\": 0.5430416068866571, \"f2\": 0.4261907442855534, \"f0_5\": 0.7481715754101601, \"p4\": 0.7035416270144866, \"phi\": 0.6097300266582261}, {\"truth_threshold\": 7.300000108778477, \"match_probability\": 0.9936942928922654, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 753.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1278.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3707533234859675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6292466765140325, \"precision\": 1.0, \"recall\": 0.3707533234859675, \"specificity\": 1.0, \"npv\": 0.9974375785719012, \"accuracy\": 0.9974414414414414, \"f1\": 0.540948275862069, \"f2\": 0.42412977357215276, \"f0_5\": 0.7465794170136824, \"p4\": 0.7017814526070769, \"phi\": 0.6081145428497235}, {\"truth_threshold\": 7.400000110268593, \"match_probability\": 0.9941140817673122, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 746.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1285.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.36730674544559333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6326932545544067, \"precision\": 1.0, \"recall\": 0.36730674544559333, \"specificity\": 1.0, \"npv\": 0.9974235795602642, \"accuracy\": 0.9974274274274274, \"f1\": 0.5372704357220022, \"f2\": 0.4205186020293123, \"f0_5\": 0.7437686939182453, \"p4\": 0.6986773639364886, \"phi\": 0.605277133913858}, {\"truth_threshold\": 7.500000111758709, \"match_probability\": 0.9945060786121668, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 744.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1287.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3663220088626292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6336779911373708, \"precision\": 1.0, \"recall\": 0.3663220088626292, \"specificity\": 1.0, \"npv\": 0.9974195799148281, \"accuracy\": 0.9974234234234234, \"f1\": 0.5362162162162162, \"f2\": 0.41948579161028415, \"f0_5\": 0.7429598562013181, \"p4\": 0.6977848707823792, \"phi\": 0.6044640139771098}, {\"truth_threshold\": 7.600000113248825, \"match_probability\": 0.9948721034855129, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 741.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1290.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.36484490398818314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6351550960118169, \"precision\": 1.0, \"recall\": 0.36484490398818314, \"specificity\": 1.0, \"npv\": 0.9974135805068179, \"accuracy\": 0.9974174174174174, \"f1\": 0.5346320346320347, \"f2\": 0.4179357021996616, \"f0_5\": 0.7417417417417418, \"p4\": 0.6964414158853732, \"phi\": 0.603242291303022}, {\"truth_threshold\": 7.700000114738941, \"match_probability\": 0.9952138598197071, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 735.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1296.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.361890694239291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.638109305760709, \"precision\": 1.0, \"recall\": 0.361890694239291, \"specificity\": 1.0, \"npv\": 0.9974015819073111, \"accuracy\": 0.9974054054054055, \"f1\": 0.5314533622559653, \"f2\": 0.4148323738570945, \"f0_5\": 0.7392878696439348, \"p4\": 0.6937373991408317, \"phi\": 0.6007914371159129}, {\"truth_threshold\": 7.900000117719173, \"match_probability\": 0.99583083992065, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 734.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1297.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.36139832594780896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.638601674052191, \"precision\": 1.0, \"recall\": 0.36139832594780896, \"specificity\": 1.0, \"npv\": 0.9973995821687925, \"accuracy\": 0.9974034034034034, \"f1\": 0.5309222423146474, \"f2\": 0.4143147437344773, \"f0_5\": 0.7388765854640628, \"p4\": 0.6932844963857696, \"phi\": 0.6003819944808853}, {\"truth_threshold\": 8.100000120699406, \"match_probability\": 0.9963685754887298, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 728.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1303.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3584441161989168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6415558838010832, \"precision\": 1.0, \"recall\": 0.3584441161989168, \"specificity\": 1.0, \"npv\": 0.9973875839060733, \"accuracy\": 0.9973913913913914, \"f1\": 0.5277274374773469, \"f2\": 0.41120650700406686, \"f0_5\": 0.7363949018814485, \"p4\": 0.6905535559772998, \"phi\": 0.5979194853999872}, {\"truth_threshold\": 8.200000122189522, \"match_probability\": 0.9966109369567457, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 716.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1315.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.35253569670113244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6474643032988675, \"precision\": 1.0, \"recall\": 0.35253569670113244, \"specificity\": 1.0, \"npv\": 0.9973635882466158, \"accuracy\": 0.9973673673673674, \"f1\": 0.521295959228249, \"f2\": 0.40497737556561086, \"f0_5\": 0.7313585291113381, \"p4\": 0.6850211742953402, \"phi\": 0.5929639680847919}, {\"truth_threshold\": 8.300000123679638, \"match_probability\": 0.9968371745531442, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 712.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1319.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.35056622353520434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6494337764647957, \"precision\": 1.0, \"recall\": 0.35056622353520434, \"specificity\": 1.0, \"npv\": 0.9973555899500389, \"accuracy\": 0.9973593593593594, \"f1\": 0.5191396281443674, \"f2\": 0.40289723856948845, \"f0_5\": 0.7296577167452347, \"p4\": 0.6831558267724269, \"phi\": 0.591302953392346}, {\"truth_threshold\": 8.50000012665987, \"match_probability\": 0.997245472756309, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 706.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1325.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3476120137863122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6523879862136879, \"precision\": 1.0, \"recall\": 0.3476120137863122, \"specificity\": 1.0, \"npv\": 0.9973435927457026, \"accuracy\": 0.9973473473473473, \"f1\": 0.515893313847278, \"f2\": 0.39977349943374857, \"f0_5\": 0.7270854788877446, \"p4\": 0.6803375947164685, \"phi\": 0.5888026959102762}, {\"truth_threshold\": 8.600000128149986, \"match_probability\": 0.9974294610402847, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 705.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1326.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.34711964549483015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6528803545051699, \"precision\": 1.0, \"recall\": 0.34711964549483015, \"specificity\": 1.0, \"npv\": 0.9973415932397077, \"accuracy\": 0.9973453453453454, \"f1\": 0.5153508771929824, \"f2\": 0.399252463472647, \"f0_5\": 0.7266542980828695, \"p4\": 0.6798655126659227, \"phi\": 0.5883849592593411}, {\"truth_threshold\": 8.700000129640102, \"match_probability\": 0.997601189412643, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 704.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1327.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3466272772033481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6533727227966519, \"precision\": 1.0, \"recall\": 0.3466272772033481, \"specificity\": 1.0, \"npv\": 0.9973395937417301, \"accuracy\": 0.9973433433433433, \"f1\": 0.5148080438756856, \"f2\": 0.3987313094698686, \"f0_5\": 0.7262224056117186, \"p4\": 0.6793927476187539, \"phi\": 0.587966927493196}, {\"truth_threshold\": 8.800000131130219, \"match_probability\": 0.997761470983937, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 703.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1328.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3461349089118661, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.653865091088134, \"precision\": 1.0, \"recall\": 0.3461349089118661, \"specificity\": 1.0, \"npv\": 0.9973375942517697, \"accuracy\": 0.9973413413413413, \"f1\": 0.5142648134601316, \"f2\": 0.3982100373852951, \"f0_5\": 0.725789799710923, \"p4\": 0.6789192980888645, \"phi\": 0.5875485999819214}, {\"truth_threshold\": 8.900000132620335, \"match_probability\": 0.9979110654305032, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 693.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1338.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3412112259970458, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6587887740029542, \"precision\": 1.0, \"recall\": 0.3412112259970458, \"specificity\": 1.0, \"npv\": 0.9973175997931063, \"accuracy\": 0.9973213213213213, \"f1\": 0.5088105726872246, \"f2\": 0.3929908132017693, \"f0_5\": 0.7214241099312929, \"p4\": 0.6741468261936869, \"phi\": 0.5833489186874669}, {\"truth_threshold\": 9.00000013411045, \"match_probability\": 0.9980506824420605, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 690.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1341.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3397341211225997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6602658788774003, \"precision\": 1.0, \"recall\": 0.3397341211225997, \"specificity\": 1.0, \"npv\": 0.9973116016118362, \"accuracy\": 0.9973153153153154, \"f1\": 0.5071664829106945, \"f2\": 0.39142273655547993, \"f0_5\": 0.720100187852223, \"p4\": 0.6727014821768865, \"phi\": 0.5820831387860066}, {\"truth_threshold\": 9.100000135600567, \"match_probability\": 0.9981809849551747, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 687.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1344.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.33825701624815363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6617429837518464, \"precision\": 1.0, \"recall\": 0.33825701624815363, \"specificity\": 1.0, \"npv\": 0.9973056035027155, \"accuracy\": 0.9973093093093093, \"f1\": 0.5055187637969095, \"f2\": 0.38985359210078313, \"f0_5\": 0.7187696170747018, \"p4\": 0.6712497863978392, \"phi\": 0.5808146156291115}, {\"truth_threshold\": 9.200000137090683, \"match_probability\": 0.9983025921847976, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 684.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1347.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.33677991137370755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6632200886262924, \"precision\": 1.0, \"recall\": 0.33677991137370755, \"specificity\": 1.0, \"npv\": 0.9972996054657429, \"accuracy\": 0.9973033033033033, \"f1\": 0.5038674033149171, \"f2\": 0.388283378746594, \"f0_5\": 0.7174323473882945, \"p4\": 0.6697916968157778, \"phi\": 0.5795433312029278}, {\"truth_threshold\": 9.400000140070915, \"match_probability\": 0.9985219959137808, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 678.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1353.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.33382570162481534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6661742983751846, \"precision\": 1.0, \"recall\": 0.33382570162481534, \"specificity\": 1.0, \"npv\": 0.997287609608237, \"accuracy\": 0.9972912912912912, \"f1\": 0.5005537098560354, \"f2\": 0.38513974096796183, \"f0_5\": 0.7147375079063883, \"p4\": 0.666856166216275, \"phi\": 0.5769924054952584}, {\"truth_threshold\": 9.500000141561031, \"match_probability\": 0.9986208369212233, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 674.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1357.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.33185622845888724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6681437715411127, \"precision\": 1.0, \"recall\": 0.33185622845888724, \"specificity\": 1.0, \"npv\": 0.9972796125302209, \"accuracy\": 0.9972832832832833, \"f1\": 0.4983364140480592, \"f2\": 0.38304160036371904, \"f0_5\": 0.712925745716099, \"p4\": 0.6648846733617926, \"phi\": 0.5752855386094974}, {\"truth_threshold\": 9.600000143051147, \"match_probability\": 0.9987130764898899, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 669.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1362.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3293943870014771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.670605612998523, \"precision\": 1.0, \"recall\": 0.3293943870014771, \"specificity\": 1.0, \"npv\": 0.9972696163630568, \"accuracy\": 0.9972732732732733, \"f1\": 0.4955555555555556, \"f2\": 0.3804162401910611, \"f0_5\": 0.7106437221159975, \"p4\": 0.6624038441730594, \"phi\": 0.5731448455295636}, {\"truth_threshold\": 9.80000014603138, \"match_probability\": 0.9988794813467569, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 664.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1367.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.326932545544067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6730674544559331, \"precision\": 1.0, \"recall\": 0.326932545544067, \"specificity\": 1.0, \"npv\": 0.9972596203962826, \"accuracy\": 0.9972632632632633, \"f1\": 0.49276437847866417, \"f2\": 0.377787892580792, \"f0_5\": 0.7083422231704715, \"p4\": 0.6599045314814007, \"phi\": 0.5709961700961458}, {\"truth_threshold\": 9.900000147521496, \"match_probability\": 0.9989544406735176, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 662.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1369.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3259478089611029, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6740521910388971, \"precision\": 1.0, \"recall\": 0.3259478089611029, \"specificity\": 1.0, \"npv\": 0.9972556220656806, \"accuracy\": 0.9972592592592593, \"f1\": 0.4916450055699963, \"f2\": 0.37673571591167765, \"f0_5\": 0.707416114554392, \"p4\": 0.6588995846000425, \"phi\": 0.5701344446588457}, {\"truth_threshold\": 10.000000149011612, \"match_probability\": 0.9990243903445719, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 657.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1374.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.32348596750369274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6765140324963073, \"precision\": 1.0, \"recall\": 0.32348596750369274, \"specificity\": 1.0, \"npv\": 0.997245626379442, \"accuracy\": 0.9972492492492493, \"f1\": 0.4888392857142857, \"f2\": 0.37410317731465664, \"f0_5\": 0.7050869285254346, \"p4\": 0.6563740453448391, \"phi\": 0.567974441580059}, {\"truth_threshold\": 10.100000150501728, \"match_probability\": 0.9990896645300149, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 652.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1379.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3210241260462826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6789758739537174, \"precision\": 1.0, \"recall\": 0.3210241260462826, \"specificity\": 1.0, \"npv\": 0.9972356308935788, \"accuracy\": 0.9972392392392393, \"f1\": 0.48602310846067837, \"f2\": 0.3714676390154968, \"f0_5\": 0.702737658978228, \"p4\": 0.6538295188085093, \"phi\": 0.5658062361531768}, {\"truth_threshold\": 10.200000151991844, \"match_probability\": 0.9991505751910027, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 648.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1383.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3190546528803545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6809453471196455, \"precision\": 1.0, \"recall\": 0.3190546528803545, \"specificity\": 1.0, \"npv\": 0.9972276346491544, \"accuracy\": 0.9972312312312313, \"f1\": 0.48376259798432253, \"f2\": 0.3693570451436389, \"f0_5\": 0.7008436080467229, \"p4\": 0.6517800821564307, \"phi\": 0.5640657025699072}, {\"truth_threshold\": 10.30000015348196, \"match_probability\": 0.9992074135451509, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 640.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1391.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3151157065484983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6848842934515017, \"precision\": 1.0, \"recall\": 0.3151157065484983, \"specificity\": 1.0, \"npv\": 0.9972116425450026, \"accuracy\": 0.9972152152152152, \"f1\": 0.47922126544365407, \"f2\": 0.3651300775901415, \"f0_5\": 0.6970159006752341, \"p4\": 0.6476438917306496, \"phi\": 0.5605685072486297}, {\"truth_threshold\": 10.400000154972076, \"match_probability\": 0.9992604514366183, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 637.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1394.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.31363860167405216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6863613983259478, \"precision\": 1.0, \"recall\": 0.31363860167405216, \"specificity\": 1.0, \"npv\": 0.9972056456381813, \"accuracy\": 0.9972092092092092, \"f1\": 0.4775112443778111, \"f2\": 0.36354297454628465, \"f0_5\": 0.6955667176239354, \"p4\": 0.6460798459878585, \"phi\": 0.559251449957378}, {\"truth_threshold\": 10.500000156462193, \"match_probability\": 0.9993099426168967, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 627.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1404.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3087149187592319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.691285081240768, \"precision\": 1.0, \"recall\": 0.3087149187592319, \"specificity\": 1.0, \"npv\": 0.9971856564696827, \"accuracy\": 0.9971891891891892, \"f1\": 0.4717832957110609, \"f2\": 0.35824477202605415, \"f0_5\": 0.6906807666886979, \"p4\": 0.6408144252869089, \"phi\": 0.5548387954396389}, {\"truth_threshold\": 10.600000157952309, \"match_probability\": 0.9993561239419685, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 624.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1407.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3072378138847858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6927621861152142, \"precision\": 1.0, \"recall\": 0.3072378138847858, \"specificity\": 1.0, \"npv\": 0.9971796598753999, \"accuracy\": 0.9971831831831832, \"f1\": 0.47005649717514125, \"f2\": 0.35665294924554186, \"f0_5\": 0.6891981444665342, \"p4\": 0.6392190268159532, \"phi\": 0.5535081740593287}, {\"truth_threshold\": 10.700000159442425, \"match_probability\": 0.9993992164911604, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 613.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1418.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.3018217626784835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6981782373215165, \"precision\": 1.0, \"recall\": 0.3018217626784835, \"specificity\": 1.0, \"npv\": 0.9971576729800536, \"accuracy\": 0.9971611611611612, \"f1\": 0.4636913767019667, \"f2\": 0.350806913128076, \"f0_5\": 0.6836939549408878, \"p4\": 0.6333057924084281, \"phi\": 0.5486017558550234}, {\"truth_threshold\": 10.800000160932541, \"match_probability\": 0.9994394266126935, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 606.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1425.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2983751846381093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7016248153618907, \"precision\": 1.0, \"recall\": 0.2983751846381093, \"specificity\": 1.0, \"npv\": 0.9971436818241951, \"accuracy\": 0.9971471471471471, \"f1\": 0.459613196814562, \"f2\": 0.3470790378006873, \"f0_5\": 0.6801346801346801, \"p4\": 0.6294900691957122, \"phi\": 0.5454566253837406}, {\"truth_threshold\": 10.900000162422657, \"match_probability\": 0.9994769469006325, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 602.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1429.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2964057114721812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7035942885278188, \"precision\": 1.0, \"recall\": 0.2964057114721812, \"specificity\": 1.0, \"npv\": 0.9971356870542676, \"accuracy\": 0.9971391391391391, \"f1\": 0.45727307254082794, \"f2\": 0.3449461379784552, \"f0_5\": 0.6780806487947736, \"p4\": 0.6272909160573399, \"phi\": 0.5436512786296215}, {\"truth_threshold\": 11.000000163912773, \"match_probability\": 0.9995119571076428, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 600.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1431.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.29542097488921715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7045790251107829, \"precision\": 1.0, \"recall\": 0.29542097488921715, \"specificity\": 1.0, \"npv\": 0.9971316897173782, \"accuracy\": 0.9971351351351352, \"f1\": 0.45610034207525657, \"f2\": 0.343878954607978, \"f0_5\": 0.6770480704129993, \"p4\": 0.6261861765341137, \"phi\": 0.5427463642155885}, {\"truth_threshold\": 11.10000016540289, \"match_probability\": 0.9995446249976983, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 591.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1440.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.29098966026587886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7090103397341211, \"precision\": 1.0, \"recall\": 0.29098966026587886, \"specificity\": 1.0, \"npv\": 0.9971137020979778, \"accuracy\": 0.9971171171171171, \"f1\": 0.45080091533180777, \"f2\": 0.33907056798623064, \"f0_5\": 0.6723549488054608, \"p4\": 0.6211717499439194, \"phi\": 0.538655527605485}, {\"truth_threshold\": 11.200000166893005, \"match_probability\": 0.9995751071426191, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 576.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1455.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.28360413589364847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7163958641063516, \"precision\": 1.0, \"recall\": 0.28360413589364847, \"specificity\": 1.0, \"npv\": 0.9970837241744234, \"accuracy\": 0.997087087087087, \"f1\": 0.44188722669735325, \"f2\": 0.3310344827586207, \"f0_5\": 0.6643598615916955, \"p4\": 0.6126543944030148, \"phi\": 0.5317678704172605}, {\"truth_threshold\": 11.300000168383121, \"match_probability\": 0.9996035496660847, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 574.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1457.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2826193993106844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7173806006893156, \"precision\": 1.0, \"recall\": 0.2826193993106844, \"specificity\": 1.0, \"npv\": 0.9970797272541418, \"accuracy\": 0.9970830830830831, \"f1\": 0.44069097888675623, \"f2\": 0.3299609105541504, \"f0_5\": 0.6632770972960481, \"p4\": 0.6115033236497196, \"phi\": 0.530842795544431}, {\"truth_threshold\": 11.400000169873238, \"match_probability\": 0.99963008893853, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 572.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1459.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2816346627277203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7183653372722797, \"precision\": 1.0, \"recall\": 0.2816346627277203, \"specificity\": 1.0, \"npv\": 0.9970757303659045, \"accuracy\": 0.9970790790790791, \"f1\": 0.4394928928159816, \"f2\": 0.32888684452621897, \"f0_5\": 0.6621903218337578, \"p4\": 0.6103485686137895, \"phi\": 0.529916113206229}, {\"truth_threshold\": 11.500000171363354, \"match_probability\": 0.999654852226126, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 553.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1478.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2722796651895618, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7277203348104382, \"precision\": 1.0, \"recall\": 0.2722796651895618, \"specificity\": 1.0, \"npv\": 0.9970377615257733, \"accuracy\": 0.9970410410410411, \"f1\": 0.4280185758513932, \"f2\": 0.3186585225308286, \"f0_5\": 0.6516615602168278, \"p4\": 0.5991912027014249, \"phi\": 0.5210308128024558}, {\"truth_threshold\": 11.60000017285347, \"match_probability\": 0.9996779582968373, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 547.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1484.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2693254554406696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7306745445593303, \"precision\": 1.0, \"recall\": 0.2693254554406696, \"specificity\": 1.0, \"npv\": 0.9970257719664979, \"accuracy\": 0.997029029029029, \"f1\": 0.4243599689681924, \"f2\": 0.315419213470188, \"f0_5\": 0.6482578810144584, \"p4\": 0.5955958967463277, \"phi\": 0.5181934196040724}, {\"truth_threshold\": 11.700000174343586, \"match_probability\": 0.9996995179863626, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 543.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1488.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2673559822747415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7326440177252584, \"precision\": 1.0, \"recall\": 0.2673559822747415, \"specificity\": 1.0, \"npv\": 0.9970177790871758, \"accuracy\": 0.997021021021021, \"f1\": 0.4219114219114219, \"f2\": 0.31325718241606093, \"f0_5\": 0.6459671663097787, \"p4\": 0.5931793891193405, \"phi\": 0.5162931993288631}, {\"truth_threshold\": 11.800000175833702, \"match_probability\": 0.9997196347265854, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 540.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1491.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2658788774002954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7341211225997046, \"precision\": 1.0, \"recall\": 0.2658788774002954, \"specificity\": 1.0, \"npv\": 0.9970117845117845, \"accuracy\": 0.997015015015015, \"f1\": 0.4200700116686114, \"f2\": 0.31163434903047094, \"f0_5\": 0.6442376521116678, \"p4\": 0.5913565887427883, \"phi\": 0.5148634518208284}, {\"truth_threshold\": 11.900000177323818, \"match_probability\": 0.9997384050389891, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 526.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1505.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.258985721319547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.741014278680453, \"precision\": 1.0, \"recall\": 0.258985721319547, \"specificity\": 1.0, \"npv\": 0.99698381077972, \"accuracy\": 0.996986986986987, \"f1\": 0.4114196323816973, \"f2\": 0.3040462427745665, \"f0_5\": 0.6360338573155986, \"p4\": 0.5827300340308567, \"phi\": 0.5081383388199483}, {\"truth_threshold\": 12.000000178813934, \"match_probability\": 0.9997559189953416, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 516.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1515.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.25406203840472674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7459379615952733, \"precision\": 1.0, \"recall\": 0.25406203840472674, \"specificity\": 1.0, \"npv\": 0.9969638305035833, \"accuracy\": 0.996966966966967, \"f1\": 0.40518256772673733, \"f2\": 0.2986111111111111, \"f0_5\": 0.63003663003663, \"p4\": 0.5764443016145133, \"phi\": 0.5032799052153035}, {\"truth_threshold\": 12.10000018030405, \"match_probability\": 0.9997722606477963, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 507.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1524.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.24963072378138848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7503692762186115, \"precision\": 1.0, \"recall\": 0.24963072378138848, \"specificity\": 1.0, \"npv\": 0.9969458489397647, \"accuracy\": 0.9969489489489489, \"f1\": 0.39952718676122934, \"f2\": 0.29370872436565865, \"f0_5\": 0.6245380635624538, \"p4\": 0.5706963950831065, \"phi\": 0.49886703022116446}, {\"truth_threshold\": 12.200000181794167, \"match_probability\": 0.9997875084304283, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 504.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1527.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2481536189069424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7518463810930576, \"precision\": 1.0, \"recall\": 0.2481536189069424, \"specificity\": 1.0, \"npv\": 0.9969398552293004, \"accuracy\": 0.996942942942943, \"f1\": 0.39763313609467454, \"f2\": 0.29207232267037553, \"f0_5\": 0.6226834692364714, \"p4\": 0.5687609652746577, \"phi\": 0.4973874072669252}, {\"truth_threshold\": 12.300000183284283, \"match_probability\": 0.9998017355340825, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 500.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1531.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.24618414574101427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7538158542589857, \"precision\": 1.0, \"recall\": 0.24618414574101427, \"specificity\": 1.0, \"npv\": 0.9969318637274549, \"accuracy\": 0.9969349349349349, \"f1\": 0.3951007506914263, \"f2\": 0.2898886827458256, \"f0_5\": 0.6201935003721161, \"p4\": 0.5661650499150063, \"phi\": 0.49540773029267593}, {\"truth_threshold\": 12.400000184774399, \"match_probability\": 0.9998150102562988, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 488.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1543.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.24027572624322993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7597242737567701, \"precision\": 1.0, \"recall\": 0.24027572624322993, \"specificity\": 1.0, \"npv\": 0.9969078899906215, \"accuracy\": 0.9969109109109109, \"f1\": 0.38745533942040494, \"f2\": 0.2833255921969345, \"f0_5\": 0.6126035651518955, \"p4\": 0.5582703820327369, \"phi\": 0.4894208488255303}, {\"truth_threshold\": 12.700000189244747, \"match_probability\": 0.9998497364189812, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 487.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1544.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2397833579517479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7602166420482521, \"precision\": 1.0, \"recall\": 0.2397833579517479, \"specificity\": 1.0, \"npv\": 0.9969058922312645, \"accuracy\": 0.9969089089089089, \"f1\": 0.3868149324861001, \"f2\": 0.2827778422947393, \"f0_5\": 0.6119628047248052, \"p4\": 0.5576051477023994, \"phi\": 0.4889186459945007}, {\"truth_threshold\": 12.800000190734863, \"match_probability\": 0.9998597977108138, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 463.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1568.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.22796651895617923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7720334810438207, \"precision\": 1.0, \"recall\": 0.22796651895617923, \"specificity\": 1.0, \"npv\": 0.9968579484086351, \"accuracy\": 0.9968608608608609, \"f1\": 0.37129109863672816, \"f2\": 0.2695935716781181, \"f0_5\": 0.5961885140355395, \"p4\": 0.5412894930798509, \"phi\": 0.4767077054050155}, {\"truth_threshold\": 12.90000019222498, \"match_probability\": 0.9998691854106266, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 453.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1578.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.22304283604135894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7769571639586411, \"precision\": 1.0, \"recall\": 0.22304283604135894, \"specificity\": 1.0, \"npv\": 0.9968379731768752, \"accuracy\": 0.9968408408408408, \"f1\": 0.3647342995169082, \"f2\": 0.26407834907310246, \"f0_5\": 0.5893832943013271, \"p4\": 0.5342868026431918, \"phi\": 0.47152684823993884}, {\"truth_threshold\": 13.000000193715096, \"match_probability\": 0.9998779446032292, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 431.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1600.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2122107336287543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7877892663712457, \"precision\": 1.0, \"recall\": 0.2122107336287543, \"specificity\": 1.0, \"npv\": 0.9967940304847627, \"accuracy\": 0.9967967967967968, \"f1\": 0.35012185215272135, \"f2\": 0.25189947399181767, \"f0_5\": 0.5739014647137151, \"p4\": 0.5184360214072936, \"phi\": 0.4599243334353319}, {\"truth_threshold\": 13.100000195205212, \"match_probability\": 0.9998861173572945, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 417.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1614.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.20531757754800592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.794682422451994, \"precision\": 1.0, \"recall\": 0.20531757754800592, \"specificity\": 1.0, \"npv\": 0.9967660689704919, \"accuracy\": 0.9967687687687687, \"f1\": 0.34068627450980393, \"f2\": 0.24411661397962767, \"f0_5\": 0.5636658556366586, \"p4\": 0.5080172733036484, \"phi\": 0.45238655446760345}, {\"truth_threshold\": 13.200000196695328, \"match_probability\": 0.9998937429269453, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 413.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1618.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.2033481043820778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7966518956179222, \"precision\": 1.0, \"recall\": 0.2033481043820778, \"specificity\": 1.0, \"npv\": 0.9967580802545448, \"accuracy\": 0.9967607607607608, \"f1\": 0.33797054009819966, \"f2\": 0.2418882511420874, \"f0_5\": 0.5606842248167255, \"p4\": 0.5049913337897823, \"phi\": 0.45020980236694164}, {\"truth_threshold\": 13.300000198185444, \"match_probability\": 0.9999008579398913, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 412.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1619.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.20285573609059576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7971442639094042, \"precision\": 1.0, \"recall\": 0.20285573609059576, \"specificity\": 1.0, \"npv\": 0.9967560830955663, \"accuracy\": 0.9967587587587587, \"f1\": 0.3372902169463774, \"f2\": 0.24133083411433928, \"f0_5\": 0.5599347648817613, \"p4\": 0.504231375792285, \"phi\": 0.44966397336136477}, {\"truth_threshold\": 13.500000201165676, \"match_probability\": 0.9999136907162209, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 407.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1624.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.20039389463318563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7996061053668144, \"precision\": 1.0, \"recall\": 0.20039389463318563, \"specificity\": 1.0, \"npv\": 0.9967460974207212, \"accuracy\": 0.9967487487487487, \"f1\": 0.3338802296964725, \"f2\": 0.23854178877036689, \"f0_5\": 0.5561628860344356, \"p4\": 0.500410554633783, \"phi\": 0.44692486216652455}, {\"truth_threshold\": 13.700000204145908, \"match_probability\": 0.9999248625650565, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 402.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1629.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.19793205317577547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8020679468242246, \"precision\": 1.0, \"recall\": 0.19793205317577547, \"specificity\": 1.0, \"npv\": 0.9967361119459505, \"accuracy\": 0.9967387387387387, \"f1\": 0.33045622688039455, \"f2\": 0.23574947220267417, \"f0_5\": 0.5523495465787304, \"p4\": 0.49655432377542263, \"phi\": 0.44416891506711903}, {\"truth_threshold\": 13.800000205636024, \"match_probability\": 0.999929893941616, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 396.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1635.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.19497784342688332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8050221565731167, \"precision\": 1.0, \"recall\": 0.19497784342688332, \"specificity\": 1.0, \"npv\": 0.9967241296403154, \"accuracy\": 0.9967267267267267, \"f1\": 0.3263288009888752, \"f2\": 0.2323943661971831, \"f0_5\": 0.5477178423236515, \"p4\": 0.49187940817017556, \"phi\": 0.4408391104346414}, {\"truth_threshold\": 13.90000020712614, \"match_probability\": 0.9999345884275949, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 388.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1643.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.19103889709502708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8089611029049729, \"precision\": 1.0, \"recall\": 0.19103889709502708, \"specificity\": 1.0, \"npv\": 0.9967081536809373, \"accuracy\": 0.9967107107107107, \"f1\": 0.32079371641174037, \"f2\": 0.22791353383458646, \"f0_5\": 0.541445715880547, \"p4\": 0.48556424769986567, \"phi\": 0.43635997342197536}, {\"truth_threshold\": 14.000000208616257, \"match_probability\": 0.9999389685776376, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 382.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1649.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1880846873461349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8119153126538651, \"precision\": 1.0, \"recall\": 0.1880846873461349, \"specificity\": 1.0, \"npv\": 0.9966961720474917, \"accuracy\": 0.9966986986986986, \"f1\": 0.31661831744716123, \"f2\": 0.22454737832118504, \"f0_5\": 0.5366676032593425, \"p4\": 0.4807652606354247, \"phi\": 0.4329703083337724}, {\"truth_threshold\": 14.100000210106373, \"match_probability\": 0.9999430554367367, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 377.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1654.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.18562284588872477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8143771541112752, \"precision\": 1.0, \"recall\": 0.18562284588872477, \"specificity\": 1.0, \"npv\": 0.9966861875730031, \"accuracy\": 0.9966886886886887, \"f1\": 0.3131229235880399, \"f2\": 0.22173861898600164, \"f0_5\": 0.532636337948573, \"p4\": 0.47672436577810395, \"phi\": 0.43012524524292245}, {\"truth_threshold\": 14.200000211596489, \"match_probability\": 0.9999468686412301, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 361.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1670.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1777449532250123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8222550467749877, \"precision\": 1.0, \"recall\": 0.1777449532250123, \"specificity\": 1.0, \"npv\": 0.9966542385988673, \"accuracy\": 0.9966566566566567, \"f1\": 0.30183946488294316, \"f2\": 0.21272834413671185, \"f0_5\": 0.5194244604316547, \"p4\": 0.4635318746105203, \"phi\": 0.4208922201957004}, {\"truth_threshold\": 14.300000213086605, \"match_probability\": 0.9999504265130488, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 348.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1683.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.17134416543574593, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8286558345642541, \"precision\": 1.0, \"recall\": 0.17134416543574593, \"specificity\": 1.0, \"npv\": 0.9966282815655352, \"accuracy\": 0.9966306306306306, \"f1\": 0.29255989911727615, \"f2\": 0.20538243626062322, \"f0_5\": 0.5083260297984225, \"p4\": 0.4525096740997463, \"phi\": 0.413238963741935}, {\"truth_threshold\": 14.400000214576721, \"match_probability\": 0.9999537461476637, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 347.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1684.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1708517971442639, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8291482028557361, \"precision\": 1.0, \"recall\": 0.1708517971442639, \"specificity\": 1.0, \"npv\": 0.9966262849266657, \"accuracy\": 0.9966286286286287, \"f1\": 0.29184188393608074, \"f2\": 0.20481643253452958, \"f0_5\": 0.5074583211465341, \"p4\": 0.4516502189669047, \"phi\": 0.4126443891063249}, {\"truth_threshold\": 14.500000216066837, \"match_probability\": 0.9999568434961527, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 342.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1689.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.16838995568685378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8316100443131462, \"precision\": 1.0, \"recall\": 0.16838995568685378, \"specificity\": 1.0, \"npv\": 0.9966163018523193, \"accuracy\": 0.9966186186186187, \"f1\": 0.28824273072060685, \"f2\": 0.20198440822111977, \"f0_5\": 0.5030891438658429, \"p4\": 0.44732763619010013, \"phi\": 0.4096586077524896}, {\"truth_threshold\": 14.70000021904707, \"match_probability\": 0.9999624298714548, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 335.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1696.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.16494337764647957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8350566223535204, \"precision\": 1.0, \"recall\": 0.16494337764647957, \"specificity\": 1.0, \"npv\": 0.9966023258842267, \"accuracy\": 0.9966046046046046, \"f1\": 0.28317836010143704, \"f2\": 0.19801394963943728, \"f0_5\": 0.4968851972708395, \"p4\": 0.4412042490270683, \"phi\": 0.4054416774354629}, {\"truth_threshold\": 14.900000222027302, \"match_probability\": 0.9999672931444318, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 325.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1706.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.16001969473165928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8399803052683407, \"precision\": 1.0, \"recall\": 0.16001969473165928, \"specificity\": 1.0, \"npv\": 0.9965823608954776, \"accuracy\": 0.9965845845845845, \"f1\": 0.2758913412563667, \"f2\": 0.1923304533080838, \"f0_5\": 0.48784148904232966, \"p4\": 0.43230810862869334, \"phi\": 0.39934046272003365}, {\"truth_threshold\": 15.000000223517418, \"match_probability\": 0.9999694833578969, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 324.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1707.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.15952732644017725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8404726735598228, \"precision\": 1.0, \"recall\": 0.15952732644017725, \"specificity\": 1.0, \"npv\": 0.996580364440598, \"accuracy\": 0.9965825825825826, \"f1\": 0.2751592356687898, \"f2\": 0.19176136363636365, \"f0_5\": 0.48692515779981965, \"p4\": 0.43140871642639556, \"phi\": 0.3987252200726537}, {\"truth_threshold\": 15.20000022649765, \"match_probability\": 0.9999734336151354, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 322.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1709.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1585425898572132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8414574101427869, \"precision\": 1.0, \"recall\": 0.1585425898572132, \"specificity\": 1.0, \"npv\": 0.9965763715548361, \"accuracy\": 0.9965785785785786, \"f1\": 0.27369315767105823, \"f2\": 0.1906227800142079, \"f0_5\": 0.4850858692377222, \"p4\": 0.4296045289878701, \"phi\": 0.39749188537227786}, {\"truth_threshold\": 15.300000227987766, \"match_probability\": 0.9999752126423825, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 319.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1712.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.15706548498276712, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8429345150172329, \"precision\": 1.0, \"recall\": 0.15706548498276712, \"specificity\": 1.0, \"npv\": 0.9965703822861848, \"accuracy\": 0.9965725725725726, \"f1\": 0.2714893617021277, \"f2\": 0.1889138931659363, \"f0_5\": 0.4823102509827638, \"p4\": 0.4268846587739541, \"phi\": 0.3956346931365363}, {\"truth_threshold\": 15.400000229477882, \"match_probability\": 0.9999768725392036, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 318.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1713.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.15657311669128507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.843426883308715, \"precision\": 1.0, \"recall\": 0.15657311669128507, \"specificity\": 1.0, \"npv\": 0.9965683858792985, \"accuracy\": 0.9965705705705705, \"f1\": 0.2707535121328225, \"f2\": 0.18834399431414356, \"f0_5\": 0.48138056312443234, \"p4\": 0.4259743897423014, \"phi\": 0.39501369365266953}, {\"truth_threshold\": 15.500000230967999, \"match_probability\": 0.9999784212826682, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 317.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1714.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.15608074839980304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.843919251600197, \"precision\": 1.0, \"recall\": 0.15608074839980304, \"specificity\": 1.0, \"npv\": 0.996566389480411, \"accuracy\": 0.9965685685685686, \"f1\": 0.27001703577512776, \"f2\": 0.18777396043122851, \"f0_5\": 0.48044862079418005, \"p4\": 0.42506228871673374, \"phi\": 0.394391718853467}, {\"truth_threshold\": 15.600000232458115, \"match_probability\": 0.9999798663157408, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 315.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1716.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.155096011816839, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.844903988183161, \"precision\": 1.0, \"recall\": 0.155096011816839, \"specificity\": 1.0, \"npv\": 0.9965623967066318, \"accuracy\": 0.9965645645645645, \"f1\": 0.26854219948849106, \"f2\": 0.18663348738002133, \"f0_5\": 0.4785779398359161, \"p4\": 0.4232325684952077, \"phi\": 0.39314482478576407}, {\"truth_threshold\": 15.70000023394823, \"match_probability\": 0.9999812145830361, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 311.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1720.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1531265386509109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8468734613490891, \"precision\": 1.0, \"recall\": 0.1531265386509109, \"specificity\": 1.0, \"npv\": 0.9965544112550557, \"accuracy\": 0.9965565565565565, \"f1\": 0.2655849701110162, \"f2\": 0.18435091879075283, \"f0_5\": 0.47480916030534354, \"p4\": 0.41955089879085256, \"phi\": 0.3906391270377086}, {\"truth_threshold\": 15.800000235438347, \"match_probability\": 0.9999824725641815, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 300.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1731.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.14771048744460857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8522895125553914, \"precision\": 1.0, \"recall\": 0.14771048744460857, \"specificity\": 1.0, \"npv\": 0.9965324519230769, \"accuracy\": 0.9965345345345346, \"f1\": 0.2574002574002574, \"f2\": 0.17806267806267806, \"f0_5\": 0.46425255338904364, \"p4\": 0.4092708183838623, \"phi\": 0.3836642988706776}, {\"truth_threshold\": 15.900000236928463, \"match_probability\": 0.9999836463049459, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 297.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1734.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.14623338257016247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8537666174298375, \"precision\": 1.0, \"recall\": 0.14623338257016247, \"specificity\": 1.0, \"npv\": 0.9965264631823126, \"accuracy\": 0.9965285285285286, \"f1\": 0.2551546391752577, \"f2\": 0.17634485215532597, \"f0_5\": 0.4613233923578751, \"p4\": 0.406426848783649, \"phi\": 0.3817400103890475}, {\"truth_threshold\": 16.00000023841858, \"match_probability\": 0.9999847414462861, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 294.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1737.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1447562776957164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8552437223042836, \"precision\": 1.0, \"recall\": 0.1447562776957164, \"specificity\": 1.0, \"npv\": 0.9965204745135274, \"accuracy\": 0.9965225225225225, \"f1\": 0.25290322580645164, \"f2\": 0.17462580185317178, \"f0_5\": 0.4583723105706268, \"p4\": 0.4035653000581266, \"phi\": 0.379805995921796}, {\"truth_threshold\": 16.300000242888927, \"match_probability\": 0.9999876061677141, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 293.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1738.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.14426390940423436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8557360905957656, \"precision\": 1.0, \"recall\": 0.14426390940423436, \"specificity\": 1.0, \"npv\": 0.9965184783065942, \"accuracy\": 0.9965205205205205, \"f1\": 0.2521514629948365, \"f2\": 0.17405251277177142, \"f0_5\": 0.45738370277864504, \"p4\": 0.4026075157839411, \"phi\": 0.3791591374002056}, {\"truth_threshold\": 16.400000244379044, \"match_probability\": 0.9999884361359999, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 292.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1739.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.14377154111275234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8562284588872476, \"precision\": 1.0, \"recall\": 0.14377154111275234, \"specificity\": 1.0, \"npv\": 0.9965164821076585, \"accuracy\": 0.9965185185185185, \"f1\": 0.2513990529487731, \"f2\": 0.17347908745247148, \"f0_5\": 0.4563926226945921, \"p4\": 0.40164775399594516, \"phi\": 0.3785111760263844}, {\"truth_threshold\": 16.50000024586916, \"match_probability\": 0.9999892105250341, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 291.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1740.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1432791728212703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8567208271787297, \"precision\": 1.0, \"recall\": 0.1432791728212703, \"specificity\": 1.0, \"npv\": 0.9965144859167202, \"accuracy\": 0.9965165165165165, \"f1\": 0.25064599483204136, \"f2\": 0.17290552584670232, \"f0_5\": 0.45539906103286387, \"p4\": 0.40068600855770675, \"phi\": 0.3778621061267736}, {\"truth_threshold\": 16.600000247359276, \"match_probability\": 0.9999899330566321, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 283.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1748.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.13934022648941408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8606597735105859, \"precision\": 1.0, \"recall\": 0.13934022648941408, \"specificity\": 1.0, \"npv\": 0.9964985166771164, \"accuracy\": 0.9965005005005005, \"f1\": 0.2445980985306828, \"f2\": 0.16831212085167122, \"f0_5\": 0.44736010116977554, \"p4\": 0.3929198888228585, \"phi\": 0.3726289427971941}, {\"truth_threshold\": 16.700000248849392, \"match_probability\": 0.9999906072033913, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 281.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1750.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.13835548990645002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8616445100935499, \"precision\": 1.0, \"recall\": 0.13835548990645002, \"specificity\": 1.0, \"npv\": 0.9964945244471866, \"accuracy\": 0.9964964964964965, \"f1\": 0.2430795847750865, \"f2\": 0.16716240333135038, \"f0_5\": 0.44532488114104596, \"p4\": 0.3909580850538738, \"phi\": 0.3713091543700282}, {\"truth_threshold\": 16.800000250339508, \"match_probability\": 0.9999912362053778, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 274.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1757.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.13490891186607581, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8650910881339242, \"precision\": 1.0, \"recall\": 0.13490891186607581, \"specificity\": 1.0, \"npv\": 0.9964805518943324, \"accuracy\": 0.9964824824824825, \"f1\": 0.23774403470715835, \"f2\": 0.16313407954274828, \"f0_5\": 0.4381196034537896, \"p4\": 0.384026766205053, \"phi\": 0.36665256981476496}, {\"truth_threshold\": 16.900000251829624, \"match_probability\": 0.999991823085696, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 268.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1763.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.13195470211718366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8680452978828164, \"precision\": 1.0, \"recall\": 0.13195470211718366, \"specificity\": 1.0, \"npv\": 0.9964685757323248, \"accuracy\": 0.9964704704704704, \"f1\": 0.23314484558503698, \"f2\": 0.15967588179218303, \"f0_5\": 0.43184015468901066, \"p4\": 0.378003873397531, \"phi\": 0.362613725719109}, {\"truth_threshold\": 17.00000025331974, \"match_probability\": 0.9999923706650156, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 266.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1765.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1309699655342196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8690300344657804, \"precision\": 1.0, \"recall\": 0.1309699655342196, \"specificity\": 1.0, \"npv\": 0.9964645837422932, \"accuracy\": 0.9964664664664664, \"f1\": 0.23160644318676535, \"f2\": 0.15852205005959474, \"f0_5\": 0.4297253634894992, \"p4\": 0.3759792035638725, \"phi\": 0.3612574320187733}, {\"truth_threshold\": 17.200000256299973, \"match_probability\": 0.999993358271586, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 263.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1768.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1294928606597735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8705071393402265, \"precision\": 1.0, \"recall\": 0.1294928606597735, \"specificity\": 1.0, \"npv\": 0.9964585958172171, \"accuracy\": 0.9964604604604604, \"f1\": 0.22929380993897122, \"f2\": 0.15679027065696913, \"f0_5\": 0.4265325981187155, \"p4\": 0.3729260376731259, \"phi\": 0.35921341024715714}, {\"truth_threshold\": 17.30000025779009, \"match_probability\": 0.999993803045519, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 254.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1777.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.12506154603643527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8749384539635647, \"precision\": 1.0, \"recall\": 0.12506154603643527, \"specificity\": 1.0, \"npv\": 0.9964406324737705, \"accuracy\": 0.9964424424424424, \"f1\": 0.2223194748358862, \"f2\": 0.1515874910479828, \"f0_5\": 0.4168034131933049, \"p4\": 0.36364842770586453, \"phi\": 0.35301048997259715}, {\"truth_threshold\": 17.400000259280205, \"match_probability\": 0.9999942180346287, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 253.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1778.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.12456917774495323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8754308222550468, \"precision\": 1.0, \"recall\": 0.12456917774495323, \"specificity\": 1.0, \"npv\": 0.9964386365866996, \"accuracy\": 0.9964404404404404, \"f1\": 0.22154115586690018, \"f2\": 0.15100871433687477, \"f0_5\": 0.41570818271442656, \"p4\": 0.3626064927551711, \"phi\": 0.352314549277925}, {\"truth_threshold\": 17.50000026077032, \"match_probability\": 0.9999946052334694, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 249.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1782.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.12259970457902511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8774002954209749, \"precision\": 1.0, \"recall\": 0.12259970457902511, \"specificity\": 1.0, \"npv\": 0.9964306531183713, \"accuracy\": 0.9964324324324324, \"f1\": 0.21842105263157896, \"f2\": 0.14869222500895737, \"f0_5\": 0.41129831516352827, \"p4\": 0.3584162383936605, \"phi\": 0.3495169576798776}, {\"truth_threshold\": 17.600000262260437, \"match_probability\": 0.999994966503032, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 245.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1786.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.12063023141309699, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.879369768586903, \"precision\": 1.0, \"recall\": 0.12063023141309699, \"specificity\": 1.0, \"npv\": 0.9964226697779692, \"accuracy\": 0.9964244244244245, \"f1\": 0.21528998242530756, \"f2\": 0.14637352132871312, \"f0_5\": 0.4068415808701428, \"p4\": 0.35418960863255716, \"phi\": 0.346696837655858}, {\"truth_threshold\": 17.700000263750553, \"match_probability\": 0.9999953035796879, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 240.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1791.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.11816838995568685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8818316100443131, \"precision\": 1.0, \"recall\": 0.11816838995568685, \"specificity\": 1.0, \"npv\": 0.9964126907823578, \"accuracy\": 0.9964144144144144, \"f1\": 0.21136063408190225, \"f2\": 0.14347202295552366, \"f0_5\": 0.4012036108324975, \"p4\": 0.3488544423770536, \"phi\": 0.34313916040167275}, {\"truth_threshold\": 17.80000026524067, \"match_probability\": 0.9999956180835331, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 236.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1795.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.11619891678975874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8838010832102413, \"precision\": 1.0, \"recall\": 0.11619891678975874, \"specificity\": 1.0, \"npv\": 0.9964047077297782, \"accuracy\": 0.9964064064064064, \"f1\": 0.20820467578297308, \"f2\": 0.14114832535885166, \"f0_5\": 0.39663865546218485, \"p4\": 0.3445442143793838, \"phi\": 0.3402662894299351}, {\"truth_threshold\": 17.900000266730785, \"match_probability\": 0.9999959115261747, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 231.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1800.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.1137370753323486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8862629246676514, \"precision\": 1.0, \"recall\": 0.1137370753323486, \"specificity\": 1.0, \"npv\": 0.9963947290939353, \"accuracy\": 0.9963963963963964, \"f1\": 0.20424403183023873, \"f2\": 0.13824057450628366, \"f0_5\": 0.39086294416243655, \"p4\": 0.339102998241512, \"phi\": 0.33664079129498253}, {\"truth_threshold\": 18.0000002682209, \"match_probability\": 0.9999961853179954, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 224.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1807.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.11029049729197439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8897095027080256, \"precision\": 1.0, \"recall\": 0.11029049729197439, \"specificity\": 1.0, \"npv\": 0.9963807593395236, \"accuracy\": 0.9963823823823824, \"f1\": 0.19866962305986696, \"f2\": 0.13416387158600862, \"f0_5\": 0.38264434574649814, \"p4\": 0.3313837839511626, \"phi\": 0.331498611520035}, {\"truth_threshold\": 18.100000269711018, \"match_probability\": 0.999996440774932, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 220.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1811.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.10832102412604629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8916789758739537, \"precision\": 1.0, \"recall\": 0.10832102412604629, \"specificity\": 1.0, \"npv\": 0.9963727767985899, \"accuracy\": 0.9963743743743744, \"f1\": 0.19546868058640604, \"f2\": 0.1318312559923298, \"f0_5\": 0.3778770182068018, \"p4\": 0.326918681809007, \"phi\": 0.32852415374540694}, {\"truth_threshold\": 18.200000271201134, \"match_probability\": 0.9999966791247992, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 215.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1816.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.10585918266863614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8941408173313639, \"precision\": 1.0, \"recall\": 0.10585918266863614, \"specificity\": 1.0, \"npv\": 0.9963627988022873, \"accuracy\": 0.9963643643643644, \"f1\": 0.19145146927871773, \"f2\": 0.12891233960906584, \"f0_5\": 0.37184365271532344, \"p4\": 0.32128095728728057, \"phi\": 0.32476784250083146}, {\"truth_threshold\": 18.30000027269125, \"match_probability\": 0.999996901513191, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 210.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1821.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.103397341211226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.896602658788774, \"precision\": 1.0, \"recall\": 0.103397341211226, \"specificity\": 1.0, \"npv\": 0.9963528210058282, \"accuracy\": 0.9963543543543544, \"f1\": 0.18741633199464525, \"f2\": 0.1259899208063355, \"f0_5\": 0.3657262277951933, \"p4\": 0.31557963562363744, \"phi\": 0.3209676503953431}, {\"truth_threshold\": 18.400000274181366, \"match_probability\": 0.9999971090089864, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 209.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1822.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.10290497291974397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.897095027080256, \"precision\": 1.0, \"recall\": 0.10290497291974397, \"specificity\": 1.0, \"npv\": 0.9963508254705172, \"accuracy\": 0.9963523523523523, \"f1\": 0.18660714285714286, \"f2\": 0.12540501620064803, \"f0_5\": 0.36449250087199164, \"p4\": 0.3144316447528884, \"phi\": 0.3202022091016989}, {\"truth_threshold\": 18.500000275671482, \"match_probability\": 0.9999973026094866, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 201.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1830.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.09896602658788774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9010339734121122, \"precision\": 1.0, \"recall\": 0.09896602658788774, \"specificity\": 1.0, \"npv\": 0.9963348614757891, \"accuracy\": 0.9963363363363363, \"f1\": 0.18010752688172044, \"f2\": 0.12072072072072072, \"f0_5\": 0.3544973544973545, \"p4\": 0.30515351883685193, \"phi\": 0.31401162779625275}, {\"truth_threshold\": 18.600000277161598, \"match_probability\": 0.999997483245208, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 200.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1831.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.09847365829640571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9015263417035942, \"precision\": 1.0, \"recall\": 0.09847365829640571, \"specificity\": 1.0, \"npv\": 0.9963328660124174, \"accuracy\": 0.9963343343343344, \"f1\": 0.17929179740026893, \"f2\": 0.12013455069678039, \"f0_5\": 0.35323207347227126, \"p4\": 0.3039818437775873, \"phi\": 0.31322921670429366}, {\"truth_threshold\": 18.80000028014183, \"match_probability\": 0.9999978090369889, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 195.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1836.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.09601181683899557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9039881831610044, \"precision\": 1.0, \"recall\": 0.09601181683899557, \"specificity\": 1.0, \"npv\": 0.9963228888154535, \"accuracy\": 0.9963243243243243, \"f1\": 0.1752021563342318, \"f2\": 0.11720158672917418, \"f0_5\": 0.3468516542155816, \"p4\": 0.2980831325024318, \"phi\": 0.30928752110851204}, {\"truth_threshold\": 18.900000281631947, \"match_probability\": 0.9999979557589296, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 192.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1839.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.09453471196454949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9054652880354506, \"precision\": 1.0, \"recall\": 0.09453471196454949, \"specificity\": 1.0, \"npv\": 0.996316902593189, \"accuracy\": 0.9963183183183183, \"f1\": 0.17273954116059378, \"f2\": 0.11544011544011544, \"f0_5\": 0.3429796355841372, \"p4\": 0.29451130228296535, \"phi\": 0.30689824276469757}, {\"truth_threshold\": 19.000000283122063, \"match_probability\": 0.9999980926553794, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 190.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1841.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.09354997538158542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9064500246184146, \"precision\": 1.0, \"recall\": 0.09354997538158542, \"specificity\": 1.0, \"npv\": 0.9963129118183093, \"accuracy\": 0.9963143143143143, \"f1\": 0.1710941017559658, \"f2\": 0.11426509502044743, \"f0_5\": 0.3403797921891795, \"p4\": 0.29211634045500046, \"phi\": 0.3052950185852342}, {\"truth_threshold\": 19.10000028461218, \"match_probability\": 0.9999982203843173, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 182.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1849.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0896110290497292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9103889709502708, \"precision\": 1.0, \"recall\": 0.0896110290497292, \"specificity\": 1.0, \"npv\": 0.9962969490384885, \"accuracy\": 0.9962982982982983, \"f1\": 0.16448260280162674, \"f2\": 0.10955935468336142, \"f0_5\": 0.3298296484233418, \"p4\": 0.28242489359262934, \"phi\": 0.29879624301929325}, {\"truth_threshold\": 19.200000286102295, \"match_probability\": 0.9999983395596597, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 175.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1856.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.08616445100935499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.913835548990645, \"precision\": 1.0, \"recall\": 0.08616445100935499, \"specificity\": 1.0, \"npv\": 0.9962829820257347, \"accuracy\": 0.9962842842842843, \"f1\": 0.1586582048957389, \"f2\": 0.10543438968550428, \"f0_5\": 0.3203954595386305, \"p4\": 0.27379547635489215, \"phi\": 0.2929917681372815}, {\"truth_threshold\": 19.30000028759241, \"match_probability\": 0.9999984507542113, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 169.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1862.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.08321024126046282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9167897587395372, \"precision\": 1.0, \"recall\": 0.08321024126046282, \"specificity\": 1.0, \"npv\": 0.9962710106121991, \"accuracy\": 0.9962722722722722, \"f1\": 0.15363636363636363, \"f2\": 0.10189316290847703, \"f0_5\": 0.31215367565570745, \"p4\": 0.2662850903205423, \"phi\": 0.2879235161528947}, {\"truth_threshold\": 19.400000289082527, \"match_probability\": 0.9999985545024187, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 166.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1865.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.08173313638601674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9182668636139832, \"precision\": 1.0, \"recall\": 0.08173313638601674, \"specificity\": 1.0, \"npv\": 0.9962650250133177, \"accuracy\": 0.9962662662662662, \"f1\": 0.1511151570323168, \"f2\": 0.10012062726176116, \"f0_5\": 0.3079777365491651, \"p4\": 0.26248977646324917, \"phi\": 0.28535568185342286}, {\"truth_threshold\": 19.500000290572643, \"match_probability\": 0.9999986513029383, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 146.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1885.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.07188577055637617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9281142294436239, \"precision\": 1.0, \"recall\": 0.07188577055637617, \"specificity\": 1.0, \"npv\": 0.9962251228587334, \"accuracy\": 0.9962262262262263, \"f1\": 0.13412953605879652, \"f2\": 0.08827085852478839, \"f0_5\": 0.27915869980879543, \"p4\": 0.23648002204423532, \"phi\": 0.2676086893288792}, {\"truth_threshold\": 19.60000029206276, \"match_probability\": 0.9999987416210334, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 143.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1888.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.07040866568193008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.92959133431807, \"precision\": 1.0, \"recall\": 0.07040866568193008, \"specificity\": 1.0, \"npv\": 0.9962191378112253, \"accuracy\": 0.9962202202202202, \"f1\": 0.13155473781048757, \"f2\": 0.08648844804644974, \"f0_5\": 0.2746830580099885, \"p4\": 0.23246903882659015, \"phi\": 0.26484421877792835}, {\"truth_threshold\": 19.700000293552876, \"match_probability\": 0.9999988258908107, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 139.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1892.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.06843919251600197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.931560807483998, \"precision\": 1.0, \"recall\": 0.06843919251600197, \"specificity\": 1.0, \"npv\": 0.9962111578597448, \"accuracy\": 0.9962122122122122, \"f1\": 0.12811059907834102, \"f2\": 0.08410988745007866, \"f0_5\": 0.2686509470429068, \"p4\": 0.227075145531802, \"phi\": 0.2611127863957495}, {\"truth_threshold\": 19.80000029504299, \"match_probability\": 0.9999989045173057, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 136.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1895.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.06696208764155588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9330379123584441, \"precision\": 1.0, \"recall\": 0.06696208764155588, \"specificity\": 1.0, \"npv\": 0.9962051729800306, \"accuracy\": 0.9962062062062063, \"f1\": 0.12551915089986157, \"f2\": 0.08232445520581114, \"f0_5\": 0.26407766990291265, \"p4\": 0.22299486459127488, \"phi\": 0.25827887660832843}, {\"truth_threshold\": 19.900000296533108, \"match_probability\": 0.9999989778784306, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 135.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1896.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.06646971935007386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9335302806499262, \"precision\": 1.0, \"recall\": 0.06646971935007386, \"specificity\": 1.0, \"npv\": 0.9962031780361058, \"accuracy\": 0.9962042042042042, \"f1\": 0.12465373961218837, \"f2\": 0.08172902288412641, \"f0_5\": 0.26254375729288215, \"p4\": 0.22162806524031964, \"phi\": 0.2573273123081023}, {\"truth_threshold\": 20.000000298023224, \"match_probability\": 0.99999904632679, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 133.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1898.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0654849827671098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9345150172328902, \"precision\": 1.0, \"recall\": 0.0654849827671098, \"specificity\": 1.0, \"npv\": 0.9961991881722261, \"accuracy\": 0.9962002002002002, \"f1\": 0.12292051756007394, \"f2\": 0.08053772556618627, \"f0_5\": 0.259461568474444, \"p4\": 0.21888433336147764, \"phi\": 0.25541356007476773}, {\"truth_threshold\": 20.10000029951334, \"match_probability\": 0.9999991101913761, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 132.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1899.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.06499261447562776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9350073855243722, \"precision\": 1.0, \"recall\": 0.06499261447562776, \"specificity\": 1.0, \"npv\": 0.9961971932522709, \"accuracy\": 0.9961981981981982, \"f1\": 0.12205270457697642, \"f2\": 0.07994186046511628, \"f0_5\": 0.25791324736225085, \"p4\": 0.21750737574445428, \"phi\": 0.25445129224027785}, {\"truth_threshold\": 20.200000301003456, \"match_probability\": 0.9999991697791492, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 129.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1902.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.06351550960118169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9364844903988183, \"precision\": 1.0, \"recall\": 0.06351550960118169, \"specificity\": 1.0, \"npv\": 0.9961912085403437, \"accuracy\": 0.9961921921921922, \"f1\": 0.11944444444444445, \"f2\": 0.0781533987640858, \"f0_5\": 0.25323910482921086, \"p4\": 0.21335598433878963, \"phi\": 0.2515424263830199}, {\"truth_threshold\": 20.300000302493572, \"match_probability\": 0.9999992253765136, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 120.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1911.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.059084194977843424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9409158050221565, \"precision\": 1.0, \"recall\": 0.059084194977843424, \"specificity\": 1.0, \"npv\": 0.9961732548359966, \"accuracy\": 0.9961741741741742, \"f1\": 0.11157601115760112, \"f2\": 0.07278020378457059, \"f0_5\": 0.23894862604540024, \"p4\": 0.2007141263559989, \"phi\": 0.24260687298681985}, {\"truth_threshold\": 20.40000030398369, \"match_probability\": 0.9999992772506945, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 109.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1922.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.05366814377154111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9463318562284588, \"precision\": 1.0, \"recall\": 0.05366814377154111, \"specificity\": 1.0, \"npv\": 0.9961513122983794, \"accuracy\": 0.9961521521521521, \"f1\": 0.10186915887850467, \"f2\": 0.06619701202477833, \"f0_5\": 0.22091609241994326, \"p4\": 0.18486944289555415, \"phi\": 0.23121762875403504}, {\"truth_threshold\": 20.60000030696392, \"match_probability\": 0.9999993708101274, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 98.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1933.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0482520925652388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9517479074347612, \"precision\": 1.0, \"recall\": 0.0482520925652388, \"specificity\": 1.0, \"npv\": 0.9961293707273899, \"accuracy\": 0.9961301301301301, \"f1\": 0.09206200093940817, \"f2\": 0.059596205302846025, \"f0_5\": 0.2022286421791168, \"p4\": 0.16857454088546495, \"phi\": 0.21923805920344008}, {\"truth_threshold\": 20.700000308454037, \"match_probability\": 0.9999994129450668, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 83.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1948.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.04086656819300837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9591334318069916, \"precision\": 1.0, \"recall\": 0.04086656819300837, \"specificity\": 1.0, \"npv\": 0.9960994519609865, \"accuracy\": 0.9961001001001001, \"f1\": 0.07852412488174078, \"f2\": 0.05056658949677105, \"f0_5\": 0.17562420651713923, \"p4\": 0.14559328081554498, \"phi\": 0.2017601699557718}, {\"truth_threshold\": 21.500000320374966, \"match_probability\": 0.9999996628254004, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 80.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1951.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.03938946331856229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9606105366814377, \"precision\": 1.0, \"recall\": 0.03938946331856229, \"specificity\": 1.0, \"npv\": 0.9960934684233711, \"accuracy\": 0.9960940940940941, \"f1\": 0.07579346281383231, \"f2\": 0.04875670404680644, \"f0_5\": 0.1701403658017865, \"p4\": 0.1408876251704697, \"phi\": 0.19807974943522585}, {\"truth_threshold\": 21.700000323355198, \"match_probability\": 0.9999997064724503, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 78.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1953.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.03840472673559823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9615952732644018, \"precision\": 1.0, \"recall\": 0.03840472673559823, \"specificity\": 1.0, \"npv\": 0.9960894794382306, \"accuracy\": 0.9960900900900901, \"f1\": 0.07396870554765292, \"f2\": 0.04754937820043892, \"f0_5\": 0.16645326504481434, \"p4\": 0.13772972391565044, \"phi\": 0.19558768944396662}, {\"truth_threshold\": 21.800000324845314, \"match_probability\": 0.999999726129107, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 75.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1956.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.03692762186115214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9630723781388478, \"precision\": 1.0, \"recall\": 0.03692762186115214, \"specificity\": 1.0, \"npv\": 0.9960834960204235, \"accuracy\": 0.9960840840840841, \"f1\": 0.07122507122507123, \"f2\": 0.045737285034760336, \"f0_5\": 0.16087516087516088, \"p4\": 0.13296134337951887, \"phi\": 0.19178893263996397}, {\"truth_threshold\": 21.90000032633543, \"match_probability\": 0.9999997444694171, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 68.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1963.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.03348104382077794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.966518956179222, \"precision\": 1.0, \"recall\": 0.03348104382077794, \"specificity\": 1.0, \"npv\": 0.9960695349917507, \"accuracy\": 0.9960700700700701, \"f1\": 0.06479275845640782, \"f2\": 0.04150390625, \"f0_5\": 0.14763352149370387, \"p4\": 0.12168561456520233, \"phi\": 0.18261831164919007}, {\"truth_threshold\": 22.000000327825546, \"match_probability\": 0.9999997615815319, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 65.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1966.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.032003938946331856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9679960610536681, \"precision\": 1.0, \"recall\": 0.032003938946331856, \"specificity\": 1.0, \"npv\": 0.9960635518135493, \"accuracy\": 0.9960640640640641, \"f1\": 0.06202290076335878, \"f2\": 0.03968738551715716, \"f0_5\": 0.14185945002182454, \"p4\": 0.11678796022930997, \"phi\": 0.17854399205491986}, {\"truth_threshold\": 22.100000329315662, \"match_probability\": 0.9999997775477002, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 64.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1967.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.03151157065484983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9684884293451502, \"precision\": 1.0, \"recall\": 0.03151157065484983, \"specificity\": 1.0, \"npv\": 0.9960615574367887, \"accuracy\": 0.996062062062062, \"f1\": 0.06109785202863962, \"f2\": 0.039081582804103565, \"f0_5\": 0.139921294271972, \"p4\": 0.11514658630375932, \"phi\": 0.17716507597082762}, {\"truth_threshold\": 22.20000033080578, \"match_probability\": 0.9999997924446623, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 55.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1976.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.02708025603151157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9729197439684885, \"precision\": 1.0, \"recall\": 0.02708025603151157, \"specificity\": 1.0, \"npv\": 0.9960436084053299, \"accuracy\": 0.996044044044044, \"f1\": 0.052732502396931925, \"f2\": 0.03362269226066757, \"f0_5\": 0.12216792536650378, \"p4\": 0.10017218387808424, \"phi\": 0.16423494127062907}, {\"truth_threshold\": 22.500000335276127, \"match_probability\": 0.9999998314126736, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 53.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1978.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.026095519448547513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9739044805514525, \"precision\": 1.0, \"recall\": 0.026095519448547513, \"specificity\": 1.0, \"npv\": 0.9960396198195204, \"accuracy\": 0.99604004004004, \"f1\": 0.0508637236084453, \"f2\": 0.03240797358444417, \"f0_5\": 0.1181453410610789, \"p4\": 0.09679433884485965, \"phi\": 0.16122087727873263}, {\"truth_threshold\": 22.600000336766243, \"match_probability\": 0.9999998427024609, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 52.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1979.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.025603151157065487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9743968488429345, \"precision\": 1.0, \"recall\": 0.025603151157065487, \"specificity\": 1.0, \"npv\": 0.9960376255385947, \"accuracy\": 0.996038038038038, \"f1\": 0.04992798847815651, \"f2\": 0.031800391389432484, \"f0_5\": 0.11612326931665923, \"p4\": 0.09509845799462915, \"phi\": 0.15969252294578237}, {\"truth_threshold\": 22.90000034123659, \"match_probability\": 0.9999998722346936, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 51.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1980.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.025110782865583457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9748892171344166, \"precision\": 1.0, \"recall\": 0.025110782865583457, \"specificity\": 1.0, \"npv\": 0.9960356312656548, \"accuracy\": 0.9960360360360361, \"f1\": 0.04899135446685879, \"f2\": 0.031192660550458717, \"f0_5\": 0.11409395973154363, \"p4\": 0.09339791272392751, \"phi\": 0.15814940550977802}, {\"truth_threshold\": 23.100000344216824, \"match_probability\": 0.9999998887738388, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 50.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1981.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.024618414574101428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9753815854258986, \"precision\": 1.0, \"recall\": 0.024618414574101428, \"specificity\": 1.0, \"npv\": 0.9960336370007008, \"accuracy\": 0.996034034034034, \"f1\": 0.048053820278712155, \"f2\": 0.030584781012967948, \"f0_5\": 0.11205737337516809, \"p4\": 0.09169268375229242, \"phi\": 0.15659108852496462}, {\"truth_threshold\": 23.20000034570694, \"match_probability\": 0.9999998962223214, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 49.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1982.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0241260462826194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9758739537173806, \"precision\": 1.0, \"recall\": 0.0241260462826194, \"specificity\": 1.0, \"npv\": 0.9960316427437326, \"accuracy\": 0.996032032032032, \"f1\": 0.047115384615384615, \"f2\": 0.029976752722378562, \"f0_5\": 0.11001347103726987, \"p4\": 0.08998275169285351, \"phi\": 0.15501711360939707}, {\"truth_threshold\": 23.300000347197056, \"match_probability\": 0.9999999031720016, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 45.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1986.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.022156573116691284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9778434268833087, \"precision\": 1.0, \"recall\": 0.022156573116691284, \"specificity\": 1.0, \"npv\": 0.9960236657957173, \"accuracy\": 0.996024024024024, \"f1\": 0.04335260115606936, \"f2\": 0.027543150936467132, \"f0_5\": 0.10176390773405698, \"p4\": 0.08309560107403288, \"phi\": 0.14855460671806076}, {\"truth_threshold\": 23.400000348687172, \"match_probability\": 0.9999999096562825, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 43.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1988.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.02117183653372723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9788281634662728, \"precision\": 1.0, \"recall\": 0.02117183653372723, \"specificity\": 1.0, \"npv\": 0.9960196773696234, \"accuracy\": 0.99602002002002, \"f1\": 0.041465766634522665, \"f2\": 0.026325456103832495, \"f0_5\": 0.09759418974126191, \"p4\": 0.07962329523364889, \"phi\": 0.145215583852579}, {\"truth_threshold\": 23.500000350177288, \"match_probability\": 0.9999999157063305, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 42.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1989.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0206794682422452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9793205317577548, \"precision\": 1.0, \"recall\": 0.0206794682422452, \"specificity\": 1.0, \"npv\": 0.9960176831685548, \"accuracy\": 0.996018018018018, \"f1\": 0.04052098408104197, \"f2\": 0.025716385011021307, \"f0_5\": 0.09549795361527967, \"p4\": 0.07787988963301433, \"phi\": 0.14351695386886792}, {\"truth_threshold\": 23.600000351667404, \"match_probability\": 0.9999999213512251, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 41.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1990.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.02018709995076317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798129000492368, \"precision\": 1.0, \"recall\": 0.02018709995076317, \"specificity\": 1.0, \"npv\": 0.9960156889754714, \"accuracy\": 0.996016016016016, \"f1\": 0.03957528957528957, \"f2\": 0.02510716472749541, \"f0_5\": 0.09339407744874716, \"p4\": 0.07613162192941447, \"phi\": 0.14179798399792604}, {\"truth_threshold\": 23.70000035315752, \"match_probability\": 0.9999999266180979, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 40.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1991.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.019694731659281144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9803052683407188, \"precision\": 1.0, \"recall\": 0.019694731659281144, \"specificity\": 1.0, \"npv\": 0.9960136947903736, \"accuracy\": 0.996014014014014, \"f1\": 0.0386286817962337, \"f2\": 0.02449779519843214, \"f0_5\": 0.09128251939753537, \"p4\": 0.07437847174448221, \"phi\": 0.14005792533043446}, {\"truth_threshold\": 23.800000354647636, \"match_probability\": 0.9999999315322641, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 39.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1992.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.019202363367799114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9807976366322009, \"precision\": 1.0, \"recall\": 0.019202363367799114, \"specificity\": 1.0, \"npv\": 0.996011700613261, \"accuracy\": 0.9960120120120121, \"f1\": 0.03768115942028986, \"f2\": 0.02388827636898199, \"f0_5\": 0.08916323731138547, \"p4\": 0.07262041858580959, \"phi\": 0.13829598184240707}, {\"truth_threshold\": 23.900000356137753, \"match_probability\": 0.9999999361173434, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 38.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1993.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.018709995076317085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9812900049236829, \"precision\": 1.0, \"recall\": 0.018709995076317085, \"specificity\": 1.0, \"npv\": 0.9960097064441339, \"accuracy\": 0.99601001001001, \"f1\": 0.03673272112131464, \"f2\": 0.02327860818426856, \"f0_5\": 0.08703618873110398, \"p4\": 0.07085744184614896, \"phi\": 0.1365113061381136}, {\"truth_threshold\": 24.100000359117985, \"match_probability\": 0.9999999443869169, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 37.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1994.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.018217626784835055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9817823732151649, \"precision\": 1.0, \"recall\": 0.018217626784835055, \"specificity\": 1.0, \"npv\": 0.9960077122829919, \"accuracy\": 0.996008008008008, \"f1\": 0.035783365570599614, \"f2\": 0.022668790589388556, \"f0_5\": 0.08490133088572739, \"p4\": 0.0690895208026074, \"phi\": 0.13470299468530358}, {\"truth_threshold\": 24.2000003606081, \"match_probability\": 0.9999999481111586, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 34.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 1997.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.01674052191038897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983259478089611, \"precision\": 1.0, \"recall\": 0.01674052191038897, \"specificity\": 1.0, \"npv\": 0.9960017298474771, \"accuracy\": 0.996002002002002, \"f1\": 0.03292978208232446, \"f2\": 0.02083844079431233, \"f0_5\": 0.07844946931241348, \"p4\": 0.0637558828679807, \"phi\": 0.1291262513251934}, {\"truth_threshold\": 24.50000036507845, \"match_probability\": 0.999999957853164, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 28.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2003.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.013786312161496799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9862136878385032, \"precision\": 1.0, \"recall\": 0.013786312161496799, \"specificity\": 1.0, \"npv\": 0.9959897651920427, \"accuracy\": 0.99598998998999, \"f1\": 0.027197668771248178, \"f2\": 0.01717369970559372, \"f0_5\": 0.06532897806812879, \"p4\": 0.0529522601569346, \"phi\": 0.11717945985791793}, {\"truth_threshold\": 24.800000369548798, \"match_probability\": 0.9999999657661313, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 25.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2006.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.012309207287050714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9876907927129492, \"precision\": 1.0, \"recall\": 0.012309207287050714, \"specificity\": 1.0, \"npv\": 0.9959837829721208, \"accuracy\": 0.995983983983984, \"f1\": 0.024319066147859923, \"f2\": 0.015339305436249846, \"f0_5\": 0.05865790708587518, \"p4\": 0.04748110798441443, \"phi\": 0.11072384945956659}, {\"truth_threshold\": 25.00000037252903, \"match_probability\": 0.9999999701976862, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 22.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2009.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.010832102412604629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9891678975873953, \"precision\": 1.0, \"recall\": 0.010832102412604629, \"specificity\": 1.0, \"npv\": 0.9959778008240603, \"accuracy\": 0.9959779779779779, \"f1\": 0.02143205065757428, \"f2\": 0.013503560029462312, \"f0_5\": 0.05191127890514394, \"p4\": 0.041962933606214586, \"phi\": 0.10386786576803701}, {\"truth_threshold\": 25.100000374019146, \"match_probability\": 0.9999999721934579, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 20.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2011.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.009847365829640572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9901526341703595, \"precision\": 1.0, \"recall\": 0.009847365829640572, \"specificity\": 1.0, \"npv\": 0.9959738127652759, \"accuracy\": 0.995973973973974, \"f1\": 0.019502681618722574, \"f2\": 0.012278978388998035, \"f0_5\": 0.04737091425864519, \"p4\": 0.03825772687285187, \"phi\": 0.09903392595995382}, {\"truth_threshold\": 25.200000375509262, \"match_probability\": 0.9999999740555788, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 19.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2012.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.009354997538158542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906450024618415, \"precision\": 1.0, \"recall\": 0.009354997538158542, \"specificity\": 1.0, \"npv\": 0.9959718187478602, \"accuracy\": 0.995971971971972, \"f1\": 0.018536585365853658, \"f2\": 0.011666461991894878, \"f0_5\": 0.045087802562885616, \"p4\": 0.03639712790378083, \"phi\": 0.09652623432239299}, {\"truth_threshold\": 25.300000376999378, \"match_probability\": 0.9999999757929992, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 18.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2013.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.008862629246676515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9911373707533235, \"precision\": 1.0, \"recall\": 0.008862629246676515, \"specificity\": 1.0, \"npv\": 0.995969824738429, \"accuracy\": 0.99596996996997, \"f1\": 0.017569546120058566, \"f2\": 0.01105379513633014, \"f0_5\": 0.042796005706134094, \"p4\": 0.03453116780034147, \"phi\": 0.09395164339985801}, {\"truth_threshold\": 25.400000378489494, \"match_probability\": 0.9999999774140695, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 17.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2014.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.008370260955194485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9916297390448056, \"precision\": 1.0, \"recall\": 0.008370260955194485, \"specificity\": 1.0, \"npv\": 0.995967830736982, \"accuracy\": 0.9959679679679679, \"f1\": 0.0166015625, \"f2\": 0.010440977766859108, \"f0_5\": 0.040495474035254886, \"p4\": 0.03265982334659531, \"phi\": 0.09130449411856742}, {\"truth_threshold\": 25.50000037997961, \"match_probability\": 0.9999999789265818, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 16.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2015.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.007877892663712457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921221073362876, \"precision\": 1.0, \"recall\": 0.007877892663712457, \"specificity\": 1.0, \"npv\": 0.9959658367435194, \"accuracy\": 0.995965965965966, \"f1\": 0.015632633121641426, \"f2\": 0.009828009828009828, \"f0_5\": 0.03818615751789976, \"p4\": 0.03078307119236397, \"phi\": 0.08857828152876984}, {\"truth_threshold\": 25.600000381469727, \"match_probability\": 0.9999999803378055, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 14.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2017.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.006893156080748399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931068439192516, \"precision\": 1.0, \"recall\": 0.006893156080748399, \"specificity\": 1.0, \"npv\": 0.9959618487805464, \"accuracy\": 0.995961961961962, \"f1\": 0.013691931540342298, \"f2\": 0.00860162202015237, \"f0_5\": 0.033540967896502155, \"p4\": 0.027013249704693862, \"phi\": 0.082857229461979}, {\"truth_threshold\": 25.700000382959843, \"match_probability\": 0.9999999816545239, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 13.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2018.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.006400787789266372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935992122107337, \"precision\": 1.0, \"recall\": 0.006400787789266372, \"specificity\": 1.0, \"npv\": 0.9959598548110361, \"accuracy\": 0.99595995995996, \"f1\": 0.012720156555772993, \"f2\": 0.007988202040063905, \"f0_5\": 0.031204992798847815, \"p4\": 0.025120132990911218, \"phi\": 0.07984314420959378}, {\"truth_threshold\": 25.900000385940075, \"match_probability\": 0.9999999840293354, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 10.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2021.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.004923682914820286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950763170851797, \"precision\": 1.0, \"recall\": 0.004923682914820286, \"specificity\": 1.0, \"npv\": 0.9959538729504094, \"accuracy\": 0.9959539539539539, \"f1\": 0.009799118079372856, \"f2\": 0.006147037128104254, \"f0_5\": 0.024142926122646065, \"p4\": 0.01940767178591773, \"phi\": 0.07002685961968468}, {\"truth_threshold\": 26.00000038743019, \"match_probability\": 0.999999985098843, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 9.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2022.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.004431314623338257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955686853766618, \"precision\": 1.0, \"recall\": 0.004431314623338257, \"specificity\": 1.0, \"npv\": 0.9959518790128351, \"accuracy\": 0.995951951951952, \"f1\": 0.008823529411764706, \"f2\": 0.005533013648100332, \"f0_5\": 0.02177068214804064, \"p4\": 0.017492400440941448, \"phi\": 0.06643324563507935}, {\"truth_threshold\": 26.100000388920307, \"match_probability\": 0.9999999860967289, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 7.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2024.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0034465780403741997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965534219596258, \"precision\": 1.0, \"recall\": 0.0034465780403741997, \"specificity\": 1.0, \"npv\": 0.995947891161638, \"accuracy\": 0.9959479479479479, \"f1\": 0.0068694798822374874, \"f2\": 0.004304513589964334, \"f0_5\": 0.016998542982030112, \"p4\": 0.013645034789052582, \"phi\": 0.05858849828280884}, {\"truth_threshold\": 26.200000390410423, \"match_probability\": 0.9999999870277894, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 6.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2025.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0029542097488921715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970457902511078, \"precision\": 1.0, \"recall\": 0.0029542097488921715, \"specificity\": 1.0, \"npv\": 0.995945897248015, \"accuracy\": 0.995945945945946, \"f1\": 0.005891016200294551, \"f2\": 0.0036900369003690036, \"f0_5\": 0.014598540145985401, \"p4\": 0.011712891131601923, \"phi\": 0.054242355028328616}, {\"truth_threshold\": 26.400000393390656, \"match_probability\": 0.9999999887070348, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 4.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2027.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0019694731659281144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980305268340719, \"precision\": 1.0, \"recall\": 0.0019694731659281144, \"specificity\": 1.0, \"npv\": 0.9959419094447203, \"accuracy\": 0.995941941941942, \"f1\": 0.003931203931203931, \"f2\": 0.0024606299212598425, \"f0_5\": 0.009770395701025891, \"p4\": 0.007831557688366788, \"phi\": 0.04428860875523846}, {\"truth_threshold\": 26.600000396370888, \"match_probability\": 0.9999999901689027, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 3.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2028.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0014771048744460858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985228951255539, \"precision\": 1.0, \"recall\": 0.0014771048744460858, \"specificity\": 1.0, \"npv\": 0.9959399155550483, \"accuracy\": 0.9959399399399399, \"f1\": 0.0029498525073746312, \"f2\": 0.0018456995201181247, \"f0_5\": 0.007342143906020558, \"p4\": 0.00588231767637118, \"phi\": 0.038355021886602864}, {\"truth_threshold\": 26.700000397861004, \"match_probability\": 0.999999990827262, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 2.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2029.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0009847365829640572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999015263417036, \"precision\": 1.0, \"recall\": 0.0009847365829640572, \"specificity\": 1.0, \"npv\": 0.99593792167336, \"accuracy\": 0.995937937937938, \"f1\": 0.001967535661583866, \"f2\": 0.0012306177701206006, \"f0_5\": 0.004904364884747425, \"p4\": 0.003927328406300723, \"phi\": 0.03131671288358581}, {\"truth_threshold\": 27.500000409781933, \"match_probability\": 0.9999999947316455, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1.0, \"tn\": 497469.0, \"fp\": 0.0, \"fn\": 2030.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.0004923682914820286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999507631708518, \"precision\": 1.0, \"recall\": 0.0004923682914820286, \"specificity\": 1.0, \"npv\": 0.9959359277996552, \"accuracy\": 0.995935935935936, \"f1\": 0.000984251968503937, \"f2\": 0.0006153846153846154, \"f0_5\": 0.002457002457002457, \"p4\": 0.001966564392884295, \"phi\": 0.0221442378779737}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.evaluation.accuracy_analysis_from_labels_column(\"cluster\", output_type=\"roc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:21.327370Z",
     "iopub.status.busy": "2024-06-07T09:09:21.327111Z",
     "iopub.status.idle": "2024-06-07T09:09:22.635682Z",
     "shell.execute_reply": "2024-06-07T09:09:22.635098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6b3f7f85ab904d128c8414728e959752.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6b3f7f85ab904d128c8414728e959752.vega-embed details,\n",
       "  #altair-viz-6b3f7f85ab904d128c8414728e959752.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6b3f7f85ab904d128c8414728e959752\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6b3f7f85ab904d128c8414728e959752\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6b3f7f85ab904d128c8414728e959752\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": {\"step\": 150}, \"discreteWidth\": {\"step\": 150}}, \"axis\": {\"gridWidth\": 0.5, \"labelFontSize\": 12, \"titleFontSize\": 16}, \"axisX\": {\"format\": \"+.0f\", \"grid\": false, \"offset\": 20, \"values\": {\"expr\": \"[-25,-20,-15,-10,-5,0,5,10,15,20,25]\"}}, \"axisY\": {\"title\": \"Match probability threshold\", \"titleFontSize\": 16}, \"concat\": {\"spacing\": 40}}, \"hconcat\": [{\"vconcat\": [{\"layer\": [{\"layer\": [{\"mark\": {\"type\": \"rule\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 0.3, \"empty\": false}, \"value\": 0}, \"x\": {\"axis\": {\"orient\": \"bottom\"}, \"field\": \"truth_threshold\", \"scale\": {\"nice\": false}, \"title\": null, \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"threshold\", \"select\": {\"type\": \"point\", \"encodings\": [\"x\"], \"fields\": [\"truth_threshold\"], \"nearest\": true, \"on\": \"mouseover\", \"toggle\": false}, \"value\": null}]}, {\"mark\": {\"type\": \"rule\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 0.3, \"empty\": false}, \"value\": 0}, \"y\": {\"axis\": {\"orient\": \"right\"}, \"field\": \"match_probability\", \"title\": \" \", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"prob\", \"select\": {\"type\": \"point\", \"encodings\": [\"y\"], \"fields\": [\"match_probability\"], \"nearest\": true, \"on\": \"mouseover\", \"toggle\": false}}]}]}, {\"layer\": [{\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"fontWeight\": \"bold\", \"xOffset\": 25, \"yOffset\": 10}, \"encoding\": {\"text\": {\"aggregate\": \"min\", \"field\": \"truth_threshold\", \"format\": \"+.2f\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"match_probability\", \"title\": \"Match probability threshold\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"threshold\", \"empty\": false}}]}, {\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"xOffset\": -25, \"yOffset\": -10}, \"encoding\": {\"text\": {\"aggregate\": \"min\", \"field\": \"match_probability\", \"format\": \".3f\"}}, \"transform\": [{\"filter\": {\"param\": \"threshold\", \"empty\": false}}]}, {\"mark\": {\"type\": \"line\", \"color\": \"red\", \"opacity\": 0.5}}, {\"mark\": {\"type\": \"line\", \"color\": \"green\", \"opacity\": 0.5, \"strokeWidth\": 3}, \"transform\": [{\"filter\": \"datum.truth_threshold >= threshold.truth_threshold\"}]}, {\"mark\": {\"type\": \"point\", \"color\": \"green\", \"size\": 100}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 1, \"empty\": false}, \"value\": 0}}}], \"encoding\": {\"x\": {\"field\": \"truth_threshold\", \"type\": \"quantitative\", \"title\": \"Match weight threshold\", \"axis\": {\"orient\": \"top\"}}, \"y\": {\"field\": \"match_probability\", \"type\": \"quantitative\", \"title\": \"Match probability threshold\", \"axis\": {\"orient\": \"left\", \"titlePadding\": 10}}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"red\", \"fontSize\": 12, \"text\": \"Non-match\", \"x\": 0, \"y\": \"height\", \"yOffset\": 10}, \"data\": {\"values\": [{}]}}, {\"mark\": {\"type\": \"text\", \"align\": \"right\", \"color\": \"green\", \"fontSize\": 12, \"fontWeight\": \"bold\", \"text\": \"Match\", \"x\": \"width\", \"y\": 0, \"yOffset\": -10}, \"data\": {\"values\": [{}]}}], \"description\": \"Match weight vs probability\"}, {\"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"rect\", \"opacity\": 0.5}, \"encoding\": {\"color\": {\"field\": \"count\", \"legend\": null, \"scale\": {\"scheme\": \"reds\", \"zero\": true}, \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": \"datum.predicted == 0\"}]}, {\"mark\": {\"type\": \"rect\", \"opacity\": 0.5}, \"encoding\": {\"color\": {\"field\": \"count\", \"legend\": null, \"scale\": {\"scheme\": \"greens\", \"zero\": true}, \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": \"datum.predicted == 1\"}]}, {\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"yOffset\": -40}, \"encoding\": {\"color\": {\"condition\": [{\"test\": \"datum.predicted==1 && datum.actual==1\", \"value\": \"darkgreen\"}, {\"test\": \"datum.predicted==0 && datum.actual==0\", \"value\": \"darkred\"}], \"value\": \"black\"}, \"opacity\": {\"condition\": {\"test\": \"datum.predicted != datum.actual\", \"value\": 1}, \"value\": 0.5}, \"text\": {\"field\": \"confusion_label\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"fontSize\": 28, \"fontWeight\": \"bold\", \"yOffset\": 10}, \"encoding\": {\"color\": {\"condition\": [{\"test\": \"datum.predicted==1 && datum.actual==1\", \"value\": \"darkgreen\"}, {\"test\": \"datum.predicted==0 && datum.actual==0\", \"value\": \"darkred\"}], \"value\": \"black\"}, \"text\": {\"field\": \"count\", \"format\": \",\", \"type\": \"nominal\"}}}], \"description\": \"Confusion matrix\", \"encoding\": {\"x\": {\"field\": \"actual\", \"type\": \"nominal\", \"title\": \"Actual\", \"axis\": {\"domain\": false, \"labelAngle\": 0, \"labelExpr\": \"datum.label == 1 ? 'Match' : 'Non-match'\", \"labelFontSize\": 18, \"labelPadding\": 10, \"orient\": \"top\", \"ticks\": false, \"titleAngle\": 0, \"titleFontSize\": 20}, \"sort\": \"-x\"}, \"y\": {\"field\": \"predicted\", \"type\": \"nominal\", \"title\": \"Predicted\", \"axis\": {\"domain\": false, \"labelExpr\": \"datum.label == 1 ? 'Match' : 'Non-match'\", \"labelFontSize\": 18, \"labelPadding\": 10, \"ticks\": false, \"titleAngle\": 0, \"titleFontSize\": 20, \"titlePadding\": -30}, \"sort\": \"-y\"}}, \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"transform\": [{\"filter\": {\"or\": [{\"param\": \"threshold\", \"empty\": false}, {\"and\": [{\"param\": \"threshold\", \"empty\": true}, \"datum.truth_threshold == datum.median_threshold\"]}]}}]}], \"transform\": [{\"fold\": [\"tp\", \"tn\", \"fp\", \"fn\"], \"as\": [\"label\", \"count\"]}, {\"calculate\": \"datum.label === 'tp' ? 'True Positive (TP)' : datum.label === 'tn' ? 'True Negative (TN)' : datum.label === 'fp' ? 'False Positive (FP)' : 'False Negative (FN)'\", \"as\": \"confusion_label\"}, {\"calculate\": \"datum.label === 'tp' || datum.label === 'fp' ? 1 : 0\", \"as\": \"predicted\"}, {\"calculate\": \"datum.label === 'tp' || datum.label === 'fn' ? 1 : 0\", \"as\": \"actual\"}, {\"joinaggregate\": [{\"op\": \"median\", \"field\": \"truth_threshold\", \"as\": \"median_threshold\"}]}]}]}, {\"layer\": [{\"layer\": [{\"mark\": {\"type\": \"point\", \"size\": 100}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 1, \"empty\": false}, \"value\": 0}, \"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".3f\", \"title\": \"Match weight threshold\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".3%\", \"title\": \"Match probability threshold\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"title\": \"Precision\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"title\": \"Recall (TPR)\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FPR\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"orient\": \"top\"}, \"field\": \"truth_threshold\", \"title\": \"Match weight threshold\"}}, \"params\": [{\"name\": \"metric\", \"select\": {\"type\": \"point\", \"fields\": [\"metric\"]}, \"bind\": \"legend\", \"value\": [{\"metric\": \"precision\"}, {\"metric\": \"recall\"}]}, {\"name\": \"threshold\", \"select\": {\"type\": \"point\", \"encodings\": [\"x\"], \"fields\": [\"truth_threshold\"], \"nearest\": true, \"on\": \"mouseover\", \"toggle\": false}, \"value\": null}], \"transform\": [{\"filter\": {\"param\": \"metric\", \"empty\": true}}]}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"metric\", \"value\": 1}, \"value\": 0.1}, \"x\": {\"axis\": {\"orient\": \"bottom\"}, \"field\": \"truth_threshold\", \"title\": null}}}], \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\", \"sort\": [\"precision\", \"recall\", \"f1\"], \"title\": [\"Performance\", \"Metric\"], \"legend\": {\"fillColor\": \"whitesmoke\", \"labelExpr\": \"{'precision': 'Precision (PPV)', 'recall': 'Recall (TPR)', 'specificity': 'Specificity (TNR)', 'accuracy': 'Accuracy', 'npv': 'NPV', 'f1': 'F1', 'f2': 'F2', 'f0_5': 'F0.5', 'p4': 'P4', 'phi': '\\u03c6 (MCC)'}[datum.value]\", \"labelFontSize\": 14, \"legendX\": 800, \"legendY\": 160, \"orient\": \"none\", \"padding\": 10, \"titleFontSize\": 16, \"titlePadding\": 15}}, \"x\": {\"type\": \"quantitative\", \"field\": \"truth_threshold\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\", \"axis\": {\"labelFontSize\": 12, \"title\": \"Performance metric score\", \"titleFontSize\": 18, \"titlePadding\": 10, \"values\": {\"expr\": \"[0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0]\"}}, \"scale\": {\"domain\": [0.5, 1]}}}}, {\"layer\": [{\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"x\": {\"field\": \"truth_threshold\", \"title\": null, \"type\": \"quantitative\"}}}, {\"layer\": [{\"mark\": {\"type\": \"rect\", \"fill\": \"whitesmoke\", \"x\": 200, \"x2\": 10, \"y2Offset\": 20, \"yOffset\": -20}, \"encoding\": {\"y2\": {\"field\": \"score_index\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"right\", \"baseline\": \"middle\", \"fontSize\": 16, \"x\": 200, \"xOffset\": -10}}], \"encoding\": {\"color\": {\"field\": \"metric\", \"sort\": [\"precision\", \"recall\", \"f1\"]}, \"text\": {\"field\": \"y_text\"}, \"y\": {\"field\": \"score_index\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"metric\", \"empty\": true}}]}, {\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"fontWeight\": \"bold\", \"xOffset\": 20, \"y\": 0, \"yOffset\": -10}, \"encoding\": {\"text\": {\"condition\": {\"param\": \"threshold\", \"aggregate\": \"min\", \"empty\": false, \"field\": \"truth_threshold\", \"format\": \"+.2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"field\": \"truth_threshold\", \"type\": \"quantitative\"}}}], \"transform\": [{\"filter\": {\"param\": \"threshold\", \"empty\": false}}]}], \"description\": \"Accuracy chart\", \"height\": 700, \"transform\": [{\"fold\": [\"precision\", \"recall\", \"f1\"], \"as\": [\"metric\", \"value\"]}, {\"calculate\": \"0.6375 - 0.025*indexof(['precision', 'recall', 'f1'], datum.metric)\", \"as\": \"score_index\"}, {\"calculate\": \"{'precision': 'Precision (PPV)', 'recall': 'Recall (TPR)', 'specificity': 'Specificity (TNR)', 'accuracy': 'Accuracy', 'npv': 'NPV', 'f1': 'F1', 'f2': 'F2', 'f0_5': 'F0.5', 'p4': 'P4', 'phi': '\\u03c6 (MCC)'}[datum.metric]\", \"as\": \"metric_text\"}, {\"calculate\": \"datum.metric_text + ' = ' + format(datum.value, ',.3g')\", \"as\": \"y_text\"}], \"width\": 500}], \"data\": {\"name\": \"data-b1d4a612b3e0bd7db0b2bc8593709358\"}, \"title\": {\"text\": \"Match Threshold Selection Tool\", \"anchor\": \"middle\", \"baseline\": \"line-bottom\", \"fontSize\": 28, \"subtitle\": [\"Hover over either line graph to show Confusion Matrix (bottom left) and selected performance metrics (right).\", \"\", \"Click a legend value to show a specific evaluation metric. Shift + Click to show multiple metrics\"], \"subtitleFontSize\": 14, \"subtitleFontStyle\": \"italic\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-b1d4a612b3e0bd7db0b2bc8593709358\": [{\"truth_threshold\": -13.300000198185444, \"match_probability\": 9.914206010875549e-05, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496488.0, \"fp\": 981.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9980280178262364, \"fp_rate\": 0.0019719821737635914, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5112107623318386, \"recall\": 0.5051698670605613, \"specificity\": 0.9980280178262364, \"npv\": 0.9979798710735629, \"accuracy\": 0.996024024024024, \"f1\": 0.5081723625557206, \"f2\": 0.5063665975718094, \"f0_5\": 0.5099910527885476, \"p4\": 0.6734377905595093, \"phi\": 0.5061853906759526}, {\"truth_threshold\": -13.200000196695328, \"match_probability\": 0.00010625707305470121, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496533.0, \"fp\": 936.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9981184757241155, \"fp_rate\": 0.0018815242758845275, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5229357798165137, \"recall\": 0.5051698670605613, \"specificity\": 0.9981184757241155, \"npv\": 0.9979800537848366, \"accuracy\": 0.9961141141141141, \"f1\": 0.5138993238166792, \"f2\": 0.5086258179654968, \"f0_5\": 0.5192833282720923, \"p4\": 0.6784580445813054, \"phi\": 0.5120262362648247}, {\"truth_threshold\": -13.100000195205212, \"match_probability\": 0.00011388264270550263, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496537.0, \"fp\": 932.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9981265164261491, \"fp_rate\": 0.001873483573850833, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5240040858018387, \"recall\": 0.5051698670605613, \"specificity\": 0.9981265164261491, \"npv\": 0.9979800700242392, \"accuracy\": 0.9961221221221221, \"f1\": 0.5144146402607169, \"f2\": 0.5088276135687364, \"f0_5\": 0.5201257223968366, \"p4\": 0.6789079139975555, \"phi\": 0.512555107149103}, {\"truth_threshold\": -12.800000190734863, \"match_probability\": 0.00014020228918616167, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496555.0, \"fp\": 914.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9981626995853008, \"fp_rate\": 0.0018373004146992073, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5288659793814433, \"recall\": 0.5051698670605613, \"specificity\": 0.9981626995853008, \"npv\": 0.9979801430983198, \"accuracy\": 0.9961581581581581, \"f1\": 0.5167464114832536, \"f2\": 0.509737678855326, \"f0_5\": 0.5239505668471045, \"p4\": 0.6809397311477347, \"phi\": 0.5149551544116822}, {\"truth_threshold\": -12.200000181794167, \"match_probability\": 0.00021249156957169895, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496575.0, \"fp\": 894.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9982029030954692, \"fp_rate\": 0.0017970969045307346, \"fn_rate\": 0.4948301329394387, \"precision\": 0.534375, \"recall\": 0.5051698670605613, \"specificity\": 0.9982029030954692, \"npv\": 0.997980224285542, \"accuracy\": 0.9961981981981982, \"f1\": 0.5193621867881549, \"f2\": 0.510752688172043, \"f0_5\": 0.5282669138090825, \"p4\": 0.683211616514616, \"phi\": 0.5176612057665209}, {\"truth_threshold\": -12.10000018030405, \"match_probability\": 0.0002277393522037113, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496603.0, \"fp\": 866.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9982591880097051, \"fp_rate\": 0.0017408119902948727, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5422832980972516, \"recall\": 0.5051698670605613, \"specificity\": 0.9982591880097051, \"npv\": 0.9979803379366892, \"accuracy\": 0.9962542542542543, \"f1\": 0.5230690797858781, \"f2\": 0.5121805111821086, \"f0_5\": 0.5344306698614439, \"p4\": 0.6864178434080551, \"phi\": 0.5215212476758672}, {\"truth_threshold\": -11.900000177323818, \"match_probability\": 0.0002615949610108224, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496624.0, \"fp\": 845.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983014016953821, \"fp_rate\": 0.0016985983046179762, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5483698556921432, \"recall\": 0.5051698670605613, \"specificity\": 0.9983014016953821, \"npv\": 0.9979804231666562, \"accuracy\": 0.9962962962962963, \"f1\": 0.5258841619682214, \"f2\": 0.5132566283141571, \"f0_5\": 0.5391487125591172, \"p4\": 0.6888423312645094, \"phi\": 0.5244727524688039}, {\"truth_threshold\": -11.800000175833702, \"match_probability\": 0.0002803652734145845, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496637.0, \"fp\": 832.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983275339769915, \"fp_rate\": 0.0016724660230084689, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5522066738428417, \"recall\": 0.5051698670605613, \"specificity\": 0.9983275339769915, \"npv\": 0.9979804759244597, \"accuracy\": 0.9963223223223223, \"f1\": 0.5276420673695037, \"f2\": 0.513925065117211, \"f0_5\": 0.5421113811687626, \"p4\": 0.6903518062146036, \"phi\": 0.5263248046521227}, {\"truth_threshold\": -11.000000163912773, \"match_probability\": 0.00048804289235713973, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496641.0, \"fp\": 828.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983355746790252, \"fp_rate\": 0.0016644253209747743, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5533980582524272, \"recall\": 0.5051698670605613, \"specificity\": 0.9983355746790252, \"npv\": 0.9979804921570755, \"accuracy\": 0.9963303303303304, \"f1\": 0.5281853281853282, \"f2\": 0.5141310883944679, \"f0_5\": 0.5430295331851381, \"p4\": 0.690817591837267, \"phi\": 0.5268985676481476}, {\"truth_threshold\": -10.900000162422657, \"match_probability\": 0.0005230530993675534, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496646.0, \"fp\": 823.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983456255565674, \"fp_rate\": 0.0016543744434326562, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5548945375878853, \"recall\": 0.5051698670605613, \"specificity\": 0.9983456255565674, \"npv\": 0.9979805124474782, \"accuracy\": 0.9963403403403404, \"f1\": 0.5288659793814433, \"f2\": 0.5143888498947158, \"f0_5\": 0.5441816060252467, \"p4\": 0.6914007084716597, \"phi\": 0.5276183783515087}, {\"truth_threshold\": -10.700000159442425, \"match_probability\": 0.0006007835088396779, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496649.0, \"fp\": 820.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983516560830926, \"fp_rate\": 0.0016483439169073851, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5557963163596966, \"recall\": 0.5051698670605613, \"specificity\": 0.9983516560830926, \"npv\": 0.9979805246215242, \"accuracy\": 0.9963463463463463, \"f1\": 0.529275212793397, \"f2\": 0.5145436308926781, \"f0_5\": 0.544875199150292, \"p4\": 0.6917510511984236, \"phi\": 0.5280516626737817}, {\"truth_threshold\": -10.600000157952309, \"match_probability\": 0.0006438760580315065, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496656.0, \"fp\": 813.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983657273116516, \"fp_rate\": 0.0016342726883484197, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5579119086460033, \"recall\": 0.5051698670605613, \"specificity\": 0.9983657273116516, \"npv\": 0.9979805530270606, \"accuracy\": 0.9963603603603604, \"f1\": 0.5302325581395348, \"f2\": 0.5149051490514905, \"f0_5\": 0.5465004793863855, \"p4\": 0.6925698999011948, \"phi\": 0.5290667643082287}, {\"truth_threshold\": -9.700000144541264, \"match_probability\": 0.001200845581852835, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496667.0, \"fp\": 802.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983878392422443, \"fp_rate\": 0.0016121607577557597, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5612691466083151, \"recall\": 0.5051698670605613, \"specificity\": 0.9983878392422443, \"npv\": 0.9979805976627176, \"accuracy\": 0.9963823823823824, \"f1\": 0.5317439751230889, \"f2\": 0.5154742765273312, \"f0_5\": 0.5490741731777802, \"p4\": 0.6938605861076456, \"phi\": 0.5306736459214381}, {\"truth_threshold\": -9.400000140070915, \"match_probability\": 0.001478004086219237, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496670.0, \"fp\": 799.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983938697687695, \"fp_rate\": 0.0016061302312304886, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5621917808219178, \"recall\": 0.5051698670605613, \"specificity\": 0.9983938697687695, \"npv\": 0.9979806098357362, \"accuracy\": 0.9963883883883884, \"f1\": 0.5321576763485477, \"f2\": 0.5156297115287969, \"f0_5\": 0.5497803022184118, \"p4\": 0.6942134267544686, \"phi\": 0.5311143966305074}, {\"truth_threshold\": -9.300000138580799, \"match_probability\": 0.0015839175344616876, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496672.0, \"fp\": 797.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9983978901197864, \"fp_rate\": 0.0016021098802136416, \"fn_rate\": 0.4948301329394387, \"precision\": 0.5628085573230938, \"recall\": 0.5051698670605613, \"specificity\": 0.9983978901197864, \"npv\": 0.9979806179510003, \"accuracy\": 0.9963923923923924, \"f1\": 0.5324338349766476, \"f2\": 0.5157333869508395, \"f0_5\": 0.5502520647860131, \"p4\": 0.6944488532771046, \"phi\": 0.531408832485679}, {\"truth_threshold\": -8.600000128149986, \"match_probability\": 0.0025705389597152823, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496910.0, \"fp\": 559.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9988763118907912, \"fp_rate\": 0.001123688109208815, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6473186119873817, \"recall\": 0.5051698670605613, \"specificity\": 0.9988763118907912, \"npv\": 0.9979815832019522, \"accuracy\": 0.9968688688688688, \"f1\": 0.5674778761061947, \"f2\": 0.5283757338551859, \"f0_5\": 0.6128300083622028, \"p4\": 0.7236526322200384, \"phi\": 0.5703166643731759}, {\"truth_threshold\": -8.400000125169754, \"match_probability\": 0.0029516456585356845, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496912.0, \"fp\": 557.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.998880332241808, \"fp_rate\": 0.0011196677581919677, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6481364497789008, \"recall\": 0.5051698670605613, \"specificity\": 0.998880332241808, \"npv\": 0.9979815913093949, \"accuracy\": 0.9968728728728729, \"f1\": 0.5677919203099059, \"f2\": 0.528484598743175, \"f0_5\": 0.6134162381920364, \"p4\": 0.7239084525411419, \"phi\": 0.5706802321645739}, {\"truth_threshold\": -8.100000120699406, \"match_probability\": 0.003631424511270156, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 496914.0, \"fp\": 555.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9988843525928249, \"fp_rate\": 0.0011156474071751204, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6489563567362429, \"recall\": 0.5051698670605613, \"specificity\": 0.9988843525928249, \"npv\": 0.9979815994167726, \"accuracy\": 0.9968768768768769, \"f1\": 0.5681063122923588, \"f2\": 0.5285935085007728, \"f0_5\": 0.6140035906642729, \"p4\": 0.7241644537933594, \"phi\": 0.571044487455106}, {\"truth_threshold\": -7.200000107288361, \"match_probability\": 0.006755232248084272, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1026.0, \"tn\": 497008.0, \"fp\": 461.0, \"fn\": 1005.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 0.9990733090906168, \"fp_rate\": 0.0009266909093832982, \"fn_rate\": 0.4948301329394387, \"precision\": 0.6899798251513114, \"recall\": 0.5051698670605613, \"specificity\": 0.9990733090906168, \"npv\": 0.9979819803900701, \"accuracy\": 0.9970650650650651, \"f1\": 0.5832859579306424, \"f2\": 0.5337633961086256, \"f0_5\": 0.6429377114926682, \"p4\": 0.7364041991592148, \"phi\": 0.5889822118679692}, {\"truth_threshold\": -7.1000001057982445, \"match_probability\": 0.007236570039195372, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1025.0, \"tn\": 497054.0, \"fp\": 415.0, \"fn\": 1006.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5046774987690793, \"tn_rate\": 0.9991657771640042, \"fp_rate\": 0.0008342228359958108, \"fn_rate\": 0.49532250123092075, \"precision\": 0.7118055555555556, \"recall\": 0.5046774987690793, \"specificity\": 0.9991657771640042, \"npv\": 0.9979801630325663, \"accuracy\": 0.9971551551551552, \"f1\": 0.5906078939786805, \"f2\": 0.5358636553743203, \"f0_5\": 0.6578102939288923, \"p4\": 0.7422251487416562, \"phi\": 0.5980140146049732}, {\"truth_threshold\": -6.600000098347664, \"match_probability\": 0.010203470791514735, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1025.0, \"tn\": 497107.0, \"fp\": 362.0, \"fn\": 1006.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5046774987690793, \"tn_rate\": 0.9992723164659506, \"fp_rate\": 0.0007276835340493578, \"fn_rate\": 0.49532250123092075, \"precision\": 0.7390050468637347, \"recall\": 0.5046774987690793, \"specificity\": 0.9992723164659506, \"npv\": 0.9979803779463696, \"accuracy\": 0.9972612612612612, \"f1\": 0.5997659449970744, \"f2\": 0.5388497529176742, \"f0_5\": 0.6762105818709593, \"p4\": 0.7494305167951033, \"phi\": 0.6094289693343778}, {\"truth_threshold\": -6.000000089406967, \"match_probability\": 0.015384614445865122, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1025.0, \"tn\": 497123.0, \"fp\": 346.0, \"fn\": 1006.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5046774987690793, \"tn_rate\": 0.9993044792740854, \"fp_rate\": 0.0006955207259145796, \"fn_rate\": 0.49532250123092075, \"precision\": 0.7476294675419402, \"recall\": 0.5046774987690793, \"specificity\": 0.9993044792740854, \"npv\": 0.9979804428170213, \"accuracy\": 0.9972932932932933, \"f1\": 0.6025867136978248, \"f2\": 0.539757767245919, \"f0_5\": 0.6819693945442449, \"p4\": 0.751633293636175, \"phi\": 0.6130040436010974}, {\"truth_threshold\": -5.900000087916851, \"match_probability\": 0.016470634520449206, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1023.0, \"tn\": 497167.0, \"fp\": 302.0, \"fn\": 1008.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5036927621861153, \"tn_rate\": 0.9993929269964561, \"fp_rate\": 0.0006070730035439394, \"fn_rate\": 0.4963072378138848, \"precision\": 0.7720754716981132, \"recall\": 0.5036927621861153, \"specificity\": 0.9993929269964561, \"npv\": 0.9979766146434486, \"accuracy\": 0.9973773773773774, \"f1\": 0.6096543504171633, \"f2\": 0.5413271245634459, \"f0_5\": 0.6977220024553267, \"p4\": 0.7571194297807958, \"phi\": 0.6224164076915241}, {\"truth_threshold\": -5.600000083446503, \"match_probability\": 0.02020082327925431, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1023.0, \"tn\": 497194.0, \"fp\": 275.0, \"fn\": 1008.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5036927621861153, \"tn_rate\": 0.9994472017351835, \"fp_rate\": 0.0005527982648165012, \"fn_rate\": 0.4963072378138848, \"precision\": 0.788135593220339, \"recall\": 0.5036927621861153, \"specificity\": 0.9994472017351835, \"npv\": 0.9979767243005849, \"accuracy\": 0.9974314314314314, \"f1\": 0.614598978672274, \"f2\": 0.542878369772872, \"f0_5\": 0.7081545064377682, \"p4\": 0.7609286094405532, \"phi\": 0.6289074042142978}, {\"truth_threshold\": -5.000000074505806, \"match_probability\": 0.030303028785498974, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1022.0, \"tn\": 497295.0, \"fp\": 174.0, \"fn\": 1009.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5032003938946332, \"tn_rate\": 0.9996502294615343, \"fp_rate\": 0.00034977053846571343, \"fn_rate\": 0.49679960610536683, \"precision\": 0.8545150501672241, \"recall\": 0.5032003938946332, \"specificity\": 0.9996502294615343, \"npv\": 0.997975131646545, \"accuracy\": 0.9976316316316316, \"f1\": 0.6334056399132321, \"f2\": 0.5482832618025751, \"f0_5\": 0.7498165810711666, \"p4\": 0.7752068513314447, \"phi\": 0.6547329374104119}, {\"truth_threshold\": -4.500000067055225, \"match_probability\": 0.04232371044088178, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1021.0, \"tn\": 497295.0, \"fp\": 174.0, \"fn\": 1010.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5027080256031512, \"tn_rate\": 0.9996502294615343, \"fp_rate\": 0.00034977053846571343, \"fn_rate\": 0.49729197439684886, \"precision\": 0.8543933054393306, \"recall\": 0.5027080256031512, \"specificity\": 0.9996502294615343, \"npv\": 0.9979731289069947, \"accuracy\": 0.9976296296296296, \"f1\": 0.6329820210787352, \"f2\": 0.5478055585363236, \"f0_5\": 0.7495228307150198, \"p4\": 0.7748892061614011, \"phi\": 0.6543648176926443}, {\"truth_threshold\": -4.400000065565109, \"match_probability\": 0.04522405175894309, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1021.0, \"tn\": 497297.0, \"fp\": 172.0, \"fn\": 1010.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5027080256031512, \"tn_rate\": 0.9996542498125511, \"fp_rate\": 0.00034575018744886614, \"fn_rate\": 0.49729197439684886, \"precision\": 0.8558256496227996, \"recall\": 0.5027080256031512, \"specificity\": 0.9996542498125511, \"npv\": 0.9979731370420243, \"accuracy\": 0.9976336336336337, \"f1\": 0.6333746898263027, \"f2\": 0.5479231512289363, \"f0_5\": 0.7504042334264295, \"p4\": 0.7751839749617189, \"phi\": 0.6549170185726637}, {\"truth_threshold\": -4.300000064074993, \"match_probability\": 0.048313119674570026, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1016.0, \"tn\": 497331.0, \"fp\": 138.0, \"fn\": 1015.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5002461841457411, \"tn_rate\": 0.9997225957798376, \"fp_rate\": 0.0002774042201624624, \"fn_rate\": 0.499753815854259, \"precision\": 0.8804159445407279, \"recall\": 0.5002461841457411, \"specificity\": 0.9997225957798376, \"npv\": 0.9979632624722582, \"accuracy\": 0.9976916916916917, \"f1\": 0.6379905808477238, \"f2\": 0.5475317956456133, \"f0_5\": 0.7642545509252294, \"p4\": 0.7786402025597812, \"phi\": 0.6626931269013433}, {\"truth_threshold\": -3.500000052154064, \"match_probability\": 0.08121030044424019, \"total_clerical_labels\": 499500.0, \"p\": 2031.0, \"n\": 497469.0, \"tp\": 1016.0, \"tn\": 497358.0, \"fp\": 111.0, \"fn\": 1015.0, \"P_rate\": 0.004066066066066066, \"N_rate\": 0.9959339339339339, \"tp_rate\": 0.5002461841457411, \"tn_rate\": 0.999776870518565, \"fp_rate\": 0.0002231294814350241, \"fn_rate\": 0.499753815854259, \"precision\": 0.90150842945874, \"recall\": 0.5002461841457411, \"specificity\": 0.999776870518565, \"npv\": 0.9979633728151405, \"accuracy\": 0.9977457457457457, \"f1\": 0.643445218492717, \"f2\": 0.5491298238028322, \"f0_5\": 0.7768771983483713, \"p4\": 0.7826974277823744, \"phi\": 0.6706389775112944}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.evaluation.accuracy_analysis_from_labels_column(\n",
    "    \"cluster\",\n",
    "    output_type=\"threshold_selection\",\n",
    "    threshold_actual=0.5,\n",
    "    add_metrics=[\"f1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:22.638822Z",
     "iopub.status.busy": "2024-06-07T09:09:22.638569Z",
     "iopub.status.idle": "2024-06-07T09:09:22.853941Z",
     "shell.execute_reply": "2024-06-07T09:09:22.853250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clerical_match_score</th>\n",
       "      <th>found_by_blocking_rules</th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>unique_id_l</th>\n",
       "      <th>unique_id_r</th>\n",
       "      <th>first_name_l</th>\n",
       "      <th>first_name_r</th>\n",
       "      <th>gamma_first_name</th>\n",
       "      <th>bf_first_name</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_city_r</th>\n",
       "      <th>bf_city</th>\n",
       "      <th>bf_tf_adj_city</th>\n",
       "      <th>email_l</th>\n",
       "      <th>email_r</th>\n",
       "      <th>gamma_email</th>\n",
       "      <th>bf_email</th>\n",
       "      <th>cluster_l</th>\n",
       "      <th>cluster_r</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-24.165914</td>\n",
       "      <td>5.312940e-08</td>\n",
       "      <td>417</td>\n",
       "      <td>418</td>\n",
       "      <td>Florence</td>\n",
       "      <td>Brown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>0.427845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fb@reose.cem</td>\n",
       "      <td>f@b@reese.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-21.941506</td>\n",
       "      <td>2.482839e-07</td>\n",
       "      <td>796</td>\n",
       "      <td>797</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00738</td>\n",
       "      <td>0.427845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jt40o@combs.net</td>\n",
       "      <td>jt40@cotbs.nm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-19.517277</td>\n",
       "      <td>1.332642e-06</td>\n",
       "      <td>452</td>\n",
       "      <td>454</td>\n",
       "      <td>None</td>\n",
       "      <td>Davies</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01599</td>\n",
       "      <td>0.427845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rd@lewis.com</td>\n",
       "      <td>idlewrs.cocm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-17.978364</td>\n",
       "      <td>3.872323e-06</td>\n",
       "      <td>717</td>\n",
       "      <td>718</td>\n",
       "      <td>Mia</td>\n",
       "      <td>Jones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00615</td>\n",
       "      <td>0.427845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mia.j63@martinez.biz</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-15.518690</td>\n",
       "      <td>2.130097e-05</td>\n",
       "      <td>594</td>\n",
       "      <td>595</td>\n",
       "      <td>Grace</td>\n",
       "      <td>Grace</td>\n",
       "      <td>3</td>\n",
       "      <td>85.794621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>0.427845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gk@frey-robinson.org</td>\n",
       "      <td>rgk@frey-robinon.org</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clerical_match_score  found_by_blocking_rules  match_weight  \\\n",
       "0                   1.0                    False    -24.165914   \n",
       "1                   1.0                    False    -21.941506   \n",
       "2                   1.0                    False    -19.517277   \n",
       "3                   1.0                    False    -17.978364   \n",
       "4                   1.0                     True    -15.518690   \n",
       "\n",
       "   match_probability  unique_id_l  unique_id_r first_name_l first_name_r  \\\n",
       "0       5.312940e-08          417          418     Florence        Brown   \n",
       "1       2.482839e-07          796          797       Taylor         None   \n",
       "2       1.332642e-06          452          454         None       Davies   \n",
       "3       3.872323e-06          717          718          Mia        Jones   \n",
       "4       2.130097e-05          594          595        Grace        Grace   \n",
       "\n",
       "   gamma_first_name  bf_first_name  ... tf_city_r   bf_city  bf_tf_adj_city  \\\n",
       "0                 0       0.213986  ...   0.00123  0.427845             1.0   \n",
       "1                -1       1.000000  ...   0.00738  0.427845             1.0   \n",
       "2                -1       1.000000  ...   0.01599  0.427845             1.0   \n",
       "3                 0       0.213986  ...   0.00615  0.427845             1.0   \n",
       "4                 3      85.794621  ...   0.00123  0.427845             1.0   \n",
       "\n",
       "                email_l               email_r gamma_email  bf_email  \\\n",
       "0          fb@reose.cem         f@b@reese.com           0  0.001023   \n",
       "1       jt40o@combs.net         jt40@cotbs.nm           0  0.001023   \n",
       "2          rd@lewis.com          idlewrs.cocm           0  0.001023   \n",
       "3  mia.j63@martinez.biz                  None          -1  1.000000   \n",
       "4  gk@frey-robinson.org  rgk@frey-robinon.org           0  0.001023   \n",
       "\n",
       "   cluster_l cluster_r match_key  \n",
       "0        108       108         2  \n",
       "1        201       201         2  \n",
       "2        115       115         2  \n",
       "3        182       182         2  \n",
       "4        146       146         0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot some false positives\n",
    "linker.evaluation.prediction_errors_from_labels_column(\n",
    "    \"cluster\", include_false_negatives=True, include_false_positives=True\n",
    ").as_pandas_dataframe(limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:22.857193Z",
     "iopub.status.busy": "2024-06-07T09:09:22.856931Z",
     "iopub.status.idle": "2024-06-07T09:09:23.602967Z",
     "shell.execute_reply": "2024-06-07T09:09:23.602410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7f15f5dc5c7d4b0ea63b8914e1e331bc.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7f15f5dc5c7d4b0ea63b8914e1e331bc.vega-embed details,\n",
       "  #altair-viz-7f15f5dc5c7d4b0ea63b8914e1e331bc.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7f15f5dc5c7d4b0ea63b8914e1e331bc\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7f15f5dc5c7d4b0ea63b8914e1e331bc\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7f15f5dc5c7d4b0ea63b8914e1e331bc\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-6457d8b9c1db605b06bd6789fc56658f\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 4, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-6457d8b9c1db605b06bd6789fc56658f\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -8.224622793739668, \"bayes_factor\": 0.0033430420247643373, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.21075181163122353, \"u_probability\": 0.9848839400924999, \"bayes_factor\": 0.2139864435310315, \"log2_bayes_factor\": -2.22440869298082, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.67 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"Florence\", \"value_r\": \"Brown\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22629686446829, \"u_probability\": 0.9878019291222225, \"bayes_factor\": 0.2290913368324571, \"log2_bayes_factor\": -2.126005191221481, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.37 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"Brown\", \"value_r\": \"Florence\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 10 year'\", \"m_probability\": 0.22767659077874, \"u_probability\": 0.30747947947947946, \"bayes_factor\": 0.7404610908154431, \"log2_bayes_factor\": -0.43350416701999833, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 10 year'` then comparison is  1.35 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"2002-02-24\", \"value_r\": \"1993-03-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 0.42784548530970185, \"log2_bayes_factor\": -1.2248382277597478, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"city\", \"value_l\": \"London\", \"value_r\": \"Loonon\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"tf_city\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.00101907095234151, \"u_probability\": 0.9958535188795172, \"bayes_factor\": 0.0010233141049580423, \"log2_bayes_factor\": -9.932535238200462, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  977.22 times less likely to be a match\", \"column_name\": \"email\", \"value_l\": \"fb@reose.cem\", \"value_r\": \"f@b@reese.com\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -24.165914310922176, \"bayes_factor\": 5.3129401027159083e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -8.224622793739668, \"bayes_factor\": 0.0033430420247643373, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" IS NULL OR \\\"first_name_r\\\" IS NULL\", \"label_for_charts\": \"first_name is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `first_name is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"Taylor\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22629686446829, \"u_probability\": 0.9878019291222225, \"bayes_factor\": 0.2290913368324571, \"log2_bayes_factor\": -2.126005191221481, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.37 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"Joshua\", \"value_r\": \"Taylr\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 10 year'\", \"m_probability\": 0.22767659077874, \"u_probability\": 0.30747947947947946, \"bayes_factor\": 0.7404610908154431, \"log2_bayes_factor\": -0.43350416701999833, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 10 year'` then comparison is  1.35 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1989-02-09\", \"value_r\": \"1999-02-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 0.42784548530970185, \"log2_bayes_factor\": -1.2248382277597478, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"city\", \"value_l\": \"London\", \"value_r\": \"Lonon\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"tf_city\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.00101907095234151, \"u_probability\": 0.9958535188795172, \"bayes_factor\": 0.0010233141049580423, \"log2_bayes_factor\": -9.932535238200462, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  977.22 times less likely to be a match\", \"column_name\": \"email\", \"value_l\": \"jt40o@combs.net\", \"value_r\": \"jt40@cotbs.nm\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -21.941505617941356, \"bayes_factor\": 2.482839573874897e-07, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -8.224622793739668, \"bayes_factor\": 0.0033430420247643373, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" IS NULL OR \\\"first_name_r\\\" IS NULL\", \"label_for_charts\": \"first_name is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `first_name is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"None\", \"value_r\": \"Davies\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22629686446829, \"u_probability\": 0.9878019291222225, \"bayes_factor\": 0.2290913368324571, \"log2_bayes_factor\": -2.126005191221481, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.37 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"Daves\", \"value_r\": \"Reuben\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 31557600.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 1 year'\", \"m_probability\": 0.1313648732932813, \"u_probability\": 0.033053053053053054, \"bayes_factor\": 3.9743642768015754, \"log2_bayes_factor\": 1.990724111201016, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 1 year'` then comparison is 3.97 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1986-12-21\", \"value_r\": \"1987-11-21\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 0.42784548530970185, \"log2_bayes_factor\": -1.2248382277597478, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"city\", \"value_l\": \"Swanse\", \"value_r\": \"Swansea\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"tf_city\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.00101907095234151, \"u_probability\": 0.9958535188795172, \"bayes_factor\": 0.0010233141049580423, \"log2_bayes_factor\": -9.932535238200462, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  977.22 times less likely to be a match\", \"column_name\": \"email\", \"value_l\": \"rd@lewis.com\", \"value_r\": \"idlewrs.cocm\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -19.517277339720344, \"bayes_factor\": 1.3326438120564402e-06, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 7, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -8.224622793739668, \"bayes_factor\": 0.0033430420247643373, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.21075181163122353, \"u_probability\": 0.9848839400924999, \"bayes_factor\": 0.2139864435310315, \"log2_bayes_factor\": -2.22440869298082, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.67 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"Mia\", \"value_r\": \"Jones\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22629686446829, \"u_probability\": 0.9878019291222225, \"bayes_factor\": 0.2290913368324571, \"log2_bayes_factor\": -2.126005191221481, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.37 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"Jones\", \"value_r\": \"Mia\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.03609994786816682, \"u_probability\": 0.6536676676676677, \"bayes_factor\": 0.05522676071309138, \"log2_bayes_factor\": -4.178488680149763, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  18.11 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"2031-02-20\", \"value_r\": \"2021-01-21\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 0.42784548530970185, \"log2_bayes_factor\": -1.2248382277597478, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"city\", \"value_l\": \"Ipsich\", \"value_r\": \"Ipswich\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"tf_city\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"\\\"email_l\\\" IS NULL OR \\\"email_r\\\" IS NULL\", \"label_for_charts\": \"email is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `email is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"email\", \"value_l\": \"mia.j63@martinez.biz\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -17.97836358585148, \"bayes_factor\": 3.872338264700716e-06, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 7, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -8.224622793739668, \"bayes_factor\": 0.0033430420247643373, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.49705726325538413, \"u_probability\": 0.0057935713975033705, \"bayes_factor\": 85.79462116745148, \"log2_bayes_factor\": 6.422815296711335, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 85.79 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"Grace\", \"value_r\": \"Grace\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22629686446829, \"u_probability\": 0.9878019291222225, \"bayes_factor\": 0.2290913368324571, \"log2_bayes_factor\": -2.126005191221481, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.37 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"Kik\", \"value_r\": \"Kiirk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 10 year'\", \"m_probability\": 0.22767659077874, \"u_probability\": 0.30747947947947946, \"bayes_factor\": 0.7404610908154431, \"log2_bayes_factor\": -0.43350416701999833, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 10 year'` then comparison is  1.35 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"2020-05-12\", \"value_r\": \"2011-03-17\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 0.42784548530970185, \"log2_bayes_factor\": -1.2248382277597478, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"city\", \"value_l\": \"Edinburgh\", \"value_r\": \"Edhibnurgh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.40425084595448124, \"u_probability\": 0.9448524288198547, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  2.34 times less likely to be a match\", \"column_name\": \"tf_city\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.00101907095234151, \"u_probability\": 0.9958535188795172, \"bayes_factor\": 0.0010233141049580423, \"log2_bayes_factor\": -9.932535238200462, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  977.22 times less likely to be a match\", \"column_name\": \"email\", \"value_l\": \"gk@frey-robinson.org\", \"value_r\": \"rgk@frey-robinon.org\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.518690321230022, \"bayes_factor\": 2.130142806601533e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 7, \"record_number\": 4}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.evaluation.prediction_errors_from_labels_column(\n",
    "    \"cluster\", include_false_negatives=True, include_false_positives=True\n",
    ").as_record_dict(limit=5)\n",
    "\n",
    "linker.visualisations.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
