---
date: 2024-08-27
authors:
  - erica-k
categories:
  - Bias
---

# Bias in Data Linking #2

This Splink Blog is the second installment dedicated to the topic of bias. It wraps up the work completed during the the six-month [Alan Turing Institute](https://www.turing.ac.uk) internship on '_Bias in Data Linking_', summarising the final thoughts.

<!-- more -->

## ‚è™ Recap

This blog builds upon the [previous post in this series](https://moj-analytical-services.github.io/splink/blog/2024/08/19/bias-in-data-linking.html)...

In the first few months of the internship, the focus was on exploring potential sources of bias in data linking pipelines. This highlighted the complexity of these biases and the need for a standardised approach to evaluate them. As a result, a goal was set to develop such an approach. 

To achieve this, a common performance evaluation method using clerical review was examined to see how it could be adapted for bias assessment. However, challenges arose with this method, primarily due to difficulties in using real data to detect bias in the messy linkage output.

## ‚è© Recent developments 

Building upon these challenges, it was determined that the output of a linkage pipeline (linked data) shouldn‚Äôt be used to _detect_ bias within a pipeline. Instead, it can be used to understand the _impact_ of any detected bias.

Bias detection, which needs to come before assessing its impact, should be a key part of developing any linkage pipeline. This means using a bias hypothesis to shape how the model is trained and interpreted.

This blog will explain a method for detecting bias in a data linking pipeline, broken down into 5 key steps:

![Image 1](./img/bias_investigation_steps.png)

These steps will be broken down to show how this bias detection process can be used with any data linkage pipeline...

## <u>1. Generate synthetic data</u>

This process aims to build a neutral base for identification by creating a use-case specific dataset. While the process of generating this data can vary, it's crucial to keep it controlled. Automatically generating large amounts of data without understanding the content can lead to issues similar to using real production data.

Instead of focussing on the size of the synthetic dataset, the key is ensuring each row has a clear purpose that is relevant to the hypothesis. Additionally, including records that capture potential downstream effects is useful, as they provide important context for the next steps. 

For example, if the hypothesis is that misspellings of names lead to worse linkage, and you suspect that misspellings are more common for names of certain origins, your synthetic data might look like this:

![Image 2](./img/sp_mistake_data.png)

This is a simplification, and a real generation would likely include more rows with various spelling error iterations. This data accounts for potential downstream effects by including similar names that relate to different individuals.

## <u>2. Train and investigate model</u>

The model should then be trained with real production data and settings. After training, it can be analysed specifically in relation to the hypothesis, rather than just generally. In Splink, one way to do this is by using a [match weights chart](https://moj-analytical-services.github.io/splink/charts/match_weights_chart.html):

![Image 3](./img/match_weights_chart.png)

These model parameters will be relevant to the hypothesis, and it's useful to start thinking about how they relate to the scenarios in the synthetic data. However, because linkage relies on the accumulation of these weights, it‚Äôs difficult to fully understand their impact without generating comparisons. 

## <u>3. Perform and evaluate linkage</u>

Instead of dumping the entire dataset into the model, it‚Äôs better to manually decide which records be compared. This lets you focus on the scenarios you care about, rather than sifting through every possible combination. You'll generate match probabilities for each comparison and compare them to the pipeline's thresholds to see which records link.

It‚Äôs also useful to examine each comparison to see which features impact the match probability the most. In Splink, you can use a [waterfall chart](https://moj-analytical-services.github.io/splink/charts/waterfall_chart.html) for this. This will help you identify if any weights are too predictive or not predictive enough based on your hypothesis. 

Some factor weightings might seem off for your hypothesis but be reasonable for the [overall model](#2-train-and-investigate-model). They might not be _wrong_ per se, but if they create issues in specific scenarios, they will **introduce bias into the pipeline**.

## <u>4. Bias mitigation</u>

If you detect bias in the pipeline, you'll need to decide whether or not to address it. Here's some considerations which should help you make that decision:

![Image 4](./img/bias_mitigation_flowchart.png)

If you choose to attempt a bias mitigation, **repeat steps 1-3**, incorporating the technical solution before reassessing the results to determine if it was successful. Keep in mind, this attempt may only work partially - or not at all. 

This outcome will guide your next steps...

## <u>5. Bias statement</u>

The mitigation stage could lead to three potential outcomes, each shaping a different statement about the bias in the pipeline:

1. **Bias was not detected**  
_You might disprove the hypothesis, though it's rare that there's no bias at all. Before concluding there's no bias in the pipeline, consider exploring other potential bias hypotheses._

2. **Bias was detected - it has been fully mitigated**  
_It's unlikely, but possible. If this happens, ensure the impact on overall performance and any further bias is thoroughly investigated and clearly explained._

3. **Bias was detected - it has been partially/could not be mitigated**  
_This is the most likely scenario. If mitigation is partial, clearly explain where it falls short. If there's no mitigation, work to gain a more detailed understanding of the bias._

If you conclude that bias has been detected and it can only be partially mitigated or not mitigated, this is not a failure. It's a likely outcome when you're trying to standardise a pipeline that handles thousands of different scenarios with varying impacts on results.

## üí≠ Final thoughts

This approach doesn‚Äôt aim to make statements about the _impact_ of the detected bias. In other words, detecting bias alone doesn‚Äôt allow you to draw conclusions on how the resulting linked data will look. This is because many other unrelated factors in the pipeline will interact with the isolated scenarios and affect whether records are linked or not.

Therefore, the goal here is to better understand bias. This is done by highlighting specific scenarios, examining how the model handles them, and introducing mitigations directly. This approach allows for more transparent statements about bias during the development of a linkage pipeline.

We‚Äôve created a simple demonstration of this process using Splink ‚Äî please check it out and let us know your feedback!