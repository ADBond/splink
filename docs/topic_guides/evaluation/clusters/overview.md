# Cluster Evaluation

Graphs provide a natural way to think about linked data (see [link to intro page] for a refresher). Visualising linked data as a graph and employing graph metrics are powerful ways to evaluate linkage quality.

Graph metrics help to give a big-picture view of the clusters generated by a Splink model. Through metric distributions and statistics, we can gauge the quality of clusters and monitor how adjustments to models impact results.
<!-- Insights gained can be used to refine linking strategies, leading to more accurate predictions. -->

Graph metrics can also help us home in on problematic clusters, such as those containing inaccurate links (false positives). spot-checking can be performed with Splinkâ€™s [Cluster Studio Dashboard]() which enables users to visualise individual clusters and interrogate the links between their member records.

<!-- For example, the distribution of cluster sizes can reveal outliers, such as very large clusters, that may require closer examination. -->
<!-- For example, the 'is bridge' metric (see below/name of section) can be a signaller of false positives.  -->

## Evaluating cluster quality

### What is a high quality cluster?

When it comes to data linking, the highest quality clusters will be those containing all possible true matches (no false negatives) and no false matches (no false positives).

This idealised situation is rarely realised in practice, at least not across all clusters generated. Blocking rules, necessary to make computations tractable, can prevent record comparisons between some true matches ever being made, and the limitations of data and resources can place an upper bound on the level of quality that's possible to achieve. However, graph metrics can help us get closer to a satisfactory level of quality as well as monitor it going forward.

### What does high quality look like for you?

The extent of cluster evaluation efforts and what is considered 'good enough' will vary greatly with linkage use-case. You might have a labeled dataset or quality assured outputs from another model which provide a clear target for cluster quality.

Domain knowledge can also help set expectations of what is reasonable when it comes to evaluating clusters. For example, ...cluster size.

However, you also might not have a clear idea of wat good looks like which...makes it difficult to make a judgement call on quality with little or no idea...

This topic guide is intended to help users develop a better understanding of their clusters and help them wisely focus quality assurance efforts, regardless of how much prior knowledge they have about what qualifies quality...
And in that way can create an expectation/baseline of what good looks like.

<hr>
<br>

# Linked data as graphs <-- to go somewhere upstream

For clarity, let us first define what we mean by a graph. A graph is a collection of points (nodes) connected by lines (edges).

[Include picture here]

In data linking, we refer to these collections of nodes as clusters, within which the nodes represent the entity to be linked (e.g. person or journey) and the edges represent a potential match.

[Include picture here]

Edges come with an associate Splink score (the probability of two records being a match). This makes graphs (clusters) produced by Splink so called weighted graphs, as each edge has a weight (Splink score).

Graphs can also be directed or undirected. Directed (undirected) graphs are those in which edges (do not) have an associated direction. For example, ...

[insert image]

[Impact of directed versus non-directed on the definitions below...]
[Are there any differences between our definitions and those in the literature?]

Other properties of graphs such as self-loops and multi-edges are not be present in clusters produced with Splink.
