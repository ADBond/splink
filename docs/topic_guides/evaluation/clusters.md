# Cluster Evaluation

Graphs provide a natural way to think about linked data [link to intro page for a refresher]. Visualising linked data as a graph and employing graph metrics are powerful ways to evaluate linkage quality. Insights gained can be used to refine linking strategies, resulting in more accurate predictions.

Graph metrics can help determine a big-picture view of the quality of clusters generated by a Splink model. For example, the distribution of cluster sizes can reveal outliers, such as very large clusters, that may require closer examination.

Metrics can also help us to home in on problematic clusters, such as those containing inaccurate links. For example, the 'is bridge' metric (see below) can be a signaller of false positives. 

Splink’s [Cluster Studio Dashboard]() empowers users to visualise individual clusters and interrogate the links between their member records, as well as view graph metrics of individual clusters.

## Evaluating cluster quality

What is a high quality cluster?
When it comes to data linking, the highest quality clusters will be those containing all possible true matches and no false matches (no false positives).
This idealised situation is often not realised in practice, at least not across all clusters (for instance, blocking rules necessary to make computations tractable can prevent record comparisons between some true matches ever being made).
However, graph metrics can help us get closer to a satisfactory level of quality and monitor it going forward.

What does high quality look like for your clusters?
It can be hard to know what good quality looks like for you.
In the rare circumstances that access to labelled data to give an idea of what good looks like and a benchmark that we can iterate towards. However often not the case.
Having experience with linking similar datasets which have undergone quality assurance via clerical review or or having SME knowledge of datasets can also help set expectations...
However in a lot of cases, no prior knowledge.
How much variation from this you can tolerate, and in which direction, will depend on use case. - this will inform when you stop iterating

This means that cluster evaluation is often an iterative process. An understanding is developed... in which we develop an understanding/buildup an intuition of what good looks like for our linkage by using graph metrics to guide our QA efforts. Lessons learnt, affirmative or negative, then fed back and update. Use metrics to get traction

Even then, graph metrics are not a one stop shop when it comes to cluster evaluation.
It is important to bear in mind that whilst graph metrics can be very useful for assessing linkage quality, they are rarely definitive, especially when taken in isolation. A more comprehensive picture can be built by considering various metrics in conjunction with one another.

It is also important to consider metrics within the context of their distribution and the underlying dataset. For example: a cluster density (see below) of 0.4 might seem low but could actually be above average for the dataset in question; a cluster of size 80 might be suspiciously large for one dataset but not for another.

## Linked data as graphs <-- to go somewhere upstream

For clarity, let us first define what we mean by a graph. A graph is a collection of points (nodes) connected by lines (edges).

[Include picture here]

In data linking, we refer to these collections of nodes as clusters, within which the nodes represent the entity to be linked (e.g. person or journey) and the edges represent a potential match.

[Include picture here]

Edges come with an associate Splink score (the probability of two records being a match). This makes graphs (clusters) produced by Splink so called weighted graphs, as each edge has a weight (Splink score).

Graphs can also be directed or undirected. Directed (undirected) graphs are those in which edges (do not) have an associated direction. For example, ...

[insert image]

[Impact of directed versus non-directed on the definitions below...]
[Are there any differences between our definitions and those in the literature?]

Other properties of graphs such as self-loops and multi-edges are not be present in clusters produced with Splink.

## Graph metrics

Graph metrics quantify the characteristics of a graph (a cluster). A simple example of a graph metric is cluster size, which is the number of nodes in a cluster.

For data linking with Splink, it is useful to sort graph metrics into three categories:
- cluster metrics, 
- node metrics, and 
- edge metrics

Each of these are defined below together with examples and how they can be applied to linked data to evaluate cluster quality. The examples given are of all metrics currently available in Splink.

### :fontawesome-solid-circle-nodes: Cluster metrics

Cluster metrics refer to the characteristics of a cluster as a whole, rather than the individual nodes and edges it contains.

#### Example: cluster size

Cluster size is defined as the number of nodes within a cluster.

When thinking about cluster size, one important thing to consider is the size of the biggest clusters produced and to ask - does this seem reasonable for the dataset being linked? For example, does it make sense that one person is appearing hundreds of times in the data resulting in a cluster of size 100+ nodes? If the answer is no, then false positives links are probably being formed. This could be due to having blocking rules which are too loose or the clustering threshold which is too low.

If you don't have prior knowledge of what seems reasonable, then it is worth inspecting a sample of the largest clusters in Splink Cluster Studio to validate or invalidate links[link to guidance]. From there you can develop an understanding of what maximum cluster size to expect.

There also might be an expected cutoff on minimum cluster size. For example, when linking two datasets in which you know people appear least once in each, the minimum expected size of cluster will be 2. Clusters smaller than the minimum size indicate links have been missed. This could be due to blocking rules not letting through comparisons on true matches.

Lisewise, the modal cluster size...


#### Example: cluster density

The density of a cluster is given by the number of edges it contains divided by the maximum possible number of edges. Density ranges from 0 to 1. A density of 1 means that all nodes are connected to all other nodes in a cluster.

[picture: edges vs max possible edges]

When evaluating clusters, a high density (close to 1) is generally considered good as it means there are many edges in support of the records in a cluster being linked.

A low density could indicate links being missed. This could happen for example if blocking rules are too tight or the clustering threshold is too high.
A sample of low density clusters can be inspected in Splink Cluster Studio by choosing [inser option here]. Ask yourself the question: why aren't more links being formed between records?

It is important to consider cluster density within the context of cluster size. Bigger clusters can have a greater range of densities than smaller ones
This is why `sampling_method = "lowest_density_clusters_by_size"` performs a stratified sample...]

[Explain the relationship between density and cluster size and it's consequences. Stratified sampling in cluster studio.]

#### Example: cluster centralisation

[TBC]

### ⚫️ Node metrics

Node metrics quantify the properties of the nodes within clusters.

#### Example: node degree

A node degree is the number of edges (links) connected to a node.

within clusters or across clusters?

High node degree also places more pressure on a node to be a legitimate member of a cluster as its removal could dramatically change the cluster’s structure. Therefore... 

Low node degree

[TBC]

### 🔗 Edge metrics

Edge metrics quantify the properties of edges within a cluster. 

#### Example: 'is bridge'

An edge is classified as a bridge if its removal splits a cluster into two smaller clusters.

[insert picture]

Bridges can be signalers of false positives in linked data, especially when joining two highly connected clusters. Examining bridges can shed light on potential errors in the linking process leading to false positive links.

## How to compute graph metrics with Splink

To enable users to calculate a variety of graph metrics for their linked data, Splink provides the `compute_graph_metrics()` method.

Code snippets and outputs

## How to Splink Cluster Studio

